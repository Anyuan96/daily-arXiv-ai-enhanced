<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [FOLK: Fast Open-Vocabulary 3D Instance Segmentation via Label-guided Knowledge Distillation](https://arxiv.org/abs/2510.08849)
*Hongrui Wu,Zhicheng Gao,Jin Cao,Kelu Yao,Wen Shen,Zhihua Wei*

Main category: cs.CV

TL;DR: 提出了一种名为FOLK的快速开放词汇3D实例分割方法，通过标签引导的知识蒸馏，实现高效准确的3D实例分类。


<details>
  <summary>Details</summary>
Motivation: 现有方法将3D实例映射到2D图像进行分类，存在遮挡噪声和高计算开销，推理速度慢，限制了开放词汇3D实例分割的效率与实用性。

Method: 设计一个教师模型生成高质量的2D CLIP实例嵌入（考虑可视性和视角多样性），并通过标签引导的知识蒸馏方法，将开放词汇知识迁移到直接处理3D点云的3D学生模型。

Result: 在ScanNet200和Replica数据集上验证了方法有效性，FOLK在ScanNet200上达到35.7的AP50分数，为当前最优，且推理速度比现有方法快6.0至152.2倍。

Conclusion: FOLK通过知识蒸馏避免了2D映射带来的噪声和计算负担，实现了快速、准确的开放词汇3D实例分割，显著提升了推理效率。

Abstract: Open-vocabulary 3D instance segmentation seeks to segment and classify
instances beyond the annotated label space. Existing methods typically map 3D
instances to 2D RGB-D images, and then employ vision-language models (VLMs) for
classification. However, such a mapping strategy usually introduces noise from
2D occlusions and incurs substantial computational and memory costs during
inference, slowing down the inference speed. To address the above problems, we
propose a Fast Open-vocabulary 3D instance segmentation method via Label-guided
Knowledge distillation (FOLK). Our core idea is to design a teacher model that
extracts high-quality instance embeddings and distills its open-vocabulary
knowledge into a 3D student model. In this way, during inference, the distilled
3D model can directly classify instances from the 3D point cloud, avoiding
noise caused by occlusions and significantly accelerating the inference
process. Specifically, we first design a teacher model to generate a 2D CLIP
embedding for each 3D instance, incorporating both visibility and viewpoint
diversity, which serves as the learning target for distillation. We then
develop a 3D student model that directly produces a 3D embedding for each 3D
instance. During training, we propose a label-guided distillation algorithm to
distill open-vocabulary knowledge from label-consistent 2D embeddings into the
student model. FOLK conducted experiments on the ScanNet200 and Replica
datasets, achieving state-of-the-art performance on the ScanNet200 dataset with
an AP50 score of 35.7, while running approximately 6.0x to 152.2x faster than
previous methods. All codes will be released after the paper is accepted.

</details>

<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 123]
- [cs.CL](#cs.CL) [Total: 60]
- [cs.SD](#cs.SD) [Total: 13]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [PolypSeg-GradCAM: Towards Explainable Computer-Aided Gastrointestinal Disease Detection Using U-Net Based Segmentation and Grad-CAM Visualization on the Kvasir Dataset](https://arxiv.org/abs/2509.18159)
*Akwasi Asare,Ulas Bagci*

Main category: cs.CV

TL;DR: 本研究提出PolypSeg-GradCAM，一个结合U-Net和Grad-CAM的可解释深度学习框架，实现了准确且透明的息肉分割，为结直肠癌的早期预防提供了可靠的AI支持。


<details>
  <summary>Details</summary>
Motivation: 手动划定息肉是劳动密集型且容易受到观察者差异的影响，因此需要高效的自动化分析方法。

Method: 采用U-Net结构与Grad-CAM进行透明的息肉分割。

Result: 在Kvasir-SEG数据集上训练和评估后，该模型在测试集上获得了0.9257的平均交并比（IoU），在训练和验证集上保持了高的Dice系数（F-score > 0.96）。

Conclusion: PolypSeg-GradCAM通过结合高分割精度与可解释性，推动了可靠的AI辅助结肠镜检查，并改善了早期结直肠癌的预防。

Abstract: Colorectal cancer (CRC) remains one of the leading causes of cancer-related
morbidity and mortality worldwide, with gastrointestinal (GI) polyps serving as
critical precursors according to the World Health Organization (WHO). Early and
accurate segmentation of polyps during colonoscopy is essential for reducing
CRC progression, yet manual delineation is labor-intensive and prone to
observer variability. Deep learning methods have demonstrated strong potential
for automated polyp analysis, but their limited interpretability remains a
barrier to clinical adoption. In this study, we present PolypSeg-GradCAM, an
explainable deep learning framework that integrates the U-Net architecture with
Gradient-weighted Class Activation Mapping (Grad-CAM) for transparent polyp
segmentation. The model was trained and evaluated on the Kvasir-SEG dataset of
1000 annotated endoscopic images. Experimental results demonstrate robust
segmentation performance, achieving a mean Intersection over Union (IoU) of
0.9257 on the test set and consistently high Dice coefficients (F-score > 0.96)
on training and validation sets. Grad-CAM visualizations further confirmed that
predictions were guided by clinically relevant regions, enhancing transparency
and trust in the model's decisions. By coupling high segmentation accuracy with
interpretability, PolypSeg-GradCAM represents a step toward reliable,
trustworthy AI-assisted colonoscopy and improved early colorectal cancer
prevention.

</details>


### [2] [PerceptronCARE: A Deep Learning-Based Intelligent Teleopthalmology Application for Diabetic Retinopathy Diagnosis](https://arxiv.org/abs/2509.18160)
*Akwasi Asare,Isaac Baffour Senkyire,Emmanuel Freeman,Simon Hilary Ayinedenaba Aluze-Ele,Kelvin Kwao*

Main category: cs.CV

TL;DR: 本研究开发了PerceptronCARE，一种基于深度学习的远程医疗应用，用于自动化糖尿病视网膜病变检测，提供了85.4%的分类准确率，有助于早期诊断和改善医生与患者的互动，降低医疗成本。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变是成年人视觉丧失的主要原因，尤其在服务不足的地区面临重大挑战。

Method: 使用多种卷积神经网络（如ResNet-18、EfficientNet-B0和SqueezeNet）开发和评估深度学习基础的远程眼科应用。

Result: 最终模型以85.4%的准确率分类疾病严重程度，支持临床和远程医疗环境中的实时筛查。

Conclusion: 研究强调了人工智能驱动的远程医疗解决方案在扩大糖尿病视网膜病变筛查获取渠道的潜力，特别是在偏远和资源有限的环境中。

Abstract: Diabetic retinopathy is a leading cause of vision loss among adults and a
major global health challenge, particularly in underserved regions. This study
presents PerceptronCARE, a deep learning-based teleophthalmology application
designed for automated diabetic retinopathy detection using retinal images. The
system was developed and evaluated using multiple convolutional neural
networks, including ResNet-18, EfficientNet-B0, and SqueezeNet, to determine
the optimal balance between accuracy and computational efficiency. The final
model classifies disease severity with an accuracy of 85.4%, enabling real-time
screening in clinical and telemedicine settings. PerceptronCARE integrates
cloud-based scalability, secure patient data management, and a multi-user
framework, facilitating early diagnosis, improving doctor-patient interactions,
and reducing healthcare costs. This study highlights the potential of AI-driven
telemedicine solutions in expanding access to diabetic retinopathy screening,
particularly in remote and resource-constrained environments.

</details>


### [3] [Self Identity Mapping](https://arxiv.org/abs/2509.18165)
*Xiuding Cai,Yaoyao Zhu,Linjie Fu,Dong Miao,Yu Yao*

Main category: cs.CV

TL;DR: 提出了一种新的数据内在正则化框架$ho$SIM，能够提升深度学习模型在多种任务中的表现，且可以与现有方法结合使用。


<details>
  <summary>Details</summary>
Motivation: 正则化在深度学习中至关重要，但传统技术常依赖启发式方法，导致在不同设置下效果不一致。

Method: 提出了自我身份映射（Self Identity Mapping, SIM）框架，通过逆映射机制进行正则化，降低信息损失，促进梯度流动，同时提出了$ho$SIM以降低计算复杂度。

Result: 在图像分类、少样本学习和领域泛化等任务上，$ho$SIM在基线方法之上表现出一致的提升，并且有效地保留语义信息。

Conclusion: $ho$SIM能有效提升多种任务中的表示学习能力，并且与现有的正则化方法互补。

Abstract: Regularization is essential in deep learning to enhance generalization and
mitigate overfitting. However, conventional techniques often rely on
heuristics, making them less reliable or effective across diverse settings. We
propose Self Identity Mapping (SIM), a simple yet effective, data-intrinsic
regularization framework that leverages an inverse mapping mechanism to enhance
representation learning. By reconstructing the input from its transformed
output, SIM reduces information loss during forward propagation and facilitates
smoother gradient flow. To address computational inefficiencies, We instantiate
SIM as $ \rho\text{SIM} $ by incorporating patch-level feature sampling and
projection-based method to reconstruct latent features, effectively lowering
complexity. As a model-agnostic, task-agnostic regularizer, SIM can be
seamlessly integrated as a plug-and-play module, making it applicable to
different network architectures and tasks.
  We extensively evaluate $\rho\text{SIM}$ across three tasks: image
classification, few-shot prompt learning, and domain generalization.
Experimental results show consistent improvements over baseline methods,
highlighting $\rho\text{SIM}$'s ability to enhance representation learning
across various tasks. We also demonstrate that $\rho\text{SIM}$ is orthogonal
to existing regularization methods, boosting their effectiveness. Moreover, our
results confirm that $\rho\text{SIM}$ effectively preserves semantic
information and enhances performance in dense-to-dense tasks, such as semantic
segmentation and image translation, as well as in non-visual domains including
audio classification and time series anomaly detection. The code is publicly
available at https://github.com/XiudingCai/SIM-pytorch.

</details>


### [4] [MAGIA: Sensing Per-Image Signals from Single-Round Averaged Gradients for Label-Inference-Free Gradient Inversion](https://arxiv.org/abs/2509.18170)
*Zhanting Zhou,Jinbo Wang,Zeqin Wu,Fengli Zhang*

Main category: cs.CV

TL;DR: 本文研究了单轮平均梯度下的梯度反演问题，提出了MAGIA，一个基于动量的自适应校正框架，能够在大批量场景下实现高保真的多图像重建。


<details>
  <summary>Details</summary>
Motivation: 研究在挑战性的单轮平均梯度SAG环境中的梯度反演问题，尤其是样本线索在单个批次均值梯度中交织的情况。

Method: 引入MAGIA，一个基于动量的自适应校正框架，针对梯度反演攻击，使用随机数据子集探测潜在的每张图像信号。

Result: 通过广泛的实验，MAGIA在大批量情况下远超前期工作，提供了具竞争力的计算成本，与标准求解器相当，且无需任何辅助信息。

Conclusion: MAGIA显著优于现有先进方法，在大批量场景下实现高保真度的多图像重建。

Abstract: We study gradient inversion in the challenging single round averaged gradient
SAG regime where per sample cues are entangled within a single batch mean
gradient. We introduce MAGIA a momentum based adaptive correction on gradient
inversion attack a novel label inference free framework that senses latent per
image signals by probing random data subsets. MAGIA objective integrates two
core innovations 1 a closed form combinatorial rescaling that creates a
provably tighter optimization bound and 2 a momentum based mixing of whole
batch and subset losses to ensure reconstruction robustness. Extensive
experiments demonstrate that MAGIA significantly outperforms advanced methods
achieving high fidelity multi image reconstruction in large batch scenarios
where prior works fail. This is all accomplished with a computational footprint
comparable to standard solvers and without requiring any auxiliary information.

</details>


### [5] [Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR](https://arxiv.org/abs/2509.18174)
*Khalil Hennara,Muhammad Hreden,Mohamed Motasim Hamed,Ahmad Bastati,Zeina Aldallal,Sara Chrouf,Safwan AlModhayan*

Main category: cs.CV

TL;DR: 本研究提出了Baseer，一个针对阿拉伯文档OCR的视觉语言模型，通过特定领域的适配和大规模数据集训练，实现了新的性能标准。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯文档OCR由于其书写特点和多样的字体面临挑战，现有的多模态大型语言模型在这一领域的应用效果有限，因此需要特定的解决方案。

Method: 使用解码器微调策略对预训练的多模态大型语言模型（MLLM）进行调整，结合了合成和真实文档的大规模数据集。

Result: Baseer模型显著优于现有的开源和商业解决方案，取得了0.25的词错误率（WER），在阿拉伯文档OCR领域建立了新的标准。

Conclusion: Baseer在阿拉伯文档OCR领域实现了新的最先进水平，表现出较大的优势，表明领域特定适配的重要性。

Abstract: Arabic document OCR remains a challenging task due to the language's cursive
script, diverse fonts, diacritics, and right-to-left orientation. While modern
Multimodal Large Language Models (MLLMs) have advanced document understanding
for high-resource languages, their performance on Arabic remains limited. In
this work, we introduce Baseer, a vision-language model fine- tuned
specifically for Arabic document OCR. Leveraging a large-scale dataset
combining synthetic and real-world documents, Baseer is trained using a
decoder-only fine-tuning strategy to adapt a pre-trained MLLM while preserving
general visual features. We also present Misraj-DocOCR, a high-quality,
expert-verified benchmark designed for rigorous evaluation of Arabic OCR
systems. Our experiments show that Baseer significantly outperforms existing
open-source and commercial solutions, achieving a WER of 0.25 and establishing
a new state-of-the-art in the domain of Arabic document OCR. Our results
highlight the benefits of domain-specific adaptation of general-purpose MLLMs
and establish a strong baseline for high-accuracy OCR on morphologically rich
languages like Arabic.

</details>


### [6] [A Deep Learning Approach for Spatio-Temporal Forecasting of InSAR Ground Deformation in Eastern Ireland](https://arxiv.org/abs/2509.18176)
*Wendong Yao,Saeed Azadnejad,Binhua Huang,Shane Donohue,Soumyabrata Dev*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的深度学习框架，通过将稀疏的InSAR数据转换为密集的时空张量，首次实现了先进计算机视觉架构在地面变形预测中的直接应用，并通过CNN-LSTM模型提高了预测的准确性和空间一致性。


<details>
  <summary>Details</summary>
Motivation: 监测地面位移对城市基础设施稳定性和减轻地质灾害至关重要，但从稀疏的干涉合成孔径雷达（InSAR）时间序列数据中预测未来变形仍然是一个挑战。

Method: 设计并实施混合卷积神经网络和长短期记忆（CNN-LSTM）模型，以同时学习生成的数据张量中的空间模式和时间依赖性。

Result: 实验结果表明，提出的架构在准确性和空间一致性上显著优于主要的机器学习基线模型，确立了这一任务的新性能基准。同时，解释性分析表明，基线模型通常依赖于简单的持续性模式，强调了我们时空综合方法的必要性。

Conclusion: 本研究表明，结合时空深度学习的方法在高分辨率变形预测中非常有效，超越了传统模型的表现。

Abstract: Monitoring ground displacement is crucial for urban infrastructure stability
and mitigating geological hazards. However, forecasting future deformation from
sparse Interferometric Synthetic Aperture Radar (InSAR) time-series data
remains a significant challenge. This paper introduces a novel deep learning
framework that transforms these sparse point measurements into a dense
spatio-temporal tensor. This methodological shift allows, for the first time,
the direct application of advanced computer vision architectures to this
forecasting problem. We design and implement a hybrid Convolutional Neural
Network and Long-Short Term Memory (CNN-LSTM) model, specifically engineered to
simultaneously learn spatial patterns and temporal dependencies from the
generated data tensor. The model's performance is benchmarked against powerful
machine learning baselines, Light Gradient Boosting Machine and LASSO
regression, using Sentinel-1 data from eastern Ireland. Results demonstrate
that the proposed architecture provides significantly more accurate and
spatially coherent forecasts, establishing a new performance benchmark for this
task. Furthermore, an interpretability analysis reveals that baseline models
often default to simplistic persistence patterns, highlighting the necessity of
our integrated spatio-temporal approach to capture the complex dynamics of
ground deformation. Our findings confirm the efficacy and potential of
spatio-temporal deep learning for high-resolution deformation forecasting.

</details>


### [7] [A Framework for Generating Artificial Datasets to Validate Absolute and Relative Position Concepts](https://arxiv.org/abs/2509.18177)
*George Corrêa de Araújo,Helena de Almeida Maia,Helio Pedrini*

Main category: cs.CV

TL;DR: Scrapbook框架旨在生成丰富的数据集，以验证人工智能模型对基本概念的理解，实验表明当前模型在位置理解上存在不足，为模型性能的提升提供了机会。


<details>
  <summary>Details</summary>
Motivation: 通过生成拥有丰富语言变体的问题数据集，Scrapbook框架旨在在处理更复杂任务之前，检验人工智能模型对基础概念的掌握情况。

Method: 提出的Scrapbook框架通过生成大量有关基本概念的问题数据集，以验证模型对这些基本要素的理解。

Result: 实验结果表明，尽管现代模型在识别和列举物体方面表现良好，但在理解位置关系和处理附加约束的问题时面临挑战，特别是MobileVLM-V2模型显示出显著的答案分歧和合理的错误答案。

Conclusion: Scrapbook框架为生成多样化和全面的数据集提供了有价值的工具，可以系统地评估和提升人工智能模型的性能。

Abstract: In this paper, we present the Scrapbook framework, a novel methodology
designed to generate extensive datasets for probing the learned concepts of
artificial intelligence (AI) models. The framework focuses on fundamental
concepts such as object recognition, absolute and relative positions, and
attribute identification. By generating datasets with a large number of
questions about individual concepts and a wide linguistic variation, the
Scrapbook framework aims to validate the model's understanding of these basic
elements before tackling more complex tasks. Our experimental findings reveal
that, while contemporary models demonstrate proficiency in recognizing and
enumerating objects, they encounter challenges in comprehending positional
information and addressing inquiries with additional constraints. Specifically,
the MobileVLM-V2 model showed significant answer disagreements and plausible
wrong answers, while other models exhibited a bias toward affirmative answers
and struggled with questions involving geometric shapes and positional
information, indicating areas for improvement in understanding and consistency.
The proposed framework offers a valuable instrument for generating diverse and
comprehensive datasets, which can be utilized to systematically assess and
enhance the performance of AI models.

</details>


### [8] [The Describe-Then-Generate Bottleneck: How VLM Descriptions Alter Image Generation Outcomes](https://arxiv.org/abs/2509.18179)
*Sai Varun Kodathala,Rakesh Vunnam*

Main category: cs.CV

TL;DR: 本研究分析了描述-然后-生成过程中的信息损失，发现几乎所有样本都存在显著的感知和结构损失，揭示了该方法在多模态系统中的限制。


<details>
  <summary>Details</summary>
Motivation: 随着多模态AI系统在创意工作流程中的日益整合，理解视觉-语言-视觉管道中的信息损失变得重要。

Method: 生成150对图像，通过描述-然后-生成管道，并应用现有指标（LPIPS、SSIM和颜色距离）来测量信息保留。

Result: 99.3%的样本表现出明显的感知降解，91.5%的样本展示了显著的结构信息丢失。

Conclusion: 描述-然后-生成瓶颈在当代多模态系统中显示出可测量且一致的限制，几乎所有样本都经历了显著的感知降解和结构信息丢失。

Abstract: With the increasing integration of multimodal AI systems in creative
workflows, understanding information loss in vision-language-vision pipelines
has become important for evaluating system limitations. However, the
degradation that occurs when visual content passes through textual
intermediation remains poorly quantified. In this work, we provide empirical
analysis of the describe-then-generate bottleneck, where natural language
serves as an intermediate representation for visual information. We generated
150 image pairs through the describe-then-generate pipeline and applied
existing metrics (LPIPS, SSIM, and color distance) to measure information
preservation across perceptual, structural, and chromatic dimensions. Our
evaluation reveals that 99.3% of samples exhibit substantial perceptual
degradation and 91.5% demonstrate significant structural information loss,
providing empirical evidence that the describe-then-generate bottleneck
represents a measurable and consistent limitation in contemporary multimodal
systems.

</details>


### [9] [AI-Derived Structural Building Intelligence for Urban Resilience: An Application in Saint Vincent and the Grenadines](https://arxiv.org/abs/2509.18182)
*Isabelle Tingzon,Yoji Toriumi,Caroline Gevaert*

Main category: cs.CV

TL;DR: 本文提出了一种AI驱动的工作流程，通过高分辨率卫星图像自动推断小岛发展中国家的屋顶属性，表现出良好的分类性能，帮助实现更高效的城市治理。


<details>
  <summary>Details</summary>
Motivation: 许多气候脆弱地区的小岛发展中国家（SIDS）缺乏详细的结构建筑信息，而这些信息对于城市韧性规划和灾害风险降低至关重要，因此需要填补这一数据空白。

Method: 使用高分辨率卫星图像自动推断屋顶属性，比较地理基础模型与浅层分类器和精细调整的深度学习模型在屋顶分类中的效用，并评估追加来自邻近小岛发展中国家的训练数据对模型性能的影响。

Result: 最佳模型在屋顶坡度和屋顶材料分类中分别获得0.88和0.83的F1分数，表明AI驱动的工作流程在填补数据空白方面的有效性。

Conclusion: 我们的最佳模型在屋顶坡度和屋顶材料分类中分别达到了0.88和0.83的F1分数，结合地方能力建设，旨在为小岛发展中国家提供利用人工智能和地球观测数据的能力，以实现更高效、基于证据的城市治理。

Abstract: Detailed structural building information is used to estimate potential damage
from hazard events like cyclones, floods, and landslides, making them critical
for urban resilience planning and disaster risk reduction. However, such
information is often unavailable in many small island developing states (SIDS)
in climate-vulnerable regions like the Caribbean. To address this data gap, we
present an AI-driven workflow to automatically infer rooftop attributes from
high-resolution satellite imagery, with Saint Vincent and the Grenadines as our
case study. Here, we compare the utility of geospatial foundation models
combined with shallow classifiers against fine-tuned deep learning models for
rooftop classification. Furthermore, we assess the impact of incorporating
additional training data from neighboring SIDS to improve model performance.
Our best models achieve F1 scores of 0.88 and 0.83 for roof pitch and roof
material classification, respectively. Combined with local capacity building,
our work aims to provide SIDS with novel capabilities to harness AI and Earth
Observation (EO) data to enable more efficient, evidence-based urban
governance.

</details>


### [10] [VLA-LPAF: Lightweight Perspective-Adaptive Fusion for Vision-Language-Action to Enable More Unconstrained Robotic Manipulation](https://arxiv.org/abs/2509.18183)
*Jinyue Bian,Zhaoxing Zhang,Zhengyu Liang,Shiwei Zheng,Shengtao Zhang,Rong Shen,Chen Yang,Anzhou Hou*

Main category: cs.CV

TL;DR: VLA模型存在视角异质性问题，提出VLA-LPAF模块提升视角适应性，实验证明其在多项任务上的成功率显著提高。


<details>
  <summary>Details</summary>
Motivation: 由于第三方全局和腕部局部摄像头捕获的视觉观察在不同环境中数量和视角不一致，导致VLA模型的视觉特征存在显著差异，从而限制其通用性。

Method: 引入轻量级模块VLA-LPAF，通过对2D数据进行微调，融合多视角观察，改善了VLA模型的视角适应性。

Result: RoboFlamingo-LPAF在CALVIN上平均提高了约8%的任务成功率，在LIBERO上提高了15%，在定制的仿真基准上提高了30%。

Conclusion: RoboFlamingo-LPAF通过适应不同视角的数据显著提升了任务成功率。

Abstract: The Visual-Language-Action (VLA) models can follow text instructions
according to visual observations of the surrounding environment. This ability
to map multimodal inputs to actions is derived from the training of the VLA
model on extensive standard demonstrations. These visual observations captured
by third-personal global and in-wrist local cameras are inevitably varied in
number and perspective across different environments, resulting in significant
differences in the visual features. This perspective heterogeneity constrains
the generality of VLA models. In light of this, we first propose the
lightweight module VLA-LPAF to foster the perspective adaptivity of VLA models
using only 2D data. VLA-LPAF is finetuned using images from a single view and
fuses other multiview observations in the latent space, which effectively and
efficiently bridge the gap caused by perspective inconsistency. We instantiate
our VLA-LPAF framework with the VLA model RoboFlamingo to construct
RoboFlamingo-LPAF. Experiments show that RoboFlamingo-LPAF averagely achieves
around 8% task success rate improvement on CALVIN, 15% on LIBERO, and 30% on a
customized simulation benchmark. We also demonstrate the developed viewadaptive
characteristics of the proposed RoboFlamingo-LPAF through real-world tasks.

</details>


### [11] [URNet: Uncertainty-aware Refinement Network for Event-based Stereo Depth Estimation](https://arxiv.org/abs/2509.18184)
*Yifeng Cheng,Alois Knoll,Hu Cao*

Main category: cs.CV

TL;DR: URNet是一种针对事件基础立体深度估计的网络，具有高级的细化模块和不确定性建模，表现超越现有最优方法。


<details>
  <summary>Details</summary>
Motivation: 事件相机提供高时间分辨率，高动态范围和低延迟，具有相较于传统帧摄像机显著的优势。

Method: 引入不确定性感知的细化网络URNet，包括局部-全局细化模块和基于KL散度的不确定性建模方法。

Result: 在DSEC数据集上的广泛实验表明，URNet在定性和定量评估中均优于最先进的方法。

Conclusion: URNet在事件基础立体深度估计中表现优异，超越了现有最先进方法，具有很高的可靠性。

Abstract: Event cameras provide high temporal resolution, high dynamic range, and low
latency, offering significant advantages over conventional frame-based cameras.
In this work, we introduce an uncertainty-aware refinement network called URNet
for event-based stereo depth estimation. Our approach features a local-global
refinement module that effectively captures fine-grained local details and
long-range global context. Additionally, we introduce a Kullback-Leibler (KL)
divergence-based uncertainty modeling method to enhance prediction reliability.
Extensive experiments on the DSEC dataset demonstrate that URNet consistently
outperforms state-of-the-art (SOTA) methods in both qualitative and
quantitative evaluations.

</details>


### [12] [Visionerves: Automatic and Reproducible Hybrid AI for Peripheral Nervous System Recognition Applied to Endometriosis Cases](https://arxiv.org/abs/2509.18185)
*Giammarco La Barbera,Enzo Bonnot,Thomas Isla,Juan Pablo de la Plata,Joy-Rose Dunoyer de Segonzac,Jennifer Attali,Cécile Lozach,Alexandre Bellucci,Louis Marcellin,Laure Fournier,Sabine Sarnacki,Pietro Gori,Isabelle Bloch*

Main category: cs.CV

TL;DR: Visionerves 是一种新颖的 AI 框架，通过深度学习和空间推理，显著提高了内膜异位症相关神经的识别精度，开启了非侵入性诊断的新路径。


<details>
  <summary>Details</summary>
Motivation: 由于内膜异位症常导致慢性盆腔疼痛和神经受累，现有的神经影像学方法面临挑战，因此需要一种新颖的解决方案。

Method: Visionerves 通过结合多梯度 DWI 和形态 MRI 数据，采用深度学习和符号空间推理，进行神经识别。

Result: 在 10 名患有（确诊或疑似）内膜异位症的女性中，Visionerves 在神经识别方面显示出比传统轨迹绘制更显著的改进，包括 Dice 分数提高高达 25%，空间误差减少到 5 mm 以下。

Conclusion: Visionerves 作为一种创新的 AI 框架，为外周神经系统识别提供了非侵入性的解决方案，有效改善了神经分析的精确度。

Abstract: Endometriosis often leads to chronic pelvic pain and possible nerve
involvement, yet imaging the peripheral nerves remains a challenge. We
introduce Visionerves, a novel hybrid AI framework for peripheral nervous
system recognition from multi-gradient DWI and morphological MRI data. Unlike
conventional tractography, Visionerves encodes anatomical knowledge through
fuzzy spatial relationships, removing the need for selection of manual ROIs.
The pipeline comprises two phases: (A) automatic segmentation of anatomical
structures using a deep learning model, and (B) tractography and nerve
recognition by symbolic spatial reasoning. Applied to the lumbosacral plexus in
10 women with (confirmed or suspected) endometriosis, Visionerves demonstrated
substantial improvements over standard tractography, with Dice score
improvements of up to 25% and spatial errors reduced to less than 5 mm. This
automatic and reproducible approach enables detailed nerve analysis and paves
the way for non-invasive diagnosis of endometriosis-related neuropathy, as well
as other conditions with nerve involvement.

</details>


### [13] [V-SenseDrive: A Privacy-Preserving Road Video and In-Vehicle Sensor Fusion Framework for Road Safety & Driver Behaviour Modelling](https://arxiv.org/abs/2509.18187)
*Muhammad Naveed,Nazia Perwaiz,Sidra Sultana,Mohaira Ahmad,Muhammad Moazam Fraz*

Main category: cs.CV

TL;DR: V-SenseDrive是首个隐私保护的多模态驾驶行为数据集，收集于巴基斯坦，以支持道路安全和驾驶行为分析。


<details>
  <summary>Details</summary>
Motivation: 在巴基斯坦这样的新兴经济体中，交通事故的高发和现有数据集对行为多样性的有限代表性激发了研发具有隐私保护的驾驶行为数据集的需求。

Method: 使用定制Android应用收集手机基于惯性和GPS传感器数据，并与同步的道路视频相结合，以记录三种目标驾驶行为。

Result: V-SenseDrive是首个完全基于巴基斯坦驾驶环境收集的隐私保护多模态驾驶行为数据集，涵盖正常、激进和危险的驾驶行为，确保未来相关研究的适应性。

Conclusion: V-SenseDrive填补了全球驾驶行为数据集的空白，为基于上下文的智能交通解决方案奠定了基础。

Abstract: Road traffic accidents remain a major public health challenge, particularly
in countries with heterogeneous road conditions, mixed traffic flow, and
variable driving discipline, such as Pakistan. Reliable detection of unsafe
driving behaviours is a prerequisite for improving road safety, enabling
advanced driver assistance systems (ADAS), and supporting data driven decisions
in insurance and fleet management. Most of existing datasets originate from the
developed countries with limited representation of the behavioural diversity
observed in emerging economies and the driver's face recording voilates the
privacy preservation. We present V-SenseDrive, the first privacy-preserving
multimodal driver behaviour dataset collected entirely within the Pakistani
driving environment. V-SenseDrive combines smartphone based inertial and GPS
sensor data with synchronized road facing video to record three target driving
behaviours (normal, aggressive, and risky) on multiple types of roads,
including urban arterials, secondary roads, and motorways. Data was gathered
using a custom Android application designed to capture high frequency
accelerometer, gyroscope, and GPS streams alongside continuous video, with all
sources precisely time aligned to enable multimodal analysis. The focus of this
work is on the data acquisition process, covering participant selection,
driving scenarios, environmental considerations, and sensor video
synchronization techniques. The dataset is structured into raw, processed, and
semantic layers, ensuring adaptability for future research in driver behaviour
classification, traffic safety analysis, and ADAS development. By representing
real world driving in Pakistan, V-SenseDrive fills a critical gap in the global
landscape of driver behaviour datasets and lays the groundwork for context
aware intelligent transportation solutions.

</details>


### [14] [Qianfan-VL: Domain-Enhanced Universal Vision-Language Models](https://arxiv.org/abs/2509.18189)
*Daxiang Dong,Mingming Zheng,Dong Xu,Bairong Zhuang,Wenyu Zhang,Chunhua Luo,Haoran Wang,Zijian Zhao,Jie Li,Yuxuan Li,Hanjun Zhong,Mengyue Liu,Jieting Chen,Shupeng Li,Lun Tian,Yaping Feng,Xin Li,Donggang Jiang,Yong Chen,Yehua Xu,Duohao Qin,Chen Feng,Dan Wang,Henghua Zhang,Jingjing Ha,Jinhui He,Yanfeng Zhai,Chengxin Zheng,Jiayi Mao,Jiacheng Chen,Ruchang Yao,Ziye Yuan,Jianmin Wu,Guangjun Xie,Dou Shen*

Main category: cs.CV

TL;DR: Qianfan-VL是一系列新的多模态大型语言模型，通过域增强技术实现了在多个基准上的最佳性能，适用于企业部署。


<details>
  <summary>Details</summary>
Motivation: 旨在提升大型语言模型在特定领域的能力，提高其在多模态任务中的表现，尤其是在文档理解和数学推理方面。

Method: 采用多阶段渐进训练和高精度数据合成流程，聚焦于增强特定领域能力，同时保持强大的通用性能。

Result: 在各类基准测试中表现优异，特别是在OCRBench和DocVQA等公共基准上取得显著优势，同时在数学推理和逻辑推理任务上表现卓越。

Conclusion: Qianfan-VL系列模型通过创新的领域增强技术在多模态学习领域取得了领先的性能，尤其在OCR和文档理解方面表现卓越，适合多种企业场景的应用。

Abstract: We present Qianfan-VL, a series of multimodal large language models ranging
from 3B to 70B parameters, achieving state-of-the-art performance through
innovative domain enhancement techniques. Our approach employs multi-stage
progressive training and high-precision data synthesis pipelines, which prove
to be critical technologies for enhancing domain-specific capabilities while
maintaining strong general performance. Qianfan-VL achieves comparable results
to leading open-source models on general benchmarks, with state-of-the-art
performance on benchmarks such as CCBench, SEEDBench IMG, ScienceQA, and
MMStar. The domain enhancement strategy delivers significant advantages in OCR
and document understanding, validated on both public benchmarks (OCRBench 873,
DocVQA 94.75%) and in-house evaluations. Notably, Qianfan-VL-8B and 70B
variants incorporate long chain-of-thought capabilities, demonstrating superior
performance on mathematical reasoning (MathVista 78.6%) and logical inference
tasks. All models are trained entirely on Baidu's Kunlun P800 chips, validating
the capability of large-scale AI infrastructure to train SOTA-level multimodal
models with over 90% scaling efficiency on 5000 chips for a single task. This
work establishes an effective methodology for developing domain-enhanced
multimodal models suitable for diverse enterprise deployment scenarios.

</details>


### [15] [HazeFlow: Revisit Haze Physical Model as ODE and Non-Homogeneous Haze Generation for Real-World Dehazing](https://arxiv.org/abs/2509.18190)
*Junseong Shin,Seungwoo Chung,Yunjeong Yang,Tae Hyun Kim*

Main category: cs.CV

TL;DR: HazeFlow是一个基于ODE的新框架，通过物理驱动的学习方法提升真实场景的去雾效果，并使用MCBM解决真实数据对的不足问题。


<details>
  <summary>Details</summary>
Motivation: 传统的去雾方法难以处理真实世界的复杂性和多样化的雾霾模式，因此需要发展新的基于物理的学习方法。

Method: 开发了一种基于常微分方程（ODE）的框架，通过最优ODE轨迹将有雾图像映射为清晰图像。

Result: 通过引入马尔可夫链布朗运动（MCBM）生成非均匀雾霾，增加了HazeFlow对多样真实场景的适应性。

Conclusion: HazeFlow在多个真实世界去雾基准数据集上实现了最先进的性能，能够有效应对多样的真实场景。

Abstract: Dehazing involves removing haze or fog from images to restore clarity and
improve visibility by estimating atmospheric scattering effects. While deep
learning methods show promise, the lack of paired real-world training data and
the resulting domain gap hinder generalization to real-world scenarios. In this
context, physics-grounded learning becomes crucial; however, traditional
methods based on the Atmospheric Scattering Model (ASM) often fall short in
handling real-world complexities and diverse haze patterns. To solve this
problem, we propose HazeFlow, a novel ODE-based framework that reformulates ASM
as an ordinary differential equation (ODE). Inspired by Rectified Flow (RF),
HazeFlow learns an optimal ODE trajectory to map hazy images to clean ones,
enhancing real-world dehazing performance with only a single inference step.
Additionally, we introduce a non-homogeneous haze generation method using
Markov Chain Brownian Motion (MCBM) to address the scarcity of paired
real-world data. By simulating realistic haze patterns through MCBM, we enhance
the adaptability of HazeFlow to diverse real-world scenarios. Through extensive
experiments, we demonstrate that HazeFlow achieves state-of-the-art performance
across various real-world dehazing benchmark datasets.

</details>


### [16] [TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection](https://arxiv.org/abs/2509.18193)
*Omar H. Khater,Abdul Jabbar Siddiqui,Aiman El-Maleh,M. Shamim Hossain*

Main category: cs.CV

TL;DR: 该研究展示了一种压缩的EcoWeedNet模型，在资源受限的边缘设备上实现高效的深度学习应用，特别适用于精确农业。


<details>
  <summary>Details</summary>
Motivation: 由于边缘设备资源有限，在农业中部署深度学习模型存在困难。

Method: 使用结构化通道剪枝、量化感知训练(QAT)以及NVIDIA的TensorRT加速。

Result: 模型大小减少了68.5%，计算量减少了3.2 GFLOPs，推理速度达到184 FPS，比基线快28.7%。其在CottonWeedDet12数据集上的表现优于YOLO11n和YOLO12n，精确度为83.7%，召回率为77.5%，mAP50为85.9%。

Conclusion: 压缩后的EcoWeedNet在农业中的应用证明其在精确农业中高效且有效。

Abstract: Deploying deep learning models in agriculture is difficult because edge
devices have limited resources, but this work presents a compressed version of
EcoWeedNet using structured channel pruning, quantization-aware training (QAT),
and acceleration with NVIDIA's TensorRT on the Jetson Orin Nano. Despite the
challenges of pruning complex architectures with residual shortcuts, attention
mechanisms, concatenations, and CSP blocks, the model size was reduced by up to
68.5% and computations by 3.2 GFLOPs, while inference speed reached 184 FPS at
FP16, 28.7% faster than the baseline. On the CottonWeedDet12 dataset, the
pruned EcoWeedNet with a 39.5% pruning ratio outperformed YOLO11n and YOLO12n
(with only 20% pruning), achieving 83.7% precision, 77.5% recall, and 85.9%
mAP50, proving it to be both efficient and effective for precision agriculture.

</details>


### [17] [Learning Contrastive Multimodal Fusion with Improved Modality Dropout for Disease Detection and Prediction](https://arxiv.org/abs/2509.18284)
*Yi Gu,Kuniaki Saito,Jiaxin Ma*

Main category: cs.CV

TL;DR: 本文提出了一种多模态学习框架，利用模态丢失技术和对比学习应对模态不平衡和缺失，展示了良好的效果和广泛应用潜力。


<details>
  <summary>Details</summary>
Motivation: 随着医学诊断日益依赖多模态数据，亟需有效融合异构信息并对缺失模态保持鲁棒性，解决模态不平衡和缺失的问题。

Method: 通过集成增强的模态丢失技术和对比学习，引入可学习的模态标记，以改善模态的缺失感知融合，并增强传统的单模态对比目标。

Result: 在大规模临床数据集上，我们的方法在疾病检测和预测任务中达到了最先进的性能，特别是在严格和实际的场景下。

Conclusion: 本研究提出的多模态学习框架在实际挑战中表现出色，特别是在只有单一模态可用的情况下，显示出其有效性和适应性，具有广泛的临床应用潜力。

Abstract: As medical diagnoses increasingly leverage multimodal data, machine learning
models are expected to effectively fuse heterogeneous information while
remaining robust to missing modalities. In this work, we propose a novel
multimodal learning framework that integrates enhanced modalities dropout and
contrastive learning to address real-world limitations such as modality
imbalance and missingness. Our approach introduces learnable modality tokens
for improving missingness-aware fusion of modalities and augments conventional
unimodal contrastive objectives with fused multimodal representations. We
validate our framework on large-scale clinical datasets for disease detection
and prediction tasks, encompassing both visual and tabular modalities.
Experimental results demonstrate that our method achieves state-of-the-art
performance, particularly in challenging and practical scenarios where only a
single modality is available. Furthermore, we show its adaptability through
successful integration with a recent CT foundation model. Our findings
highlight the effectiveness, efficiency, and generalizability of our approach
for multimodal learning, offering a scalable, low-cost solution with
significant potential for real-world clinical applications. The code is
available at https://github.com/omron-sinicx/medical-modality-dropout.

</details>


### [18] [Rethinking Pulmonary Embolism Segmentation: A Study of Current Approaches and Challenges with an Open Weight Model](https://arxiv.org/abs/2509.18308)
*Yixin Zhang,Ryan Chamberlain,Lawrance Ngo,Kevin Kramer,Maciej A. Mazurowski*

Main category: cs.CV

TL;DR: 本研究评估了不同分割模型在PE分割任务中的表现，发现3D U-Net和CNN模型更为有效，且不同模型在同数据集上的表现具有一致性。


<details>
  <summary>Details</summary>
Motivation: 本研究动机在于评估和优化针对肺栓塞CTPA扫描的分割性能，尤其关注不同模型架构和初始化策略对分割效果的影响。

Method: 系统评估九种广泛使用的分割架构，包括CNN和ViT，将预训练和随机权重进行比较。

Result: 经过评估，3D U-Net使用ResNet编码器在PE分割中表现良好，3D模型适合处理栓塞的形态特点，而CNN模型整体优于ViT模型。

Conclusion: 本研究表明，在肺栓塞(PE)分割任务中，3D U-Net架构表现优异，并且得出了CNN与ViT模型之间的性能差异，以及不同模型在同一数据上表现的一致性。

Abstract: In this study, we curated a densely annotated in-house dataset comprising 490
CTPA scans. Using this dataset, we systematically evaluated nine widely used
segmentation architectures from both the CNN and Vision Transformer (ViT)
families, initialized with either pretrained or random weights, under a unified
testing framework as a performance audit. Our study leads to several important
observations: (1) 3D U-Net with a ResNet encoder remains a highly effective
architecture for PE segmentation; (2) 3D models are particularly well-suited to
this task given the morphological characteristics of emboli; (3) CNN-based
models generally yield superior performance compared to their ViT-based
counterparts in PE segmentation; (4) classification-based pretraining, even on
large PE datasets, can adversely impact segmentation performance compared to
training from scratch, suggesting that PE classification and segmentation may
rely on different sets of discriminative features; (5) different model
architectures show a highly consistent pattern of segmentation performance when
trained on the same data; and (6) while central and large emboli can be
segmented with satisfactory accuracy, distal emboli remain challenging due to
both task complexity and the scarcity of high-quality datasets. Besides these
findings, our best-performing model achieves a mean Dice score of 0.7131 for
segmentation. It detects 181 emboli with 49 false positives and 28 false
negatives from 60 in-house testing scans. Its generalizability is further
validated on public datasets.

</details>


### [19] [Improving Handshape Representations for Sign Language Processing: A Graph Neural Network Approach](https://arxiv.org/abs/2509.18309)
*Alessa Carbo,Eric Nalisnick*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的图神经网络模型用于手语的手型识别，显著提高了识别准确性，首次建立了结构化手型识别的基准。


<details>
  <summary>Details</summary>
Motivation: 由于手型在手语中扮演着重要的语音角色，现有的计算方法未能有效处理手型，影响了识别精度和语言分析，因此需要提供改进的方法。

Method: 采用基于图的神经网络，利用解剖学知识构建图结构，并结合对比学习分离时间动态与静态手型配置。

Result: 在37个手型类别中，我们的方法取得了46%的识别准确率，显著超越了基线方法的25%。

Conclusion: 我们的模型在手势的手型识别中实现了显著提高，打破了以往的方法限制，首次建立了结构化手型识别的基准。

Abstract: Handshapes serve a fundamental phonological role in signed languages, with
American Sign Language employing approximately 50 distinct shapes.
However,computational approaches rarely model handshapes explicitly, limiting
both recognition accuracy and linguistic analysis.We introduce a novel graph
neural network that separates temporal dynamics from static handshape
configurations. Our approach combines anatomically-informed graph structures
with contrastive learning to address key challenges in handshape recognition,
including subtle interclass distinctions and temporal variations. We establish
the first benchmark for structured handshape recognition in signing sequences,
achieving 46% accuracy across 37 handshape classes (with baseline methods
achieving 25%).

</details>


### [20] [Influence of Classification Task and Distribution Shift Type on OOD Detection in Fetal Ultrasound](https://arxiv.org/abs/2509.18326)
*Chun Kit Wong,Anders N. Christensen,Cosmin I. Bercea,Julia A. Schnabel,Martin G. Tolsgaard,Aasa Feragen*

Main category: cs.CV

TL;DR: 该研究探讨了分类任务对OUD检测性能的影响，发现不同任务对于不同的OOD样本特征有显著作用，提示医疗图像分析中任务选择和不确定性策略需进行适当对齐。


<details>
  <summary>Details</summary>
Motivation: 在异构图像特征和临床环境中，安全部署深度学习模型需要可靠的OOD检测。

Method: 通过对八种不确定性量化方法在四个分类任务中的实验来检验OOD检测性能的变化。

Result: OOD检测性能因分类任务的不同而显著变化，最佳任务依赖于定义的ID-OOD标准。

Conclusion: 任务选择和不确定性策略的对齐对医疗图像分析至关重要。

Abstract: Reliable out-of-distribution (OOD) detection is important for safe deployment
of deep learning models in fetal ultrasound amidst heterogeneous image
characteristics and clinical settings. OOD detection relies on estimating a
classification model's uncertainty, which should increase for OOD samples.
While existing research has largely focused on uncertainty quantification
methods, this work investigates the impact of the classification task itself.
Through experiments with eight uncertainty quantification methods across four
classification tasks, we demonstrate that OOD detection performance
significantly varies with the task, and that the best task depends on the
defined ID-OOD criteria; specifically, whether the OOD sample is due to: i) an
image characteristic shift or ii) an anatomical feature shift. Furthermore, we
reveal that superior OOD detection does not guarantee optimal abstained
prediction, underscoring the necessity to align task selection and uncertainty
strategies with the specific downstream application in medical image analysis.

</details>


### [21] [OrthoLoC: UAV 6-DoF Localization and Calibration Using Orthographic Geodata](https://arxiv.org/abs/2509.18350)
*Oussema Dhaouadi,Riccardo Marin,Johannes Meier,Jacques Kaiser,Daniel Cremers*

Main category: cs.CV

TL;DR: 针对无人机图像定位问题，提出OrthoLoC数据集并引入AdHoP技术，从而显著提升定位精度与性能。


<details>
  <summary>Details</summary>
Motivation: 在没有互联网连接和GNSS/GPS支持的情况下，实现高精度的视觉定位问题，填补了利用轻量级的正交地理数据进行视觉定位的研究空白。

Method: 创建了一个包含16,425张来自德国和美国的无人机图像的大规模数据集，利用配对结构进行公平基准测试，并评估了不同因素对定位精度的影响。

Result: 开发的AdHoP技术能将特征匹配有效提升至95%，并将平移误差降低至63%。

Conclusion: 提出的OrthoLoC数据集和AdHoP技术显著提高了无人机图像的定位精度，解决了现有方法中存在的域转移和特征匹配问题。

Abstract: Accurate visual localization from aerial views is a fundamental problem with
applications in mapping, large-area inspection, and search-and-rescue
operations. In many scenarios, these systems require high-precision
localization while operating with limited resources (e.g., no internet
connection or GNSS/GPS support), making large image databases or heavy 3D
models impractical. Surprisingly, little attention has been given to leveraging
orthographic geodata as an alternative paradigm, which is lightweight and
increasingly available through free releases by governmental authorities (e.g.,
the European Union). To fill this gap, we propose OrthoLoC, the first
large-scale dataset comprising 16,425 UAV images from Germany and the United
States with multiple modalities. The dataset addresses domain shifts between
UAV imagery and geospatial data. Its paired structure enables fair benchmarking
of existing solutions by decoupling image retrieval from feature matching,
allowing isolated evaluation of localization and calibration performance.
Through comprehensive evaluation, we examine the impact of domain shifts, data
resolutions, and covisibility on localization accuracy. Finally, we introduce a
refinement technique called AdHoP, which can be integrated with any feature
matcher, improving matching by up to 95% and reducing translation error by up
to 63%. The dataset and code are available at:
https://deepscenario.github.io/OrthoLoC.

</details>


### [22] [A Single Image Is All You Need: Zero-Shot Anomaly Localization Without Training Data](https://arxiv.org/abs/2509.18354)
*Mehrdad Moradi,Shengzhe Chen,Hao Yan,Kamran Paynabar*

Main category: cs.CV

TL;DR: 提出了一种名为SSDnet的单图像异常定位方法，能够在无训练数据的情况下有效检测异常，并且在多个数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 应对在缺乏训练数据情况下的零样本异常检测，设计出一个能有效检测图像中异常的解决方案。

Method: 采用基于图像补全的单图像异常定位方法，通过自重构和感知损失学习深度图像先验。

Result: SSDnet在MVTec-AD和fabric数据集上分别取得了0.99 AUROC与0.60 AUPRC，以及0.98 AUROC与0.67 AUPRC的成绩。

Conclusion: SSDnet在无监督的异常检测方面表现突出，超越了现有的最先进方法。

Abstract: Anomaly detection in images is typically addressed by learning from
collections of training data or relying on reference samples. In many
real-world scenarios, however, such training data may be unavailable, and only
the test image itself is provided. We address this zero-shot setting by
proposing a single-image anomaly localization method that leverages the
inductive bias of convolutional neural networks, inspired by Deep Image Prior
(DIP). Our method is named Single Shot Decomposition Network (SSDnet). Our key
assumption is that natural images often exhibit unified textures and patterns,
and that anomalies manifest as localized deviations from these repetitive or
stochastic patterns. To learn the deep image prior, we design a patch-based
training framework where the input image is fed directly into the network for
self-reconstruction, rather than mapping random noise to the image as done in
DIP. To avoid the model simply learning an identity mapping, we apply masking,
patch shuffling, and small Gaussian noise. In addition, we use a perceptual
loss based on inner-product similarity to capture structure beyond pixel
fidelity. Our approach needs no external training data, labels, or references,
and remains robust in the presence of noise or missing pixels. SSDnet achieves
0.99 AUROC and 0.60 AUPRC on MVTec-AD and 0.98 AUROC and 0.67 AUPRC on the
fabric dataset, outperforming state-of-the-art methods. The implementation code
will be released at https://github.com/mehrdadmoradi124/SSDnet

</details>


### [23] [Align Where the Words Look: Cross-Attention-Guided Patch Alignment with Contrastive and Transport Regularization for Bengali Captioning](https://arxiv.org/abs/2509.18369)
*Riad Ahmed Anonto,Sardar Md. Saffat Zabin,M. Saifur Rahman*

Main category: cs.CV

TL;DR: 本研究提出了一种孟加拉语图像描述生成新方法，通过三重损失目标提升模型效果，成功缩小真实与合成数据间的差距。


<details>
  <summary>Details</summary>
Motivation: 针对低资源语言在视觉-语言模型中遭遇的挑战，特别是数据稀缺、语言对齐破裂和偏向英语的预训练方法的问题进行研究。

Method: 构建一种基于已验证的英语-孟加拉语对的图像描述生成管道，利用固定的MaxViT、孟加拉本地化的mBART-50解码器和轻量级桥接，实现多模态链接。采用了补丁对齐损失(PAL)、信息对比损失(InfoNCE)和Sinkhorn最优传输(OT)技术。

Result: 该方法在Flickr30k-1k和MSCOCO-1k数据集上取得了显著的 BLEU-4、METEOR和BERTScore-F1的表现，超越了现有的竞争基准。

Conclusion: 该研究提出了一种计算感知的孟加拉语图像描述生成管道，通过三重损失目标显著提高了视觉-语言模型在孟加拉语场景中的表现。

Abstract: Grounding vision--language models in low-resource languages remains
challenging, as they often produce fluent text about the wrong objects. This
stems from scarce paired data, translation pivots that break alignment, and
English-centric pretraining that ignores target-language semantics. We address
this with a compute-aware Bengali captioning pipeline trained on LaBSE-verified
EN--BN pairs and 110k bilingual-prompted synthetic images. A frozen MaxViT
yields stable visual patches, a Bengali-native mBART-50 decodes, and a
lightweight bridge links the modalities. Our core novelty is a tri-loss
objective: Patch-Alignment Loss (PAL) aligns real and synthetic patch
descriptors using decoder cross-attention, InfoNCE enforces global
real--synthetic separation, and Sinkhorn-based OT ensures balanced fine-grained
patch correspondence. This PAL+InfoNCE+OT synergy improves grounding, reduces
spurious matches, and drives strong gains on Flickr30k-1k (BLEU-4 12.29, METEOR
27.98, BERTScore-F1 71.20) and MSCOCO-1k (BLEU-4 12.00, METEOR 28.14,
BERTScore-F1 75.40), outperforming strong CE baselines and narrowing the
real--synthetic centroid gap by 41%.

</details>


### [24] [TinyBEV: Cross Modal Knowledge Distillation for Efficient Multi Task Bird's Eye View Perception and Planning](https://arxiv.org/abs/2509.18372)
*Reeshad Khan,John Gauch*

Main category: cs.CV

TL;DR: TinyBEV是一种轻量化的鸟瞰图框架，能高效地在资源受限情况下实现完整的自动驾驶功能，包括3D检测和运动预测，性能优于其他相似方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决资源受限的环境中如何实现高效的实时自动驾驶系统。

Method: 采用模型无关的多阶段蒸馏策略，包括特征级、输出级和自适应区域Aware监督，以将高容量多模态知识有效转移到轻量级BEV表示。

Result: 在nuScenes数据集上，Tiny-BEV达到了39.0 mAP的检测性能，1.08 minADE的运动预测表现和0.32的碰撞率，同时速度快于传统方法5倍（11 FPS），且仅需要摄像头输入。

Conclusion: TinyBEV有效地在资源有限的环境中保留了完整的自动驾驶智能，同时实现了实时性能。

Abstract: We present TinyBEV, a unified, camera only Bird's Eye View (BEV) framework
that distills the full-stack capabilities of a large planning-oriented teacher
(UniAD [19]) into a compact, real-time student model. Unlike prior efficient
camera only baselines such as VAD[23] and VADv2[7], TinyBEV supports the
complete autonomy stack 3D detection, HD-map segmentation, motion forecasting,
occupancy prediction, and goal-directed planning within a streamlined
28M-parameter backbone, achieving a 78% reduction in parameters over UniAD
[19]. Our model-agnostic, multi-stage distillation strategy combines
feature-level, output-level, and adaptive region-aware supervision to
effectively transfer high-capacity multi-modal knowledge to a lightweight BEV
representation. On nuScenes[4], Tiny-BEV achieves 39.0 mAP for detection, 1.08
minADE for motion forecasting, and a 0.32 collision rate, while running 5x
faster (11 FPS) and requiring only camera input. These results demonstrate that
full-stack driving intelligence can be retained in resource-constrained
settings, bridging the gap between large-scale, multi-modal perception-planning
models and deployment-ready real-time autonomy.

</details>


### [25] [BlurBall: Joint Ball and Motion Blur Estimation for Table Tennis Ball Tracking](https://arxiv.org/abs/2509.18387)
*Thomas Gossard,Filip Radovic,Andreas Ziegler,Andrea Zell*

Main category: cs.CV

TL;DR: 本文提出了一种新标签策略，标记乒乓球在模糊中心，显著提高了球的检测与轨迹预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决快速运动物体（如乒乓球）由于运动模糊导致的检测困难，特别是在乒乓球等场景中的真实应用需求。

Method: 提出新的标签策略，将球标记在模糊的中心位置，并注释模糊属性，结合了多帧输入的Squeeze-and-Excitation注意力机制的BlurBall模型。

Result: 该新的标记方法在多种检测模型中均提升了检测性能，并通过BlurBall模型实现了先进的检测结果。

Conclusion: 采用中心标记模糊和模糊属性注释的新标签策略显著提升了乒乓球检测性能，并促成实时运动分析的准确性和可靠性。

Abstract: Motion blur reduces the clarity of fast-moving objects, posing challenges for
detection systems, especially in racket sports, where balls often appear as
streaks rather than distinct points. Existing labeling conventions mark the
ball at the leading edge of the blur, introducing asymmetry and ignoring
valuable motion cues correlated with velocity. This paper introduces a new
labeling strategy that places the ball at the center of the blur streak and
explicitly annotates blur attributes. Using this convention, we release a new
table tennis ball detection dataset. We demonstrate that this labeling approach
consistently enhances detection performance across various models. Furthermore,
we introduce BlurBall, a model that jointly estimates ball position and motion
blur attributes. By incorporating attention mechanisms such as
Squeeze-and-Excitation over multi-frame inputs, we achieve state-of-the-art
results in ball detection. Leveraging blur not only improves detection accuracy
but also enables more reliable trajectory prediction, benefiting real-time
sports analytics.

</details>


### [26] [MVP: Motion Vector Propagation for Zero-Shot Video Object Detection](https://arxiv.org/abs/2509.18388)
*Binhua Huang,Ni Wang,Wendong Yao,Soumyabrata Dev*

Main category: cs.CV

TL;DR: 我们提出了一种训练无关的方法，通过关键帧和压缩域运动向量传播检测，显著降低了开放词汇检测器的计算成本，同时保持了零样本检测的高准确性。


<details>
  <summary>Details</summary>
Motivation: 运行大规模开放词汇检测器在每个视频帧上虽然准确但代价高昂，因此需要一种更为高效的方法。

Method: 通过固定间隔的关键帧来调用OWLv2，并利用压缩域运动向量在中间帧之间传播检测结果。

Result: 在ILSVRC2015-VID（验证数据集）上，MVP方法在mAP@0.5取得0.609，达到0.316的mAP@[0.5:0.95]。在较松的交并比阈值下，其效果接近于帧级OWLv2-Large。

Conclusion: 压缩域传播是一种有效的减小检测器调用频率的方法，同时在视频中保持强大的零样本覆盖能力。

Abstract: Running a large open-vocabulary (Open-vocab) detector on every video frame is
accurate but expensive. We introduce a training-free pipeline that invokes
OWLv2 only on fixed-interval keyframes and propagates detections to
intermediate frames using compressed-domain motion vectors (MV). A simple 3x3
grid aggregation of motion vectors provides translation and uniform-scale
updates, augmented with an area-growth check and an optional single-class
switch. The method requires no labels, no fine-tuning, and uses the same prompt
list for all open-vocabulary methods. On ILSVRC2015-VID (validation dataset),
our approach (MVP) attains mAP@0.5=0.609 and mAP@[0.5:0.95]=0.316. At loose
intersection-over-union (IoU) thresholds it remains close to framewise
OWLv2-Large (0.747/0.721 at 0.2/0.3 versus 0.784/0.780), reflecting that coarse
localization is largely preserved. Under the same keyframe schedule, MVP
outperforms tracker-based propagation (MOSSE, KCF, CSRT) at mAP@0.5. A
supervised reference (YOLOv12x) reaches 0.631 at mAP@0.5 but requires labeled
training, whereas our method remains label-free and open-vocabulary. These
results indicate that compressed-domain propagation is a practical way to
reduce detector invocations while keeping strong zero-shot coverage in videos.
Our code and models are available at https://github.com/microa/MVP.

</details>


### [27] [Improving the color accuracy of lighting estimation models](https://arxiv.org/abs/2509.18390)
*Zitian Zhang,Joshua Urban Davis,Jeanne Phuong Anh Vu,Jiangtao Kuang,Jean-François Lalonde*

Main category: cs.CV

TL;DR: 本研究探讨了简单的适应技术如何通过预处理输入图像来提高现有高动态范围光照估计模型的颜色准确性，尤其是在使用预训练的白平衡网络时，显著提升了颜色鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着单幅图像的高动态范围光照估计技术的进步，改善虚拟物体的真实渲染和合成的需求日益增强，而颜色鲁棒性是实现视觉现实感的关键因素。

Method: 通过使用一个新的多样化照明颜色的HDR数据集，系统评估几种适应策略来改善颜色准确性。

Result: 预处理输入图像时使用预训练的白平衡网络显著提高了颜色鲁棒性，在所有测试场景中超越了其他策略，并且该方法不需要对光照估计模型进行重新训练。

Conclusion: 简单的适应技术可以显著提高现有高动态范围照明估计模型的颜色鲁棒性，尤其是使用预训练的白平衡网络作为预处理手段。

Abstract: Advances in high dynamic range (HDR) lighting estimation from a single image
have opened new possibilities for augmented reality (AR) applications.
Predicting complex lighting environments from a single input image allows for
the realistic rendering and compositing of virtual objects. In this work, we
investigate the color robustness of such methods -- an often overlooked yet
critical factor for achieving visual realism. While most evaluations conflate
color with other lighting attributes (e.g., intensity, direction), we isolate
color as the primary variable of interest. Rather than introducing a new
lighting estimation algorithm, we explore whether simple adaptation techniques
can enhance the color accuracy of existing models. Using a novel HDR dataset
featuring diverse lighting colors, we systematically evaluate several
adaptation strategies. Our results show that preprocessing the input image with
a pre-trained white balance network improves color robustness, outperforming
other strategies across all tested scenarios. Notably, this approach requires
no retraining of the lighting estimation model. We further validate the
generality of this finding by applying the technique to three state-of-the-art
lighting estimation methods from recent literature.

</details>


### [28] [Check Field Detection Agent (CFD-Agent) using Multimodal Large Language and Vision Language Models](https://arxiv.org/abs/2509.18405)
*Sourav Halder,Jinjun Tong,Xinyu Wu*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的训练无关支票字段检测框架，利用视觉语言模型和多模态大语言模型，能够有效降低在金融环境中的部署门槛，并优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 支票作为金融生态系统中的重要工具，面临欺诈风险，因此需要一个稳健的支票欺诈检测机制。

Method: 引入了一种新颖的训练无关框架，结合视觉语言模型（VLM）和多模态大语言模型（MLLM）进行支票字段检测。

Result: 在涵盖多种格式和布局的110张支票的手工策划数据集上，我们的模型表现出强大的性能和良好的泛化能力。

Conclusion: 我们提出的训练无关框架能够有效检测支票字段，降低了在实际金融环境中部署的门槛，同时为生成高质量标注数据集提供了基础。

Abstract: Checks remain a foundational instrument in the financial ecosystem,
facilitating substantial transaction volumes across institutions. However,
their continued use also renders them a persistent target for fraud,
underscoring the importance of robust check fraud detection mechanisms. At the
core of such systems lies the accurate identification and localization of
critical fields, such as the signature, magnetic ink character recognition
(MICR) line, courtesy amount, legal amount, payee, and payer, which are
essential for subsequent verification against reference checks belonging to the
same customer. This field-level detection is traditionally dependent on object
detection models trained on large, diverse, and meticulously labeled datasets,
a resource that is scarce due to proprietary and privacy concerns. In this
paper, we introduce a novel, training-free framework for automated check field
detection, leveraging the power of a vision language model (VLM) in conjunction
with a multimodal large language model (MLLM). Our approach enables zero-shot
detection of check components, significantly lowering the barrier to deployment
in real-world financial settings. Quantitative evaluation of our model on a
hand-curated dataset of 110 checks spanning multiple formats and layouts
demonstrates strong performance and generalization capability. Furthermore,
this framework can serve as a bootstrap mechanism for generating high-quality
labeled datasets, enabling the development of specialized real-time object
detection models tailored to institutional needs.

</details>


### [29] [Losing the Plot: How VLM responses degrade on imperfect charts](https://arxiv.org/abs/2509.18425)
*Philip Wootaek Shin,Jack Sampson,Vijaykrishnan Narayanan,Andres Marquez,Mahantesh Halappanavar*

Main category: cs.CV

TL;DR: 研究评估了先进的视觉语言模型在干扰和遮挡情况下的表现，发现其在图表理解中存在脆弱性，并提出了新数据集CHART NOISe和缓解策略以提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 针对现实世界中图表理解所面临的挑战，尤其是当图表受到干扰时，现有的基准测试不足以评估模型的真实能力，迫切需要更严谨的评估方法。

Method: 通过评估多种先进的视觉语言模型，并引入包含图表干扰、遮挡和反向不一致性的问题的CHART NOISe数据集，进行对比分析。

Result: 在面对干扰或遮挡时，评估的模型表现显著下降，常常出现如数值伪造、趋势误解和实体混淆等幻觉，并且在恶劣环境下依然过于自信地生成合理但缺乏支持的解释。

Conclusion: 本研究揭示了在存在干扰和遮挡的情况下，现有视觉语言模型在图表理解中的系统性脆弱性，并提出了新的测试集和缓解策略以提高模型的鲁棒性和可靠性。

Abstract: Vision language models (VLMs) show strong results on chart understanding, yet
existing benchmarks assume clean figures and fact based queries. Real world
charts often contain distortions and demand reasoning beyond simple matching.
We evaluate ChatGPT 4o, Claude Sonnet 4, and Gemini 2.5 Pro, finding sharp
performance drops under corruption or occlusion, with hallucinations such as
value fabrication, trend misinterpretation, and entity confusion becoming more
frequent. Models remain overconfident in degraded settings, generating
plausible but unsupported explanations.
  To address this gap, we introduce CHART NOISe(Chart Hallucinations, Answers,
and Reasoning Testing on Noisy and Occluded Input Selections), a dataset
combining chart corruptions, occlusions, and exam style multiple choice
questions inspired by Korea's CSAT English section. A key innovation is prompt
reverse inconsistency, where models contradict themselves when asked to confirm
versus deny the same statement. Our contributions are threefold: (1)
benchmarking state of the art VLMs, exposing systematic vulnerabilities in
chart reasoning; (2) releasing CHART NOISe, the first dataset unifying
corruption, occlusion, and reverse inconsistency; and (3) proposing baseline
mitigation strategies such as quality filtering and occlusion detection.
Together, these efforts establish a rigorous testbed for advancing robustness
and reliability in chart understanding.

</details>


### [30] [CPT-4DMR: Continuous sPatial-Temporal Representation for 4D-MRI Reconstruction](https://arxiv.org/abs/2509.18427)
*Xinyang Wu,Muheng Li,Xia Li,Orso Pusterla,Sairos Safai,Philippe C. Cattin,Antony J. Lomax,Ye Zhang*

Main category: cs.CV

TL;DR: 本研究提出了一种新的神经表示框架用于4D MRI重建，显著提高了效率和准确性，能够有效捕捉呼吸运动，为放射治疗提供了良好的应用前景。


<details>
  <summary>Details</summary>
Motivation: 传统的4D重建方法无法有效捕捉时间变化，工作流程复杂且计算负担重，因此需要一种新的方法来解决这些问题。

Method: 采用神经表示框架，通过空间解剖网络（SAN）和时间运动网络（TMN）进行运动建模和图像重建，利用1D替代信号引导。

Result: 在19名志愿者的自由呼吸数据集上评估显示，该方法能够准确捕捉规律和不规律的呼吸模式，并保持高解剖一致性，处理时间从约5小时缩短至15分钟。

Conclusion: 该方法在4D MRI重建中表现出色，显著提高了效率和准确性，具有在放射治疗规划和实时自适应治疗中的应用潜力。

Abstract: Four-dimensional MRI (4D-MRI) is an promising technique for capturing
respiratory-induced motion in radiation therapy planning and delivery.
Conventional 4D reconstruction methods, which typically rely on phase binning
or separate template scans, struggle to capture temporal variability,
complicate workflows, and impose heavy computational loads. We introduce a
neural representation framework that considers respiratory motion as a smooth,
continuous deformation steered by a 1D surrogate signal, completely replacing
the conventional discrete sorting approach. The new method fuses motion
modeling with image reconstruction through two synergistic networks: the
Spatial Anatomy Network (SAN) encodes a continuous 3D anatomical
representation, while a Temporal Motion Network (TMN), guided by
Transformer-derived respiratory signals, produces temporally consistent
deformation fields. Evaluation using a free-breathing dataset of 19 volunteers
demonstrates that our template- and phase-free method accurately captures both
regular and irregular respiratory patterns, while preserving vessel and
bronchial continuity with high anatomical fidelity. The proposed method
significantly improves efficiency, reducing the total processing time from
approximately five hours required by conventional discrete sorting methods to
just 15 minutes of training. Furthermore, it enables inference of each 3D
volume in under one second. The framework accurately reconstructs 3D images at
any respiratory state, achieves superior performance compared to conventional
methods, and demonstrates strong potential for application in 4D radiation
therapy planning and real-time adaptive treatment.

</details>


### [31] [An Analysis of Kalman Filter based Object Tracking Methods for Fast-Moving Tiny Objects](https://arxiv.org/abs/2509.18451)
*Prithvi Raj Singh,Raju Gottumukkala,Anthony Maida*

Main category: cs.CV

TL;DR: 快速移动的小物体（如乒乓球）的跟踪仍存在显著误差，当前的卡尔曼滤波跟踪方法需要改进。


<details>
  <summary>Details</summary>
Motivation: 当处理快速移动和不规则跳跃行为的小物体时，传统的卡尔曼滤波跟踪方法普遍存在性能下降的问题，尤其是在体育机器人等应用中尤为重要。

Method: 评估五种基于卡尔曼滤波的跟踪方法的性能，使用包含10,000个标注乒乓球帧的定制数据集，关注推理速度和每幅图像的更新频率对跟踪精度的影响。

Result: 实验结果显示，DeepOCSORT在跟踪误差上表现最佳，ADE为31.15像素，而ByteTrack在处理速度上最快，推理时间为26.6毫秒，但所有方法均存在3-11cm的显著跟踪漂移和误差。

Conclusion: 现有的跟踪方法在快速移动小物体（如乒乓球）的跟踪上表现出显著的漂移和误差，需针对这一领域开发专门的方法。

Abstract: Unpredictable movement patterns and small visual mark make precise tracking
of fast-moving tiny objects like a racquetball one of the challenging problems
in computer vision. This challenge is particularly relevant for sport robotics
applications, where lightweight and accurate tracking systems can improve robot
perception and planning capabilities. While Kalman filter-based tracking
methods have shown success in general object tracking scenarios, their
performance degrades substantially when dealing with rapidly moving objects
that exhibit irregular bouncing behavior. In this study, we evaluate the
performance of five state-of-the-art Kalman filter-based tracking
methods-OCSORT, DeepOCSORT, ByteTrack, BoTSORT, and StrongSORT-using a custom
dataset containing 10,000 annotated racquetball frames captured at 720p-1280p
resolution. We focus our analysis on two critical performance factors:
inference speed and update frequency per image, examining how these parameters
affect tracking accuracy and reliability for fast-moving tiny objects. Our
experimental evaluation across four distinct scenarios reveals that DeepOCSORT
achieves the lowest tracking error with an average ADE of 31.15 pixels compared
to ByteTrack's 114.3 pixels, while ByteTrack demonstrates the fastest
processing at 26.6ms average inference time versus DeepOCSORT's 26.8ms.
However, our results show that all Kalman filter-based trackers exhibit
significant tracking drift with spatial errors ranging from 3-11cm (ADE values:
31-114 pixels), indicating fundamental limitations in handling the
unpredictable motion patterns of fast-moving tiny objects like racquetballs.
Our analysis demonstrates that current tracking approaches require substantial
improvements, with error rates 3-4x higher than standard object tracking
benchmarks, highlighting the need for specialized methodologies for fast-moving
tiny object tracking applications.

</details>


### [32] [MoCrop: Training Free Motion Guided Cropping for Efficient Video Action Recognition](https://arxiv.org/abs/2509.18473)
*Binhua Huang,Wendong Yao,Shaowu Chen,Guoxin Wang,Qingyuan Wang,Soumyabrata Dev*

Main category: cs.CV

TL;DR: MoCrop是一个高效的运动感知自适应剪裁模块，通过利用视频压缩中的运动矢量，实现视频动作识别的准确性提升和计算量减少。


<details>
  <summary>Details</summary>
Motivation: 在压缩域中提高视频动作识别的效率，同时减少计算资源的消耗。

Method: MoCrop模块利用H.264视频中的运动矢量，定位运动密集区域，并在推理时对所有I帧应用单个剪裁，包含去噪与合并、蒙特卡洛采样和针对运动密度的自适应剪裁。

Result: 在UCF101上，使用ResNet-50时，MoCrop在相同FLOPs下提升了3.5%的Top-1准确率，或在减少26.5% FLOPs的情况下提升了2.4%的准确率。应用于CoViAR时，达到89.2% Top-1准确率，同时将计算从11.6 GFLOPs减少到8.5 GFLOPs。

Conclusion: MoCrop对于视频动作识别具有显著的准确性提升或计算减少，展现出强大的通用性，适用于压缩域中的实时部署。

Abstract: We introduce MoCrop, a motion-aware adaptive cropping module for efficient
video action recognition in the compressed domain. MoCrop uses motion vectors
that are available in H.264 video to locate motion-dense regions and produces a
single clip-level crop that is applied to all I-frames at inference. The module
is training free, adds no parameters, and can be plugged into diverse
backbones. A lightweight pipeline that includes denoising & merge (DM), Monte
Carlo sampling (MCS), and adaptive cropping (AC) via a motion-density submatrix
search yields robust crops with negligible overhead. On UCF101, MoCrop improves
accuracy or reduces compute. With ResNet-50, it delivers +3.5% Top-1 accuracy
at equal FLOPs (attention setting), or +2.4% Top-1 accuracy with 26.5% fewer
FLOPs (efficiency setting). Applied to CoViAR, it reaches 89.2% Top-1 accuracy
at the original cost and 88.5% Top-1 accuracy while reducing compute from 11.6
to 8.5 GFLOPs. Consistent gains on MobileNet-V3, EfficientNet-B1, and Swin-B
indicate strong generality and make MoCrop practical for real-time deployment
in the compressed domain. Our code and models are available at
https://github.com/microa/MoCrop.

</details>


### [33] [Codebook-Based Adaptive Feature Compression With Semantic Enhancement for Edge-Cloud Systems](https://arxiv.org/abs/2509.18481)
*Xinyu Wang,Zikun Zhou,Yingjian Li,Xin An,Hongpeng Wang*

Main category: cs.CV

TL;DR: 本研究提出CAFC-SE框架，通过向量量化在低比特率条件下有效压缩和传输视觉特征，提升了图像分析性能。


<details>
  <summary>Details</summary>
Motivation: 在低比特率条件下，现有图像编码和分析方法表现较差，存在冗余细节和符号分布过于集中等问题。因此，需要一种新方法来改善这一现状。

Method: 提出了一种基于代码本的自适应特征压缩框架CAFC-SE，使用向量量化将连续视觉特征映射到离散索引，并选择性地传输到云端。

Result: 通过广泛的实验，展示了CAFC-SE在比特率和准确性方面的优越性。

Conclusion: CAFC-SE方法在低比特率条件下表现优越，能够保留更多信息性视觉模式，提升分析性能。

Abstract: Coding images for machines with minimal bitrate and strong analysis
performance is key to effective edge-cloud systems. Several approaches deploy
an image codec and perform analysis on the reconstructed image. Other methods
compress intermediate features using entropy models and subsequently perform
analysis on the decoded features. Nevertheless, these methods both perform
poorly under low-bitrate conditions, as they retain many redundant details or
learn over-concentrated symbol distributions. In this paper, we propose a
Codebook-based Adaptive Feature Compression framework with Semantic
Enhancement, named CAFC-SE. It maps continuous visual features to discrete
indices with a codebook at the edge via Vector Quantization (VQ) and
selectively transmits them to the cloud. The VQ operation that projects feature
vectors onto the nearest visual primitives enables us to preserve more
informative visual patterns under low-bitrate conditions. Hence, CAFC-SE is
less vulnerable to low-bitrate conditions. Extensive experiments demonstrate
the superiority of our method in terms of rate and accuracy.

</details>


### [34] [MK-UNet: Multi-kernel Lightweight CNN for Medical Image Segmentation](https://arxiv.org/abs/2509.18493)
*Md Mostafijur Rahman,Radu Marculescu*

Main category: cs.CV

TL;DR: MK-UNet是一种新型轻量级多核U形CNN，专为医疗图像分割设计，显著提高了分割精度并减少了计算资源消耗，适合在资源有限的环境中应用。


<details>
  <summary>Details</summary>
Motivation: 为了提高医疗图像分割的精度和效率，同时降低计算资源的需求。

Method: 采用多核深度卷积块和复杂的注意力机制，构建超轻量级的多核U型CNN。

Result: MK-UNet在六个二元医疗成像基准中 outperform了当前最先进的方法，表现出显著的性能提升和计算效率。

Conclusion: MK-UNet在医疗图像分割方面表现优异，是一个轻量级和高效的解决方案，适合资源有限的环境。

Abstract: In this paper, we introduce MK-UNet, a paradigm shift towards
ultra-lightweight, multi-kernel U-shaped CNNs tailored for medical image
segmentation. Central to MK-UNet is the multi-kernel depth-wise convolution
block (MKDC) we design to adeptly process images through multiple kernels,
while capturing complex multi-resolution spatial relationships. MK-UNet also
emphasizes the images salient features through sophisticated attention
mechanisms, including channel, spatial, and grouped gated attention. Our
MK-UNet network, with a modest computational footprint of only 0.316M
parameters and 0.314G FLOPs, represents not only a remarkably lightweight, but
also significantly improved segmentation solution that provides higher accuracy
over state-of-the-art (SOTA) methods across six binary medical imaging
benchmarks. Specifically, MK-UNet outperforms TransUNet in DICE score with
nearly 333$\times$ and 123$\times$ fewer parameters and FLOPs, respectively.
Similarly, when compared against UNeXt, MK-UNet exhibits superior segmentation
performance, improving the DICE score up to 6.7% margins while operating with
4.7$\times$ fewer #Params. Our MK-UNet also outperforms other recent
lightweight networks, such as MedT, CMUNeXt, EGE-UNet, and Rolling-UNet, with
much lower computational resources. This leap in performance, coupled with
drastic computational gains, positions MK-UNet as an unparalleled solution for
real-time, high-fidelity medical diagnostics in resource-limited settings, such
as point-of-care devices. Our implementation is available at
https://github.com/SLDGroup/MK-UNet.

</details>


### [35] [BridgeSplat: Bidirectionally Coupled CT and Non-Rigid Gaussian Splatting for Deformable Intraoperative Surgical Navigation](https://arxiv.org/abs/2509.18501)
*Maximilian Fehrentz,Alexander Winkler,Thomas Heiliger,Nazim Haouchine,Christian Heiliger,Nassir Navab*

Main category: cs.CV

TL;DR: BridgeSplat是一种新的可变形手术导航方法，通过结合手术视频和预操作CT数据，实现了更精准的三维重建和数据更新。


<details>
  <summary>Details</summary>
Motivation: 现有手术导航方法缺乏将手术视频与体积患者数据有效结合的手段，BridgeSplat旨在填补这一空白。

Method: 通过将手术视频与预操作CT数据结合，使用3D高斯与CT网格绑扎，实现高斯参数与网格变形的联合优化。

Result: 在实际的内脏手术和模拟环境中，展示了BridgeSplat对预操作CT的有效变形。

Conclusion: BridgeSplat的方法在内脏手术和模拟人肝的合成数据上有效，显示出合理的CT变形结果。

Abstract: We introduce BridgeSplat, a novel approach for deformable surgical navigation
that couples intraoperative 3D reconstruction with preoperative CT data to
bridge the gap between surgical video and volumetric patient data. Our method
rigs 3D Gaussians to a CT mesh, enabling joint optimization of Gaussian
parameters and mesh deformation through photometric supervision. By
parametrizing each Gaussian relative to its parent mesh triangle, we enforce
alignment between Gaussians and mesh and obtain deformations that can be
propagated back to update the CT. We demonstrate BridgeSplat's effectiveness on
visceral pig surgeries and synthetic data of a human liver under simulation,
showing sensible deformations of the preoperative CT on monocular RGB data.
Code, data, and additional resources can be found at
https://maxfehrentz.github.io/ct-informed-splatting/ .

</details>


### [36] [Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment](https://arxiv.org/abs/2509.18502)
*Wenjie Liu,Hongmin Liu,Lixin Zhang,Bin Fan*

Main category: cs.CV

TL;DR: 研究提出一种新的伪标签优化框架DGLE，用以提升无监督领域适应中的伪标签质量，进而增强模型在目标域的性能。


<details>
  <summary>Details</summary>
Motivation: 在源域数据不可及的情况下，提升目标域内无监督领域适应的性能，尤其是在伪标签质量不足的情况下。

Method: 通过基于置信度过滤和超分辨率增强的伪标签融合方法，结合扩散模型以传播高质量的种子伪标签，生成完整的伪标签集。

Result: 改善了伪标签的质量，有效提升了在目标域的模型性能。

Conclusion: 提出的Diffusion-Guided Label Enrichment (DGLE)框架通过优化初始的高质量伪标签，有效提高了伪标签的整体质量，从而增强了模型在目标域的性能。

Abstract: Research on unsupervised domain adaptation (UDA) for semantic segmentation of
remote sensing images has been extensively conducted. However, research on how
to achieve domain adaptation in practical scenarios where source domain data is
inaccessible namely, source-free domain adaptation (SFDA) remains limited.
Self-training has been widely used in SFDA, which requires obtaining as many
high-quality pseudo-labels as possible to train models on target domain data.
Most existing methods optimize the entire pseudo-label set to obtain more
supervisory information. However, as pseudo-label sets often contain
substantial noise, simultaneously optimizing all labels is challenging. This
limitation undermines the effectiveness of optimization approaches and thus
restricts the performance of self-training. To address this, we propose a novel
pseudo-label optimization framework called Diffusion-Guided Label Enrichment
(DGLE), which starts from a few easily obtained high-quality pseudo-labels and
propagates them to a complete set of pseudo-labels while ensuring the quality
of newly generated labels. Firstly, a pseudo-label fusion method based on
confidence filtering and super-resolution enhancement is proposed, which
utilizes cross-validation of details and contextual information to obtain a
small number of high-quality pseudo-labels as initial seeds. Then, we leverage
the diffusion model to propagate incomplete seed pseudo-labels with irregular
distributions due to its strong denoising capability for randomly distributed
noise and powerful modeling capacity for complex distributions, thereby
generating complete and high-quality pseudo-labels. This method effectively
avoids the difficulty of directly optimizing the complete set of pseudo-labels,
significantly improves the quality of pseudo-labels, and thus enhances the
model's performance in the target domain.

</details>


### [37] [Hyperbolic Coarse-to-Fine Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2509.18504)
*Jiaxin Dai,Xiang Xiang*

Main category: cs.CV

TL;DR: 本研究提出了一种在双曲空间中进行粗到细的Few-Shot增量学习的方法，使用Poincaré球模型和双曲对比损失，实验结果显示出准确性的显著提升。


<details>
  <summary>Details</summary>
Motivation: 双曲空间在处理层次数据时优于传统的欧几里得空间，因此我们探索在C2FSCIL任务中采用双曲空间。

Method: 通过嵌入特征提取器到双曲空间，并引入双曲对比损失和双曲全连接层，优化和分类模型。

Result: 在C2FSCIL基准测试上，我们的方法显著提高了粗类和细类的准确性。

Conclusion: 实验结果表明，我们的方法有效提高了粗类与细类的准确率。

Abstract: In the field of machine learning, hyperbolic space demonstrates superior
representation capabilities for hierarchical data compared to conventional
Euclidean space. This work focuses on the Coarse-To-Fine Few-Shot
Class-Incremental Learning (C2FSCIL) task. Our study follows the Knowe
approach, which contrastively learns coarse class labels and subsequently
normalizes and freezes the classifier weights of learned fine classes in the
embedding space. To better interpret the "coarse-to-fine" paradigm, we propose
embedding the feature extractor into hyperbolic space. Specifically, we employ
the Poincar\'e ball model of hyperbolic space, enabling the feature extractor
to transform input images into feature vectors within the Poincar\'e ball
instead of Euclidean space. We further introduce hyperbolic contrastive loss
and hyperbolic fully-connected layers to facilitate model optimization and
classification in hyperbolic space. Additionally, to enhance performance under
few-shot conditions, we implement maximum entropy distribution in hyperbolic
space to estimate the probability distribution of fine-class feature vectors.
This allows generation of augmented features from the distribution to mitigate
overfitting during training with limited samples. Experiments on C2FSCIL
benchmarks show that our method effectively improves both coarse and fine class
accuracies.

</details>


### [38] [GeoRemover: Removing Objects and Their Causal Visual Artifacts](https://arxiv.org/abs/2509.18538)
*Zixin Zhu,Haoxiang Li,Xuelu Feng,He Wu,Chunming Qiao,Junsong Yuan*

Main category: cs.CV

TL;DR: 提出了一种几何感知两阶段框架，能有效去除图像中的对象及其视觉伪影，超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有的图像外观基础方法在去除目标对象及其因果视觉伪影方面存在局限性。

Method: 提出了一种几何感知的两阶段框架，第一阶段进行几何去除，第二阶段进行外观渲染。

Result: 通过严格的掩码对齐监督和更新的几何条件，方法有效去除了对象及其伪影。

Conclusion: 我们的方法在两个热门基准测试中显示出在去除对象及其相关伪影方面的最先进表现。

Abstract: Towards intelligent image editing, object removal should eliminate both the
target object and its causal visual artifacts, such as shadows and reflections.
However, existing image appearance-based methods either follow strictly
mask-aligned training and fail to remove these causal effects which are not
explicitly masked, or adopt loosely mask-aligned strategies that lack
controllability and may unintentionally over-erase other objects. We identify
that these limitations stem from ignoring the causal relationship between an
object's geometry presence and its visual effects. To address this limitation,
we propose a geometry-aware two-stage framework that decouples object removal
into (1) geometry removal and (2) appearance rendering. In the first stage, we
remove the object directly from the geometry (e.g., depth) using strictly
mask-aligned supervision, enabling structure-aware editing with strong
geometric constraints. In the second stage, we render a photorealistic RGB
image conditioned on the updated geometry, where causal visual effects are
considered implicitly as a result of the modified 3D geometry. To guide
learning in the geometry removal stage, we introduce a preference-driven
objective based on positive and negative sample pairs, encouraging the model to
remove objects as well as their causal visual artifacts while avoiding new
structural insertions. Extensive experiments demonstrate that our method
achieves state-of-the-art performance in removing both objects and their
associated artifacts on two popular benchmarks. The code is available at
https://github.com/buxiangzhiren/GeoRemover.

</details>


### [39] [SEGA: A Transferable Signed Ensemble Gaussian Black-Box Attack against No-Reference Image Quality Assessment Models](https://arxiv.org/abs/2509.18546)
*Yujia Liu,Dingquan Li,Tiejun Huang*

Main category: cs.CV

TL;DR: 本研究提出SEGA，提升不同NR-IQA模型间的对抗攻击转移性并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着对NR-IQA模型的对抗性攻击日益关注，提升攻击的可转移性以适应黑箱场景成为亟待解决的挑战。

Method: 提出了一种可转移的Signed Ensemble Gaussian黑箱攻击（SEGA），利用高斯平滑近似目标模型的梯度并进行集成。

Result: SEGA在CLIVE数据集上的实验结果显示其在黑箱攻击中具备优异的可转移性，验证了该方法的有效性。

Conclusion: SEGA通过高斯平滑和滤波器设计有效提升了在黑箱场景下攻击NR-IQA模型的可转移性，在CLIVE数据集上验证了其有效性。

Abstract: No-Reference Image Quality Assessment (NR-IQA) models play an important role
in various real-world applications. Recently, adversarial attacks against
NR-IQA models have attracted increasing attention, as they provide valuable
insights for revealing model vulnerabilities and guiding robust system design.
Some effective attacks have been proposed against NR-IQA models in white-box
settings, where the attacker has full access to the target model. However,
these attacks often suffer from poor transferability to unknown target models
in more realistic black-box scenarios, where the target model is inaccessible.
This work makes the first attempt to address the challenge of low
transferability in attacking NR-IQA models by proposing a transferable Signed
Ensemble Gaussian black-box Attack (SEGA). The main idea is to approximate the
gradient of the target model by applying Gaussian smoothing to source models
and ensembling their smoothed gradients. To ensure the imperceptibility of
adversarial perturbations, SEGA further removes inappropriate perturbations
using a specially designed perturbation filter mask. Experimental results on
the CLIVE dataset demonstrate the superior transferability of SEGA, validating
its effectiveness in enabling successful transfer-based black-box attacks
against NR-IQA models.

</details>


### [40] [HadaSmileNet: Hadamard fusion of handcrafted and deep-learning features for enhancing facial emotion recognition of genuine smiles](https://arxiv.org/abs/2509.18550)
*Mohammad Junayed Hasan,Nabeel Mohammed,Shafin Rahman,Philipp Koehn*

Main category: cs.CV

TL;DR: 研究提出HadaSmileNet，通过无参数乘法结合生理特征和深度学习，显著提高情感识别效率并设定新标准。


<details>
  <summary>Details</summary>
Motivation: 区分真实和摆拍情绪是模式识别中的一个重要挑战，对于社会科学、医疗保健和人机交互的数据挖掘应用有重要意义。

Method: 提出HadaSmileNet，一个新颖的特征融合框架，通过无参数乘法交互直接整合基于变换器的表示和生理D-Marker特征。

Result: Hadamard乘法融合策略在15种融合策略的评估中表现最佳，在四个基准数据集上实现了最佳性能，参数减少26%，训练简化，与多任务学习方法相比更具优势。

Conclusion: HadaSmileNet在多个基准数据集上展示了新的最先进结果，并显著提高了计算效率和参数利用率，适合实时情感计算的多媒体数据挖掘应用。

Abstract: The distinction between genuine and posed emotions represents a fundamental
pattern recognition challenge with significant implications for data mining
applications in social sciences, healthcare, and human-computer interaction.
While recent multi-task learning frameworks have shown promise in combining
deep learning architectures with handcrafted D-Marker features for smile facial
emotion recognition, these approaches exhibit computational inefficiencies due
to auxiliary task supervision and complex loss balancing requirements. This
paper introduces HadaSmileNet, a novel feature fusion framework that directly
integrates transformer-based representations with physiologically grounded
D-Markers through parameter-free multiplicative interactions. Through
systematic evaluation of 15 fusion strategies, we demonstrate that Hadamard
multiplicative fusion achieves optimal performance by enabling direct feature
interactions while maintaining computational efficiency. The proposed approach
establishes new state-of-the-art results for deep learning methods across four
benchmark datasets: UvA-NEMO (88.7 percent, +0.8), MMI (99.7 percent), SPOS
(98.5 percent, +0.7), and BBC (100 percent, +5.0). Comprehensive computational
analysis reveals 26 percent parameter reduction and simplified training
compared to multi-task alternatives, while feature visualization demonstrates
enhanced discriminative power through direct domain knowledge integration. The
framework's efficiency and effectiveness make it particularly suitable for
practical deployment in multimedia data mining applications that require
real-time affective computing capabilities.

</details>


### [41] [Event-guided 3D Gaussian Splatting for Dynamic Human and Scene Reconstruction](https://arxiv.org/abs/2509.18566)
*Xiaoting Yin,Hao Shi,Kailun Yang,Jiajun Zhai,Shangwei Guo,Lin Wang,Kaiwei Wang*

Main category: cs.CV

TL;DR: 提出了一种新颖的事件引导人类-场景重建框架，通过单视角事件相机和3D高斯点云实现高效重建，尤其在快速运动情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 旨在解决单视角视频中由于运动模糊导致的人类与场景重建的难题，尤其是在快速运动下。

Method: 通过3D高斯点云模型实现单视角事件相机的人类和场景重建，运用事件引导损失来提高动态区域的局部保真度。

Result: 在ZJU-MoCap-Blur和MMHPSD-Blur两个基准数据集上，展现出在PSNR/SSIM指标上的领先表现，并减少了LPIPS，使得动态重建更为精确。

Conclusion: 该方法在动态人类重建和静态场景融合方面取得了显著进展，特别是在快速运动的情况下，优于其他基线方法。

Abstract: Reconstructing dynamic humans together with static scenes from monocular
videos remains difficult, especially under fast motion, where RGB frames suffer
from motion blur. Event cameras exhibit distinct advantages, e.g., microsecond
temporal resolution, making them a superior sensing choice for dynamic human
reconstruction. Accordingly, we present a novel event-guided human-scene
reconstruction framework that jointly models human and scene from a single
monocular event camera via 3D Gaussian Splatting. Specifically, a unified set
of 3D Gaussians carries a learnable semantic attribute; only Gaussians
classified as human undergo deformation for animation, while scene Gaussians
stay static. To combat blur, we propose an event-guided loss that matches
simulated brightness changes between consecutive renderings with the event
stream, improving local fidelity in fast-moving regions. Our approach removes
the need for external human masks and simplifies managing separate Gaussian
sets. On two benchmark datasets, ZJU-MoCap-Blur and MMHPSD-Blur, it delivers
state-of-the-art human-scene reconstruction, with notable gains over strong
baselines in PSNR/SSIM and reduced LPIPS, especially for high-speed subjects.

</details>


### [42] [Live-E2T: Real-time Threat Monitoring in Video via Deduplicated Event Reasoning and Chain-of-Thought](https://arxiv.org/abs/2509.18571)
*Yuhan Wang,Cheng Liu,Zihan Zhao,Weichao Wu*

Main category: cs.CV

TL;DR: 提出Live-E2T框架，通过解构视频帧、去重机制和语言模型微调，实现实时威胁监测的准确性、效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的威胁监测方法在实时性能和决策可解释性方面无法同时满足要求，亟需一个新的方法来解决这一问题。

Method: 通过将视频帧解构为结构化的语义元组，并引入高效的事件去重机制和基于Chain-of-Thought的语言模型微调，构建实时威胁监测框架。

Result: Live-E2T在威胁检测的准确性和实时响应性上展示了优越的性能。

Conclusion: Live-E2T在威胁检测准确性、实时效率和可解释性方面显著优于现有方法。

Abstract: Real-time threat monitoring identifies threatening behaviors in video streams
and provides reasoning and assessment of threat events through explanatory
text. However, prevailing methodologies, whether based on supervised learning
or generative models, struggle to concurrently satisfy the demanding
requirements of real-time performance and decision explainability. To bridge
this gap, we introduce Live-E2T, a novel framework that unifies these two
objectives through three synergistic mechanisms. First, we deconstruct video
frames into structured Human-Object-Interaction-Place semantic tuples. This
approach creates a compact, semantically focused representation, circumventing
the information degradation common in conventional feature compression. Second,
an efficient online event deduplication and updating mechanism is proposed to
filter spatio-temporal redundancies, ensuring the system's real time
responsiveness. Finally, we fine-tune a Large Language Model using a
Chain-of-Thought strategy, endow it with the capability for transparent and
logical reasoning over event sequences to produce coherent threat assessment
reports. Extensive experiments on benchmark datasets, including XD-Violence and
UCF-Crime, demonstrate that Live-E2T significantly outperforms state-of-the-art
methods in terms of threat detection accuracy, real-time efficiency, and the
crucial dimension of explainability.

</details>


### [43] [The Photographer Eye: Teaching Multimodal Large Language Models to See and Critique like Photographers](https://arxiv.org/abs/2509.18582)
*Daiqing Qi,Handong Zhao,Jing Shi,Simon Jenni,Yifei Fan,Franck Dernoncourt,Scott Cohen,Sheng Li*

Main category: cs.CV

TL;DR: 本研究旨在解决多模态大语言模型在图像美学理解上的不足，通过构建新数据集和模型，提升其分析能力。


<details>
  <summary>Details</summary>
Motivation: 探讨一般视觉理解与美学视觉理解之间的差距，针对当前多模态大语言模型在处理图像美学时的不足之处进行改进。

Method: 提出了一种语言引导的多视角视觉融合机制来学习图像美学，并构建了一个专业的基准测试PhotoBench。

Result: 模型在现有基准测试和新创建的PhotoBench上表现出明显的优势，提升了对图像美学的理解能力。

Conclusion: 本研究通过创建一个新数据集PhotoCritique和提出模型PhotoEye，显著提升了多模态大语言模型在图像美学理解方面的能力。

Abstract: While editing directly from life, photographers have found it too difficult
to see simultaneously both the blue and the sky. Photographer and curator,
Szarkowski insightfully revealed one of the notable gaps between general and
aesthetic visual understanding: while the former focuses on identifying the
factual element in an image (sky), the latter transcends such object
identification, viewing it instead as an aesthetic component--a pure color
block (blue). Such fundamental distinctions between general (detection,
localization, etc.) and aesthetic (color, lighting, composition, etc.) visual
understanding present a significant challenge for Multimodal Large Language
Models (MLLMs). Although some recent works have made initial explorations, they
are often limited to general and basic aesthetic commonsense. As a result, they
frequently fall short in real-world scenarios (Fig. 1), which require extensive
expertise--including photographic techniques, photo pre/post-processing
knowledge, and more, to provide a detailed analysis and description. To
fundamentally enhance the aesthetics understanding of MLLMs, we first introduce
a novel dataset, PhotoCritique, derived from extensive discussions among
professional photographers and enthusiasts, and characterized by the large
scale, expertise, and diversity. Then, to better learn visual aesthetics from
PhotoCritique, we furthur propose a novel model, PhotoEye, featuring a
languageguided multi-view vision fusion mechanism to understand image
aesthetics from multiple perspectives. Finally, we present a novel benchmark,
PhotoBench, a comprehensive and professional benchmark for aesthetic visual
understanding. On existing benchmarks and PhotoBench, our model demonstrates
clear advantages over existing models.

</details>


### [44] [Enhancing Video Object Segmentation in TrackRAD Using XMem Memory Network](https://arxiv.org/abs/2509.18591)
*Pengchao Deng,Shengqi Chen*

Main category: cs.CV

TL;DR: 本论文提出一种先进的肿瘤分割框架，运用XMem模型以提高实时MRI引导放射治疗中的肿瘤跟踪精确度，尽管缺乏详细实验数据，初步性能令人满意。


<details>
  <summary>Details</summary>
Motivation: 为了改善MRI引导下放射治疗中的肿瘤跟踪精确度，以提高癌症治疗的准确性和安全性。

Method: 提出一种基于XMem模型的肿瘤分割框架，使用内存增强架构处理长时间序列的cine-MRI数据。

Result: 尽管缺乏定量结果，初步印象表明XMem框架能够实时有效地跟踪肿瘤运动。

Conclusion: 本研究提出的XMem框架在肿瘤分割中显示出合理的性能，并满足临床实时要求，虽然缺乏详细实验记录。

Abstract: This paper presents an advanced tumor segmentation framework for real-time
MRI-guided radiotherapy, designed for the TrackRAD2025 challenge. Our method
leverages the XMem model, a memory-augmented architecture, to segment tumors
across long cine-MRI sequences. The proposed system efficiently integrates
memory mechanisms to track tumor motion in real-time, achieving high
segmentation accuracy even under challenging conditions with limited annotated
data. Unfortunately, the detailed experimental records have been lost,
preventing us from reporting precise quantitative results at this stage.
Nevertheless, From our preliminary impressions during development, the
XMem-based framework demonstrated reasonable segmentation performance and
satisfied the clinical real-time requirement. Our work contributes to improving
the precision of tumor tracking during MRI-guided radiotherapy, which is
crucial for enhancing the accuracy and safety of cancer treatments.

</details>


### [45] [SSCM: A Spatial-Semantic Consistent Model for Multi-Contrast MRI Super-Resolution](https://arxiv.org/abs/2509.18593)
*Xiaoman Wu,Lubin Gan,Siying Wu,Jing Zhang,Yunwei Ou,Xiaoyan Sun*

Main category: cs.CV

TL;DR: 本文提出了一种新的SSCM模型，解决了MC-MRI SR中的空间-语义一致性问题，达到了最佳性能和效率。


<details>
  <summary>Details</summary>
Motivation: 多对比磁共振成像超分辨率旨在利用高分辨率参考增强低分辨率对比，面临保持空间-语义一致性的挑战。

Method: 提出了空间-语义一致性模型（SSCM），集成了动态空间扭曲模块、语义感知令牌聚合块和空间频率融合块。

Result: 在公共和私有数据集测试中，SSCM在性能上达到了领先水平，同时确保了重建结果的空间和语义一致性。

Conclusion: SSCM在图像重建过程中实现了空间和语义的一致性，达到最先进的性能且参数较少。

Abstract: Multi-contrast Magnetic Resonance Imaging super-resolution (MC-MRI SR) aims
to enhance low-resolution (LR) contrasts leveraging high-resolution (HR)
references, shortening acquisition time and improving imaging efficiency while
preserving anatomical details. The main challenge lies in maintaining
spatial-semantic consistency, ensuring anatomical structures remain
well-aligned and coherent despite structural discrepancies and motion between
the target and reference images. Conventional methods insufficiently model
spatial-semantic consistency and underuse frequency-domain information, which
leads to poor fine-grained alignment and inadequate recovery of high-frequency
details. In this paper, we propose the Spatial-Semantic Consistent Model
(SSCM), which integrates a Dynamic Spatial Warping Module for inter-contrast
spatial alignment, a Semantic-Aware Token Aggregation Block for long-range
semantic consistency, and a Spatial-Frequency Fusion Block for fine structure
restoration. Experiments on public and private datasets show that SSCM achieves
state-of-the-art performance with fewer parameters while ensuring spatially and
semantically consistent reconstructions.

</details>


### [46] [OraPO: Oracle-educated Reinforcement Learning for Data-efficient and Factual Radiology Report Generation](https://arxiv.org/abs/2509.18600)
*Zhuoxiao Chen,Hongyang Yu,Ying Xu,Yadan Luo,Long Duong,Yuan-Fang Li*

Main category: cs.CV

TL;DR: 本文提出的OraPO和FactS提高了放射科报告生成的效率和效果，在CheXpert Plus数据集上设定了新的最佳性能。


<details>
  <summary>Details</summary>
Motivation: 旨在解决放射科报告生成任务在数据和计算资源有限的情况下的挑战。

Method: 提出了Oracle-educated GRPO (OraPO)和FactScore-based reward (FactS)，通过单阶段、强化学习训练以提高效率。

Result: 通过使用OraPO和FactS，训练效率显著提高，并在CheXpert Plus数据集上实现了0.341的F1评分，使用的训练数据量比传统方法少2-3个数量级。

Conclusion: OraPO和FactS架构在临床具有挑战性的情况下显著提高了学习效率，实现了CheXpert Plus数据集上的新SOTA性能。

Abstract: Radiology report generation (RRG) aims to automatically produce clinically
faithful reports from chest X-ray images. Prevailing work typically follows a
scale-driven paradigm, by multi-stage training over large paired corpora and
oversized backbones, making pipelines highly data- and compute-intensive. In
this paper, we propose Oracle-educated GRPO {OraPO) with a FactScore-based
reward (FactS) to tackle the RRG task under constrained budgets. OraPO enables
single-stage, RL-only training by converting failed GRPO explorations on rare
or difficult studies into direct preference supervision via a lightweight
oracle step. FactS grounds learning in diagnostic evidence by extracting atomic
clinical facts and checking entailment against ground-truth labels, yielding
dense, interpretable sentence-level rewards. Together, OraPO and FactS create a
compact and powerful framework that significantly improves learning efficiency
on clinically challenging cases, setting the new SOTA performance on the
CheXpert Plus dataset (0.341 in F1) with 2--3 orders of magnitude less training
data using a small base VLM on modest hardware.

</details>


### [47] [Training-Free Multi-Style Fusion Through Reference-Based Adaptive Modulation](https://arxiv.org/abs/2509.18602)
*Xu Liu,Yibo Lu,Xinxian Wang,Xinyu Wu*

Main category: cs.CV

TL;DR: 本研究提出了一种自适应多样式融合框架（AMSF），克服了现有方法在风格融合中的限制，实现了可控的多风格生成。


<details>
  <summary>Details</summary>
Motivation: 现有的参考基础方法只能接受单一风格图像，这限制了混合美学和扩展到更多风格的可能性，且缺少有效的机制来平衡多个风格的影响。

Method: 通过语义令牌分解模块对多个风格图像和文本提示进行编码，并在每个跨注意力层中自适应注入。然后，利用相似度感知重标定模块在每个去噪步骤中调整每个风格组件的注意力分配，确保融合结果的平衡和可控性。

Result: AMSF通过在去噪过程中动态调整样式组件的注意力分配，能够实现用户可控的多样式融合。定性和定量评估显示其产生的融合结果超越了现有的最高水平方法。

Conclusion: AMSF在多种风格融合方面的表现超越了现有最先进的方法，并且能够灵活扩展到多个风格的应用中。

Abstract: We propose Adaptive Multi-Style Fusion (AMSF), a reference-based
training-free framework that enables controllable fusion of multiple reference
styles in diffusion models. Most of the existing reference-based methods are
limited by (a) acceptance of only one style image, thus prohibiting hybrid
aesthetics and scalability to more styles, and (b) lack of a principled
mechanism to balance several stylistic influences. AMSF mitigates these
challenges by encoding all style images and textual hints with a semantic token
decomposition module that is adaptively injected into every cross-attention
layer of an frozen diffusion model. A similarity-aware re-weighting module then
recalibrates, at each denoising step, the attention allocated to every style
component, yielding balanced and user-controllable blends without any
fine-tuning or external adapters. Both qualitative and quantitative evaluations
show that AMSF produces multi-style fusion results that consistently outperform
the state-of-the-art approaches, while its fusion design scales seamlessly to
two or more styles. These capabilities position AMSF as a practical step toward
expressive multi-style generation in diffusion models.

</details>


### [48] [MLF-4DRCNet: Multi-Level Fusion with 4D Radar and Camera for 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2509.18613)
*Yuzhi Wu,Li Xiao,Jun Liu,Guangfeng Jiang,XiangGen Xia*

Main category: cs.CV

TL;DR: 本研究提出的MLF-4DRCNet框架以多级融合4D雷达和相机图像为基础，显著提升了3D目标检测性能，且在某些数据集上与激光雷达模型表现相当。


<details>
  <summary>Details</summary>
Motivation: 解决4D毫米波雷达在3D目标检测中由于点云稀疏和噪声问题，导致其单独应用受限。

Method: 提出了一种名为MLF-4DRCNet的两阶段框架，通过多级融合4D雷达和相机图像进行3D目标检测。

Result: 在View-of-Delft (VoD)和TJ4DRadSet数据集上的实验结果表明，MLF-4DRCNet达到了最先进的性能。

Conclusion: MLF-4DRCNet在3D目标检测中表现出色，达到了与基于激光雷达模型相当的性能。

Abstract: The emerging 4D millimeter-wave radar, measuring the range, azimuth,
elevation, and Doppler velocity of objects, is recognized for its
cost-effectiveness and robustness in autonomous driving. Nevertheless, its
point clouds exhibit significant sparsity and noise, restricting its standalone
application in 3D object detection. Recent 4D radar-camera fusion methods have
provided effective perception. Most existing approaches, however, adopt
explicit Bird's-Eye-View fusion paradigms originally designed for LiDAR-camera
fusion, neglecting radar's inherent drawbacks. Specifically, they overlook the
sparse and incomplete geometry of radar point clouds and restrict fusion to
coarse scene-level integration. To address these problems, we propose
MLF-4DRCNet, a novel two-stage framework for 3D object detection via
multi-level fusion of 4D radar and camera images. Our model incorporates the
point-, scene-, and proposal-level multi-modal information, enabling
comprehensive feature representation. It comprises three crucial components:
the Enhanced Radar Point Encoder (ERPE) module, the Hierarchical Scene Fusion
Pooling (HSFP) module, and the Proposal-Level Fusion Enhancement (PLFE) module.
Operating at the point-level, ERPE densities radar point clouds with 2D image
instances and encodes them into voxels via the proposed Triple-Attention Voxel
Feature Encoder. HSFP dynamically integrates multi-scale voxel features with 2D
image features using deformable attention to capture scene context and adopts
pooling to the fused features. PLFE refines region proposals by fusing image
features, and further integrates with the pooled features from HSFP.
Experimental results on the View-of-Delft (VoD) and TJ4DRadSet datasets
demonstrate that MLF-4DRCNet achieves the state-of-the-art performance.
Notably, it attains performance comparable to LiDAR-based models on the VoD
dataset.

</details>


### [49] [Prompt-Guided Dual Latent Steering for Inversion Problems](https://arxiv.org/abs/2509.18619)
*Yichen Wu,Xu Liu,Chenxuan Zhao,Xinyu Wu*

Main category: cs.CV

TL;DR: PDLS是一种新颖的框架，通过通过双重引导减少图像重建中的语义漂移，而无需每张图片的昂贵优化，表现出更好的重建效果。


<details>
  <summary>Details</summary>
Motivation: 当前方法难以平衡结构保真性与语义准确性，导致图像重建出现模糊或属性错误。

Method: 提出了一种训练-free的方法Prompt-Guided Dual Latent Steering (PDLS)，利用Rectified Flow模型进行稳定的反演。通过最优控制的问题制定双重指导策略，并通过线性二次调节器(LQR)得出闭合解。

Result: 在FFHQ-1K和ImageNet-1K上进行大量实验表明，PDLS在更高级的反演任务中能更忠实地重建图像，同时更好地对齐语义信息。

Conclusion: PDLS框架在各种重建任务中表现优于单一潜在基线，能够更好地保持图像的结构完整性和语义准确性。

Abstract: Inverting corrupted images into the latent space of diffusion models is
challenging. Current methods, which encode an image into a single latent
vector, struggle to balance structural fidelity with semantic accuracy, leading
to reconstructions with semantic drift, such as blurred details or incorrect
attributes. To overcome this, we introduce Prompt-Guided Dual Latent Steering
(PDLS), a novel, training-free framework built upon Rectified Flow models for
their stable inversion paths. PDLS decomposes the inversion process into two
complementary streams: a structural path to preserve source integrity and a
semantic path guided by a prompt. We formulate this dual guidance as an optimal
control problem and derive a closed-form solution via a Linear Quadratic
Regulator (LQR). This controller dynamically steers the generative trajectory
at each step, preventing semantic drift while ensuring the preservation of fine
detail without costly, per-image optimization. Extensive experiments on FFHQ-1K
and ImageNet-1K under various inversion tasks, including Gaussian deblurring,
motion deblurring, super-resolution and freeform inpainting, demonstrate that
PDLS produces reconstructions that are both more faithful to the original image
and better aligned with the semantic information than single-latent baselines.

</details>


### [50] [Learning neuroimaging models from health system-scale data](https://arxiv.org/abs/2509.18638)
*Yiwei Lyu,Samir Harake,Asadur Chowdury,Soumyanil Banerjee,Rachel Gologorsky,Shixuan Liu,Anna-Katharina Meissner,Akshay Rao,Chenhui Zhao,Akhil Kondepudi,Cheng Jiang,Xinhai Hou,Rushikesh S. Joshi,Volker Neuschmelting,Ashok Srinivasan,Dawn Kleindorfer,Brian Athey,Vikas Gulani,Aditya Pandey,Honglak Lee,Todd Hollon*

Main category: cs.CV

TL;DR: 该研究开发了Prima，一个针对神经影像学的视觉语言模型，显著提升了MRI诊断效率，尤其是在低资源环境中。


<details>
  <summary>Details</summary>
Motivation: 全球MRI研究需求不断增加，给健康系统带来了巨大压力，尤其是在资源匮乏和乡村地区。

Method: 开发了Prima，一种基于220,000个MRI研究训练的视觉语言模型，使用分层视觉架构来提供MRI特征。

Result: Prima在30,000个MRI研究中，对52种主要神经疾病的诊断平均ROC曲线下的面积达到92.0，优于其他先进的AI模型。

Conclusion: Prima展示了在神经影像学中应用VLM的转型潜力，它能提高诊断效率并减轻健康系统的负担，尤其是在资源有限的环境中。

Abstract: Neuroimaging is a ubiquitous tool for evaluating patients with neurological
diseases. The global demand for magnetic resonance imaging (MRI) studies has
risen steadily, placing significant strain on health systems, prolonging
turnaround times, and intensifying physician burnout \cite{Chen2017-bt,
Rula2024-qp-1}. These challenges disproportionately impact patients in
low-resource and rural settings. Here, we utilized a large academic health
system as a data engine to develop Prima, the first vision language model (VLM)
serving as an AI foundation for neuroimaging that supports real-world, clinical
MRI studies as input. Trained on over 220,000 MRI studies, Prima uses a
hierarchical vision architecture that provides general and transferable MRI
features. Prima was tested in a 1-year health system-wide study that included
30K MRI studies. Across 52 radiologic diagnoses from the major neurologic
disorders, including neoplastic, inflammatory, infectious, and developmental
lesions, Prima achieved a mean diagnostic area under the ROC curve of 92.0,
outperforming other state-of-the-art general and medical AI models. Prima
offers explainable differential diagnoses, worklist priority for radiologists,
and clinical referral recommendations across diverse patient demographics and
MRI systems. Prima demonstrates algorithmic fairness across sensitive groups
and can help mitigate health system biases, such as prolonged turnaround times
for low-resource populations. These findings highlight the transformative
potential of health system-scale VLMs and Prima's role in advancing AI-driven
healthcare.

</details>


### [51] [Understanding-in-Generation: Reinforcing Generative Capability of Unified Model via Infusing Understanding into Generation](https://arxiv.org/abs/2509.18639)
*Yuanhuiyi Lyu,Chi Kit Wong,Chenfei Liao,Lutao Jiang,Xu Zheng,Zexin Lu,Linfeng Zhang,Xuming Hu*

Main category: cs.CV

TL;DR: 提出了一种新颖的理解增强生成框架UiG，利用理解能力改善文本到图像生成，取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有文本到图像生成方法中理解与生成过程分离的问题，从而提高生成模型的性能。

Method: 提出了一种新的推理框架，结合生成指导与理解能力，通过图像编辑过程逐步增强生成效果。

Result: 在TIIF基准长提示设置上，性能提升了3.92%。

Conclusion: UiG框架在文本到图像生成任务中显示出显著的性能提升，尤其是在长提示设置下超越了现有方法。

Abstract: Recent works have made notable advancements in enhancing unified models for
text-to-image generation through the Chain-of-Thought (CoT). However, these
reasoning methods separate the processes of understanding and generation, which
limits their ability to guide the reasoning of unified models in addressing the
deficiencies of their generative capabilities. To this end, we propose a novel
reasoning framework for unified models, Understanding-in-Generation (UiG),
which harnesses the robust understanding capabilities of unified models to
reinforce their performance in image generation. The core insight of our UiG is
to integrate generative guidance by the strong understanding capabilities
during the reasoning process, thereby mitigating the limitations of generative
abilities. To achieve this, we introduce "Image Editing" as a bridge to infuse
understanding into the generation process. Initially, we verify the generated
image and incorporate the understanding of unified models into the editing
instructions. Subsequently, we enhance the generated image step by step,
gradually infusing the understanding into the generation process. Our UiG
framework demonstrates a significant performance improvement in text-to-image
generation over existing text-to-image reasoning methods, e.g., a 3.92% gain on
the long prompt setting of the TIIF benchmark. The project code:
https://github.com/QC-LY/UiG

</details>


### [52] [Zero-shot Monocular Metric Depth for Endoscopic Images](https://arxiv.org/abs/2509.18642)
*Nicolas Toussaint,Emanuele Colleoni,Ricardo Sanchez-Matilla,Joshua Sutcliffe,Vanessa Thompson,Muhammad Asad,Imanol Luengo,Danail Stoyanov*

Main category: cs.CV

TL;DR: 本文提供了内窥镜图像深度估计的基准测试和合成数据集，显著提高了模型在真实数据上的表现。


<details>
  <summary>Details</summary>
Motivation: 目前内窥镜图像领域缺乏可靠的基准和高质量的数据集，限制了深度估计的应用和研究。

Method: 通过评估先进的深度估计模型在真实未见内窥镜图像上的表现，结合合成数据集对模型进行微调。

Result: 微调深度基础模型时使用我们的合成数据集，在大多数未见真实数据上的准确性显著提高。

Conclusion: 该论文提供了一个全面的基准测试和一个新的合成数据集，以促进内窥镜图像的深度估计研究。

Abstract: Monocular relative and metric depth estimation has seen a tremendous boost in
the last few years due to the sharp advancements in foundation models and in
particular transformer based networks. As we start to see applications to the
domain of endoscopic images, there is still a lack of robust benchmarks and
high-quality datasets in that area. This paper addresses these limitations by
presenting a comprehensive benchmark of state-of-the-art (metric and relative)
depth estimation models evaluated on real, unseen endoscopic images, providing
critical insights into their generalisation and performance in clinical
scenarios. Additionally, we introduce and publish a novel synthetic dataset
(EndoSynth) of endoscopic surgical instruments paired with ground truth metric
depth and segmentation masks, designed to bridge the gap between synthetic and
real-world data. We demonstrate that fine-tuning depth foundation models using
our synthetic dataset boosts accuracy on most unseen real data by a significant
margin. By providing both a benchmark and a synthetic dataset, this work
advances the field of depth estimation for endoscopic images and serves as an
important resource for future research. Project page, EndoSynth dataset and
trained weights are available at https://github.com/TouchSurgery/EndoSynth.

</details>


### [53] [LEAF-Mamba: Local Emphatic and Adaptive Fusion State Space Model for RGB-D Salient Object Detection](https://arxiv.org/abs/2509.18683)
*Lanhu Wu,Zilin Gao,Hao Fei,Mong-Li Lee,Wynne Hsu*

Main category: cs.CV

TL;DR: 本研究提出了一种新型LEAF-Mamba模型，有效提升了RGB-D显著性物体检测的性能和效率，解决了局部语义和模态融合的问题。


<details>
  <summary>Details</summary>
Motivation: 旨在改善现有RGB-D显著性物体检测方法在局部语义和跨模态融合方面的不足。

Method: 提出了一个包含局部强调状态空间模块(LE-SSM)和自适应融合模块(AFMs)的局部强调和自适应融合状态空间模型(LEAF-Mamba)。

Result: 通过大量实验，LEAF-Mamba在效能和效率上显著优于现有的RGB-D SOD方法，并在RGB-T SOD任务上表现出色。

Conclusion: LEAF-Mamba在效能和效率上均超越了16种最先进的RGB-D SOD方法，并在RGB-T SOD任务中展现了优越的泛化能力。

Abstract: RGB-D salient object detection (SOD) aims to identify the most conspicuous
objects in a scene with the incorporation of depth cues. Existing methods
mainly rely on CNNs, limited by the local receptive fields, or Vision
Transformers that suffer from the cost of quadratic complexity, posing a
challenge in balancing performance and computational efficiency. Recently,
state space models (SSM), Mamba, have shown great potential for modeling
long-range dependency with linear complexity. However, directly applying SSM to
RGB-D SOD may lead to deficient local semantics as well as the inadequate
cross-modality fusion. To address these issues, we propose a Local Emphatic and
Adaptive Fusion state space model (LEAF-Mamba) that contains two novel
components: 1) a local emphatic state space module (LE-SSM) to capture
multi-scale local dependencies for both modalities. 2) an SSM-based adaptive
fusion module (AFM) for complementary cross-modality interaction and reliable
cross-modality integration. Extensive experiments demonstrate that the
LEAF-Mamba consistently outperforms 16 state-of-the-art RGB-D SOD methods in
both efficacy and efficiency. Moreover, our method can achieve excellent
performance on the RGB-T SOD task, proving a powerful generalization ability.

</details>


### [54] [Lightweight Vision Transformer with Window and Spatial Attention for Food Image Classification](https://arxiv.org/abs/2509.18692)
*Xinle Gao,Linghui Ye,Zhiyong Xiao*

Main category: cs.CV

TL;DR: 本研究提出了一种集成窗口多头注意机制和空间注意机制的轻量级食品图像分类算法，能在资源受限环境中实现高效的分类。


<details>
  <summary>Details</summary>
Motivation: 随着社会和科技的快速发展，食品行业对生产质量和效率的要求不断提高，自动化的食品图像分类成为解决这一需求的关键。

Method: 结合了窗口多头注意机制（WMHAM）和空间注意机制（SAM）的轻量级算法。

Result: 在Food-101和Vireo Food-172数据集上，模型分别达到了95.24%和94.33%的准确率，同时大幅减少了参数数量和FLOPs，与基线方法相比显著提高了性能。

Conclusion: 所提出的轻量级食品图像分类算法在资源受限环境下表现出色，能够有效平衡计算效率和分类性能。

Abstract: With the rapid development of society and continuous advances in science and
technology, the food industry increasingly demands higher production quality
and efficiency. Food image classification plays a vital role in enabling
automated quality control on production lines, supporting food safety
supervision, and promoting intelligent agricultural production. However, this
task faces challenges due to the large number of parameters and high
computational complexity of Vision Transformer models. To address these issues,
we propose a lightweight food image classification algorithm that integrates a
Window Multi-Head Attention Mechanism (WMHAM) and a Spatial Attention Mechanism
(SAM). The WMHAM reduces computational cost by capturing local and global
contextual features through efficient window partitioning, while the SAM
adaptively emphasizes key spatial regions to improve discriminative feature
representation. Experiments conducted on the Food-101 and Vireo Food-172
datasets demonstrate that our model achieves accuracies of 95.24% and 94.33%,
respectively, while significantly reducing parameters and FLOPs compared with
baseline methods. These results confirm that the proposed approach achieves an
effective balance between computational efficiency and classification
performance, making it well-suited for deployment in resource-constrained
environments.

</details>


### [55] [OSDA: A Framework for Open-Set Discovery and Automatic Interpretation of Land-cover in Remote Sensing Imagery](https://arxiv.org/abs/2509.18693)
*Siyi Chen,Kai Wang,Weicong Pang,Ruiming Yang,Ziru Chen,Renjun Gao,Alexis Kai Hon Lau,Dasa Gu,Chenchen Zhang,Cheng Li*

Main category: cs.CV

TL;DR: 本研究提出的OSDA框架用于无注释的开放集土地覆盖发现与描述，结合精准的分割与语义理解，具有强大潜力用于动态土地覆盖监测和大规模地球观测分析。


<details>
  <summary>Details</summary>
Motivation: 开放集土地覆盖分析需要在没有类别监督的情况下检测和分割新物体，并通过多模态推理赋予其可解释的语义标签。

Method: OSDA框架包括三个阶段：精准发现和掩膜提取、语义归属和上下文描述、以及评估和手动打分。

Result: OSDA框架通过结合像素级的准确性与高级语义理解，解决了开放世界遥感解读中的关键挑战，支持广泛的卫星影像评价。

Conclusion: 本研究提出的OSDA框架为动态土地覆盖监测提供了可扩展且可解释的解决方案，展示了在自动制图更新和大规模地球观测分析中的强大潜力。

Abstract: Open-set land-cover analysis in remote sensing requires the ability to
achieve fine-grained spatial localization and semantically open categorization.
This involves not only detecting and segmenting novel objects without
categorical supervision but also assigning them interpretable semantic labels
through multimodal reasoning. In this study, we introduce OSDA, an integrated
three-stage framework for annotation-free open-set land-cover discovery,
segmentation, and description. The pipeline consists of: (1) precise discovery
and mask extraction with a promptable fine-tuned segmentation model (SAM), (2)
semantic attribution and contextual description via a two-phase fine-tuned
multimodal large language model (MLLM), and (3) LLM-as-judge and manual scoring
of the MLLMs evaluation. By combining pixel-level accuracy with high-level
semantic understanding, OSDA addresses key challenges in open-world remote
sensing interpretation. Designed to be architecture-agnostic and label-free,
the framework supports robust evaluation across diverse satellite imagery
without requiring manual annotation. Our work provides a scalable and
interpretable solution for dynamic land-cover monitoring, showing strong
potential for automated cartographic updating and large-scale earth observation
analysis.

</details>


### [56] [Overview of PlantCLEF 2021: cross-domain plant identification](https://arxiv.org/abs/2509.18697)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: 本研究探讨了如何利用标本馆的植物记录改善热带地区的植物自动识别，展示了数据集与评估结果。


<details>
  <summary>Details</summary>
Motivation: 旨在提高对热带地区植物的自动识别，填补数据不足的空白。

Method: 使用了跨领域分类任务的方法，将几百千个标本与几千张照片对照学习。

Result: 评估结果表明，结合标本与照片的方法有效提升了植物识别准确度。

Conclusion: 通过结合标本样本与实地照片，植物自动识别在数据稀缺地区得到了显著改善。

Abstract: Automated plant identification has improved considerably thanks to recent
advances in deep learning and the availability of training data with more and
more field photos. However, this profusion of data concerns only a few tens of
thousands of species, mainly located in North America and Western Europe, much
less in the richest regions in terms of biodiversity such as tropical
countries. On the other hand, for several centuries, botanists have
systematically collected, catalogued and stored plant specimens in herbaria,
especially in tropical regions, and recent efforts by the biodiversity
informatics community have made it possible to put millions of digitised
records online. The LifeCLEF 2021 plant identification challenge (or "PlantCLEF
2021") was designed to assess the extent to which automated identification of
flora in data-poor regions can be improved by using herbarium collections. It
is based on a dataset of about 1,000 species mainly focused on the Guiana
Shield of South America, a region known to have one of the highest plant
diversities in the world. The challenge was evaluated as a cross-domain
classification task where the training set consisted of several hundred
thousand herbarium sheets and a few thousand photos to allow learning a
correspondence between the two domains. In addition to the usual metadata
(location, date, author, taxonomy), the training data also includes the values
of 5 morphological and functional traits for each species. The test set
consisted exclusively of photos taken in the field. This article presents the
resources and evaluations of the assessment carried out, summarises the
approaches and systems used by the participating research groups and provides
an analysis of the main results.

</details>


### [57] [AGSwap: Overcoming Category Boundaries in Object Fusion via Adaptive Group Swapping](https://arxiv.org/abs/2509.18699)
*Zedong Zhang,Ying Tai,Jianjun Qian,Jian Yang,Jun Li*

Main category: cs.CV

TL;DR: 提出了AGSwap，一种有效的多类别对象融合方法，结合了新数据集COF，显著改善了文本到图像生成的视觉一致性和质量。


<details>
  <summary>Details</summary>
Motivation: 针对当前文本到图像生成中多类别对象融合存在的偏差和不一致性，提出了一种新颖的解决方案以改善视觉效果和语义一致性。

Method: AGSwap包括两个核心组成部分：基于组的嵌入交换和自适应组更新，后者基于平衡评估分数进行动态优化。

Result: AGSwap在各种文本提示下表现优于目前最先进的组合T2I方法，展示了其在虚拟现实、数字媒体等领域的应用潜力。

Conclusion: AGSwap在高度复杂的文本到图像生成任务中展现出优越性能，有效解决了多类别对象融合的困难，并通过提供COF数据集推动研究进展。

Abstract: Fusing cross-category objects to a single coherent object has gained
increasing attention in text-to-image (T2I) generation due to its broad
applications in virtual reality, digital media, film, and gaming. However,
existing methods often produce biased, visually chaotic, or semantically
inconsistent results due to overlapping artifacts and poor integration.
Moreover, progress in this field has been limited by the absence of a
comprehensive benchmark dataset. To address these problems, we propose
\textbf{Adaptive Group Swapping (AGSwap)}, a simple yet highly effective
approach comprising two key components: (1) Group-wise Embedding Swapping,
which fuses semantic attributes from different concepts through feature
manipulation, and (2) Adaptive Group Updating, a dynamic optimization mechanism
guided by a balance evaluation score to ensure coherent synthesis.
Additionally, we introduce \textbf{Cross-category Object Fusion (COF)}, a
large-scale, hierarchically structured dataset built upon ImageNet-1K and
WordNet. COF includes 95 superclasses, each with 10 subclasses, enabling
451,250 unique fusion pairs. Extensive experiments demonstrate that AGSwap
outperforms state-of-the-art compositional T2I methods, including GPT-Image-1
using simple and complex prompts.

</details>


### [58] [Overview of LifeCLEF Plant Identification task 2019: diving into data deficient tropical countries](https://arxiv.org/abs/2509.18705)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: 本文介绍了PlantCLEF 2019挑战，评估植物识别系统，研究植物多样性丰富地区的植物物种。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习和训练数据的进步使自动化植物识别有所提高，但全球植物物种识别依然面临数据不足的挑战。

Method: 评估自动化植物识别系统的性能，与最佳热带植物专家进行比较。

Result: 研究表明，参与系统的表现与热带植物专家进行了比较，并对各组采用的方法和系统进行了总结与分析。

Conclusion: 本文总结了PlantCLEF 2019植物识别挑战的资源与评估，分析了参与研究组的主要成果。

Abstract: Automated identification of plants has improved considerably thanks to the
recent progress in deep learning and the availability of training data.
However, this profusion of data only concerns a few tens of thousands of
species, while the planet has nearly 369K. The LifeCLEF 2019 Plant
Identification challenge (or "PlantCLEF 2019") was designed to evaluate
automated identification on the flora of data deficient regions. It is based on
a dataset of 10K species mainly focused on the Guiana shield and the Northern
Amazon rainforest, an area known to have one of the greatest diversity of
plants and animals in the world. As in the previous edition, a comparison of
the performance of the systems evaluated with the best tropical flora experts
was carried out. This paper presents the resources and assessments of the
challenge, summarizes the approaches and systems employed by the participating
research groups, and provides an analysis of the main outcomes.

</details>


### [59] [RSVG-ZeroOV: Exploring a Training-Free Framework for Zero-Shot Open-Vocabulary Visual Grounding in Remote Sensing Images](https://arxiv.org/abs/2509.18711)
*Ke Li,Di Wang,Ting Wang,Fuyu Dong,Yiming Zhang,Luyao Zhang,Xiangyu Wang,Shaofeng Li,Quan Wang*

Main category: cs.CV

TL;DR: RSVG-ZeroOV 是一个无须训练的框架，通过高效利用冻结的通用基础模型，提供了一种零样本开放词汇的遥感视觉定位解决方案，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法由于依赖封闭词汇，使其在开放世界场景中应用受限；虽然最新的尝试利用通用基础模型进行开放词汇 RSVG，但过于依赖昂贵的高质量数据集和耗时的微调，因此需要寻找新的解决方案。

Method: RSVG-ZeroOV 包括三个关键阶段：概述、聚焦和演变，分别使用视觉语言模型、扩散模型和注意力演变模块以增强图像与文本之间的语义关联以及目标的细节信息。

Result: RSVG-ZeroOV 在不进行复杂的任务特定训练的情况下，通过使用冷冻通用基础模型，成功提高了零样本开放词汇的遥感视觉定位性能，并在广泛实验中超越了现有方法。

Conclusion: RSVG-ZeroOV 是一个高效且可扩展的解决方案，在没有特定训练的情况下，能够在零样本开放词汇的遥感视觉定位任务中 consistently outperform 现有的弱监督和零样本方法。

Abstract: Remote sensing visual grounding (RSVG) aims to localize objects in remote
sensing images based on free-form natural language expressions. Existing
approaches are typically constrained to closed-set vocabularies, limiting their
applicability in open-world scenarios. While recent attempts to leverage
generic foundation models for open-vocabulary RSVG, they overly rely on
expensive high-quality datasets and time-consuming fine-tuning. To address
these limitations, we propose \textbf{RSVG-ZeroOV}, a training-free framework
that aims to explore the potential of frozen generic foundation models for
zero-shot open-vocabulary RSVG. Specifically, RSVG-ZeroOV comprises three key
stages: (i) Overview: We utilize a vision-language model (VLM) to obtain
cross-attention\footnote[1]{In this paper, although decoder-only VLMs use
self-attention over all tokens, we refer to the image-text interaction part as
cross-attention to distinguish it from pure visual self-attention.}maps that
capture semantic correlations between text queries and visual regions. (ii)
Focus: By leveraging the fine-grained modeling priors of a diffusion model
(DM), we fill in gaps in structural and shape information of objects, which are
often overlooked by VLM. (iii) Evolve: A simple yet effective attention
evolution module is introduced to suppress irrelevant activations, yielding
purified segmentation masks over the referred objects. Without cumbersome
task-specific training, RSVG-ZeroOV offers an efficient and scalable solution.
Extensive experiments demonstrate that the proposed framework consistently
outperforms existing weakly-supervised and zero-shot methods.

</details>


### [60] [What Makes You Unique? Attribute Prompt Composition for Object Re-Identification](https://arxiv.org/abs/2509.18715)
*Yingquan Wang,Pingping Zhang,Chong Sun,Dong Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: 本文提出了一个属性提示组合框架(APC)，旨在通过文本语义增强对象重新识别的辨别性和泛化能力，取得了优于现有方法的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的单域和跨域模型在识别过程中存在过拟合或对特定特征的抑制，从而限制了其在现实世界中的应用。因此需要更加有效的框架来提高模型的辨别性和泛化能力。

Method: 提出了一个属性提示组合框架(APC)，通过构建一个语义属性字典(SAD)和一个适应性提示组合模块(PCM)，来共同增强辨别性和泛化能力。同时采用快速-慢速训练策略(FSTS)，平衡ReID特有的辨别性与可泛化的表示学习。

Result: 通过在多个常规和领域泛化(ReID)数据集上的广泛实验，验证了我们提出的框架优于现有的技术，显示出在辨别性和泛化方面的卓越表现。

Conclusion: 我们的框架在辨别性和泛化能力方面都超越了最先进的方法，尤其在常规和领域泛化(ReID)数据集上表现优异。

Abstract: Object Re-IDentification (ReID) aims to recognize individuals across
non-overlapping camera views. While recent advances have achieved remarkable
progress, most existing models are constrained to either single-domain or
cross-domain scenarios, limiting their real-world applicability. Single-domain
models tend to overfit to domain-specific features, whereas cross-domain models
often rely on diverse normalization strategies that may inadvertently suppress
identity-specific discriminative cues. To address these limitations, we propose
an Attribute Prompt Composition (APC) framework, which exploits textual
semantics to jointly enhance discrimination and generalization. Specifically,
we design an Attribute Prompt Generator (APG) consisting of a Semantic
Attribute Dictionary (SAD) and a Prompt Composition Module (PCM). SAD is an
over-complete attribute dictionary to provide rich semantic descriptions, while
PCM adaptively composes relevant attributes from SAD to generate discriminative
attribute-aware features. In addition, motivated by the strong generalization
ability of Vision-Language Models (VLM), we propose a Fast-Slow Training
Strategy (FSTS) to balance ReID-specific discrimination and generalizable
representation learning. Specifically, FSTS adopts a Fast Update Stream (FUS)
to rapidly acquire ReID-specific discriminative knowledge and a Slow Update
Stream (SUS) to retain the generalizable knowledge inherited from the
pre-trained VLM. Through a mutual interaction, the framework effectively
focuses on ReID-relevant features while mitigating overfitting. Extensive
experiments on both conventional and Domain Generalized (DG) ReID datasets
demonstrate that our framework surpasses state-of-the-art methods, exhibiting
superior performances in terms of both discrimination and generalization. The
source code is available at https://github.com/AWangYQ/APC.

</details>


### [61] [Pre-training CLIP against Data Poisoning with Optimal Transport-based Matching and Alignment](https://arxiv.org/abs/2509.18717)
*Tong Zhang,Kuofeng Gao,Jiawang Bai,Leo Yu Zhang,Xin Yin,Zonghui Wang,Shouling Ji,Wenzhi Chen*

Main category: cs.CV

TL;DR: 本文提出OTCCLIP框架来修复CLIP模型的图像-字幕对，采用最优传输方法来增强防御效果，有效降低数据中毒攻击成功率并提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 针对现有防御方法仅依赖全局表示而忽略细粒度特征的问题，提出OTCCLIP框架以改善CLIP模型的鲁棒性。

Method: 提出了一种基于最优传输的框架来重构图像-字幕对，通过新的最优传输距离度量重新分配新的字幕，并鼓励模态之间和模态内部的细粒度对齐。

Result: OTCCLIP通过重构图像-字幕对成功降低了数据中毒攻击的效果，并相比以往方法在零-shot和线性探测性能上显著提升。

Conclusion: OTCCLIP成功降低了数据中毒攻击的成功率，并显著提升了在受污染数据集上训练的CLIP的零-shot性能和线性探测性能。

Abstract: Recent studies have shown that Contrastive Language-Image Pre-training (CLIP)
models are threatened by targeted data poisoning and backdoor attacks due to
massive training image-caption pairs crawled from the Internet. Previous
defense methods correct poisoned image-caption pairs by matching a new caption
for each image. However, the matching process relies solely on the global
representations of images and captions, overlooking fine-grained features of
visual and textual features. It may introduce incorrect image-caption pairs and
harm the CLIP pre-training. To address their limitations, we propose an Optimal
Transport-based framework to reconstruct image-caption pairs, named OTCCLIP. We
propose a new optimal transport-based distance measure between fine-grained
visual and textual feature sets and re-assign new captions based on the
proposed optimal transport distance. Additionally, to further reduce the
negative impact of mismatched pairs, we encourage the inter- and intra-modality
fine-grained alignment by employing optimal transport-based objective
functions. Our experiments demonstrate that OTCCLIP can successfully decrease
the attack success rates of poisoning attacks. Also, compared to previous
methods, OTCCLIP significantly improves CLIP's zero-shot and linear probing
performance trained on poisoned datasets.

</details>


### [62] [Knowledge Transfer from Interaction Learning](https://arxiv.org/abs/2509.18733)
*Yilin Gao,Kangyi Chen,Zhongxing Peng,Hengjie Lu,Shugong Xu*

Main category: cs.CV

TL;DR: 学习互动（LFI）框架通过建模视觉理解的互动过程，成功提高了视觉基础模型的知识转移效率，在多个视觉任务中展现了显著的性能改善。


<details>
  <summary>Details</summary>
Motivation: 当前视觉基础模型在知识转移方面存在局限性，而视觉语言模型在跨模态交互建模上具有优势，二者之间的代表性差距限制了在多样化视觉任务中的表现。

Method: 通过引入互动查询和基于互动的监督机制，LFI框架实现了对视觉理解的动态互动模式的捕捉。

Result: 在多个基准测试中，LFI框架实现了显著的性能提升，TinyImageNet分类任务上达到3.3 mAP的提升，COCO检测/分割任务上达到1.6mAP/2.4AP的提升，且在零样本设置下表现出色。

Conclusion: 提出的学习互动（LFI）框架通过明确建模视觉理解的互动过程，提高了视觉基础模型与视觉语言模型之间的知识转移效率，展现出更强的跨领域通用性。

Abstract: Current visual foundation models (VFMs) face a fundamental limitation in
transferring knowledge from vision language models (VLMs), while VLMs excel at
modeling cross-modal interactions through unified representation spaces,
existing VFMs predominantly adopt result-oriented paradigms that neglect the
underlying interaction processes. This representational discrepancy hinders
effective knowledge transfer and limits generalization across diverse vision
tasks. We propose Learning from Interactions (LFI), a cognitive-inspired
framework that addresses this gap by explicitly modeling visual understanding
as an interactive process. Our key insight is that capturing the dynamic
interaction patterns encoded in pre-trained VLMs enables more faithful and
efficient knowledge transfer to VFMs. The approach centers on two technical
innovations, Interaction Queries, which maintain persistent relational
structures across network layers, and interaction-based supervision, derived
from the cross-modal attention mechanisms of VLMs. Comprehensive experiments
demonstrate consistent improvements across multiple benchmarks, achieving 3.3
and 1.6mAP/2.4AP absolute gains on TinyImageNet classification and COCO
detection/segmentation respectively, with minimal parameter overhead and faster
convergence. The framework particularly excels in cross-domain settings,
delivering 2.4 and 9.3 zero-shot improvements on PACS and VLCS. Human
evaluations further confirm its cognitive alignment, outperforming
result-oriented methods by 2.7 times in semantic consistency metrics.

</details>


### [63] [HyPSAM: Hybrid Prompt-driven Segment Anything Model for RGB-Thermal Salient Object Detection](https://arxiv.org/abs/2509.18738)
*Ruichao Hou,Xingyuan Li,Tongwei Ren,Dongming Zhou,Gangshan Wu,Jinde Cao*

Main category: cs.CV

TL;DR: 本文提出了一种新的混合提示驱动的显著性检测模型HyPSAM，通过动态融合网络和优化策略，有效提高了RGB-热成像显著性物体检测的性能，具有显著的灵活性和优越性。


<details>
  <summary>Details</summary>
Motivation: 解决RGB-热成像显著性物体检测中的特征融合不足和数据稀缺问题。

Method: 提出了动态融合网络(DFNet)和插件式精炼网络(P2RNet)来实现高质量显著性图的生成和优化。

Result: 在三个公共数据集上，HyPSAM的性能达到了最新水平，且具有良好的通用性，与多种方法无缝集成，显著提升性能。

Conclusion: HyPSAM在RGB-热成像显著性物体检测任务中表现出卓越的性能，展示了提示工程在此领域的潜力。

Abstract: RGB-thermal salient object detection (RGB-T SOD) aims to identify prominent
objects by integrating complementary information from RGB and thermal
modalities. However, learning the precise boundaries and complete objects
remains challenging due to the intrinsic insufficient feature fusion and the
extrinsic limitations of data scarcity. In this paper, we propose a novel
hybrid prompt-driven segment anything model (HyPSAM), which leverages the
zero-shot generalization capabilities of the segment anything model (SAM) for
RGB-T SOD. Specifically, we first propose a dynamic fusion network (DFNet) that
generates high-quality initial saliency maps as visual prompts. DFNet employs
dynamic convolution and multi-branch decoding to facilitate adaptive
cross-modality interaction, overcoming the limitations of fixed-parameter
kernels and enhancing multi-modal feature representation. Moreover, we propose
a plug-and-play refinement network (P2RNet), which serves as a general
optimization strategy to guide SAM in refining saliency maps by using hybrid
prompts. The text prompt ensures reliable modality input, while the mask and
box prompts enable precise salient object localization. Extensive experiments
on three public datasets demonstrate that our method achieves state-of-the-art
performance. Notably, HyPSAM has remarkable versatility, seamlessly integrating
with different RGB-T SOD methods to achieve significant performance gains,
thereby highlighting the potential of prompt engineering in this field. The
code and results of our method are available at:
https://github.com/milotic233/HyPSAM.

</details>


### [64] [Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions](https://arxiv.org/abs/2509.18847)
*Junhao Su,Yuanliang Wan,Junwei Yang,Hengyu Shi,Tianyang Han,Junfeng Luo,Yurui Qiu*

Main category: cs.CV

TL;DR: 提出结构化反思方法，通过优化反思过程，提升工具交互的成功率和可靠性，并为模型从失败中学习提供新途径。


<details>
  <summary>Details</summary>
Motivation: 现有的自我反思实践依赖启发式提示或单向推理，无法有效诊断和修复错误。

Method: 结合DAPO和GSPO目标及针对工具使用的奖励机制，优化步骤策略：反思、调用、最终结果。

Result: 在BFCL v3和Tool-Reflection-Bench上的实验显示，多轮工具调用成功率和错误恢复有显著提升，同时减少了冗余调用。

Conclusion: 将反思过程显性化并直接优化，提高了工具交互的可靠性，并为代理从失败中学习提供了可复现的路径。

Abstract: Tool-augmented large language models (LLMs) are usually trained with
supervised imitation or coarse-grained reinforcement learning that optimizes
single tool calls. Current self-reflection practices rely on heuristic prompts
or one-way reasoning: the model is urged to 'think more' instead of learning
error diagnosis and repair. This is fragile in multi-turn interactions; after a
failure the model often repeats the same mistake. We propose structured
reflection, which turns the path from error to repair into an explicit,
controllable, and trainable action. The agent produces a short yet precise
reflection: it diagnoses the failure using evidence from the previous step and
then proposes a correct, executable follow-up call. For training we combine
DAPO and GSPO objectives with a reward scheme tailored to tool use, optimizing
the stepwise strategy Reflect, then Call, then Final. To evaluate, we introduce
Tool-Reflection-Bench, a lightweight benchmark that programmatically checks
structural validity, executability, parameter correctness, and result
consistency. Tasks are built as mini trajectories of erroneous call,
reflection, and corrected call, with disjoint train and test splits.
Experiments on BFCL v3 and Tool-Reflection-Bench show large gains in multi-turn
tool-call success and error recovery, and a reduction of redundant calls. These
results indicate that making reflection explicit and optimizing it directly
improves the reliability of tool interaction and offers a reproducible path for
agents to learn from failure.

</details>


### [65] [TriFusion-AE: Language-Guided Depth and LiDAR Fusion for Robust Point Cloud Processing](https://arxiv.org/abs/2509.18743)
*Susmit Neogi*

Main category: cs.CV

TL;DR: TriFusion-AE结合文本、深度图和LiDAR点云，提升了对抗干扰和噪声的重建鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 针对传统自编码器在处理噪声、遮挡和对抗干扰时性能下降的问题，提出了更为鲁棒的多模态融合方法。

Method: 提出TriFusion-AE，这是一个多模态交叉注意力自编码器，集成了文本先验、单目深度图和LiDAR点云。

Result: 在nuScenes-mini数据集上评估，TriFusion-AE在重噪声和强对抗攻击下实现了显著改善。

Conclusion: TriFusion-AE显著提高了在强对抗攻击和重噪声下的重建鲁棒性，克服了传统CNN自编码器的局限性。

Abstract: LiDAR-based perception is central to autonomous driving and robotics, yet raw
point clouds remain highly vulnerable to noise, occlusion, and adversarial
corruptions. Autoencoders offer a natural framework for denoising and
reconstruction, but their performance degrades under challenging real-world
conditions. In this work, we propose TriFusion-AE, a multimodal cross-attention
autoencoder that integrates textual priors, monocular depth maps from
multi-view images, and LiDAR point clouds to improve robustness. By aligning
semantic cues from text, geometric (depth) features from images, and spatial
structure from LiDAR, TriFusion-AE learns representations that are resilient to
stochastic noise and adversarial perturbations. Interestingly, while showing
limited gains under mild perturbations, our model achieves significantly more
robust reconstruction under strong adversarial attacks and heavy noise, where
CNN-based autoencoders collapse. We evaluate on the nuScenes-mini dataset to
reflect realistic low-data deployment scenarios. Our multimodal fusion
framework is designed to be model-agnostic, enabling seamless integration with
any CNN-based point cloud autoencoder for joint representation learning.

</details>


### [66] [VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction](https://arxiv.org/abs/2509.19002)
*Hao Wang,Eiki Murata,Lingfang Zhang,Ayako Sato,So Fukuda,Ziqi Yin,Wentao Hu,Keisuke Nakao,Yusuke Nakamura,Sebastian Zwirner,Yi-Chia Chen,Hiroyuki Otomo,Hiroki Ouchi,Daisuke Kawahara*

Main category: cs.CV

TL;DR: 本文提出VIR-Bench基准，评估多模态大语言模型在长途旅行视频理解中的表现，显示此领域的现有模型面临挑战，并通过原型旅行规划代理验证评估协议的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有视频基准主要关注室内场景或短距离户外活动，对长途旅行的挑战未得到充分探索，掌握延伸的地理时序轨迹对下一代MLLM至关重要。

Method: 提出VIR-Bench，一个包含200个旅行视频的新基准，旨在评估和推动MLLM的地理时序智能。

Result: 实验结果显示最先进的MLLM在处理长时间和长距离的视频时，难以取得高分，表明其挑战性，为开发分析代理提供了依据。

Conclusion: VIR-Bench不仅有效评估模型性能，还转化为用户应用中的实质性性能提升。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly enhanced video understanding capabilities, opening new
possibilities for practical applications. Yet current video benchmarks focus
largely on indoor scenes or short-range outdoor activities, leaving the
challenges associated with long-distance travel largely unexplored. Mastering
extended geospatial-temporal trajectories is critical for next-generation
MLLMs, underpinning real-world tasks such as embodied-AI planning and
navigation. To bridge this gap, we present VIR-Bench, a novel benchmark
consisting of 200 travel videos that frames itinerary reconstruction as a
challenging task designed to evaluate and push forward MLLMs'
geospatial-temporal intelligence. Experimental results reveal that
state-of-the-art MLLMs, including proprietary ones, struggle to achieve high
scores, underscoring the difficulty of handling videos that span extended
spatial and temporal scales. Moreover, we conduct an in-depth case study in
which we develop a prototype travel-planning agent that leverages the insights
gained from VIR-Bench. The agent's markedly improved itinerary recommendations
verify that our evaluation protocol not only benchmarks models effectively but
also translates into concrete performance gains in user-facing applications.

</details>


### [67] [COLT: Enhancing Video Large Language Models with Continual Tool Usage](https://arxiv.org/abs/2509.18754)
*Yuyang Liu,Xinyuan Shi,Bang Yang,Peilin Zhou,Jiahua Dong,Long Chen,Ian Reid,Xiaondan Liang*

Main category: cs.CV

TL;DR: 本研究提出COLT，即一种新的工具使用策略，能够动态适应不断变化的工具流，避免过去工具知识的遗忘，在视频理解领域取得了前所未有的成果。


<details>
  <summary>Details</summary>
Motivation: 当前工具使用方法无法适应不断变化的实时环境，存在对固定工具库的依赖，无法有效应对工具数据的演变。

Method: 提出一种名为COLT的连续工具使用方法，利用可学习的工具编码本作为特定记忆系统，动态选择相关工具。

Result: COLT在视频理解任务中的表现超越了现有的方法，验证了其有效性和优越性。

Conclusion: COLT通过引入可学习的工具编码本，成功解决了工具使用的记忆效果问题，并在视频理解任务中展示出优越性能。

Abstract: The success of Large Language Models (LLMs) has significantly propelled the
research of video understanding. To harvest the benefits of well-trained expert
models (i.e., tools), video LLMs prioritize the exploration of tool usage
capabilities. Existing methods either prompt closed-source LLMs or employ the
instruction tuning paradigm for tool-use fine-tuning. These methods, however,
assume an established repository of fixed tools and struggle to generalize to
real-world environments where tool data is perpetually evolving and streaming
in. To this end, we propose to enhance open-source video LLMs with COntinuaL
Tool usage (termed COLT), which automatically acquires tool-use ability in a
successive tool stream without suffering 'catastrophic forgetting' of the past
learned tools. Specifically, our COLT incorporates a learnable tool codebook as
a tool-specific memory system. Then relevant tools are dynamically selected
based on the similarity between user instruction and tool features within the
codebook. To unleash the tool usage potential of video LLMs, we collect a
video-centric tool-use instruction tuning dataset VideoToolBench. Extensive
experiments on both previous video LLM benchmarks and the tool-use-specific
VideoToolBench dataset demonstrate the state-of-the-art performance of our
proposed COLT.

</details>


### [68] [ColorBlindnessEval: Can Vision-Language Models Pass Color Blindness Tests?](https://arxiv.org/abs/2509.19070)
*Zijian Ling,Han Zhang,Yazhuo Zhou,Jiahao Cui*

Main category: cs.CV

TL;DR: 本文提出ColorBlindnessEval基准，以评估视觉语言模型在以色盲测试为灵感的视觉对抗场景中的鲁棒性，并揭示了其在复杂视觉信息下识别数字的不足。


<details>
  <summary>Details</summary>
Motivation: 激励是评估视觉语言模型在视觉对抗场景中的鲁棒性，以应对现实应用中数字识别的准确性要求。

Method: 通过对500幅类似于石原色盲测试图像的评估，使用9种视觉语言模型，对其进行是非题和开放式问题的性能比较。

Result: 实验结果显示出这些模型在复杂视觉模式中的数字解释能力的局限性，以及人类参与者的表现与模型之间的显著差异。

Conclusion: ColorBlindnessEval为提高视觉语言模型在复杂视觉环境中的鲁棒性提供了重要的基准工具，显现了其在面对色盲测试场景中的局限性，尤其是数字识别方面的幻觉问题。

Abstract: This paper presents ColorBlindnessEval, a novel benchmark designed to
evaluate the robustness of Vision-Language Models (VLMs) in visually
adversarial scenarios inspired by the Ishihara color blindness test. Our
dataset comprises 500 Ishihara-like images featuring numbers from 0 to 99 with
varying color combinations, challenging VLMs to accurately recognize numerical
information embedded in complex visual patterns. We assess 9 VLMs using Yes/No
and open-ended prompts and compare their performance with human participants.
Our experiments reveal limitations in the models' ability to interpret numbers
in adversarial contexts, highlighting prevalent hallucination issues. These
findings underscore the need to improve the robustness of VLMs in complex
visual environments. ColorBlindnessEval serves as a valuable tool for
benchmarking and improving the reliability of VLMs in real-world applications
where accuracy is critical.

</details>


### [69] [FixingGS: Enhancing 3D Gaussian Splatting via Training-Free Score Distillation](https://arxiv.org/abs/2509.18759)
*Zhaorui Wang,Yi Gu,Deming Zhou,Renjing Xu*

Main category: cs.CV

TL;DR: FixingGS是一个无训练方法，利用扩散模型增强稀疏视图的3D重建，解决明显伪影和多视图一致性问题，实验证明其超越现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决从稀疏视点重建3D场景时，由于视觉信息不足导致的明显伪影问题，尤其是多视图一致性不足所造成的模糊结构。

Method: 基于现有的扩散模型的蒸馏方法，以及自适应渐进增强方案，针对稀疏视图进行3D重建。

Result: FixingGS在视觉质量和重建性能方面表现超越现有方法，通过蒸馏技术提供更准确且跨视图一致的扩散先验。

Conclusion: FixingGS在稀疏视图3DGS重建增强中超越了现有的最先进的方法，具有更优的视觉质量和重建性能。

Abstract: Recently, 3D Gaussian Splatting (3DGS) has demonstrated remarkable success in
3D reconstruction and novel view synthesis. However, reconstructing 3D scenes
from sparse viewpoints remains highly challenging due to insufficient visual
information, which results in noticeable artifacts persisting across the 3D
representation. To address this limitation, recent methods have resorted to
generative priors to remove artifacts and complete missing content in
under-constrained areas. Despite their effectiveness, these approaches struggle
to ensure multi-view consistency, resulting in blurred structures and
implausible details. In this work, we propose FixingGS, a training-free method
that fully exploits the capabilities of the existing diffusion model for
sparse-view 3DGS reconstruction enhancement. At the core of FixingGS is our
distillation approach, which delivers more accurate and cross-view coherent
diffusion priors, thereby enabling effective artifact removal and inpainting.
In addition, we propose an adaptive progressive enhancement scheme that further
refines reconstructions in under-constrained regions. Extensive experiments
demonstrate that FixingGS surpasses existing state-of-the-art methods with
superior visual quality and reconstruction performance. Our code will be
released publicly.

</details>


### [70] [Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning](https://arxiv.org/abs/2509.19090)
*Guoxin Wang,Jun Zhao,Xinyi Liu,Yanbo Liu,Xuyang Cao,Chao Li,Zhuoyun Liu,Qintian Sun,Fangru Zhou,Haoqiang Xing,Zhenhong Yang*

Main category: cs.CV

TL;DR: Citrus-V是一种多模态医学基础模型，结合图像分析和文本推理，显著提升医学成像和诊断的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有医学成像模型专注于狭窄的任务，导致泛化能力受限，而现实临床应用需要精确的视觉定位和多模态整合。

Method: Citrus-V结合图像分析与文本推理，集成检测、分割和多模态思维推理，支持像素级病变定位、结构化报告生成和诊断推理。

Result: Citrus-V提出了一种新型的多模态训练方法，并发布了一个覆盖推理、检测、分割和文档理解任务的开源数据集。

Conclusion: Citrus-V能够在多个基准测试中超越现有的开源医学模型和专家级成像系统，提供从视觉基础到临床推理的统一流程。

Abstract: Medical imaging provides critical evidence for clinical diagnosis, treatment
planning, and surgical decisions, yet most existing imaging models are narrowly
focused and require multiple specialized networks, limiting their
generalization. Although large-scale language and multimodal models exhibit
strong reasoning and multi-task capabilities, real-world clinical applications
demand precise visual grounding, multimodal integration, and chain-of-thought
reasoning. We introduce Citrus-V, a multimodal medical foundation model that
combines image analysis with textual reasoning. The model integrates detection,
segmentation, and multimodal chain-of-thought reasoning, enabling pixel-level
lesion localization, structured report generation, and physician-like
diagnostic inference in a single framework. We propose a novel multimodal
training approach and release a curated open-source data suite covering
reasoning, detection, segmentation, and document understanding tasks.
Evaluations demonstrate that Citrus-V outperforms existing open-source medical
models and expert-level imaging systems across multiple benchmarks, delivering
a unified pipeline from visual grounding to clinical reasoning and supporting
precise lesion quantification, automated reporting, and reliable second
opinions.

</details>


### [71] [Bi-VLM: Pushing Ultra-Low Precision Post-Training Quantization Boundaries in Vision-Language Models](https://arxiv.org/abs/2509.18763)
*Xijun Wang,Junyun Huang,Rayyan Abdalla,Chengyuan Zhang,Ruiqi Xian,Dinesh Manocha*

Main category: cs.CV

TL;DR: 本研究提出Bi-VLM，通过有效的量化技术和token pruning提升视觉语言模型的计算效率，显著超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 由于视觉语言模型的高计算成本和内存需求，该研究旨在解决其在硬件受限环境中的可行性问题。

Method: 我们提出了Bi-VLM，通过基于高斯分位数非均匀分离模型权重，并采用了一种关注显著性的混合量化算法。

Result: Bi-VLM在视觉问答任务中比现有最先进的技术提高了3%-47%，整体上提高了4%-45%。此外，对量化模型进行的token pruning表明，在量化模型中视觉token的冗余可高达90%-99%。

Conclusion: Bi-VLM在视觉语言模型任务上显著提升了效率，并在多个基准和模型上超越了当前最先进的技术。

Abstract: We address the critical gap between the computational demands of
vision-language models and the possible ultra-low-bit weight precision
(bitwidth $\leq2$ bits) we can use for higher efficiency. Our work is motivated
by the substantial computational cost and memory requirements of VLMs, which
restrict their applicability in hardware-constrained environments. We propose
Bi-VLM, which separates model weights non-uniformly based on the Gaussian
quantiles. Our formulation groups the model weights into outlier (salient) and
multiple inlier (unsalient) subsets, ensuring that each subset contains a
proportion of weights corresponding to its quantile in the distribution. We
propose a saliency-aware hybrid quantization algorithm and use it to quantize
weights by imposing different constraints on the scaler and binary matrices
based on the saliency metric and compression objective. We have evaluated our
approach on different VLMs. For the language model part of the VLM, our Bi-VLM
outperforms the SOTA by 3%-47% on the visual question answering task in terms
of four different benchmarks and three different models. For the overall VLM,
our Bi-VLM outperforms the SOTA by 4%-45%. We also perform token pruning on the
quantized models and observe that there is redundancy of image tokens 90% - 99%
in the quantized models. This helps us to further prune the visual tokens to
improve efficiency.

</details>


### [72] [DiSSECT: Structuring Transfer-Ready Medical Image Representations through Discrete Self-Supervision](https://arxiv.org/abs/2509.18765)
*Azad Singh,Deepak Mishra*

Main category: cs.CV

TL;DR: 本研究提出DiSSECT框架，通过离散自监督学习提高医学影像表示学习的效率和可转移性，实现在低标签条件下的高效性能。


<details>
  <summary>Details</summary>
Motivation: 在标注数据有限的情况下，自监督学习在医学影像表示学习中显示出强大的潜力，但现有方法往往依赖于复杂架构，限制了其可扩展性和普适性。

Method: 该研究提出了DiSSECT框架，通过将多尺度矢量量化整合到自监督学习中，创造了一个离散表示瓶颈，促使模型学习可重复的、结构感知的特征。

Result: DiSSECT在分类和分割任务上都取得了良好表现，要求的微调较少或不需要，并且在低标签情况下显示出特别高的标签效率。

Conclusion: DiSSECT框架表现出强大的性能，尤其在低标签环境下具有高标签效率，验证了其在多个医学影像数据集上的稳健性和通用性。

Abstract: Self-supervised learning (SSL) has emerged as a powerful paradigm for medical
image representation learning, particularly in settings with limited labeled
data. However, existing SSL methods often rely on complex architectures,
anatomy-specific priors, or heavily tuned augmentations, which limit their
scalability and generalizability. More critically, these models are prone to
shortcut learning, especially in modalities like chest X-rays, where anatomical
similarity is high and pathology is subtle. In this work, we introduce DiSSECT
-- Discrete Self-Supervision for Efficient Clinical Transferable
Representations, a framework that integrates multi-scale vector quantization
into the SSL pipeline to impose a discrete representational bottleneck. This
constrains the model to learn repeatable, structure-aware features while
suppressing view-specific or low-utility patterns, improving representation
transfer across tasks and domains. DiSSECT achieves strong performance on both
classification and segmentation tasks, requiring minimal or no fine-tuning, and
shows particularly high label efficiency in low-label regimes. We validate
DiSSECT across multiple public medical imaging datasets, demonstrating its
robustness and generalizability compared to existing state-of-the-art
approaches.

</details>


### [73] [Real-time Deer Detection and Warning in Connected Vehicles via Thermal Sensing and Deep Learning](https://arxiv.org/abs/2509.18779)
*Hemanth Puppala,Wayne Sarasua,Srinivas Biyaguda,Farhad Farzinpour,Mashrur Chowdhury*

Main category: cs.CV

TL;DR: 本研究开发了一种结合热成像和车辆联网的实时警告系统，有效减少鹿与车辆碰撞事件，实验表现卓越且在多种环境下有效。


<details>
  <summary>Details</summary>
Motivation: 鹿与车辆碰撞在美国成为严重的安全挑战，导致人员伤亡及经济损失，同时也影响到鹿种群的减少。

Method: 本研究采用热成像、深度学习和车辆对一切通信技术构建实时检测与警告系统。

Result: 实验结果显示系统在检测方面具有极高的准确性，具备在各种天气条件下的鲁棒性，并能够及时向驾驶员提供警告。

Conclusion: 本研究为减少鹿与车辆碰撞提供了一条可行的技术路径，通过热成像和联网车辆技术实现。

Abstract: Deer-vehicle collisions represent a critical safety challenge in the United
States, causing nearly 2.1 million incidents annually and resulting in
approximately 440 fatalities, 59,000 injuries, and 10 billion USD in economic
damages. These collisions also contribute significantly to declining deer
populations. This paper presents a real-time detection and driver warning
system that integrates thermal imaging, deep learning, and
vehicle-to-everything communication to help mitigate deer-vehicle collisions.
Our system was trained and validated on a custom dataset of over 12,000 thermal
deer images collected in Mars Hill, North Carolina. Experimental evaluation
demonstrates exceptional performance with 98.84 percent mean average precision,
95.44 percent precision, and 95.96 percent recall. The system was field tested
during a follow-up visit to Mars Hill and readily sensed deer providing the
driver with advanced warning. Field testing validates robust operation across
diverse weather conditions, with thermal imaging maintaining between 88 and 92
percent detection accuracy in challenging scenarios where conventional visible
light based cameras achieve less than 60 percent effectiveness. When a high
probability threshold is reached sensor data sharing messages are broadcast to
surrounding vehicles and roadside units via cellular vehicle to everything
(CV2X) communication devices. Overall, our system achieves end to end latency
consistently under 100 milliseconds from detection to driver alert. This
research establishes a viable technological pathway for reducing deer-vehicle
collisions through thermal imaging and connected vehicles.

</details>


### [74] [Towards Application Aligned Synthetic Surgical Image Synthesis](https://arxiv.org/abs/2509.18796)
*Danush Kumar Venkatesh,Stefanie Speidel*

Main category: cs.CV

TL;DR: 为了应对外科数据稀缺，提出SAADi框架，通过优选图像对齐扩散模型，与下游目标一致，实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 外科数据的稀缺性使得深度学习系统在计算机辅助干预中面临挑战，而扩散模型虽然能合成逼真图像，但存在数据记忆化的问题。

Method: 构建优选和非优选合成图像对，并对扩散模型进行轻量级微调，以将图像生成过程明确对齐至下游目标。

Result: 在三个外科数据集上的实验中，分类任务提升了7%至9%，分割任务提升了2%至10%，并且对少数类的改善尤为显著。通过迭代细化合成样本，性能进一步提升了4%至10%。

Conclusion: SAADi方法通过构建优选与非优选合成图像的对，成功解决了数据稀缺问题，并在外科视觉应用中实现了基于任务的对齐。

Abstract: The scarcity of annotated surgical data poses a significant challenge for
developing deep learning systems in computer-assisted interventions. While
diffusion models can synthesize realistic images, they often suffer from data
memorization, resulting in inconsistent or non-diverse samples that may fail to
improve, or even harm, downstream performance. We introduce \emph{Surgical
Application-Aligned Diffusion} (SAADi), a new framework that aligns diffusion
models with samples preferred by downstream models. Our method constructs pairs
of \emph{preferred} and \emph{non-preferred} synthetic images and employs
lightweight fine-tuning of diffusion models to align the image generation
process with downstream objectives explicitly. Experiments on three surgical
datasets demonstrate consistent gains of $7$--$9\%$ in classification and
$2$--$10\%$ in segmentation tasks, with the considerable improvements observed
for underrepresented classes. Iterative refinement of synthetic samples further
boosts performance by $4$--$10\%$. Unlike baseline approaches, our method
overcomes sample degradation and establishes task-aware alignment as a key
principle for mitigating data scarcity and advancing surgical vision
applications.

</details>


### [75] [A Kernel Space-based Multidimensional Sparse Model for Dynamic PET Image Denoising](https://arxiv.org/abs/2509.18801)
*Kuang Xiaodong,Li Bingxuan,Li Yuan,Rao Fan,Ma Gege,Xie Qingguo,Mok Greta S P,Liu Huafeng,Zhu Wentao*

Main category: cs.CV

TL;DR: 本研究提出了一种基于神经网络的动态PET图像去噪模型Neural KMDS-Net，利用时空相关性，显著提高图像质量。


<details>
  <summary>Details</summary>
Motivation: 动态正电子发射断层扫描(PET)中的短时间帧由于统计信息有限而难以获得高图像质量，深度学习在医学图像去噪任务中的有效性激发了该研究。

Method: 建立基于内核空间的多维稀疏(KMDS)模型，并用神经网络替换参数估计的内在形式，以实现自适应参数优化，形成端到端的神经KMDS-Net。

Result: 广泛的实验结果表明Neural KMDS-Net在模拟和真实数据上均展现出强大的去噪性能，超越了以往的基准方法。

Conclusion: 所提出的Neural KMDS-Net在动态PET图像去噪性能上优于之前的方法，可以有效实现高时间和空间分辨率。

Abstract: Achieving high image quality for temporal frames in dynamic positron emission
tomography (PET) is challenging due to the limited statistic especially for the
short frames. Recent studies have shown that deep learning (DL) is useful in a
wide range of medical image denoising tasks. In this paper, we propose a
model-based neural network for dynamic PET image denoising. The inter-frame
spatial correlation and intra-frame structural consistency in dynamic PET are
used to establish the kernel space-based multidimensional sparse (KMDS) model.
We then substitute the inherent forms of the parameter estimation with neural
networks to enable adaptive parameters optimization, forming the end-to-end
neural KMDS-Net. Extensive experimental results from simulated and real data
demonstrate that the neural KMDS-Net exhibits strong denoising performance for
dynamic PET, outperforming previous baseline methods. The proposed method may
be used to effectively achieve high temporal and spatial resolution for dynamic
PET. Our source code is available at
https://github.com/Kuangxd/Neural-KMDS-Net/tree/main.

</details>


### [76] [Surgical Video Understanding with Label Interpolation](https://arxiv.org/abs/2509.18802)
*Garam Kim,Tae Kyeong Jeong,Juyoun Park*

Main category: cs.CV

TL;DR: 本研究提出一种新的框架，通过光流基础的标签插值和多任务学习，解决了手术过程中的标签不足问题，提高了手术场景理解及机器人辅助手术的效果。


<details>
  <summary>Details</summary>
Motivation: 全面理解手术过程中的视觉数据，以应对复杂的时序动态和多样的工具交互，这对于提升机器人辅助手术的效果至关重要。

Method: 一种结合光流基础的分割标签插值与多任务学习的框架，用于丰富稀疏的空间监督，并在训练中平衡时空信息。

Result: 通过使用经过注释的关键帧估计的光流，成功地将标签传播到相邻的未标注帧，从而改善了手术场景理解的准确性和效率。

Conclusion: 通过结合光流基础的分割标签插值和多任务学习，本研究提出的框架提高了手术场景理解的准确性和效率，从而增强了机器人辅助手术的实用性。

Abstract: Robot-assisted surgery (RAS) has become a critical paradigm in modern
surgery, promoting patient recovery and reducing the burden on surgeons through
minimally invasive approaches. To fully realize its potential, however, a
precise understanding of the visual data generated during surgical procedures
is essential. Previous studies have predominantly focused on single-task
approaches, but real surgical scenes involve complex temporal dynamics and
diverse instrument interactions that limit comprehensive understanding.
Moreover, the effective application of multi-task learning (MTL) requires
sufficient pixel-level segmentation data, which are difficult to obtain due to
the high cost and expertise required for annotation. In particular, long-term
annotations such as phases and steps are available for every frame, whereas
short-term annotations such as surgical instrument segmentation and action
detection are provided only for key frames, resulting in a significant
temporal-spatial imbalance. To address these challenges, we propose a novel
framework that combines optical flow-based segmentation label interpolation
with multi-task learning. optical flow estimated from annotated key frames is
used to propagate labels to adjacent unlabeled frames, thereby enriching sparse
spatial supervision and balancing temporal and spatial information for
training. This integration improves both the accuracy and efficiency of
surgical scene understanding and, in turn, enhances the utility of RAS.

</details>


### [77] [Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation](https://arxiv.org/abs/2509.18824)
*Yanzuo Lu,Xin Xia,Manlin Zhang,Huafeng Kuang,Jianbin Zheng,Yuxi Ren,Xuefeng Xiao*

Main category: cs.CV

TL;DR: Hyper-Bagel 是一个加速多模态理解与生成的框架，通过高效的解码和蒸馏技术，显著提高性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 旨在解决随着多模态 token 数量增加而带来的计算开销问题。

Method: 通过分而治之的策略，使用投机解码进行下一个 token 的预测，并采用多阶段蒸馏过程进行扩散去噪。

Result: 在多模态理解中实现超过 2 倍的加速，文本到图像生成加速 16.67 倍，图像编辑加速 22 倍，同时保持原模型的高质量输出。

Conclusion: Hyper-Bagel 提供了一种有效的加速框架，显著提升了多模态理解和生成任务的性能，保持了高质量的输出。

Abstract: Unified multimodal models have recently attracted considerable attention for
their remarkable abilities in jointly understanding and generating diverse
content. However, as contexts integrate increasingly numerous interleaved
multimodal tokens, the iterative processes of diffusion denoising and
autoregressive decoding impose significant computational overhead. To address
this, we propose Hyper-Bagel, a unified acceleration framework designed to
simultaneously speed up both multimodal understanding and generation tasks. Our
approach uses a divide-and-conquer strategy, employing speculative decoding for
next-token prediction and a multi-stage distillation process for diffusion
denoising. The framework delivers substantial performance gains, achieving over
a 2x speedup in multimodal understanding. For generative tasks, our resulting
lossless 6-NFE model yields a 16.67x speedup in text-to-image generation and a
22x speedup in image editing, all while preserving the high-quality output of
the original model. We further develop a highly efficient 1-NFE model that
enables near real-time interactive editing and generation. By combining
advanced adversarial distillation with human feedback learning, this model
achieves ultimate cost-effectiveness and responsiveness, making complex
multimodal interactions seamless and instantaneous.

</details>


### [78] [Benchmarking Vision-Language and Multimodal Large Language Models in Zero-shot and Few-shot Scenarios: A study on Christian Iconography](https://arxiv.org/abs/2509.18839)
*Gianmarco Spinaci,Lukas Klic,Giovanni Colavizza*

Main category: cs.CV

TL;DR: 本研究评估了多模态大型语言模型在基督教图标分类中的表现，结果表明，不同模型和输入增强方式对分类准确率有显著影响，并建议未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 评估通用VLMs和LLMs在基督教图标的单标签分类任务中的能力，理解其在视觉复杂性和元数据对齐下的表现。

Method: 借助基准测试和三种输入条件（类标签、Iconclass描述、少量示例），评估多模态LLMs和VLMs在基督教图标分类任务中的表现。

Result: Gemini-2.5 Pro和GPT-4o的表现超过了ResNet50基准；在Wikidata数据集上，Siglip表现最佳；一般情况下，使用类描述提升了零-shot性能，而少量示例的效果较差。

Conclusion: 通用的多模态大型语言模型在视觉上复杂的文化遗产领域具有分类能力，支持其作为数字人文学科工作流中的元数据策划工具的应用。

Abstract: This study evaluates the capabilities of Multimodal Large Language Models
(LLMs) and Vision Language Models (VLMs) in the task of single-label
classification of Christian Iconography. The goal was to assess whether
general-purpose VLMs (CLIP and SigLIP) and LLMs, such as GPT-4o and Gemini 2.5,
can interpret the Iconography, typically addressed by supervised classifiers,
and evaluate their performance. Two research questions guided the analysis:
(RQ1) How do multimodal LLMs perform on image classification of Christian
saints? And (RQ2), how does performance vary when enriching input with
contextual information or few-shot exemplars? We conducted a benchmarking study
using three datasets supporting Iconclass natively: ArtDL, ICONCLASS, and
Wikidata, filtered to include the top 10 most frequent classes. Models were
tested under three conditions: (1) classification using class labels, (2)
classification with Iconclass descriptions, and (3) few-shot learning with five
exemplars. Results were compared against ResNet50 baselines fine-tuned on the
same datasets. The findings show that Gemini-2.5 Pro and GPT-4o outperformed
the ResNet50 baselines. Accuracy dropped significantly on the Wikidata dataset,
where Siglip reached the highest accuracy score, suggesting model sensitivity
to image size and metadata alignment. Enriching prompts with class descriptions
generally improved zero-shot performance, while few-shot learning produced
lower results, with only occasional and minimal increments in accuracy. We
conclude that general-purpose multimodal LLMs are capable of classification in
visually complex cultural heritage domains. These results support the
application of LLMs as metadata curation tools in digital humanities workflows,
suggesting future research on prompt optimization and the expansion of the
study to other classification strategies and models.

</details>


### [79] [ViG-LRGC: Vision Graph Neural Networks with Learnable Reparameterized Graph Construction](https://arxiv.org/abs/2509.18840)
*Ismael Elsharkawi,Hossam Sharara,Ahmed Rafea*

Main category: cs.CV

TL;DR: LRGC是一种新的可学习无超参数图构建方法，在图像表示学习中表现优于当前的主要模型。


<details>
  <summary>Details</summary>
Motivation: 解决传统图像图神经网络模型在图构建中的非参数和非可学习方法所带来的问题，以实现更加有效和可学习的图构建。

Method: 使用可学习的参数来选择邻域，并通过关键-查询注意力和软阈值重参数化进行边缘选择。

Result: LRGC提供了一种无超参数的可学习图构建方法，去除了聚类或阈值方法带来的偏差。

Conclusion: 提出的ViG-LRGC方法在ImageNet-1k基准数据集上超越了同类规模的最新ViG模型。

Abstract: Image Representation Learning is an important problem in Computer Vision.
Traditionally, images were processed as grids, using Convolutional Neural
Networks or as a sequence of visual tokens, using Vision Transformers.
Recently, Vision Graph Neural Networks (ViG) have proposed the treatment of
images as a graph of nodes; which provides a more intuitive image
representation. The challenge is to construct a graph of nodes in each layer
that best represents the relations between nodes and does not need a
hyper-parameter search. ViG models in the literature depend on
non-parameterized and non-learnable statistical methods that operate on the
latent features of nodes to create a graph. This might not select the best
neighborhood for each node. Starting from k-NN graph construction to HyperGraph
Construction and Similarity-Thresholded graph construction, these methods lack
the ability to provide a learnable hyper-parameter-free graph construction
method. To overcome those challenges, we present the Learnable Reparameterized
Graph Construction (LRGC) for Vision Graph Neural Networks. LRGC applies
key-query attention between every pair of nodes; then uses soft-threshold
reparameterization for edge selection, which allows the use of a differentiable
mathematical model for training. Using learnable parameters to select the
neighborhood removes the bias that is induced by any clustering or thresholding
methods previously introduced in the literature. In addition, LRGC allows
tuning the threshold in each layer to the training data since the thresholds
are learnable through training and are not provided as hyper-parameters to the
model. We demonstrate that the proposed ViG-LRGC approach outperforms
state-of-the-art ViG models of similar sizes on the ImageNet-1k benchmark
dataset.

</details>


### [80] [Attack for Defense: Adversarial Agents for Point Prompt Optimization Empowering Segment Anything Model](https://arxiv.org/abs/2509.18891)
*Xueyu Liu,Xiaoyi Zhang,Guangze Shi,Meilin Liu,Yexin Lai,Yongfei Wu,Mingqiang Wei*

Main category: cs.CV

TL;DR: 提出了一种新框架Point Prompt Defender，利用对抗强化学习自动优化点提示，从而增强了Segment Anything Model的分割性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖启发式或手动制作的提示，限制了其可扩展性和泛化能力。

Method: 使用对抗强化学习框架，在任务无关的点提示环境中训练攻击者和防御者代理，通过深度Q网络优化提示。

Result: 通过 extensive 实验验证，Point Prompt Defender在多样任务上增强了SAM的分割性能.

Conclusion: Point Prompt Defender大幅提升了SAM的鲁棒性和泛化能力，建立了一个灵活、可解释且易于使用的基于提示的分割框架。

Abstract: Prompt quality plays a critical role in the performance of the Segment
Anything Model (SAM), yet existing approaches often rely on heuristic or
manually crafted prompts, limiting scalability and generalization. In this
paper, we propose Point Prompt Defender, an adversarial reinforcement learning
framework that adopts an attack-for-defense paradigm to automatically optimize
point prompts. We construct a task-agnostic point prompt environment by
representing image patches as nodes in a dual-space graph, where edges encode
both physical and semantic distances. Within this environment, an attacker
agent learns to activate a subset of prompts that maximally degrade SAM's
segmentation performance, while a defender agent learns to suppress these
disruptive prompts and restore accuracy. Both agents are trained using Deep
Q-Networks with a reward signal based on segmentation quality variation. During
inference, only the defender is deployed to refine arbitrary coarse prompt
sets, enabling enhanced SAM segmentation performance across diverse tasks
without retraining. Extensive experiments show that Point Prompt Defender
effectively improves SAM's robustness and generalization, establishing a
flexible, interpretable, and plug-and-play framework for prompt-based
segmentation.

</details>


### [81] [SmartWilds: Multimodal Wildlife Monitoring Dataset](https://arxiv.org/abs/2509.18894)
*Jenna Kline,Anirudh Potlapally,Bharath Pillai,Tanishka Wani,Rugved Katole,Vedant Patil,Penelope Covey,Hari Subramoni,Tanya Berger-Wolf,Christopher Stewart*

Main category: cs.CV

TL;DR: SmartWilds是一个支持多模态AI研究的野生动物监测数据集，包含同步的无人机影像、相机照片、视频和生物声学录音，为环境监测和物种保护提供了重要支持。


<details>
  <summary>Details</summary>
Motivation: 为了满足濒危物种研究、保护生态学和栖息地管理中的关键需求，开展全面的环境监测。

Method: 通过无人机影像、相机捕捉照片、视频和生物声学录音，对野生动物进行同步监测。

Result: 我们提供了一个多模态野生动物监测数据集SmartWilds，包括不同传感器的性能比较分析，捕获了多个物种的行为和栖息情况。

Conclusion: 本研究建立了可重复的多模态野生动物监测协议，并为保护计算机视觉研究提供了开放的数据集。

Abstract: We present the first release of SmartWilds, a multimodal wildlife monitoring
dataset. SmartWilds is a synchronized collection of drone imagery, camera trap
photographs and videos, and bioacoustic recordings collected during summer 2025
at The Wilds safari park in Ohio. This dataset supports multimodal AI research
for comprehensive environmental monitoring, addressing critical needs in
endangered species research, conservation ecology, and habitat management. Our
pilot deployment captured four days of synchronized monitoring across three
modalities in a 220-acre pasture containing Pere David's deer, Sichuan takin,
Przewalski's horses, as well as species native to Ohio, including bald eagles,
white-tailed deer, and coyotes. We provide a comparative analysis of sensor
modality performance, demonstrating complementary strengths for landuse
patterns, species detection, behavioral analysis, and habitat monitoring. This
work establishes reproducible protocols for multimodal wildlife monitoring
while contributing open datasets to advance conservation computer vision
research. Future releases will include synchronized GPS tracking data from
tagged individuals, citizen science data, and expanded temporal coverage across
multiple seasons.

</details>


### [82] [RS3DBench: A Comprehensive Benchmark for 3D Spatial Perception in Remote Sensing](https://arxiv.org/abs/2509.18897)
*Jiayu Wang,Ruizhi Wang,Jie Song,Haofei Zhang,Mingli Song,Zunlei Feng,Li Sun*

Main category: cs.CV

TL;DR: 本文提出了RS3DBench数据集，以推动遥感图像领域的3D视觉模型发展，并介绍了一种来自稳定扩散的深度估计模型。


<details>
  <summary>Details</summary>
Motivation: 现有的遥感数据集缺乏全面的深度信息或与遥感图像之间的精准对齐，因此需要一个新的基准来推动3D视觉模型发展。

Method: 构建了一个包含54,951对遥感图像和像素级对齐的深度图的基准数据集，应用于遥感图像的空间理解任务。

Result: 开发了RS3DBench数据集和基于稳定扩散的遥感深度估计模型，实现在该数据集上的最先进性能。

Conclusion: 我们提出了RS3DBench这一基准数据集，将促进遥感图像的3D视觉模型的发展，并提供了基于稳定扩散的遥感深度估计模型，展现了卓越的性能。

Abstract: In this paper, we introduce a novel benchmark designed to propel the
advancement of general-purpose, large-scale 3D vision models for remote sensing
imagery. While several datasets have been proposed within the realm of remote
sensing, many existing collections either lack comprehensive depth information
or fail to establish precise alignment between depth data and remote sensing
images. To address this deficiency, we present a visual Benchmark for 3D
understanding of Remotely Sensed images, dubbed RS3DBench. This dataset
encompasses 54,951 pairs of remote sensing images and pixel-level aligned depth
maps, accompanied by corresponding textual descriptions, spanning a broad array
of geographical contexts. It serves as a tool for training and assessing 3D
visual perception models within remote sensing image spatial understanding
tasks. Furthermore, we introduce a remotely sensed depth estimation model
derived from stable diffusion, harnessing its multimodal fusion capabilities,
thereby delivering state-of-the-art performance on our dataset. Our endeavor
seeks to make a profound contribution to the evolution of 3D visual perception
models and the advancement of geographic artificial intelligence within the
remote sensing domain. The dataset, models and code will be accessed on the
https://rs3dbench.github.io.

</details>


### [83] [DeblurSplat: SfM-free 3D Gaussian Splatting with Event Camera for Robust Deblurring](https://arxiv.org/abs/2509.18898)
*Pengteng Li,Yunfan Lu,Pinhao Song,Weiyu Guo,Huizai Yao,F. Richard Yu,Hui Xiong*

Main category: cs.CV

TL;DR: 本文提出了DeblurSplat，一种基于事件相机的无SfM去模糊3D高斯喷溅方法，解决了运动模糊问题，显著提升了渲染效率和视图质量。


<details>
  <summary>Details</summary>
Motivation: 针对运动模糊问题，提出了一种不依赖传统结构光运动(SfM)的方法，以提高去模糊效果和场景重建的准确性。

Method: 通过利用预训练的稠密立体模块(DUSt3R)直接从模糊图像中获取准确的初始点云，避免了摄像机姿态带来的累积误差，并将事件流引入去模糊管道以提供细粒度监督信号。

Result: 经过广泛的实验验证，DeblurSplat在不同场景中的表现优于现有技术，能够生成高保真新视图并有效提高渲染效率。

Conclusion: DeblurSplat方法在生成高保真新视图和提高去模糊3D高斯渲染效率方面表现出显著优势。

Abstract: In this paper, we propose the first Structure-from-Motion (SfM)-free
deblurring 3D Gaussian Splatting method via event camera, dubbed DeblurSplat.
We address the motion-deblurring problem in two ways. First, we leverage the
pretrained capability of the dense stereo module (DUSt3R) to directly obtain
accurate initial point clouds from blurred images. Without calculating camera
poses as an intermediate result, we avoid the cumulative errors transfer from
inaccurate camera poses to the initial point clouds' positions. Second, we
introduce the event stream into the deblur pipeline for its high sensitivity to
dynamic change. By decoding the latent sharp images from the event stream and
blurred images, we can provide a fine-grained supervision signal for scene
reconstruction optimization. Extensive experiments across a range of scenes
demonstrate that DeblurSplat not only excels in generating high-fidelity novel
views but also achieves significant rendering efficiency compared to the SOTAs
in deblur 3D-GS.

</details>


### [84] [MoiréNet: A Compact Dual-Domain Network for Image Demoiréing](https://arxiv.org/abs/2509.18910)
*Shuwei Guo,Simin Luan,Yan Ke,Zeyd Boukhers,John See,Cong Yang*

Main category: cs.CV

TL;DR: MoiréNet是一个高效的去莫尔条纹深度学习框架，结合频域与空间域特征，实现高质量去噪，适用于智能手机摄影等资源受限应用。


<details>
  <summary>Details</summary>
Motivation: 针对显示像素格与相机传感器网格之间的光谱别名现象带来的莫尔条纹问题。

Method: 使用卷积神经网络U-Net框架，结合频域和空间域特征进行去噪。

Result: MoiréNet在多个公开数据集上展现了最先进的性能，仅需5.513M参数，相比ESDNet-L减少了48%。

Conclusion: MoiréNet在去除数字图像中的莫尔条纹方面表现出色，具有优秀的恢复质量和参数效率，适用于资源受限的应用场景。

Abstract: Moir\'e patterns arise from spectral aliasing between display pixel lattices
and camera sensor grids, manifesting as anisotropic, multi-scale artifacts that
pose significant challenges for digital image demoir\'eing. We propose
Moir\'eNet, a convolutional neural U-Net-based framework that synergistically
integrates frequency and spatial domain features for effective artifact
removal. Moir\'eNet introduces two key components: a Directional
Frequency-Spatial Encoder (DFSE) that discerns moir\'e orientation via
directional difference convolution, and a Frequency-Spatial Adaptive Selector
(FSAS) that enables precise, feature-adaptive suppression. Extensive
experiments demonstrate that Moir\'eNet achieves state-of-the-art performance
on public and actively used datasets while being highly parameter-efficient.
With only 5.513M parameters, representing a 48% reduction compared to ESDNet-L,
Moir\'eNet combines superior restoration quality with parameter efficiency,
making it well-suited for resource-constrained applications including
smartphone photography, industrial imaging, and augmented reality.

</details>


### [85] [Frequency-Domain Decomposition and Recomposition for Robust Audio-Visual Segmentation](https://arxiv.org/abs/2509.18912)
*Yunzhe Shen,Kai Peng,Leiye Liu,Wei Ji,Jingjing Li,Miao Zhang,Yongri Piao,Huchuan Lu*

Main category: cs.CV

TL;DR: 本论文提出了一种新的频率感知音视频分割框架，通过考虑频率域的差异，改善了音视频分割的效果。


<details>
  <summary>Details</summary>
Motivation: 现有音视频分割方法忽视了音频和视觉模态之间的频率域矛盾，导致性能不佳。

Method: 提出了一种频率感知音视频分割(FAVS)框架，包含频率域增强分解模块(FDED)和协同跨模态一致性模块(SCMC)。

Result: FAVS框架在多个数据集上取得了最先进的性能，并通过可视化结果验证了其有效性。

Conclusion: FAVS框架在三个基准数据集上实现了最新的性能，验证了FDED和SCMC模块的有效性。

Abstract: Audio-visual segmentation (AVS) plays a critical role in multimodal machine
learning by effectively integrating audio and visual cues to precisely segment
objects or regions within visual scenes. Recent AVS methods have demonstrated
significant improvements. However, they overlook the inherent frequency-domain
contradictions between audio and visual modalities--the pervasively interfering
noise in audio high-frequency signals vs. the structurally rich details in
visual high-frequency signals. Ignoring these differences can result in
suboptimal performance. In this paper, we rethink the AVS task from a deeper
perspective by reformulating AVS task as a frequency-domain decomposition and
recomposition problem. To this end, we introduce a novel Frequency-Aware
Audio-Visual Segmentation (FAVS) framework consisting of two key modules:
Frequency-Domain Enhanced Decomposer (FDED) module and Synergistic Cross-Modal
Consistency (SCMC) module. FDED module employs a residual-based iterative
frequency decomposition to discriminate modality-specific semantics and
structural features, and SCMC module leverages a mixture-of-experts
architecture to reinforce semantic consistency and modality-specific feature
preservation through dynamic expert routing. Extensive experiments demonstrate
that our FAVS framework achieves state-of-the-art performance on three
benchmark datasets, and abundant qualitative visualizations further verify the
effectiveness of the proposed FDED and SCMC modules. The code will be released
as open source upon acceptance of the paper.

</details>


### [86] [xAI-CV: An Overview of Explainable Artificial Intelligence in Computer Vision](https://arxiv.org/abs/2509.18913)
*Nguyen Van Tu,Pham Nguyen Hai Long,Vo Hoai Viet*

Main category: cs.CV

TL;DR: 本文调查了四种xAI方法，以帮助理解深度学习图像分析模型的决策过程，解决其‘黑箱’特性带来的可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习在图像分析中的广泛应用，其“黑箱”特性导致的可靠性问题需要被解决，以便人们理解AI的决策过程。

Method: 通过对四种xAI方法（显著性图、概念瓶颈模型、基于原型的方法和混合方法）的分析，探讨其机制、优缺点和评估指标。

Result: 通过对不同xAI方法的综合评估，本文为未来研究与应用提供了指导。

Conclusion: 本文为理解深度学习模型在图像分析任务中的决策过程提供了四种代表性xAI方法，旨在提升模型的透明度和可靠性。

Abstract: Deep learning has become the de facto standard and dominant paradigm in image
analysis tasks, achieving state-of-the-art performance. However, this approach
often results in "black-box" models, whose decision-making processes are
difficult to interpret, raising concerns about reliability in critical
applications. To address this challenge and provide human a method to
understand how AI model process and make decision, the field of xAI has
emerged. This paper surveys four representative approaches in xAI for visual
perception tasks: (i) Saliency Maps, (ii) Concept Bottleneck Models (CBM),
(iii) Prototype-based methods, and (iv) Hybrid approaches. We analyze their
underlying mechanisms, strengths and limitations, as well as evaluation
metrics, thereby providing a comprehensive overview to guide future research
and applications.

</details>


### [87] [LiDAR Point Cloud Image-based Generation Using Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2509.18917)
*Amirhesam Aghanouri,Cristina Olaverri-Monreal*

Main category: cs.CV

TL;DR: 本研究提出一种改进的去噪扩散模型，旨在生成高质量的合成LiDAR数据，以提升自动驾驶汽车的环境感知能力和数据质量。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界中LiDAR数据收集困难和噪声、稀疏性问题，以提升自动驾驶汽车的环境感知能力。

Method: 采用增强的去噪扩散概率模型（DDPM），结合新的噪声调度和时间步嵌入技术。

Result: 与最新技术（SOTA）相比，该方法在多种计算机视觉任务中展现了优异的性能，能有效改善噪声和稀疏LiDAR数据的问题。

Conclusion: 该模型在处理噪声和稀疏LiDAR数据方面表现优越，能够生成丰富的点云，展现出良好的空间关系和结构细节。

Abstract: Autonomous vehicles (AVs) are expected to revolutionize transportation by
improving efficiency and safety. Their success relies on 3D vision systems that
effectively sense the environment and detect traffic agents. Among sensors AVs
use to create a comprehensive view of surroundings, LiDAR provides
high-resolution depth data enabling accurate object detection, safe navigation,
and collision avoidance. However, collecting real-world LiDAR data is
time-consuming and often affected by noise and sparsity due to adverse weather
or sensor limitations. This work applies a denoising diffusion probabilistic
model (DDPM), enhanced with novel noise scheduling and time-step embedding
techniques to generate high-quality synthetic data for augmentation, thereby
improving performance across a range of computer vision tasks, particularly in
AV perception. These modifications impact the denoising process and the model's
temporal awareness, allowing it to produce more realistic point clouds based on
the projection. The proposed method was extensively evaluated under various
configurations using the IAMCV and KITTI-360 datasets, with four performance
metrics compared against state-of-the-art (SOTA) methods. The results
demonstrate the model's superior performance over most existing baselines and
its effectiveness in mitigating the effects of noisy and sparse LiDAR data,
producing diverse point clouds with rich spatial relationships and structural
detail.

</details>


### [88] [Advancing Metallic Surface Defect Detection via Anomaly-Guided Pretraining on a Large Industrial Dataset](https://arxiv.org/abs/2509.18919)
*Chuni Liu,Hongjie Li,Jiaqi Du,Yangyang Hou,Qian Sun,Lei Jin,Ke Xu*

Main category: cs.CV

TL;DR: AGSSP通过引导表示学习解决了金属表面缺陷检测中的数据稀缺问题，并在性能上显著超越了传统模型。


<details>
  <summary>Details</summary>
Motivation: 针对数据稀缺和现有自监督学习方法无效的问题，提出一种新的自监督预训练方法。

Method: 采用两阶段框架，首先通过异常图提取特征，然后使用伪缺陷框进行检测预训练。

Result: 在多种设置下，AGSSP的mAP提高了最大10%到11.4%。

Conclusion: AGSSP显著提升了金属表面缺陷检测的性能，尤其在数据稀缺的情况下，提供了一种有效的预训练方案。

Abstract: The pretraining-finetuning paradigm is a crucial strategy in metallic surface
defect detection for mitigating the challenges posed by data scarcity. However,
its implementation presents a critical dilemma. Pretraining on natural image
datasets such as ImageNet, faces a significant domain gap. Meanwhile, naive
self-supervised pretraining on in-domain industrial data is often ineffective
due to the inability of existing learning objectives to distinguish subtle
defect patterns from complex background noise and textures. To resolve this, we
introduce Anomaly-Guided Self-Supervised Pretraining (AGSSP), a novel paradigm
that explicitly guides representation learning through anomaly priors. AGSSP
employs a two-stage framework: (1) it first pretrains the model's backbone by
distilling knowledge from anomaly maps, encouraging the network to capture
defect-salient features; (2) it then pretrains the detector using pseudo-defect
boxes derived from these maps, aligning it with localization tasks. To enable
this, we develop a knowledge-enhanced method to generate high-quality anomaly
maps and collect a large-scale industrial dataset of 120,000 images.
Additionally, we present two small-scale, pixel-level labeled metallic surface
defect datasets for validation. Extensive experiments demonstrate that AGSSP
consistently enhances performance across various settings, achieving up to a
10\% improvement in mAP@0.5 and 11.4\% in mAP@0.5:0.95 compared to
ImageNet-based models. All code, pretrained models, and datasets are publicly
available at https://clovermini.github.io/AGSSP-Dev/.

</details>


### [89] [Audio-Driven Universal Gaussian Head Avatars](https://arxiv.org/abs/2509.18924)
*Kartik Teotia,Helge Rhodin,Mohit Mendiratta,Hyeongwoo Kim,Marc Habermann,Christian Theobalt*

Main category: cs.CV

TL;DR: 提出了一种新方法，用于音频驱动的虚拟形象合成，结合了通用头部样式先验 UHAP 和人无关的语音模型，能生成高保真、细节丰富的虚拟形象。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够精确生成基于音频的虚拟形象的新方法，弥补传统方法忽视外观变化的不足。

Method: 结合人无关的语音模型与新的通用头部虚拟形象先验（UHAP），使用扫描数据进行监督，捕捉身份特定细节。

Result: 生成的虚拟形象在唇部同步、图像质量和感知真实感等指标上都表现出色，且与现有方法相比具有更高的准确性。

Conclusion: 该方法在音频驱动的虚拟形象合成上取得了显著成果，能够生成高保真的虚拟形象，并超越了传统几何方法的性能。

Abstract: We introduce the first method for audio-driven universal photorealistic
avatar synthesis, combining a person-agnostic speech model with our novel
Universal Head Avatar Prior (UHAP). UHAP is trained on cross-identity
multi-view videos. In particular, our UHAP is supervised with neutral scan
data, enabling it to capture the identity-specific details at high fidelity. In
contrast to previous approaches, which predominantly map audio features to
geometric deformations only while ignoring audio-dependent appearance
variations, our universal speech model directly maps raw audio inputs into the
UHAP latent expression space. This expression space inherently encodes, both,
geometric and appearance variations. For efficient personalization to new
subjects, we employ a monocular encoder, which enables lightweight regression
of dynamic expression variations across video frames. By accounting for these
expression-dependent changes, it enables the subsequent model fine-tuning stage
to focus exclusively on capturing the subject's global appearance and geometry.
Decoding these audio-driven expression codes via UHAP generates highly
realistic avatars with precise lip synchronization and nuanced expressive
details, such as eyebrow movement, gaze shifts, and realistic mouth interior
appearance as well as motion. Extensive evaluations demonstrate that our method
is not only the first generalizable audio-driven avatar model that can account
for detailed appearance modeling and rendering, but it also outperforms
competing (geometry-only) methods across metrics measuring lip-sync accuracy,
quantitative image quality, and perceptual realism.

</details>


### [90] [SynapFlow: A Modular Framework Towards Large-Scale Analysis of Dendritic Spines](https://arxiv.org/abs/2509.18926)
*Pamela Osuna-Vargas,Altug Kamacioglu,Dominik F. Aschauer,Petros E. Vlachos,Sercan Alipek,Jochen Triesch,Simon Rumpel,Matthias Kaschube*

Main category: cs.CV

TL;DR: 本研究通过模块化机器学习流程，提出了一种自动化检测和分析树突棘动态的解决方案，以推动学习和记忆的研究。


<details>
  <summary>Details</summary>
Motivation: 研究树突棘作为兴奋性突触的关键结构，通过检测和跟踪其动态来理解学习和记忆的神经基础。

Method: 我们提出了一种基于模块化机器学习的流程，用于自动化检测、时间跟踪和特征提取，结合了变换器检测模块、深度跟踪组件和时间跟踪模块。

Result: 我们验证了该方法，并发布了两个补充注释数据集，提供检测、深度跟踪和时间跟踪任务的开源标签数据，首次发布此类型数据。

Conclusion: 我们的方法为树突棘动态的大规模分析提供了一个可扩展的自动化解决方案，推动了学习和记忆神经基础的研究。

Abstract: Dendritic spines are key structural components of excitatory synapses in the
brain. Given the size of dendritic spines provides a proxy for synaptic
efficacy, their detection and tracking across time is important for studies of
the neural basis of learning and memory. Despite their relevance, large-scale
analyses of the structural dynamics of dendritic spines in 3D+time microscopy
data remain challenging and labor-intense. Here, we present a modular machine
learning-based pipeline designed to automate the detection, time-tracking, and
feature extraction of dendritic spines in volumes chronically recorded with
two-photon microscopy. Our approach tackles the challenges posed by biological
data by combining a transformer-based detection module, a depth-tracking
component that integrates spatial features, a time-tracking module to associate
3D spines across time by leveraging spatial consistency, and a feature
extraction unit that quantifies biologically relevant spine properties. We
validate our method on open-source labeled spine data, and on two complementary
annotated datasets that we publish alongside this work: one for detection and
depth-tracking, and one for time-tracking, which, to the best of our knowledge,
is the first data of this kind. To encourage future research, we release our
data, code, and pre-trained weights at
https://github.com/pamelaosuna/SynapFlow, establishing a baseline for scalable,
end-to-end analysis of dendritic spine dynamics.

</details>


### [91] [No Labels Needed: Zero-Shot Image Classification with Collaborative Self-Learning](https://arxiv.org/abs/2509.18938)
*Matheus Vinícius Todescato,Joel Luís Carbonera*

Main category: cs.CV

TL;DR: 本论文提出了一种新颖的无监督零样本图像分类框架，结合视觉语言模型和预训练视觉模型，通过置信度伪标记策略在测试数据上进行自学习，显著提升了分类效果，优于传统零样本方法。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，深度学习依赖大规模标注数据的局限性，激励我们探索无需标注数据的分类方法。

Method: 结合了视觉语言模型和预训练视觉模型的零样本图像分类框架，利用基于置信度的伪标记策略在测试数据上训练轻量级分类器。

Result: 在十个多样化数据集上的实验评估显示，该方法的性能超越了基线的零样本方法。

Conclusion: 提出的零样本图像分类框架在没有标记训练数据的情况下，通过自学习循环有效提高了分类性能，证明了其优于基线零样本方法。

Abstract: While deep learning, including Convolutional Neural Networks (CNNs) and
Vision Transformers (ViTs), has significantly advanced classification
performance, its typical reliance on extensive annotated datasets presents a
major obstacle in many practical scenarios where such data is scarce.
Vision-language models (VLMs) and transfer learning with pre-trained visual
models appear as promising techniques to deal with this problem. This paper
proposes a novel zero-shot image classification framework that combines a VLM
and a pre-trained visual model within a self-learning cycle. Requiring only the
set of class names and no labeled training data, our method utilizes a
confidence-based pseudo-labeling strategy to train a lightweight classifier
directly on the test data, enabling dynamic adaptation. The VLM identifies
high-confidence samples, and the pre-trained visual model enhances their visual
representations. These enhanced features then iteratively train the classifier,
allowing the system to capture complementary semantic and visual cues without
supervision. Notably, our approach avoids VLM fine-tuning and the use of large
language models, relying on the visual-only model to reduce the dependence on
semantic representation. Experimental evaluations on ten diverse datasets
demonstrate that our approach outperforms the baseline zero-shot method.

</details>


### [92] [Seeing Through Reflections: Advancing 3D Scene Reconstruction in Mirror-Containing Environments with Gaussian Splatting](https://arxiv.org/abs/2509.18956)
*Zijing Guo,Yunyang Zhao,Lin Wang*

Main category: cs.CV

TL;DR: 针对镜面环境下的3D重建问题，提出MirrorScene3D数据集和ReflectiveGS方法，利用镜面反射提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 在镜面环境下，反射表面导致视依赖失真和不一致，应对这些挑战以提升3D重建质量。

Method: 提出了ReflectiveGS，一个利用镜面反射作为补充视角的3D高斯渲染扩展。

Result: 实验结果显示，ReflectiveGS在SSIM、PSNR、LPIPS和训练速度上优于现有方法。

Conclusion: ReflectiveGS在镜面丰富环境中的3D重建中表现优越，建立了新的基准。

Abstract: Mirror-containing environments pose unique challenges for 3D reconstruction
and novel view synthesis (NVS), as reflective surfaces introduce view-dependent
distortions and inconsistencies. While cutting-edge methods such as Neural
Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) excel in typical
scenes, their performance deteriorates in the presence of mirrors. Existing
solutions mainly focus on handling mirror surfaces through symmetry mapping but
often overlook the rich information carried by mirror reflections. These
reflections offer complementary perspectives that can fill in absent details
and significantly enhance reconstruction quality. To advance 3D reconstruction
in mirror-rich environments, we present MirrorScene3D, a comprehensive dataset
featuring diverse indoor scenes, 1256 high-quality images, and annotated mirror
masks, providing a benchmark for evaluating reconstruction methods in
reflective settings. Building on this, we propose ReflectiveGS, an extension of
3D Gaussian Splatting that utilizes mirror reflections as complementary
viewpoints rather than simple symmetry artifacts, enhancing scene geometry and
recovering absent details. Experiments on MirrorScene3D show that
ReflectiveGaussian outperforms existing methods in SSIM, PSNR, LPIPS, and
training speed, setting a new benchmark for 3D reconstruction in mirror-rich
environments.

</details>


### [93] [Generative data augmentation for biliary tract detection on intraoperative images](https://arxiv.org/abs/2509.18958)
*Cristina Iacono,Mariarosaria Meola,Federica Conte,Laura Mecozzi,Umberto Bracale,Pietro Falco,Fanny Ficuciello*

Main category: cs.CV

TL;DR: 本研究提出了一种基于深度学习的胆道定位方法，通过图像数据库和生成对抗网络来增强手术中胆道的可视化，旨在减少胆管损伤的风险。


<details>
  <summary>Details</summary>
Motivation: 为了提高内窥镜下胆道的可视化，从而降低胆管损伤的风险，改善患者的生活质量和生存率。

Method: 使用Yolo检测算法进行图像数据库的构建和注释，并提出了生成对抗网络（GAN）进行训练数据集的合成生成。

Result: 实验结果显示所提方法有效提升了胆道定位的准确性，并讨论了这一技术的伦理考量。

Conclusion: 本研究通过深度学习方法显著提高了手术中胆道的可视化，减少了胆管损伤的风险。

Abstract: Cholecystectomy is one of the most frequently performed procedures in
gastrointestinal surgery, and the laparoscopic approach is the gold standard
for symptomatic cholecystolithiasis and acute cholecystitis. In addition to the
advantages of a significantly faster recovery and better cosmetic results, the
laparoscopic approach bears a higher risk of bile duct injury, which has a
significant impact on quality of life and survival. To avoid bile duct injury,
it is essential to improve the intraoperative visualization of the bile duct.
This work aims to address this problem by leveraging a deep-learning approach
for the localization of the biliary tract from white-light images acquired
during the surgical procedures. To this end, the construction and annotation of
an image database to train the Yolo detection algorithm has been employed.
Besides classical data augmentation techniques, the paper proposes Generative
Adversarial Network (GAN) for the generation of a synthetic portion of the
training dataset. Experimental results have been discussed along with ethical
considerations.

</details>


### [94] [Prompt-DAS: Annotation-Efficient Prompt Learning for Domain Adaptive Semantic Segmentation of Electron Microscopy Images](https://arxiv.org/abs/2509.18973)
*Jiabao Chen,Shan Xiong,Jialin Peng*

Main category: cs.CV

TL;DR: Prompt-DAS 是一种新的多任务框架，支持灵活的提示配置，通过对比学习改善特征学习，在大规模电子显微镜的领域自适应分割中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在大规模电子显微镜图像中，实现有效的器官实例分割和注释学习。

Method: 提出了一种可提示的多任务框架 Prompt-DAS，采用辅助中心点检测任务和提示引导的对比学习以提升特征学习。

Result: 在多个具有挑战性的基准上，Prompt-DAS 显示出优于现有无监督和弱监督方法的效果。

Conclusion: Prompt-DAS 相较于现有的无监督和弱监督领域适应方法具有更好的性能，能够灵活处理不同的提示配置，实现高效的分割任务。

Abstract: Domain adaptive segmentation (DAS) of numerous organelle instances from
large-scale electron microscopy (EM) is a promising way to enable
annotation-efficient learning. Inspired by SAM, we propose a promptable
multitask framework, namely Prompt-DAS, which is flexible enough to utilize any
number of point prompts during the adaptation training stage and testing stage.
Thus, with varying prompt configurations, Prompt-DAS can perform unsupervised
domain adaptation (UDA) and weakly supervised domain adaptation (WDA), as well
as interactive segmentation during testing. Unlike the foundation model SAM,
which necessitates a prompt for each individual object instance, Prompt-DAS is
only trained on a small dataset and can utilize full points on all instances,
sparse points on partial instances, or even no points at all, facilitated by
the incorporation of an auxiliary center-point detection task. Moreover, a
novel prompt-guided contrastive learning is proposed to enhance discriminative
feature learning. Comprehensive experiments conducted on challenging benchmarks
demonstrate the effectiveness of the proposed approach over existing UDA, WDA,
and SAM-based approaches.

</details>


### [95] [Unveiling Chain of Step Reasoning for Vision-Language Models with Fine-grained Rewards](https://arxiv.org/abs/2509.19003)
*Honghao Chen,Xingzhou Lou,Xiaokun Feng,Kaiqi Huang,Xinlong Wang*

Main category: cs.CV

TL;DR: 本研究探索了链式逐步推理在视觉-语言模型中的应用，提出了有效的透明框架，显著提升了推理质量和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言推理方法在细粒度结构推理和中间推理质量评估方面存在挑战，迫切需要改进。

Method: 通过链式逐步推理，结合过程奖励模型（PRM）和强化学习进行模型训练。

Result: 提出的方法在视觉-语言基准测试中取得了一致的明显提升，且通过大量实证分析揭示了各个组件的影响。

Conclusion: 本研究为视觉-语言模型建立了强基线，并提供了对复杂多模态推理的深入见解。

Abstract: Chain of thought reasoning has demonstrated remarkable success in large
language models, yet its adaptation to vision-language reasoning remains an
open challenge with unclear best practices. Existing attempts typically employ
reasoning chains at a coarse-grained level, which struggles to perform
fine-grained structured reasoning and, more importantly, are difficult to
evaluate the reward and quality of intermediate reasoning. In this work, we
delve into chain of step reasoning for vision-language models, enabling
assessing reasoning step quality accurately and leading to effective
reinforcement learning and inference-time scaling with fine-grained rewards. We
present a simple, effective, and fully transparent framework, including the
step-level reasoning data, process reward model (PRM), and reinforcement
learning training. With the proposed approaches, our models set strong
baselines with consistent improvements on challenging vision-language
benchmarks. More importantly, we conduct a thorough empirical analysis and
ablation study, unveiling the impact of each component and several intriguing
properties of inference-time scaling. We believe this paper serves as a
baseline for vision-language models and offers insights into more complex
multimodal reasoning. Our dataset, PRM, and code will be available at
https://github.com/baaivision/CoS.

</details>


### [96] [Weakly Supervised Food Image Segmentation using Vision Transformers and Segment Anything Model](https://arxiv.org/abs/2509.19028)
*Ioannis Sarafis,Alexandros Papadopoulos,Anastasios Delopoulos*

Main category: cs.CV

TL;DR: 本文提出了一种弱监督的食品图像语义分割方法，利用ViTs和SAM，减少对像素级注释的需求，评估结果显示该方法有效。


<details>
  <summary>Details</summary>
Motivation: 探索通过弱监督学习改进食品图像语义分割，减少对像素级注释的依赖。

Method: 使用ViTs生成类激活图来为SAM生成提示，并通过单掩模和多掩模SAM生成策略结合图像预处理技术来提高SAM生成掩模的质量。

Result: 在FoodSeg103数据集上评估，生成每张图片平均2.4个掩模，mIoU达0.54。

Conclusion: 该方法可加速食品图像标注任务，并可作为食品和营养跟踪应用的集成组件。

Abstract: In this paper, we propose a weakly supervised semantic segmentation approach
for food images which takes advantage of the zero-shot capabilities and
promptability of the Segment Anything Model (SAM) along with the attention
mechanisms of Vision Transformers (ViTs). Specifically, we use class activation
maps (CAMs) from ViTs to generate prompts for SAM, resulting in masks suitable
for food image segmentation. The ViT model, a Swin Transformer, is trained
exclusively using image-level annotations, eliminating the need for pixel-level
annotations during training. Additionally, to enhance the quality of the
SAM-generated masks, we examine the use of image preprocessing techniques in
combination with single-mask and multi-mask SAM generation strategies. The
methodology is evaluated on the FoodSeg103 dataset, generating an average of
2.4 masks per image (excluding background), and achieving an mIoU of 0.54 for
the multi-mask scenario. We envision the proposed approach as a tool to
accelerate food image annotation tasks or as an integrated component in food
and nutrition tracking applications.

</details>


### [97] [A DyL-Unet framework based on dynamic learning for Temporally Consistent Echocardiographic Segmentation](https://arxiv.org/abs/2509.19052)
*Jierui Qu,Jianchun Zhao*

Main category: cs.CV

TL;DR: DyL-UNet是一个创新的心脏超声图像分割框架，通过动态学习和心脏相位动态注意机制，实现在准确性与时序一致性上的优越表现。


<details>
  <summary>Details</summary>
Motivation: 心脏超声的准确分割对于心血管诊断和治疗至关重要，但受框架间抖动及噪声影响，通常导致临时不稳定性，进而影响功能估计的可靠性。

Method: DyL-UNet是一种基于动态学习的时序一致性U-Net分割架构，结合了Echo-Dynamics Graph和多个基于Swin-Transformer的编码-解码分支。

Result: 在CAMUS和EchoNet-Dynamic数据集上的实验表明，DyL-UNet在保持分割准确性的同时，显著提升了时序一致性，超过了现有方法。

Conclusion: DyL-UNet提供了一种可靠的解决方案，能够在临床自动心脏超声中实现较高的时序一致性和准确的分割。

Abstract: Accurate segmentation of cardiac anatomy in echocardiography is essential for
cardiovascular diagnosis and treatment. Yet echocardiography is prone to
deformation and speckle noise, causing frame-to-frame segmentation jitter. Even
with high accuracy in single-frame segmentation, temporal instability can
weaken functional estimates and impair clinical interpretability. To address
these issues, we propose DyL-UNet, a dynamic learning-based temporal
consistency U-Net segmentation architecture designed to achieve temporally
stable and precise echocardiographic segmentation. The framework constructs an
Echo-Dynamics Graph (EDG) through dynamic learning to extract dynamic
information from videos. DyL-UNet incorporates multiple Swin-Transformer-based
encoder-decoder branches for processing single-frame images. It further
introduces Cardiac Phase-Dynamics Attention (CPDA) at the skip connections,
which uses EDG-encoded dynamic features and cardiac-phase cues to enforce
temporal consistency during segmentation. Extensive experiments on the CAMUS
and EchoNet-Dynamic datasets demonstrate that DyL-UNet maintains segmentation
accuracy comparable to existing methods while achieving superior temporal
consistency, providing a reliable solution for automated clinical
echocardiography.

</details>


### [98] [WaveletGaussian: Wavelet-domain Diffusion for Sparse-view 3D Gaussian Object Reconstruction](https://arxiv.org/abs/2509.19073)
*Hung Nguyen,Runfa Li,An Le,Truong Nguyen*

Main category: cs.CV

TL;DR: WaveletGaussian是一种新的框架，用于改进稀疏视图下的3D高斯对象重建，采用波动小波而非传统扩散方法，提升效率并缩短训练时间。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏视图下3D高斯重建性能下降的问题，同时减少扩散微调和修复步骤的计算成本。

Method: 通过在小波域内应用扩散，并使用轻量级网络优化高频子带，结合高效的在线随机掩码策略进行训练配对的整理

Result: 在两个基准数据集（Mip-NeRF 360和OmniObject3D）上的实验表明，WaveletGaussian在渲染质量和训练时间方面相比于以往方法有显著优势。

Conclusion: WaveletGaussian在稀疏视图3D高斯对象重建中实现了更高效性能，具有竞争力的渲染质量和显著降低的训练时间。

Abstract: 3D Gaussian Splatting (3DGS) has become a powerful representation for
image-based object reconstruction, yet its performance drops sharply in
sparse-view settings. Prior works address this limitation by employing
diffusion models to repair corrupted renders, subsequently using them as pseudo
ground truths for later optimization. While effective, such approaches incur
heavy computation from the diffusion fine-tuning and repair steps. We present
WaveletGaussian, a framework for more efficient sparse-view 3D Gaussian object
reconstruction. Our key idea is to shift diffusion into the wavelet domain:
diffusion is applied only to the low-resolution LL subband, while
high-frequency subbands are refined with a lightweight network. We further
propose an efficient online random masking strategy to curate training pairs
for diffusion fine-tuning, replacing the commonly used, but inefficient,
leave-one-out strategy. Experiments across two benchmark datasets, Mip-NeRF 360
and OmniObject3D, show WaveletGaussian achieves competitive rendering quality
while substantially reducing training time.

</details>


### [99] [3rd Place Report of LSVOS 2025 MeViS Track: Sa2VA-i: Improving Sa2VA Results with Consistent Training and Inference](https://arxiv.org/abs/2509.19082)
*Alexey Nekrasov,Ali Athar,Daan de Geus,Alexander Hermans,Bastian Leibe*

Main category: cs.CV

TL;DR: 该研究提出了Sa2VA的改进版本Sa2VA-i，解决了训练与推理过程中的不一致性，显著提高了视频对象分割任务的性能，达到了新的性能标准。


<details>
  <summary>Details</summary>
Motivation: 为了提高Sa2VA模型在视频对象分割任务中的表现，识别并解决训练和推理过程中的不一致性。

Method: 提出了一个改进版本的Sa2VA，即Sa2VA-i，主要通过修正训练和推理过程中的问题来提高性能。

Result: Sa2VA-i在多个视频基准上获得了显著的改进，例如MeViS提高了+11.6 J&F，Ref-YT-VOS提高了+1.4，Ref-DAVIS提高了+3.3，ReVOS提高了+4.1。

Conclusion: Sa2VA-i模型通过修正训练和推理过程中的不一致性，显著提高了视频对象分割任务的表现，并在多个基准上创下了新记录。

Abstract: Sa2VA is a recent model for language-guided dense grounding in images and
video that achieves state-of-the-art results on multiple segmentation
benchmarks and that has become widely popular. However, we found that Sa2VA
does not perform according to its full potential for referring video object
segmentation tasks. We identify inconsistencies between training and inference
procedures as the key factor holding it back. To mitigate this issue, we
propose an improved version of Sa2VA, Sa2VA-i, that rectifies these issues and
improves the results. In fact, Sa2VA-i sets a new state of the art for multiple
video benchmarks and achieves improvements of up to +11.6 J&F on MeViS, +1.4 on
Ref-YT-VOS, +3.3 on Ref-DAVIS and +4.1 on ReVOS using the same Sa2VA
checkpoints. With our fixes, the Sa2VA-i-1B model even performs on par with the
original Sa2VA-26B model on the MeViS benchmark. We hope that this work will
show the importance of seemingly trivial implementation details and that it
will provide valuable insights for the referring video segmentation field. We
provide the code and updated models at https://github.com/kumuji/sa2va-i

</details>


### [100] [Zero-Shot Multi-Spectral Learning: Reimagining a Generalist Multimodal Gemini 2.5 Model for Remote Sensing Applications](https://arxiv.org/abs/2509.19087)
*Ganesh Mallya,Yotam Gigi,Dahun Kim,Maxim Neumann,Genady Beryozkin,Tomer Shekel,Anelia Angelova*

Main category: cs.CV

TL;DR: 本研究提出了一种基于零-shot的训练免费方法，将新多光谱数据作为输入用于通用多模态模型，显著提升了遥感领域的分析能力。


<details>
  <summary>Details</summary>
Motivation: 多光谱影像在遥感应用中至关重要，但现有的机器学习模型训练成本高且无法有效处理多光谱信号。因此，需要探索通用多模态模型在此领域的应用潜力。

Method: 提出一种训练免费的方法，该方法将新多光谱数据以零-shot模式作为输入，适用于已经在RGB数据上训练的通用多模态模型，并注入领域特定的信息作为模型的指令。

Result: 在流行的遥感基准测试中，我们观察到Gemini2.5模型在土地覆盖和土地利用分类任务中具有显著的零-shot表现提升，展示了其适应新输入的能力。

Conclusion: 通过引入零-shot模式下的新多光谱数据，通用多模态模型能够有效应用于遥感数据的分析，尤其是在土地覆盖和土地利用分类任务中表现出强大的性能提升。

Abstract: Multi-spectral imagery plays a crucial role in diverse Remote Sensing
applications including land-use classification, environmental monitoring and
urban planning. These images are widely adopted because their additional
spectral bands correlate strongly with physical materials on the ground, such
as ice, water, and vegetation. This allows for more accurate identification,
and their public availability from missions, such as Sentinel-2 and Landsat,
only adds to their value. Currently, the automatic analysis of such data is
predominantly managed through machine learning models specifically trained for
multi-spectral input, which are costly to train and support. Furthermore,
although providing a lot of utility for Remote Sensing, such additional inputs
cannot be used with powerful generalist large multimodal models, which are
capable of solving many visual problems, but are not able to understand
specialized multi-spectral signals.
  To address this, we propose a training-free approach which introduces new
multi-spectral data in a Zero-Shot-only mode, as inputs to generalist
multimodal models, trained on RGB-only inputs. Our approach leverages the
multimodal models' understanding of the visual space, and proposes to adapt to
inputs to that space, and to inject domain-specific information as instructions
into the model. We exemplify this idea with the Gemini2.5 model and observe
strong Zero-Shot performance gains of the approach on popular Remote Sensing
benchmarks for land cover and land use classification and demonstrate the easy
adaptability of Gemini2.5 to new inputs. These results highlight the potential
for geospatial professionals, working with non-standard specialized inputs, to
easily leverage powerful multimodal models, such as Gemini2.5, to accelerate
their work, benefiting from their rich reasoning and contextual capabilities,
grounded in the specialized sensor data.

</details>


### [101] [Investigating Traffic Accident Detection Using Multimodal Large Language Models](https://arxiv.org/abs/2509.19096)
*Ilhan Skender,Kailin Tong,Selim Solmaz,Daniel Watzenig*

Main category: cs.CV

TL;DR: 研究探索了多模态大语言模型在交通事故检测中的零样本能力，结合视觉分析技术，显示了在实时监测中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在减少对大型标注数据集的依赖，使用基础设施摄像头图像进行交通事故的零样本检测与描述，以提高事故监测的实时性。

Method: 通过模拟的DeepAccident数据集，对不同MLLM模型进行评估，并结合YOLO、Deep SORT和Segment Anything等视觉分析技术，提高事故检测的效果。

Result: 结果显示Pixtral模型表现最佳，F1-score为0.71，召回率为83%；而Gemini模型则在增强提示下提高了精准度，但F1和召回率有所下降，Gemma 3模型的表现最为平衡。

Conclusion: 本研究展示了多模态大语言模型（MLLMs）在交通事故检测方面的潜力，特别是在与先进视觉分析技术结合使用时，提升了模型的准确性和可解释性。

Abstract: Traffic safety remains a critical global concern, with timely and accurate
accident detection essential for hazard reduction and rapid emergency response.
Infrastructure-based vision sensors offer scalable and efficient solutions for
continuous real-time monitoring, facilitating automated detection of acci-
dents directly from captured images. This research investigates the zero-shot
capabilities of multimodal large language models (MLLMs) for detecting and
describing traffic accidents using images from infrastructure cameras, thus
minimizing reliance on extensive labeled datasets. Main contributions include:
(1) Evaluation of MLLMs using the simulated DeepAccident dataset from CARLA,
explicitly addressing the scarcity of diverse, realistic, infrastructure-based
accident data through controlled simulations; (2) Comparative performance
analysis between Gemini 1.5 and 2.0, Gemma 3 and Pixtral models in acci- dent
identification and descriptive capabilities without prior fine-tuning; and (3)
Integration of advanced visual analytics, specifically YOLO for object
detection, Deep SORT for multi- object tracking, and Segment Anything (SAM) for
instance segmentation, into enhanced prompts to improve model accuracy and
explainability. Key numerical results show Pixtral as the top performer with an
F1-score of 0.71 and 83% recall, while Gemini models gained precision with
enhanced prompts (e.g., Gemini 1.5 rose to 90%) but suffered notable F1 and
recall losses. Gemma 3 offered the most balanced performance with minimal
metric fluctuation. These findings demonstrate the substantial potential of
integrating MLLMs with advanced visual analytics techniques, enhancing their
applicability in real-world automated traffic monitoring systems.

</details>


### [102] [Track-On2: Enhancing Online Point Tracking with Memory](https://arxiv.org/abs/2509.19115)
*Görkay Aydemir,Weidi Xie,Fatma Güney*

Main category: cs.CV

TL;DR: 本研究提出Track-On2模型，针对在线长效点跟踪进行改进，展现出在跨帧一致性识别上的优势，优于以往方法。


<details>
  <summary>Details</summary>
Motivation: 解决在显著外观变化、运动和遮挡下跨视频帧的一致性点识别问题，适用于实时和流式应用场景。

Method: 扩展了前期模型Track-On，采用简单高效的基于transformer的在线长效跟踪模型Track-On2，优化了架构、内存使用和合成训练策略。

Result: 通过全面实验，Track-On2超越了以前的在线跟踪器和强大的离线方法，显示出其在性能和效率上的提升。

Conclusion: Track-On2在五个基准测试中实现了最先进的结果，展示了因果性和基于记忆的架构在点跟踪中的有效性。

Abstract: In this paper, we consider the problem of long-term point tracking, which
requires consistent identification of points across video frames under
significant appearance changes, motion, and occlusion. We target the online
setting, i.e. tracking points frame-by-frame, making it suitable for real-time
and streaming applications. We extend our prior model Track-On into Track-On2,
a simple and efficient transformer-based model for online long-term tracking.
Track-On2 improves both performance and efficiency through architectural
refinements, more effective use of memory, and improved synthetic training
strategies. Unlike prior approaches that rely on full-sequence access or
iterative updates, our model processes frames causally and maintains temporal
coherence via a memory mechanism, which is key to handling drift and occlusions
without requiring future frames. At inference, we perform coarse patch-level
classification followed by refinement. Beyond architecture, we systematically
study synthetic training setups and their impact on memory behavior, showing
how they shape temporal robustness over long sequences. Through comprehensive
experiments, Track-On2 achieves state-of-the-art results across five synthetic
and real-world benchmarks, surpassing prior online trackers and even strong
offline methods that exploit bidirectional context. These results highlight the
effectiveness of causal, memory-based architectures trained purely on synthetic
data as scalable solutions for real-world point tracking. Project page:
https://kuis-ai.github.io/track_on2

</details>


### [103] [KAMERA: Enhancing Aerial Surveys of Ice-associated Seals in Arctic Environments](https://arxiv.org/abs/2509.19129)
*Adam Romlein,Benjamin X. Hou,Yuval Boss,Cynthia L. Christman,Stacie Koslovsky,Erin E. Moreland,Jason Parham,Anthony Hoogs*

Main category: cs.CV

TL;DR: KAMERA是一个用于同步和检测冰区动物的高效系统，处理时间减少80%，并具备开放源代码。


<details>
  <summary>Details</summary>
Motivation: 针对阿拉斯加周边的冰相关海豹进行空中调查，提高数据处理速度和监测准确性。

Method: KAMERA系统结合了多相机和多光谱技术，经过严格的标定和硬件同步，用于实时检测海豹和北极熊。

Result: KAMERA在数据处理时间上相比以往方法减少了80%，能够将收集到的数据进行快速引用与世界平面映射，提高了测量区域的准确性。

Conclusion: KAMERA系统通过多相机、多光谱同步和实时检测能力，显著提高了冰区动物的监测效率，促进了科学研究的开放性和合作。

Abstract: We introduce KAMERA: a comprehensive system for multi-camera, multi-spectral
synchronization and real-time detection of seals and polar bears. Utilized in
aerial surveys for ice-associated seals in the Bering, Chukchi, and Beaufort
seas around Alaska, KAMERA provides up to an 80% reduction in dataset
processing time over previous methods. Our rigorous calibration and hardware
synchronization enable using multiple spectra for object detection. All
collected data are annotated with metadata so they can be easily referenced
later. All imagery and animal detections from a survey are mapped onto a world
plane for accurate surveyed area estimates and quick assessment of survey
results. We hope KAMERA will inspire other mapping and detection efforts in the
scientific community, with all software, models, and schematics fully
open-sourced.

</details>


### [104] [NeuCODEX: Edge-Cloud Co-Inference with Spike-Driven Compression and Dynamic Early-Exit](https://arxiv.org/abs/2509.19156)
*Maurf Hassan,Steven Davy,Muhammad Zawish,Owais Bin Zuber,Nouman Ashraf*

Main category: cs.CV

TL;DR: NeuCODEX是一种新型的神经网络协同推理架构，通过减小数据传输、降低能耗和延迟，提升边缘计算效率，适合资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 解决边缘推理过程中的延迟和能量限制问题，特别是在信息传输成本高的边缘-云共推理系统中。

Method: 采用联合优化的神经形态协同推理架构NeuCODEX，包含学习的脉冲驱动压缩模块和动态提前退出机制。

Result: NeuCODEX在CIFAR10、Caltech等静态图像及动态事件流数据集上验证，数据传输减少最高达2048倍，边缘能耗降低超过90%，延迟减少最多达3倍，且精度下降小于2%。

Conclusion: NeuCODEX在资源受限环境中实现了高性能的脉冲神经网络部署，显著减少了数据传输及边缘能耗，同时降低了延迟，且精度下降微乎其微。

Abstract: Spiking Neural Networks (SNNs) offer significant potential for enabling
energy-efficient intelligence at the edge. However, performing full SNN
inference at the edge can be challenging due to the latency and energy
constraints arising from fixed and high timestep overheads. Edge-cloud
co-inference systems present a promising solution, but their deployment is
often hindered by high latency and feature transmission costs. To address these
issues, we introduce NeuCODEX, a neuromorphic co-inference architecture that
jointly optimizes both spatial and temporal redundancy. NeuCODEX incorporates a
learned spike-driven compression module to reduce data transmission and employs
a dynamic early-exit mechanism to adaptively terminate inference based on
output confidence. We evaluated NeuCODEX on both static images (CIFAR10 and
Caltech) and neuromorphic event streams (CIFAR10-DVS and N-Caltech). To
demonstrate practicality, we prototyped NeuCODEX on ResNet-18 and VGG-16
backbones in a real edge-to-cloud testbed. Our proposed system reduces data
transfer by up to 2048x and edge energy consumption by over 90%, while reducing
end-to-end latency by up to 3x compared to edge-only inference, all with a
negligible accuracy drop of less than 2%. In doing so, NeuCODEX enables
practical, high-performance SNN deployment in resource-constrained
environments.

</details>


### [105] [RoSe: Robust Self-supervised Stereo Matching under Adverse Weather Conditions](https://arxiv.org/abs/2509.19165)
*Yun Wang,Junjie Hu,Junhui Hou,Chenghao Zhang,Renwei Yang,Dapeng Oliver Wu*

Main category: cs.CV

TL;DR: 本文提出了一种新方法，通过引入视觉先验和场景对应先验来改善自监督立体匹配在恶劣天气下的性能，实验表明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自监督立体匹配方法在恶劣天气条件下性能显著下降，主要由于噪声和可见度降低导致的特征提取器表现不佳，以及像素一致性假设的破坏。

Method: 通过引入从视觉基础模型获得的稳健先验和场景对应先验，构建强有力的监督信号，采用自监督训练方案。

Result: 通过合成具有真实天气退化的立体数据集，我们的模型在恶劣天气下的视差估计方面有了显著提升，并且实验结果表明其有效性和灵活性。

Conclusion: 我们提出的方法在恶劣天气条件下显著提高了自监督立体匹配的性能，优于现有的最先进方法。

Abstract: Recent self-supervised stereo matching methods have made significant
progress, but their performance significantly degrades under adverse weather
conditions such as night, rain, and fog. We identify two primary weaknesses
contributing to this performance degradation. First, adverse weather introduces
noise and reduces visibility, making CNN-based feature extractors struggle with
degraded regions like reflective and textureless areas. Second, these degraded
regions can disrupt accurate pixel correspondences, leading to ineffective
supervision based on the photometric consistency assumption. To address these
challenges, we propose injecting robust priors derived from the visual
foundation model into the CNN-based feature extractor to improve feature
representation under adverse weather conditions. We then introduce scene
correspondence priors to construct robust supervisory signals rather than
relying solely on the photometric consistency assumption. Specifically, we
create synthetic stereo datasets with realistic weather degradations. These
datasets feature clear and adverse image pairs that maintain the same semantic
context and disparity, preserving the scene correspondence property. With this
knowledge, we propose a robust self-supervised training paradigm, consisting of
two key steps: robust self-supervised scene correspondence learning and adverse
weather distillation. Both steps aim to align underlying scene results from
clean and adverse image pairs, thus improving model disparity estimation under
adverse weather effects. Extensive experiments demonstrate the effectiveness
and versatility of our proposed solution, which outperforms existing
state-of-the-art self-supervised methods. Codes are available at
\textcolor{blue}{https://github.com/cocowy1/RoSe-Robust-Self-supervised-Stereo-Matching-under-Adverse-Weather-Conditions}.

</details>


### [106] [YOLO-LAN: Precise Polyp Detection via Optimized Loss, Augmentations and Negatives](https://arxiv.org/abs/2509.19166)
*Siddharth Gupta,Jitin Singla*

Main category: cs.CV

TL;DR: 本研究提出YOLO-LAN模型，通过深度学习显著提升结肠镜下腺瘤的检测准确性，具有重要临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 由于手动检测存在不一致性和疏漏，积极寻求基于深度学习的对象检测方法以提高结肠镜下腺瘤检测的准确性和实时性。

Method: 采用YOLO架构，通过M2IoU损失、数据增强和负样本训练实现多种情况模拟。

Result: 在Kvasir-seg和BKAI-IGH NeoPolyp数据集上，YOLO-LAN达到了0.9619的mAP$_{50}$和0.8599的mAP$_{50:95}$，相较于现有方法有显著提升。

Conclusion: 该研究提出的YOLO-LAN在多种数据集上显示出卓越的腺瘤检测效果，具有重要的临床推广价值。

Abstract: Colorectal cancer (CRC), a lethal disease, begins with the growth of abnormal
mucosal cell proliferation called polyps in the inner wall of the colon. When
left undetected, polyps can become malignant tumors. Colonoscopy is the
standard procedure for detecting polyps, as it enables direct visualization and
removal of suspicious lesions. Manual detection by colonoscopy can be
inconsistent and is subject to oversight. Therefore, object detection based on
deep learning offers a better solution for a more accurate and real-time
diagnosis during colonoscopy. In this work, we propose YOLO-LAN, a YOLO-based
polyp detection pipeline, trained using M2IoU loss, versatile data
augmentations and negative data to replicate real clinical situations. Our
pipeline outperformed existing methods for the Kvasir-seg and BKAI-IGH NeoPolyp
datasets, achieving mAP$_{50}$ of 0.9619, mAP$_{50:95}$ of 0.8599 with YOLOv12
and mAP$_{50}$ of 0.9540, mAP$_{50:95}$ of 0.8487 with YOLOv8 on the Kvasir-seg
dataset. The significant increase is achieved in mAP$_{50:95}$ score, showing
the precision of polyp detection. We show robustness based on polyp size and
precise location detection, making it clinically relevant in AI-assisted
colorectal screening.

</details>


### [107] [The 1st Solution for MOSEv2 Challenge 2025: Long-term and Concept-aware Video Segmentation via SeC](https://arxiv.org/abs/2509.19183)
*Mingqi Gao,Jingkun Chen,Yunqi Miao,Gengshen Wu,Zhijin Qin,Jungong Han*

Main category: cs.CV

TL;DR: 该报告探讨了LSVOS Challenge的MOSEv2轨道，通过增强型SAM-2框架的记忆机制，成功解决了视频目标分割中的复杂挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨在复杂的半监督视频目标分割中的挑战，旨在提升视频目标分割的效果。

Method: 通过分析和适应SeC的增强型SAM-2框架，研究其长期记忆和概念感知记忆。

Result: 我们的解决方案在测试集上取得了39.89%的JF得分，位列LSVOS Challenge MOSEv2轨道第一。

Conclusion: 我们的方法在LSVOS Challenge的MOSEv2轨道中表现优异，取得了JF得分39.89%，排名第一。

Abstract: This technical report explores the MOSEv2 track of the LSVOS Challenge, which
targets complex semi-supervised video object segmentation. By analysing and
adapting SeC, an enhanced SAM-2 framework, we conduct a detailed study of its
long-term memory and concept-aware memory, showing that long-term memory
preserves temporal continuity under occlusion and reappearance, while
concept-aware memory supplies semantic priors that suppress distractors;
together, these traits directly benefit several MOSEv2's core challenges. Our
solution achieves a JF score of 39.89% on the test set, ranking 1st in the
MOSEv2 track of the LSVOS Challenge.

</details>


### [108] [Reading Images Like Texts: Sequential Image Understanding in Vision-Language Models](https://arxiv.org/abs/2509.19191)
*Yueyan Li,Chenggong Zhao,Zeyuan Zang,Caixia Yuan,Xiaojie Wang*

Main category: cs.CV

TL;DR: 本研究重新构建视觉语言模型的视觉处理机制，分离物体识别和空间感知，提出算法提升性能，并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在处理视觉信息时的方法与人类视觉的并行特性显著不同，且其内部机制不透明限制了理解和架构创新，因此本研究受人类视觉双流假说的启发，对视觉处理进行了重构和深入分析。

Method: 通过将视觉处理拆分为物体识别和空间感知，采用文本标记图的形式，对物体识别进行了两阶段的分析，并通过理论推导和实证验证了空间感知的几何结构。

Result: 提出了一种与指令无关的标记压缩算法和RoPE缩放技术，通过实验验证提升了解码效率和空间推理能力。

Conclusion: 本研究提供了对视觉语言模型内部机制的深入理解，并提出了设计未来更强大架构的明确原则。

Abstract: Vision-Language Models (VLMs) have demonstrated remarkable performance across
a variety of real-world tasks. However, existing VLMs typically process visual
information by serializing images, a method that diverges significantly from
the parallel nature of human vision. Moreover, their opaque internal mechanisms
hinder both deeper understanding and architectural innovation. Inspired by the
dual-stream hypothesis of human vision, which distinguishes the "what" and
"where" pathways, we deconstruct the visual processing in VLMs into object
recognition and spatial perception for separate study. For object recognition,
we convert images into text token maps and find that the model's perception of
image content unfolds as a two-stage process from shallow to deep layers,
beginning with attribute recognition and culminating in semantic
disambiguation. For spatial perception, we theoretically derive and empirically
verify the geometric structure underlying the positional representation in
VLMs. Based on these findings, we introduce an instruction-agnostic token
compression algorithm based on a plug-and-play visual decoder to improve
decoding efficiency, and a RoPE scaling technique to enhance spatial reasoning.
Through rigorous experiments, our work validates these analyses, offering a
deeper understanding of VLM internals and providing clear principles for
designing more capable future architectures.

</details>


### [109] [Vision-Free Retrieval: Rethinking Multimodal Search with Textual Scene Descriptions](https://arxiv.org/abs/2509.19203)
*Ioanna Ntinou,Alexandros Xenos,Yassine Ouali,Adrian Bulat,Georgios Tzimiropoulos*

Main category: cs.CV

TL;DR: 通过引入无视觉的单编解码器检索管道，本文提出了一种新的文本到文本检索范式，显著提升了检索性能和隐私性，模型在多项基准测试上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉-语言模型因其特征设计和依赖大规模数据集而存在语言理解浅薄和隐私问题，因此我们尝试不使用视觉编码器来提升检索性能。

Method: 提出了一种无视觉的单编解码器检索管道，通过使用VLLM生成的结构化图像描述，改进了文本到文本的检索范式。

Result: 相较于传统的多模态模型，我们的方法显著减小了模态间差距、提高了可组合性，并在短/长标题查询上表现更佳，且仅需在两台GPU上进行短时间的校准。

Conclusion: 我们的方法在多项检索和组合基准测试上实现了先进的零样本表现，即使模型参数仅为0.3B，证明了视觉编解码器在检索任务中的非必要性。

Abstract: Contrastively-trained Vision-Language Models (VLMs), such as CLIP, have
become the standard approach for learning discriminative vision-language
representations. However, these models often exhibit shallow language
understanding, manifesting bag-of-words behaviour. These limitations are
reinforced by their dual-encoder design, which induces a modality gap.
Additionally, the reliance on vast web-collected data corpora for training
makes the process computationally expensive and introduces significant privacy
concerns. To address these limitations, in this work, we challenge the
necessity of vision encoders for retrieval tasks by introducing a vision-free,
single-encoder retrieval pipeline. Departing from the traditional text-to-image
retrieval paradigm, we migrate to a text-to-text paradigm with the assistance
of VLLM-generated structured image descriptions. We demonstrate that this
paradigm shift has significant advantages, including a substantial reduction of
the modality gap, improved compositionality, and better performance on short
and long caption queries, all attainable with only a few hours of calibration
on two GPUs. Additionally, substituting raw images with textual descriptions
introduces a more privacy-friendly alternative for retrieval. To further assess
generalisation and address some of the shortcomings of prior compositionality
benchmarks, we release two benchmarks derived from Flickr30k and COCO,
containing diverse compositional queries made of short captions, which we coin
subFlickr and subCOCO. Our vision-free retriever matches and often surpasses
traditional multimodal models. Importantly, our approach achieves
state-of-the-art zero-shot performance on multiple retrieval and
compositionality benchmarks, with models as small as 0.3B parameters. Code is
available at: https://github.com/IoannaNti/LexiCLIP

</details>


### [110] [Long Story Short: Disentangling Compositionality and Long-Caption Understanding in VLMs](https://arxiv.org/abs/2509.19207)
*Israfel Salazar,Desmond Elliott,Yova Kementchedjhieva*

Main category: cs.CV

TL;DR: 对视觉语言模型（VLMs）进行研究，发现复合理解与长文本理解相互促进，强调高质量数据和良好设计的重要性。


<details>
  <summary>Details</summary>
Motivation: 探讨复合性与长文本理解之间的互动，假设复合性是理解长文本的关键。

Method: 训练和评估多种模型，target每种能力。

Result: 复合训练改善长文本检索性能，长文本训练促进复合性，但结果对数据质量和模型设计敏感。

Conclusion: 复合理解和长文本理解是相互交织的能力，可以通过对密集、基础描述的训练共同学习。

Abstract: Contrastive vision-language models (VLMs) have made significant progress in
binding visual and textual information, but understanding long, dense captions
remains an open challenge. We hypothesize that compositionality, the capacity
to reason about object-attribute bindings and inter-object relationships, is
key to understanding longer captions. In this paper, we investigate the
interaction between compositionality and long-caption understanding, asking
whether training for one property enhances the other. We train and evaluate a
range of models that target each of these capabilities. Our results reveal a
bidirectional relationship: compositional training improves performance on
long-caption retrieval, and training on long captions promotes
compositionality. However, these gains are sensitive to data quality and model
design. We find that training on poorly structured captions, or with limited
parameter updates, fails to support generalization. Likewise, strategies that
aim at retaining general alignment, such as freezing positional embeddings, do
not improve compositional understanding. Overall, we find that compositional
understanding and long-caption understanding are intertwined capabilities that
can be jointly learned through training on dense, grounded descriptions.
Despite these challenges, we show that models trained on high-quality,
long-caption data can achieve strong performance in both tasks, offering
practical guidance for improving VLM generalization.

</details>


### [111] [Enabling Plant Phenotyping in Weedy Environments using Multi-Modal Imagery via Synthetic and Generated Training Data](https://arxiv.org/abs/2509.19208)
*Earl Ranario,Ismael Mayanja,Heesup Yun,Brian N. Bailey,J. Mason Earles*

Main category: cs.CV

TL;DR: 为了解决户外环境中植物与杂草的低对比度和遮挡问题，研究提出了一种结合合成图像和少量真实标注的框架，通过生成对抗网络的跨模态对齐技术，显著提升了热图像中的语义分割性能。


<details>
  <summary>Details</summary>
Motivation: 在户外环境中，由于植物与杂草之间的低对比度和频繁的遮挡，精确的植物分割在高通量田间表型分析中仍然是一项重大挑战。

Method: 利用合成RGB图像、有限的真实注释和基于GAN的跨模态对齐来增强热图像中的语义分割。

Result: 通过将1128张合成图像与少量真实手动分割图像的组合，观察到杂草类别相对提高了22%，植物类别提高了17%。

Conclusion: 结合合成数据、有限的手动注释和跨域翻译可以显著提高复杂田间环境中多模态图像的分割性能。

Abstract: Accurate plant segmentation in thermal imagery remains a significant
challenge for high throughput field phenotyping, particularly in outdoor
environments where low contrast between plants and weeds and frequent
occlusions hinder performance. To address this, we present a framework that
leverages synthetic RGB imagery, a limited set of real annotations, and
GAN-based cross-modality alignment to enhance semantic segmentation in thermal
images. We trained models on 1,128 synthetic images containing complex mixtures
of crop and weed plants in order to generate image segmentation masks for crop
and weed plants. We additionally evaluated the benefit of integrating as few as
five real, manually segmented field images within the training process using
various sampling strategies. When combining all the synthetic images with a few
labeled real images, we observed a maximum relative improvement of 22% for the
weed class and 17% for the plant class compared to the full real-data baseline.
Cross-modal alignment was enabled by translating RGB to thermal using
CycleGAN-turbo, allowing robust template matching without calibration. Results
demonstrated that combining synthetic data with limited manual annotations and
cross-domain translation via generative models can significantly boost
segmentation performance in complex field environments for multi-model imagery.

</details>


### [112] [HyKid: An Open MRI Dataset with Expert-Annotated Multi-Structure and Choroid Plexus in Pediatric Hydrocephalus](https://arxiv.org/abs/2509.19218)
*Yunzhi Xu,Yushuang Ding,Hu Sun,Hongxi Zhang,Li Zhao*

Main category: cs.CV

TL;DR: HyKid是一个开放的脑积水儿童数据集，提供高分辨率3D MRI和数据分析，为相关研究提供基准，揭示脉络丛特征及其与脑积水的关系。


<details>
  <summary>Details</summary>
Motivation: 评估儿童脑积水的挑战在于缺乏公开的专家注释数据集，尤其是缺少脉络丛的分割数据。

Method: 使用切片到体积算法对常规低分辨率图像进行重建，并由经验丰富的神经科医生手动校正分割脑组织。

Result: HyKid数据集来自48名脑积水儿童，提供高分辨率的3D MRI和结构化的临床放射学报告数据，并显示脉络丛体积与总脑脊液体积之间的强相关性，为脑积水评估提供潜在生物标志。

Conclusion: HyKid数据集为神经影像算法开发提供了高质量的基准，并揭示了在脑积水评估中相关的脉络丛特征。

Abstract: Evaluation of hydrocephalus in children is challenging, and the related
research is limited by a lack of publicly available, expert-annotated datasets,
particularly those with segmentation of the choroid plexus. To address this, we
present HyKid, an open-source dataset from 48 pediatric patients with
hydrocephalus. 3D MRIs were provided with 1mm isotropic resolution, which was
reconstructed from routine low-resolution images using a slice-to-volume
algorithm. Manually corrected segmentations of brain tissues, including white
matter, grey matter, lateral ventricle, external CSF, and the choroid plexus,
were provided by an experienced neurologist. Additionally, structured data was
extracted from clinical radiology reports using a Retrieval-Augmented
Generation framework. The strong correlation between choroid plexus volume and
total CSF volume provided a potential biomarker for hydrocephalus evaluation,
achieving excellent performance in a predictive model (AUC = 0.87). The
proposed HyKid dataset provided a high-quality benchmark for neuroimaging
algorithms development, and it revealed the choroid plexus-related features in
hydrocephalus assessments. Our datasets are publicly available at
https://www.synapse.org/Synapse:syn68544889.

</details>


### [113] [MsFIN: Multi-scale Feature Interaction Network for Traffic Accident Anticipation](https://arxiv.org/abs/2509.19227)
*Tongshuai Wu,Chao Lu,Ze Song,Yunlong Lin,Sizhe Fan,Xuemei Chen*

Main category: cs.CV

TL;DR: 本研究提出了一种多尺度特征交互网络(MsFIN)，旨在提高行车记录视频中事故预测的准确性和及时性，结果显示其在多个数据集上表现优越。


<details>
  <summary>Details</summary>
Motivation: 随着行车记录仪的普及和计算机视觉的进步，从行车记录视角开发事故预测模型变得至关重要，但特征交互建模和复杂行为捕捉仍存在挑战。

Method: 提出了一种多尺度特征交互网络(MsFIN)，包含多尺度特征聚合、时间特征处理和多尺度特征后融合三个层次。

Result: 在 DAD 和 DADA 数据集上的实验表明，MsFIN 在预测准确性和及时性上均显著优于现有模型。

Conclusion: MsFIN 在事故预测上显著优于现有单尺度特征提取模型，显示多尺度特征融合和上下文交互建模的有效性。

Abstract: With the widespread deployment of dashcams and advancements in computer
vision, developing accident prediction models from the dashcam perspective has
become critical for proactive safety interventions. However, two key challenges
persist: modeling feature-level interactions among traffic participants (often
occluded in dashcam views) and capturing complex, asynchronous multi-temporal
behavioral cues preceding accidents. To deal with these two challenges, a
Multi-scale Feature Interaction Network (MsFIN) is proposed for early-stage
accident anticipation from dashcam videos. MsFIN has three layers for
multi-scale feature aggregation, temporal feature processing and multi-scale
feature post fusion, respectively. For multi-scale feature aggregation, a
Multi-scale Module is designed to extract scene representations at short-term,
mid-term and long-term temporal scales. Meanwhile, the Transformer architecture
is leveraged to facilitate comprehensive feature interactions. Temporal feature
processing captures the sequential evolution of scene and object features under
causal constraints. In the multi-scale feature post fusion stage, the network
fuses scene and object features across multiple temporal scales to generate a
comprehensive risk representation. Experiments on DAD and DADA datasets show
that MsFIN significantly outperforms state-of-the-art models with single-scale
feature extraction in both prediction correctness and earliness. Ablation
studies validate the effectiveness of each module in MsFIN, highlighting how
the network achieves superior performance through multi-scale feature fusion
and contextual interaction modeling.

</details>


### [114] [DevFD: Developmental Face Forgery Detection by Learning Shared and Orthogonal LoRA Subspaces](https://arxiv.org/abs/2509.19230)
*Tianshuo Zhang,Li Gao,Siran Peng,Xiangyu Zhu,Zhen Lei*

Main category: cs.CV

TL;DR: 研究提出了一种有效的持续学习框架，通过发展性专家混合体架构，增强了对新型人脸伪造的检测能力。


<details>
  <summary>Details</summary>
Motivation: 随着数字人脸生成和操控技术的不断进步，面部伪造检测面临巨大挑战，需要快速适应新类型的伪造，同时保留已学知识。

Method: 论文采用了发展性专家混合体（MoE）架构，使用LoRA模型作为专家，分别分为Real-LoRA和多个Fake-LoRAs，以捕捉真实和伪造人脸信息，并防止灾难性遗忘。

Result: 实验结果表明，该方法在多种数据集和操作类型的增量协议下均表现出优越的效果。

Conclusion: 该研究提出了一种基于发展性专家混合体架构的方法，有效应对面部伪造检测中的持续学习问题，提升了模型对新伪造类型的适应能力。

Abstract: The rise of realistic digital face generation and manipulation poses
significant social risks. The primary challenge lies in the rapid and diverse
evolution of generation techniques, which often outstrip the detection
capabilities of existing models. To defend against the ever-evolving new types
of forgery, we need to enable our model to quickly adapt to new domains with
limited computation and data while avoiding forgetting previously learned
forgery types. In this work, we posit that genuine facial samples are abundant
and relatively stable in acquisition methods, while forgery faces continuously
evolve with the iteration of manipulation techniques. Given the practical
infeasibility of exhaustively collecting all forgery variants, we frame face
forgery detection as a continual learning problem and allow the model to
develop as new forgery types emerge. Specifically, we employ a Developmental
Mixture of Experts (MoE) architecture that uses LoRA models as its individual
experts. These experts are organized into two groups: a Real-LoRA to learn and
refine knowledge of real faces, and multiple Fake-LoRAs to capture incremental
information from different forgery types. To prevent catastrophic forgetting,
we ensure that the learning direction of Fake-LoRAs is orthogonal to the
established subspace. Moreover, we integrate orthogonal gradients into the
orthogonal loss of Fake-LoRAs, preventing gradient interference throughout the
training process of each task. Experimental results under both the datasets and
manipulation types incremental protocols demonstrate the effectiveness of our
method.

</details>


### [115] [Lavida-O: Elastic Masked Diffusion Models for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2509.19244)
*Shufan Li,Jiuxiang Gu,Kangning Liu,Zhe Lin,Zijun Wei,Aditya Grover,Jason Kuen*

Main category: cs.CV

TL;DR: 本文提出了一种新的多模态扩散模型 Lavida-O，它能够提升图像理解与生成能力，在多个指标上超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有多模态扩散语言模型在图像理解和生成方面的局限性，Lavida-O 致力于实现更高分辨率的图像合成和更复杂的图像处理任务。

Method: 采用 Elastic Mixture-of-Transformer 架构、通用文本条件和分层抽样等新技术以实现有效的训练和采样。

Result: Lavida-O 在 RefCOCO 目标定位、GenEval 文本到图像生成和 ImgEdit 图像编辑等多个基准测试上达到了最先进的性能，并且在推理速度上也显著提升。

Conclusion: Lavida-O 是第一款统一的多模态 Masked Diffusion Model，具备先进的图像理解和生成能力，在多个基准测试中表现出色。

Abstract: We proposed Lavida-O, a unified multi-modal Masked Diffusion Model (MDM)
capable of image understanding and generation tasks. Unlike existing multimodal
diffsion language models such as MMaDa and Muddit which only support simple
image-level understanding tasks and low-resolution image generation, Lavida-O
exhibits many new capabilities such as object grounding, image-editing, and
high-resolution (1024px) image synthesis. It is also the first unified MDM that
uses its understanding capabilities to improve image generation and editing
results through planning and iterative self-reflection. To allow effective and
efficient training and sampling, Lavida-O ntroduces many novel techniques such
as Elastic Mixture-of-Transformer architecture, universal text conditioning,
and stratified sampling. \ours~achieves state-of-the-art performance on a wide
range of benchmarks such as RefCOCO object grounding, GenEval text-to-image
generation, and ImgEdit image editing, outperforming existing autoregressive
and continuous diffusion models such as Qwen2.5-VL and FluxKontext-dev, while
offering considerable speedup at inference.

</details>


### [116] [ConViS-Bench: Estimating Video Similarity Through Semantic Concepts](https://arxiv.org/abs/2509.19245)
*Benedetta Liberatori,Alessandro Conti,Lorenzo Vaquero,Yiming Wang,Elisa Ricci,Paolo Rota*

Main category: cs.CV

TL;DR: 本文提出了一种新的视频相似性评估方法（ConViS）和基准（ConViS-Bench），以支持基于概念的视频比较存取和研究。


<details>
  <summary>Details</summary>
Motivation: 探讨视频相似性的多维评估方法，以应对传统模型依赖的广泛相似性评分的不足。

Method: 引入了一种新的比较视频相似性的任务（ConViS），通过计算一组预定义的关键语义概念的可解释相似性分数。

Result: 基准测试表明，不同概念在估计视频相似度时的表现差异显著，有些概念更具挑战性。

Conclusion: ConViS-Bench 将为语言驱动的视频理解研究提供有价值的资源。

Abstract: What does it mean for two videos to be similar? Videos may appear similar
when judged by the actions they depict, yet entirely different if evaluated
based on the locations where they were filmed. While humans naturally compare
videos by taking different aspects into account, this ability has not been
thoroughly studied and presents a challenge for models that often depend on
broad global similarity scores. Large Multimodal Models (LMMs) with video
understanding capabilities open new opportunities for leveraging natural
language in comparative video tasks. We introduce Concept-based Video
Similarity estimation (ConViS), a novel task that compares pairs of videos by
computing interpretable similarity scores across a predefined set of key
semantic concepts. ConViS allows for human-like reasoning about video
similarity and enables new applications such as concept-conditioned video
retrieval. To support this task, we also introduce ConViS-Bench, a new
benchmark comprising carefully annotated video pairs spanning multiple domains.
Each pair comes with concept-level similarity scores and textual descriptions
of both differences and similarities. Additionally, we benchmark several
state-of-the-art models on ConViS, providing insights into their alignment with
human judgments. Our results reveal significant performance differences on
ConViS, indicating that some concepts present greater challenges for estimating
video similarity. We believe that ConViS-Bench will serve as a valuable
resource for advancing research in language-driven video understanding.

</details>


### [117] [Adversarially-Refined VQ-GAN with Dense Motion Tokenization for Spatio-Temporal Heatmaps](https://arxiv.org/abs/2509.19252)
*Gabriel Maldonado,Narges Rashvand,Armin Danesh Pazho,Ghazal Alinezhad Noghre,Vinit Katariya,Hamed Tabkhi*

Main category: cs.CV

TL;DR: 提出了一种对抗性精炼的VQ-GAN框架，通过密集运动分词技术来压缩时空热图，并在CMU Panoptic数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 有效压缩与表示是分析复杂运动动态的关键，尤其是在高维度和冗余性问题下。

Method: 引入对抗性精炼的VQ-GAN框架，结合密集运动分词技术用于压缩时空热图。

Result: 在CMU Panoptic数据集上，方法超越dVAE基线，SSIM提高9.31%，时间稳定性下降37.1%。

Conclusion: 该方法在压缩和表示人类运动方面表现优越，具备多种应用的实际可行性。

Abstract: Continuous human motion understanding remains a core challenge in computer
vision due to its high dimensionality and inherent redundancy. Efficient
compression and representation are crucial for analyzing complex motion
dynamics. In this work, we introduce an adversarially-refined VQ-GAN framework
with dense motion tokenization for compressing spatio-temporal heatmaps while
preserving the fine-grained traces of human motion. Our approach combines dense
motion tokenization with adversarial refinement, which eliminates
reconstruction artifacts like motion smearing and temporal misalignment
observed in non-adversarial baselines. Our experiments on the CMU Panoptic
dataset provide conclusive evidence of our method's superiority, outperforming
the dVAE baseline by 9.31% SSIM and reducing temporal instability by 37.1%.
Furthermore, our dense tokenization strategy enables a novel analysis of motion
complexity, revealing that 2D motion can be optimally represented with a
compact 128-token vocabulary, while 3D motion's complexity demands a much
larger 1024-token codebook for faithful reconstruction. These results establish
practical deployment feasibility across diverse motion analysis applications.
The code base for this work is available at
https://github.com/TeCSAR-UNCC/Pose-Quantization.

</details>


### [118] [Graph-Radiomic Learning (GrRAiL) Descriptor to Characterize Imaging Heterogeneity in Confounding Tumor Pathologies](https://arxiv.org/abs/2509.19258)
*Dheerendranath Battalapalli,Apoorva Safai,Maria Jaramillo,Hyemin Um,Gustavo Adalfo Pineda Ortiz,Ulas Bagci,Manmeet Singh Ahluwalia,Marwa Ismail,Pallavi Tiwari*

Main category: cs.CV

TL;DR: 本研究提出了一种新的GrRAiL方法，通过识别亚区域集群和计算图论度量，提升了对内部病变异质性的捕捉，从而显著提高了肿瘤复发与良性病变的区分能力。


<details>
  <summary>Details</summary>
Motivation: 为了在常规成像中更可靠地区分良性病变和恶性肿瘤，本研究旨在改进现有放射组学方法，以捕捉内部病变异质性。

Method: 采用Graph-Radiomic Learning (GrRAiL)描述符，通过每个体素的放射组学测量识别亚区域集群，并计算图论度量以量化集群间的空间关联。

Result: 在947名患者中评估了GrRAiL的有效性，结果显示其在GBM和脑转移的复发检测及胰腺肿瘤的风险分层中均超过了现有的最先进方法。

Conclusion: GrRAiL方法在多个肿瘤类型的诊断中表现优异，显著提高了对肿瘤复发与放射效应的区分及对胰腺肿瘤风险分层的准确性。

Abstract: A significant challenge in solid tumors is reliably distinguishing
confounding pathologies from malignant neoplasms on routine imaging. While
radiomics methods seek surrogate markers of lesion heterogeneity on CT/MRI,
many aggregate features across the region of interest (ROI) and miss complex
spatial relationships among varying intensity compositions. We present a new
Graph-Radiomic Learning (GrRAiL) descriptor for characterizing intralesional
heterogeneity (ILH) on clinical MRI scans. GrRAiL (1) identifies clusters of
sub-regions using per-voxel radiomic measurements, then (2) computes
graph-theoretic metrics to quantify spatial associations among clusters. The
resulting weighted graphs encode higher-order spatial relationships within the
ROI, aiming to reliably capture ILH and disambiguate confounding pathologies
from malignancy. To assess efficacy and clinical feasibility, GrRAiL was
evaluated in n=947 subjects spanning three use cases: differentiating tumor
recurrence from radiation effects in glioblastoma (GBM; n=106) and brain
metastasis (n=233), and stratifying pancreatic intraductal papillary mucinous
neoplasms (IPMNs) into no+low vs high risk (n=608). In a multi-institutional
setting, GrRAiL consistently outperformed state-of-the-art baselines - Graph
Neural Networks (GNNs), textural radiomics, and intensity-graph analysis. In
GBM, cross-validation (CV) and test accuracies for recurrence vs
pseudo-progression were 89% and 78% with >10% test-accuracy gains over
comparators. In brain metastasis, CV and test accuracies for recurrence vs
radiation necrosis were 84% and 74% (>13% improvement). For IPMN risk
stratification, CV and test accuracies were 84% and 75%, showing >10%
improvement.

</details>


### [119] [Moving by Looking: Towards Vision-Driven Avatar Motion Generation](https://arxiv.org/abs/2509.19259)
*Markos Diomataris,Berat Mert Albaba,Giorgio Becherini,Partha Ghosh,Omid Taheri,Michael J. Black*

Main category: cs.CV

TL;DR: 提出CLOPS，是首个仅使用自我中心视觉的类人-avatar，通过解耦低级技能与高等级控制成功训练出人类行为。


<details>
  <summary>Details</summary>
Motivation: 当前的人类运动生成方法忽视了感知与运动之间的相互依赖性，认为类人行为生成需要类人感知。

Method: 使用横向学习将低级动作技能与从自我中心视觉映射到高级控制命令的学习解耦，通过Q学习政策训练。

Result: 通过实验证明，自我中心视觉能赋予avatar类人运动特征，比如在行走时能够避开视觉范围内的障碍物。

Conclusion: 为人类-avatar提供类人感知的能力，尤其是自我中心的视觉，可以有效地训练出类似人类的行为。

Abstract: The way we perceive the world fundamentally shapes how we move, whether it is
how we navigate in a room or how we interact with other humans. Current human
motion generation methods, neglect this interdependency and use task-specific
``perception'' that differs radically from that of humans. We argue that the
generation of human-like avatar behavior requires human-like perception.
Consequently, in this work we present CLOPS, the first human avatar that solely
uses egocentric vision to perceive its surroundings and navigate. Using vision
as the primary driver of motion however, gives rise to a significant challenge
for training avatars: existing datasets have either isolated human motion,
without the context of a scene, or lack scale. We overcome this challenge by
decoupling the learning of low-level motion skills from learning of high-level
control that maps visual input to motion. First, we train a motion prior model
on a large motion capture dataset. Then, a policy is trained using Q-learning
to map egocentric visual inputs to high-level control commands for the motion
prior. Our experiments empirically demonstrate that egocentric vision can give
rise to human-like motion characteristics in our avatars. For example, the
avatars walk such that they avoid obstacles present in their visual field.
These findings suggest that equipping avatars with human-like sensors,
particularly egocentric vision, holds promise for training avatars that behave
like humans.

</details>


### [120] [OverLayBench: A Benchmark for Layout-to-Image Generation with Dense Overlaps](https://arxiv.org/abs/2509.19282)
*Bingnan Li,Chen-Yu Wang,Haiyang Xu,Xiang Zhang,Ethan Armand,Divyansh Srivastava,Xiaojun Shan,Zeyuan Chen,Jianwen Xie,Zhuowen Tu*

Main category: cs.CV

TL;DR: 虽然布局到图像生成已取得进展，但处理复杂重叠仍存在挑战。我们提出了OverLayScore和OverLayBench基准，以应对这些挑战，并通过CreatiLayout-AM模型改善生成效果。


<details>
  <summary>Details</summary>
Motivation: 当前布局到图像生成方法在处理大量重叠的边界框时效果欠佳，因此需要新的工具和方法来评估和改善其性能。

Method: 提出了OverLayScore作为新的评价指标，同时开发了OverLayBench基准，并且提出了CreatiLayout-AM模型进行微调。

Result: 通过定性和定量分析，我们展示了重叠区域和实例对生成质量的影响，并推出了新的评估指标和数据集。

Conclusion: 我们的研究为在复杂重叠情况下提高布局到图像生成性能奠定了基础，并提供了新的评估工具和基准。

Abstract: Despite steady progress in layout-to-image generation, current methods still
struggle with layouts containing significant overlap between bounding boxes. We
identify two primary challenges: (1) large overlapping regions and (2)
overlapping instances with minimal semantic distinction. Through both
qualitative examples and quantitative analysis, we demonstrate how these
factors degrade generation quality. To systematically assess this issue, we
introduce OverLayScore, a novel metric that quantifies the complexity of
overlapping bounding boxes. Our analysis reveals that existing benchmarks are
biased toward simpler cases with low OverLayScore values, limiting their
effectiveness in evaluating model performance under more challenging
conditions. To bridge this gap, we present OverLayBench, a new benchmark
featuring high-quality annotations and a balanced distribution across different
levels of OverLayScore. As an initial step toward improving performance on
complex overlaps, we also propose CreatiLayout-AM, a model fine-tuned on a
curated amodal mask dataset. Together, our contributions lay the groundwork for
more robust layout-to-image generation under realistic and challenging
scenarios. Project link: https://mlpc-ucsd.github.io/OverLayBench.

</details>


### [121] [Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation](https://arxiv.org/abs/2509.19296)
*Sherwin Bahmani,Tianchang Shen,Jiawei Ren,Jiahui Huang,Yifeng Jiang,Haithem Turki,Andrea Tagliasacchi,David B. Lindell,Zan Gojcic,Sanja Fidler,Huan Ling,Jun Gao,Xuanchi Ren*

Main category: cs.CV

TL;DR: 提出了一种新自蒸馏框架，可以从视频扩散模型提取3D知识，实现无多视图数据的静态及动态场景生成，表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有3D重建方法依赖现实世界的多视图数据，缺乏有效的虚拟环境生成能力。

Method: 通过将RGB解码器与3D高斯点云解码器相结合，使用合成数据进行训练，实现3D场景的实时渲染。

Result: 实验结果表明，框架在静态和动态场景生成方面表现优异。

Conclusion: 本文提出的自蒸馏框架能够有效地从视频扩散模型中提取显式的3D知识，达到最先进的静态和动态3D场景生成性能。

Abstract: The ability to generate virtual environments is crucial for applications
ranging from gaming to physical AI domains such as robotics, autonomous
driving, and industrial AI. Current learning-based 3D reconstruction methods
rely on the availability of captured real-world multi-view data, which is not
always readily available. Recent advancements in video diffusion models have
shown remarkable imagination capabilities, yet their 2D nature limits the
applications to simulation where a robot needs to navigate and interact with
the environment. In this paper, we propose a self-distillation framework that
aims to distill the implicit 3D knowledge in the video diffusion models into an
explicit 3D Gaussian Splatting (3DGS) representation, eliminating the need for
multi-view training data. Specifically, we augment the typical RGB decoder with
a 3DGS decoder, which is supervised by the output of the RGB decoder. In this
approach, the 3DGS decoder can be purely trained with synthetic data generated
by video diffusion models. At inference time, our model can synthesize 3D
scenes from either a text prompt or a single image for real-time rendering. Our
framework further extends to dynamic 3D scene generation from a monocular input
video. Experimental results show that our framework achieves state-of-the-art
performance in static and dynamic 3D scene generation.

</details>


### [122] [VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction](https://arxiv.org/abs/2509.19297)
*Weijie Wang,Yeqing Chen,Zeyu Zhang,Hengyu Liu,Haoxiao Wang,Zhiyuan Feng,Wenkang Qin,Zheng Zhu,Donny Y. Chen,Bohan Zhuang*

Main category: cs.CV

TL;DR: VolSplat是一种新的多视角3D高斯重建框架，通过体素对齐改善了重建质量，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有方法在输入视图数量、密度分布和对齐错误等方面的固有局限性，提出了VolSplat。

Method: VolSplat采用了一种新的多视角前馈框架，基于体素对齐的高斯预测，而非传统的像素对齐方法。

Result: 在RealEstate10K和ScanNet等基准数据集上的实验证明，VolSplat达到了最先进的性能，生成了更为可信且视图一致的高斯重建。

Conclusion: VolSplat方法在3D重建中实现了更好的性能，提供了更加可靠的高斯重建结果，并为未来的研究奠定了基础。

Abstract: Feed-forward 3D Gaussian Splatting (3DGS) has emerged as a highly effective
solution for novel view synthesis. Existing methods predominantly rely on a
pixel-aligned Gaussian prediction paradigm, where each 2D pixel is mapped to a
3D Gaussian. We rethink this widely adopted formulation and identify several
inherent limitations: it renders the reconstructed 3D models heavily dependent
on the number of input views, leads to view-biased density distributions, and
introduces alignment errors, particularly when source views contain occlusions
or low texture. To address these challenges, we introduce VolSplat, a new
multi-view feed-forward paradigm that replaces pixel alignment with
voxel-aligned Gaussians. By directly predicting Gaussians from a predicted 3D
voxel grid, it overcomes pixel alignment's reliance on error-prone 2D feature
matching, ensuring robust multi-view consistency. Furthermore, it enables
adaptive control over Gaussian density based on 3D scene complexity, yielding
more faithful Gaussian point clouds, improved geometric consistency, and
enhanced novel-view rendering quality. Experiments on widely used benchmarks
including RealEstate10K and ScanNet demonstrate that VolSplat achieves
state-of-the-art performance while producing more plausible and view-consistent
Gaussian reconstructions. In addition to superior results, our approach
establishes a more scalable framework for feed-forward 3D reconstruction with
denser and more robust representations, paving the way for further research in
wider communities. The video results, code and trained models are available on
our project page: https://lhmd.top/volsplat.

</details>


### [123] [CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching](https://arxiv.org/abs/2509.19300)
*Chen Chen,Pengsheng Guo,Liangchen Song,Jiasen Lu,Rui Qian,Xinze Wang,Tsu-Jui Fu,Wei Liu,Yinfei Yang,Alex Schwing*

Main category: cs.CV

TL;DR: 提出CAR-Flow方法，通过条件意识重参数化减少模型学习的复杂性，提升生成效果与训练速度。


<details>
  <summary>Details</summary>
Motivation: 希望通过减少模型学习所需的概率路径，从而加快训练速度，提高生成效果。

Method: 提出了一种条件意识重参数化方法，旨在简化流模型在生成条件数据分布时的学习过程。

Result: 在低维合成数据和高维自然图像数据上，CAR-Flow显著提高了生成的质量，并且引入的额外参数量少于0.6%。

Conclusion: 通过将条件意识重参数化应用于流匹配，CAR-Flow在保持模型参数量微小的同时，提高了训练速度和生成质量。

Abstract: Conditional generative modeling aims to learn a conditional data distribution
from samples containing data-condition pairs. For this, diffusion and
flow-based methods have attained compelling results. These methods use a
learned (flow) model to transport an initial standard Gaussian noise that
ignores the condition to the conditional data distribution. The model is hence
required to learn both mass transport and conditional injection. To ease the
demand on the model, we propose Condition-Aware Reparameterization for Flow
Matching (CAR-Flow) -- a lightweight, learned shift that conditions the source,
the target, or both distributions. By relocating these distributions, CAR-Flow
shortens the probability path the model must learn, leading to faster training
in practice. On low-dimensional synthetic data, we visualize and quantify the
effects of CAR. On higher-dimensional natural image data (ImageNet-256),
equipping SiT-XL/2 with CAR-Flow reduces FID from 2.07 to 1.68, while
introducing less than 0.6% additional parameters.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [124] [Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs](https://arxiv.org/abs/2509.18113)
*Xin Hu,Yue Kang,Guanzi Yao,Tianze Kang,Mengjie Wang,Heyao Liu*

Main category: cs.CL

TL;DR: 本研究提出了一种动态提示调度机制，以改善大语言模型在多任务与跨领域设置下的泛化能力，实验验证了其在各种语言理解和推理任务上的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在多任务和跨领域设置下普遍存在的泛化局限性。

Method: 采用统一的多任务学习框架，通过动态提示调度机制引入提示池和任务感知调度策略，以动态融合和对齐不同任务的提示。

Result: 实验结果表明，提示调度方法在保持模型稳定性和增强迁移能力方面具有显著优势，并明确证明了其在统一多任务建模和跨领域适应中的适用性和有效性。

Conclusion: 提出的动态提示调度机制显著提高了模型在语言理解和知识推理任务上的性能，并有效应对了多任务学习中的干扰和负迁移问题。

Abstract: This study addresses the generalization limitations commonly observed in
large language models under multi-task and cross-domain settings. Unlike prior
methods such as SPoT, which depends on fixed prompt templates, our study
introduces a unified multi-task learning framework with dynamic prompt
scheduling mechanism. By introducing a prompt pool and a task-aware scheduling
strategy, the method dynamically combines and aligns prompts for different
tasks. This enhances the model's ability to capture semantic differences across
tasks. During prompt fusion, the model uses task embeddings and a gating
mechanism to finely control the prompt signals. This ensures alignment between
prompt content and task-specific demands. At the same time, it builds flexible
sharing pathways across tasks. In addition, the proposed optimization objective
centers on joint multi-task learning. It incorporates an automatic learning
strategy for scheduling weights, which effectively mitigates task interference
and negative transfer. To evaluate the effectiveness of the method, a series of
sensitivity experiments were conducted. These experiments examined the impact
of prompt temperature parameters and task number variation. The results confirm
the advantages of the proposed mechanism in maintaining model stability and
enhancing transferability. Experimental findings show that the prompt
scheduling method significantly improves performance on a range of language
understanding and knowledge reasoning tasks. These results fully demonstrate
its applicability and effectiveness in unified multi-task modeling and
cross-domain adaptation.

</details>


### [125] [GAUSS: Benchmarking Structured Mathematical Skills for Large Language Models](https://arxiv.org/abs/2509.18122)
*Yue Zhang,Jiaxin Zhang,Qiuyu Ren,Tahsin Saffat,Xiaoxuan Liu,Zitong Yang,Banghua Zhu,Yi Ma*

Main category: cs.CL

TL;DR: GAUSS是一个评估大语言模型在数学能力上的基准，通过细分和分类问题，提供可解释的技能档案，突显多维度评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 创建GAUSS基准的动机在于系统性地评估大型语言模型在数学方面的能力，以深入理解其潜在的数学智能。

Method: 通过设计任务来隔离特定能力，并根据认知技能对问题进行分类，GAUSS构建了模型数学能力的细致可解释的档案。

Result: 使用GAUSS基准，我们提取了GPT-5-thinking的技能档案，揭示了其在数学能力上的强项和弱点，并与o4-mini-high进行了比较。

Conclusion: GAUSS基准提供了一种全面的方式来评估大语言模型在数学能力上的表现，通过细分技能和展示模型的优劣势，强调了多维度技能评估的重要性。

Abstract: We introduce \textbf{GAUSS} (\textbf{G}eneral \textbf{A}ssessment of
\textbf{U}nderlying \textbf{S}tructured \textbf{S}kills in Mathematics), a
benchmark that evaluates LLMs' mathematical abilities across twelve core skill
dimensions, grouped into three domains: knowledge and understanding, problem
solving and communication, and meta-skills and creativity. By categorizing
problems according to cognitive skills and designing tasks that isolate
specific abilities, GAUSS constructs comprehensive, fine-grained, and
interpretable profiles of models' mathematical abilities. These profiles
faithfully represent their underlying mathematical intelligence. To exemplify
how to use the \textsc{GAUSS} benchmark, we have derived the skill profile of
\textsc{GPT-5-thinking}, revealing its strengths and weaknesses as well as its
differences relative to \textsc{o4-mini-high}, thereby underscoring the value
of multidimensional, skill-based evaluation.

</details>


### [126] [Event Causality Identification with Synthetic Control](https://arxiv.org/abs/2509.18156)
*Haoyu Wang,Fengze Liu,Jiayao Zhang,Dan Roth,Kyle Richardson*

Main category: cs.CL

TL;DR: 本文提出了一种基于鲁宾因果模型的新方法，通过合成对照群体来识别文本中的事件因果关系，相比于传统方法表现更为出色。


<details>
  <summary>Details</summary>
Motivation: 传统的因果关系识别方法存在识别错误的风险，因此我们采用鲁宾因果模型来提高准确性。

Method: 使用鲁宾因果模型，通过生成合成对照群体来识别事件因果关系。

Result: 实际操作中，我们生成了与主角经历相同但经过处理的双胞胎，通过这种方式更有效地识别因果关系。

Conclusion: 我们的方法比以往的技术，在因果关系识别上更加稳健，尤其是针对COPES-hard数据集的测试结果。

Abstract: Event causality identification (ECI), a process that extracts causal
relations between events from text, is crucial for distinguishing causation
from correlation. Traditional approaches to ECI have primarily utilized
linguistic patterns and multi-hop relational inference, risking false causality
identification due to informal usage of causality and specious graphical
inference. In this paper, we adopt the Rubin Causal Model to identify event
causality: given two temporally ordered events, we see the first event as the
treatment and the second one as the observed outcome. Determining their
causality involves manipulating the treatment and estimating the resultant
change in the likelihood of the outcome. Given that it is only possible to
implement manipulation conceptually in the text domain, as a work-around, we
try to find a twin for the protagonist from existing corpora. This twin should
have identical life experiences with the protagonist before the treatment but
undergoes an intervention of treatment. However, the practical difficulty of
locating such a match limits its feasibility. Addressing this issue, we use the
synthetic control method to generate such a twin' from relevant historical
data, leveraging text embedding synthesis and inversion techniques. This
approach allows us to identify causal relations more robustly than previous
methods, including GPT-4, which is demonstrated on a causality benchmark,
COPES-hard.

</details>


### [127] [ZERA: Zero-init Instruction Evolving Refinement Agent - From Zero Instructions to Structured Prompts via Principle-based Optimization](https://arxiv.org/abs/2509.18158)
*Seungyoun Yi,Minsoo Khang,Sungrae Park*

Main category: cs.CL

TL;DR: 我们提出了ZER A框架，通过低成本的修正方法联合优化系统和用户提示，显著提高大型语言模型的任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有的自动提示优化方法通常依赖于用户提示和未结构化反馈，需要大量样本和长时间迭代，造成成本高且不稳定。

Method: 通过自动推断权重的八个可推广标准来评分提示，并基于结构化批评修正提示，从而实现系统和用户提示的联合优化。

Result: 我们在五个大型语言模型和九个不同的数据集上评估了ZER A，结果展示了其在推理、摘要和代码生成任务中的一致性提升。

Conclusion: 实验结果表明，ZER A在多个任务上相较于强基线有一致的改进，且每个组成部分对更有效的提示构建都贡献显著。

Abstract: Automatic Prompt Optimization (APO) improves large language model (LLM)
performance by refining prompts for specific tasks. However, prior APO methods
typically focus only on user prompts, rely on unstructured feedback, and
require large sample sizes and long iteration cycles-making them costly and
brittle. We propose ZERA (Zero-init Instruction Evolving Refinement Agent), a
novel framework that jointly optimizes both system and user prompts through
principled, low-overhead refinement. ZERA scores prompts using eight
generalizable criteria with automatically inferred weights, and revises prompts
based on these structured critiques. This enables fast convergence to
high-quality prompts using minimal examples and short iteration cycles. We
evaluate ZERA across five LLMs and nine diverse datasets spanning reasoning,
summarization, and code generation tasks. Experimental results demonstrate
consistent improvements over strong baselines. Further ablation studies
highlight the contribution of each component to more effective prompt
construction. Our implementation including all prompts is publicly available at
https://github.com/younatics/zera-agent.

</details>


### [128] [Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning](https://arxiv.org/abs/2509.18163)
*Haodong Zhao,Chenyan Zhao,Yansi Li,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.CL

TL;DR: 这篇论文研究了外部辅助信息对大语言模型推理的因果影响，提出SciAux数据集，并揭示误导性信息显著降低模型表现，且思考过程会加剧这一问题。


<details>
  <summary>Details</summary>
Motivation: 探究辅助信息对大语言模型推理过程的因果影响，特别是在复杂的知识密集型领域中的应用。

Method: 通过引入SciAux数据集，系统测试LLMs在面对不同类型辅助信息时的鲁棒性。

Result: 发现模型在提供误导性信息时表现出显著的脆弱性，思维模式加剧了错误率的提高。

Conclusion: 模型的思考过程在处理误导性信息时可能导致更大的错误，因此需要在模型中引入评估信息真伪的能力。

Abstract: The capacity of Large Language Models (LLMs) to reason is fundamental to
their application in complex, knowledge-intensive domains. In real-world
scenarios, LLMs are often augmented with external information that can be
helpful, irrelevant, or even misleading. This paper investigates the causal
impact of such auxiliary information on the reasoning process of LLMs with
explicit step-by-step thinking capabilities. We introduce SciAux, a new dataset
derived from ScienceQA, to systematically test the robustness of the model
against these types of information. Our findings reveal a critical
vulnerability: the model's deliberative "thinking mode" is a double-edged
sword. While helpful context improves accuracy, misleading information causes a
catastrophic drop in performance, which is amplified by the thinking process.
Instead of conferring robustness, thinking reinforces the degree of error when
provided with misinformation. This highlights that the challenge is not merely
to make models "think", but to endow them with the critical faculty to evaluate
the information upon which their reasoning is based. The SciAux dataset is
available at https://huggingface.co/datasets/billhdzhao/SciAux.

</details>


### [129] [SIRAG: Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework](https://arxiv.org/abs/2509.18167)
*Junlin Wang,Zehao Wu,Shaowei Lu,Yanlan Li,Xinghao Huang*

Main category: cs.CL

TL;DR: 提出了一种过程监督的多智能体框架，优化了检索增强生成的性能，实现了高准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 旨在弥补检索器与生成器之间的协调不足，改善检索的相关性和生成的有效性。

Method: 提出了一种过程监督的多智能体框架，包含决策者和知识选择器，并使用大型语言模型作为评判者进行过程级奖励评估。

Result: 在单跳和多跳问答基准上，该方法实现了更高的准确率和更稳定的收敛性，并产生了更易于解释的推理轨迹。

Conclusion: 所提框架在准确性、稳定收敛性和可解释性上显著优于标准的检索增强生成基线，且具有模块化和可插拔特性，适用于实际应用。

Abstract: Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to
access external knowledge sources, but the effectiveness of RAG relies on the
coordination between the retriever and the generator. Since these components
are developed independently, their interaction is often suboptimal: the
retriever may return irrelevant or redundant documents, while the generator may
fail to fully leverage retrieved evidence. In this work, we propose a
process-supervised multi-agent framework to bridge the gap between retriever
and generator. The framework introduces two lightweight agents: a Decision
Maker, which determines when to continue retrieval or stop for answer
generation, and a Knowledge Selector, which filters retrieved documents to
retain only the most useful evidence. To provide fine-grained supervision, we
employ an LLM-as-a-Judge that evaluates each intermediate action with
process-level rewards, ensuring more accurate credit assignment than relying
solely on final answer correctness. We further adopt a tree-structured rollout
strategy to explore diverse reasoning paths, and train both agents with
Proximal Policy Optimization (PPO) in an end-to-end manner. Experiments on
single-hop and multi-hop question answering benchmarks show that our approach
achieves higher accuracy, more stable convergence, and produces more
interpretable reasoning trajectories compared with standard RAG baselines.
Importantly, the proposed framework is modular and plug-and-play, requiring no
modification to the retriever or generator, making it practical for real-world
RAG applications.

</details>


### [130] [ERFC: Happy Customers with Emotion Recognition and Forecasting in Conversation in Call Centers](https://arxiv.org/abs/2509.18175)
*Aditi Debsharma,Bhushan Jagyasi,Surajit Sen,Priyanka Pandey,Devicharith Dovari,Yuvaraj V. C,Rosalin Parida,Gopali Contractor*

Main category: cs.CL

TL;DR: 本研究提出了一种新架构ERFC，用于在对话中识别和预测情感，旨在提高呼叫中心客户体验。


<details>
  <summary>Details</summary>
Motivation: 在呼叫中心场景中，客服代理不仅仅是接听电话，更需要通过维持中性和积极的情绪来提高客户体验。

Method: 提出了一种新颖的ERFC架构，考虑了多种模态、情感的不同属性、上下文及说话者之间的相互依赖性。

Result: 在IEMOCAP数据集上进行的实验显示了ERFC方法的可行性，并能够有效预测未来的发言情感。

Conclusion: 本研究提出的情感识别与预测框架（ERFC）在提高客户满意度方面具有重要的商业价值。

Abstract: Emotion Recognition in Conversation has been seen to be widely applicable in
call center analytics, opinion mining, finance, retail, healthcare, and other
industries. In a call center scenario, the role of the call center agent is not
just confined to receiving calls but to also provide good customer experience
by pacifying the frustration or anger of the customers. This can be achieved by
maintaining neutral and positive emotion from the agent. As in any
conversation, the emotion of one speaker is usually dependent on the emotion of
other speaker. Hence the positive emotion of an agent, accompanied with the
right resolution will help in enhancing customer experience. This can change an
unhappy customer to a happy one. Imparting the right resolution at right time
becomes easier if the agent has the insight of the emotion of future
utterances. To predict the emotions of the future utterances we propose a novel
architecture, Emotion Recognition and Forecasting in Conversation. Our proposed
ERFC architecture considers multi modalities, different attributes of emotion,
context and the interdependencies of the utterances of the speakers in the
conversation. Our intensive experiments on the IEMOCAP dataset have shown the
feasibility of the proposed ERFC. This approach can provide a tremendous
business value for the applications like call center, where the happiness of
customer is utmost important.

</details>


### [131] [Evaluating Large Language Models for Detecting Antisemitism](https://arxiv.org/abs/2509.18293)
*Jay Patel,Hrudayangam Mehta,Jeremy Blackburn*

Main category: cs.CL

TL;DR: 本研究评估了开源大型语言模型在检测反犹太主义内容的能力，提出了新的Guided-CoT提示，提高了所有模型的性能，特别是Llama 3.1 70B优于GPT-3.5，并分析了模型的错误与语义差异。


<details>
  <summary>Details</summary>
Motivation: 检测仇恨内容是一个具有挑战性的重要问题，自动化工具（如机器学习模型）可以帮助解决此问题，但需要持续训练以适应不断变化的社交媒体环境。

Method: 本研究评估了八种开源大型语言模型（LLMs）在检测反犹太主义内容方面的能力，利用上下文定义作为政策指南，并探索了多种提示技术，设计了一种新的提示方式：Guided-CoT。

Result: 研究发现，Guided-CoT在所有评估的模型中都提高了性能，且在模型大小、解码配置或推理能力上表现出色，尤其是Llama 3.1 70B的表现优于微调的GPT-3.5。此外，对LLM的错误分析显示出模型生成推理的语义差异及其矛盾行为。

Conclusion: 本研究提出了一种新的引导型链推理提示（Guided-CoT），提高了检测反犹太主义内容的性能，并分析了不同语言模型的错误以及模型生成的推理的语义差异。

Abstract: Detecting hateful content is a challenging and important problem. Automated
tools, like machine-learning models, can help, but they require continuous
training to adapt to the ever-changing landscape of social media. In this work,
we evaluate eight open-source LLMs' capability to detect antisemitic content,
specifically leveraging in-context definition as a policy guideline. We explore
various prompting techniques and design a new CoT-like prompt, Guided-CoT.
Guided-CoT handles the in-context policy well, increasing performance across
all evaluated models, regardless of decoding configuration, model sizes, or
reasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5.
Additionally, we examine LLM errors and introduce metrics to quantify semantic
divergence in model-generated rationales, revealing notable differences and
paradoxical behaviors among LLMs. Our experiments highlight the differences
observed across LLMs' utility, explainability, and reliability.

</details>


### [132] [Exploiting Tree Structure for Credit Assignment in RL Training of LLMs](https://arxiv.org/abs/2509.18314)
*Hieu Tran,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: 文章提出了TEMPO，通过将多响应转化为前缀树并计算非参数前缀值，解决了长期序列中的token级别信用分配问题。


<details>
  <summary>Details</summary>
Motivation: 解决在长序列中因稀疏延迟奖励导致的token级别信用分配问题，从而改善LLM的推理能力。

Method: TEMPO是一种无评论者算法，通过使用基于树的分支门控时间差校正，增强GRPO的信号。

Result: TEMPO在Qwen3-1.7B/4B上对于内部分布（MATH，MedQA）和外部分布（GSM-HARD，AMC23，MedMCQA，MMLU-Medical）基准均有更好的表现。

Conclusion: TEMPO在多个基准测试上 outperform PPO和GRPO，并且提高了验证准确性，所需时间基本相同。

Abstract: Reinforcement learning improves LLM reasoning, yet sparse delayed reward over
long sequences makes token-level credit assignment the key bottleneck. We study
the verifiable-reward setting, where the final answer is checkable and multiple
responses can be drawn per prompt. Reasoning tasks in math and medical QA align
with this setup, where only a few decision tokens significantly impact the
outcome. PPO offers token-level advantages with a learned value model, but it
is complex to train both the actor and critic models simultaneously, and it is
not easily generalizable, as the token-level values from the critic model can
make training prone to overfitting. GRPO is critic-free and supports verifiable
rewards, but spreads a single sequence-level return across tokens and ignores
branching. We introduce \textbf{Prefix-to-Tree (P2T)}, a simple procedure that
converts a group of responses into a prefix tree and computes
\emph{nonparametric} prefix values \(V(s)\) by aggregating descendant outcomes.
Built on P2T, we propose \textbf{TEMPO} (\emph{\textbf{T}ree-\textbf{E}stimated
\textbf{M}ean Prefix Value for \textbf{P}olicy \textbf{O}ptimization}), a
critic-free algorithm that augments the group-relative outcome signal of GRPO
with \emph{branch-gated} temporal-difference corrections derived from the tree.
At non-branch tokens, the temporal-difference (TD) term is zero, so TEMPO
reduces to GRPO; at branching tokens, it supplies precise token-level credit
without a learned value network or extra judges/teachers. On Qwen3-1.7B/4B,
TEMPO outperforms PPO and GRPO on in-distribution (MATH, MedQA) and
out-of-distribution (GSM-HARD, AMC23, MedMCQA, MMLU-Medical) benchmarks, and
reaches higher validation accuracy with roughly the same wall-clock time.

</details>


### [133] [Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning](https://arxiv.org/abs/2509.18316)
*Saksham Khatwani,He Cheng,Majid Afshar,Dmitriy Dligach,Yanjun Gao*

Main category: cs.CL

TL;DR: 研究探讨了如何利用知识图谱提升大型语言模型的诊断推理能力，评估了奖励模型风格推理的有效性及其在医疗任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在诊断推理方面表现出潜力，但往往缺乏可靠的知识基础推理。知识图谱提供的结构化生物医学知识可以支持可信赖的推理。

Method: 本研究采用了将大型语言模型视为知识图谱推理路径的奖励模型，评估其路径判断能力并测试其在下游诊断任务中的迁移性。

Result: 研究发现，特定的奖励优化和蒸馏能够提高路径判断性能，但在下游任务上的迁移能力仍然较弱。

Conclusion: 本研究首次系统地评估了临床知识图谱上的“奖励模型风格”推理，提供了关于结构化奖励监督如何影响医疗领域生成AI系统的诊断推理的见解。

Abstract: Large language models (LLMs) show promise for diagnostic reasoning but often
lack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as
the Unified Medical Language System (UMLS), offer structured biomedical
knowledge that can support trustworthy reasoning. Prior approaches typically
integrate KGs via retrieval augmented generation or fine tuning, inserting KG
content into prompts rather than enabling structured reasoning. We explore an
alternative paradigm: treating the LLM as a reward model of KG reasoning paths,
where the model learns to judge whether a candidate path leads to correct
diagnosis for a given patient input. This approach is inspired by recent work
that leverages reward training to enhance model reasoning abilities, and
grounded in computational theory, which suggests that verifying a solution is
often easier than generating one from scratch. It also parallels physicians'
diagnostic assessment, where they judge which sequences of findings and
intermediate conditions most plausibly support a diagnosis. We first
systematically evaluate five task formulation for knowledge path judging and
eight training paradigm. Second, we test whether the path judging abilities
generalize to downstream diagnostic tasks, including diagnosis summarization
and medical question answering. Experiments with three open source
instruct-tuned LLMs reveal both promise and brittleness: while specific reward
optimization and distillation lead to strong path-judging performance, the
transferability to downstream tasks remain weak. Our finding provides the first
systematic assessment of "reward model style" reasoning over clinical KGs,
offering insights into how structured, reward-based supervision influences
diagnostic reasoning in GenAI systems for healthcare.

</details>


### [134] [LOTUSDIS: A Thai far-field meeting corpus for robust conversational ASR](https://arxiv.org/abs/2509.18722)
*Pattara Tipaksorn,Sumonmas Thatphithakkul,Vataya Chunwijitra,Kwanchiva Thangthai*

Main category: cs.CL

TL;DR: LOTUSDIS是一个公开的泰语会议语料库，旨在提升远场语音识别的鲁棒性，通过训练显著改善识别模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 创建一个可公开获取的泰语会议语料库，以提高远场对话语音识别技术的效果，填补现有数据集与泰语远场语音之间的缺口。

Method: 通过使用九个独立的单通道设备在不同距离记录泰语自然对话，分析了多种Whisper模型在零样本和微调条件下的表现。

Result: 在LOTUSDIS数据集上，通过微调，泰语Whisper模型的整体字错误率（WER）从64.3降至38.3，远场WER从81.6降至49.5，尤其在最远的麦克风上提高显著。

Conclusion: LOTUSDIS语料库对于提高远场对话语音识别（ASR）的鲁棒性至关重要，并且通过对泰语Whisper模型的微调显著提高了识别准确率。

Abstract: We present LOTUSDIS, a publicly available Thai meeting corpus designed to
advance far-field conversational ASR. The dataset comprises 114 hours of
spontaneous, unscripted dialogue collected in 15-20 minute sessions with three
participants, where overlapping speech is frequent and natural. Speech was
recorded simultaneously by nine independent single-channel devices spanning six
microphone types at distances from 0.12 m to 10 m, preserving the authentic
effects of reverberation, noise, and device coloration without relying on
microphone arrays. We provide standard train, dev, test splits and release a
reproducible baseline system. We benchmarked several Whisper variants under
zero-shot and fine-tuned conditions. Off-the-shelf models showed strong
degradation with distance, confirming a mismatch between pre-training data and
Thai far-field speech. Fine-tuning on LOTUSDIS dramatically improved
robustness: a Thai Whisper baseline reduced overall WER from 64.3 to 38.3 and
far-field WER from 81.6 to 49.5, with especially large gains on the most
distant microphones. These results underscore the importance of
distance-diverse training data for robust ASR. The corpus is available under
CC-BY-SA 4.0. We also release training and evaluation scripts as a baseline
system to promote reproducible research in this field.

</details>


### [135] [Speculate Deep and Accurate: Lossless and Training-Free Acceleration for Offloaded LLMs via Substitute Speculative Decoding](https://arxiv.org/abs/2509.18344)
*Pei-Shuo Wang,Jian-Jia Chen,Chun-Che Yang,Chi-Chih Chang,Ning-Chi Huang,Mohamed S. Abdelfattah,Kai-Chiang Wu*

Main category: cs.CL

TL;DR: 为了解决大语言模型的部署问题，SubSpec提出了一种无损且无需训练的方法，通过生成低位量化的替代层和共享GPU层，显著提高了参数卸载的速度并实现了各项基准上的优异表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的庞大规模给内存有限的消费级GPU的部署带来了挑战，现有的压缩与参数卸载策略面临质量降低与推理速度慢的双重问题，因此我们需要一种高效且无训练的方法来加速这一过程。

Method: SubSpec通过从卸载的目标LLM部分生成低位量化的替代层来构建高度对齐的草案模型，同时共享其余的GPU驻留层和KV-Cache，实现高效的参数卸载加速。

Result: SubSpec在MT-Bench和流行生成基准测试中，分别实现了9.1倍和12.5倍的速度提升，且在不同资源限制下仍能保持高平均接受长度。

Conclusion: SubSpec是一种无损且无需训练的方法，通过生成低位量化替代层和共享GPU驻留的层与KV-Cache，显著提高了参数转移的速度，减少了内存开销，并且在多个基准测试上实现了显著的加速效果。

Abstract: The immense model sizes of large language models (LLMs) challenge deployment
on memory-limited consumer GPUs. Although model compression and parameter
offloading are common strategies to address memory limitations, compression can
degrade quality, and offloading maintains quality but suffers from slow
inference. Speculative decoding presents a promising avenue to accelerate
parameter offloading, utilizing a fast draft model to propose multiple draft
tokens, which are then verified by the target LLM in parallel with a single
forward pass. This method reduces the time-consuming data transfers in forward
passes that involve offloaded weight transfers. Existing methods often rely on
pretrained weights of the same family, but require additional training to align
with custom-trained models. Moreover, approaches that involve draft model
training usually yield only modest speedups. This limitation arises from
insufficient alignment with the target model, preventing higher token
acceptance lengths. To address these challenges and achieve greater speedups,
we propose SubSpec, a plug-and-play method to accelerate parameter offloading
that is lossless and training-free. SubSpec constructs a highly aligned draft
model by generating low-bit quantized substitute layers from offloaded target
LLM portions. Additionally, our method shares the remaining GPU-resident layers
and the KV-Cache, further reducing memory overhead and enhance alignment.
SubSpec achieves a high average acceptance length, delivering 9.1x speedup for
Qwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for
Qwen2.5 32B on popular generation benchmarks (24GB VRAM limit).

</details>


### [136] [SloPalSpeech: A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data](https://arxiv.org/abs/2509.19270)
*Erik Božík,Marek Šuppa*

Main category: cs.CL

TL;DR: 为解决斯洛伐克语自动语音识别中的数据稀缺问题，提出了 SloPalSpeech 数据集并展示了其在微调多个 Whisper 模型中的有效性。


<details>
  <summary>Details</summary>
Motivation: 低资源语言（如斯洛伐克语）的自动语音识别因训练数据稀缺而受到限制。

Method: 创建了一个包含2806小时议会记录的斯洛伐克 ASR 数据集，并使用该数据集微调多个 OpenAI Whisper 模型。

Result: 微调后的 Whisper-small 模型在标准斯洛伐克基准测试中的错误率降低了高达70%，接近 Whisper-large-v3 模型的基线表现。

Conclusion: SloPalSpeech 数据集及其相关模型的发布将推动低资源语言的语音识别研究，特别是斯洛伐克语。

Abstract: Automatic Speech Recognition (ASR) for low-resource languages like Slovak is
hindered by the scarcity of training data. To address this, we introduce
SloPalSpeech, a new, large-scale Slovak ASR dataset containing 2,806 hours of
speech from parliamentary proceedings. We developed a robust processing
pipeline to align and segment long-form recordings into clean, 30-second
audio-transcript pairs suitable for model training. We use this dataset to
fine-tune several OpenAI Whisper models (small, medium, large-v3, and
large-v3-turbo), achieving significant Word Error Rate (WER) reductions on
standard Slovak benchmarks like Common Voice and FLEURS. For instance, the
fine-tuned Whisper-small model's WER dropped by up to 70\%, approaching the
baseline performance of the much larger Whisper-large-v3 model. To foster
future research in low-resource speech recognition, we publicly release the
complete SloPalSpeech dataset, the fully segmented transcripts (60 million
words), and all our fine-tuned models.

</details>


### [137] [Speech Vecalign: an Embedding-based Method for Aligning Parallel Speech Documents](https://arxiv.org/abs/2509.18360)
*Chutong Meng,Philipp Koehn*

Main category: cs.CL

TL;DR: Speech Vecalign是一种新方法，在不依赖文本的情况下提高了语音对齐和翻译性能，相比传统方法实现更长、更高质量的对齐结果。


<details>
  <summary>Details</summary>
Motivation: 通过改进以往的对齐技术，实现更长且更高质量的语音对齐，尤其是在没有文本转录的情况下。

Method: Speech Vecalign是一种不依赖文本转录的平行语音文档对齐方法，通过单调对齐语音段嵌入。

Result: 使用Speech Vecalign处理的VoxPopuli语音文档提供了约1000小时的高质量对齐，且在翻译模型上表现出优越性。

Conclusion: Speech Vecalign在对齐和翻译性能上优于传统方法，展示了其有效性。

Abstract: We present Speech Vecalign, a parallel speech document alignment method that
monotonically aligns speech segment embeddings and does not depend on text
transcriptions. Compared to the baseline method Global Mining, a variant of
speech mining, Speech Vecalign produces longer speech-to-speech alignments. It
also demonstrates greater robustness than Local Mining, another speech mining
variant, as it produces less noise. We applied Speech Vecalign to 3,000 hours
of unlabeled parallel English-German (En-De) speech documents from VoxPopuli,
yielding about 1,000 hours of high-quality alignments. We then trained En-De
speech-to-speech translation models on the aligned data. Speech Vecalign
improves the En-to-De and De-to-En performance over Global Mining by 0.37 and
0.18 ASR-BLEU, respectively. Moreover, our models match or outperform
SpeechMatrix model performance, despite using 8 times fewer raw speech
documents.

</details>


### [138] [Interactive Real-Time Speaker Diarization Correction with Human Feedback](https://arxiv.org/abs/2509.18377)
*Xinlu He,Yiwen Guan,Badrivishal Paurana,Zilin Dai,Jacob Whitehill*

Main category: cs.CL

TL;DR: 本文提出了一种 LLM 辅助的说话者 diarization 纠正系统，通过实时用户反馈显著提高了自动语音识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 大多数自动语音处理系统采用“开放循环”模式，缺乏用户反馈，而人机协作工作流程可提高系统的准确性。

Method: 提出了一种基于大语言模型（LLM）的说话者 diarization 纠正系统，通过实时用户反馈修正说话者归属错误。

Result: 在 AMI 测试集上的 LLM 驱动模拟表明，该系统将说话者识别错误率(DER)降低了 9.92%，并将说话者混淆错误降低了 44.23%。

Conclusion: 该系统显著降低了说话者识别错误率和混淆错误率，展示了人机协作在语音处理中的潜力。

Abstract: Most automatic speech processing systems operate in "open loop" mode without
user feedback about who said what; yet, human-in-the-loop workflows can
potentially enable higher accuracy. We propose an LLM-assisted speaker
diarization correction system that lets users fix speaker attribution errors in
real time. The pipeline performs streaming ASR and diarization, uses an LLM to
deliver concise summaries to the users, and accepts brief verbal feedback that
is immediately incorporated without disrupting interactions. Moreover, we
develop techniques to make the workflow more effective: First, a
split-when-merged (SWM) technique detects and splits multi-speaker segments
that the ASR erroneously attributes to just a single speaker. Second, online
speaker enrollments are collected based on users' diarization corrections, thus
helping to prevent speaker diarization errors from occurring in the future.
LLM-driven simulations on the AMI test set indicate that our system
substantially reduces DER by 9.92% and speaker confusion error by 44.23%. We
further analyze correction efficacy under different settings, including summary
vs full transcript display, the number of online enrollments limitation, and
correction frequency.

</details>


### [139] [NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided Social Norm Modeling and Violation Recovery](https://arxiv.org/abs/2509.18395)
*Minki Hong,Jangho Choi,Jihie Kim*

Main category: cs.CL

TL;DR: 本研究提出了NormGenesis，一个多文化框架，用于生成和注释社会基础对话，模型通过违规到解决的对话类型，以改进不同语言中的实用一致性，并构建了一个包含10,800个多轮对话的数据集，展示了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 社交规范在沟通中规范文化上适当的行为，使对话系统能够生成不仅连贯而且社会上可接受的响应。

Method: 提出了一种新的对话类型，违规到解决（V2R），模型通过识别和社交适当的修复来学习违反规范后的对话发展，并在对话合成早期实施例子基础的迭代改进。

Result: NormGenesis在精细化质量、对话自然性和泛化性能方面显著优于现有数据集，且训练在其V2R增强数据上的模型在伦理敏感背景下的实用能力有所提高。

Conclusion: NormGenesis建立了一个新的基准，用于文化适应性对话建模，并提供了一种可扩展的方法论，适用于语言和文化多样性的规范意识生成。

Abstract: Social norms govern culturally appropriate behavior in communication,
enabling dialogue systems to produce responses that are not only coherent but
also socially acceptable. We present NormGenesis, a multicultural framework for
generating and annotating socially grounded dialogues across English, Chinese,
and Korean. To model the dynamics of social interaction beyond static norm
classification, we propose a novel dialogue type, Violation-to-Resolution
(V2R), which models the progression of conversations following norm violations
through recognition and socially appropriate repair. To improve pragmatic
consistency in underrepresented languages, we implement an exemplar-based
iterative refinement early in the dialogue synthesis process. This design
introduces alignment with linguistic, emotional, and sociocultural expectations
before full dialogue generation begins. Using this framework, we construct a
dataset of 10,800 multi-turn dialogues annotated at the turn level for norm
adherence, speaker intent, and emotional response. Human and LLM-based
evaluations demonstrate that NormGenesis significantly outperforms existing
datasets in refinement quality, dialogue naturalness, and generalization
performance. We show that models trained on our V2R-augmented data exhibit
improved pragmatic competence in ethically sensitive contexts. Our work
establishes a new benchmark for culturally adaptive dialogue modeling and
provides a scalable methodology for norm-aware generation across linguistically
and culturally diverse languages.

</details>


### [140] [Evaluating the Creativity of LLMs in Persian Literary Text Generation](https://arxiv.org/abs/2509.18401)
*Armin Tourajmehr,Mohammad Reza Modarres,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 本研究评估大型语言模型生成波斯文学文本的能力，构建数据集并采用创造力四维评估，结果显示其优势与局限并存。


<details>
  <summary>Details</summary>
Motivation: 之前的研究主要集中在英语的创造力生成上，缺乏对非英语文学传统的探索及标准化的评估方法，因此本研究旨在评估LLM生成波斯文学文本的能力。

Method: 通过构建一个包含20个多样主题的用户生成的波斯文学数据集，并采用托伦斯创意思维测试来评估模型输出的创造力维度（原创性、流畅性、灵活性和详细程度），并使用LLM进行自动评分以降低评估成本。

Result: 研究发现，LLM在波斯文学文本生成中展示了强大的原创性和流畅性，但在文学修辞的理解与运用方面仍然有所欠缺。

Conclusion: 大型语言模型在波斯文学文本生成中表现出一定的优势，但仍存在局限性，需要进一步改进。

Abstract: Large language models (LLMs) have demonstrated notable creative abilities in
generating literary texts, including poetry and short stories. However, prior
research has primarily centered on English, with limited exploration of
non-English literary traditions and without standardized methods for assessing
creativity. In this paper, we evaluate the capacity of LLMs to generate Persian
literary text enriched with culturally relevant expressions. We build a dataset
of user-generated Persian literary spanning 20 diverse topics and assess model
outputs along four creativity dimensions-originality, fluency, flexibility, and
elaboration-by adapting the Torrance Tests of Creative Thinking. To reduce
evaluation costs, we adopt an LLM as a judge for automated scoring and validate
its reliability against human judgments using intraclass correlation
coefficients, observing strong agreement. In addition, we analyze the models'
ability to understand and employ four core literary devices: simile, metaphor,
hyperbole, and antithesis. Our results highlight both the strengths and
limitations of LLMs in Persian literary text generation, underscoring the need
for further refinement.

</details>


### [141] [Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations](https://arxiv.org/abs/2509.18439)
*Oscar J. Ponce-Ponte,David Toro-Tobon,Luis F. Figueroa,Michael Gionfriddo,Megan Branda,Victor M. Montori,Saturnino Luz,Juan P. Brito*

Main category: cs.CL

TL;DR: 本研究开发了一种自动化的方法来测量患者与医生之间的共享决策，利用深度学习模型和对话对齐分数，发现不同模型的分数与多种决策结果相关，为未来的SDM评估提供了方法学基础。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏一种可以大规模自动测量共享决策(SDM)的方法，迫切需要改善以患者为中心的护理。

Method: 采用深度学习模型和微调BERT模型，通过上下文-响应对和负采样来训练模型，计算对话对齐分数，并进行统计分析。

Result: 在157名患者中，不同模型计算的对话对齐分数与决策冲突量表(DCS)和观察患者参与决策12(OPTION12)分数之间存在统计关联，特别是微调的BERT模型效果最佳。

Conclusion: 本研究提出了一种自动化、可扩展的方法，通过可解释的对话对齐分数来测量患者与医生之间的共享决策，具有在更大规模评估SDM策略的潜力。

Abstract: Shared decision-making (SDM) is necessary to achieve patient-centred care.
Currently no methodology exists to automatically measure SDM at scale. This
study aimed to develop an automated approach to measure SDM by using language
modelling and the conversational alignment (CA) score. A total of 157
video-recorded patient-doctor conversations from a randomized multi-centre
trial evaluating SDM decision aids for anticoagulation in atrial fibrillations
were transcribed and segmented into 42,559 sentences. Context-response pairs
and negative sampling were employed to train deep learning (DL) models and
fine-tuned BERT models via the next sentence prediction (NSP) task. Each
top-performing model was used to calculate four types of CA scores. A
random-effects analysis by clinician, adjusting for age, sex, race, and trial
arm, assessed the association between CA scores and SDM outcomes: the
Decisional Conflict Scale (DCS) and the Observing Patient Involvement in
Decision-Making 12 (OPTION12) scores. p-values were corrected for multiple
comparisons with the Benjamini-Hochberg method. Among 157 patients (34% female,
mean age 70 SD 10.8), clinicians on average spoke more words than patients
(1911 vs 773). The DL model without the stylebook strategy achieved a recall@1
of 0.227, while the fine-tuned BERTbase (110M) achieved the highest recall@1
with 0.640. The AbsMax (18.36 SE7.74 p=0.025) and Max CA (21.02 SE7.63 p=0.012)
scores generated with the DL without stylebook were associated with OPTION12.
The Max CA score generated with the fine-tuned BERTbase (110M) was associated
with the DCS score (-27.61 SE12.63 p=0.037). BERT model sizes did not have an
impact the association between CA scores and SDM. This study introduces an
automated, scalable methodology to measure SDM in patient-doctor conversations
through explainable CA scores, with potential to evaluate SDM strategies at
scale.

</details>


### [142] [CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable Length, Intrinsic Difficulty, and Distractor Density](https://arxiv.org/abs/2509.18458)
*Daniel Kaiser,Arnoldo Frigessi,Ali Ramezani-Kebrya,Benjamin Ricaud*

Main category: cs.CL

TL;DR: CogniLoad 是一个基于认知负荷理论的基准，可用于分析 LLM 的推理限制，揭示了任务长度的主要影响及其他因素的作用。


<details>
  <summary>Details</summary>
Motivation: 当前的 LLM 基准模糊了关键因素，难以进行精准的失败分析，因此需要一个更精确的基准工具。

Method: CogniLoad 通过生成自然语言逻辑难题，使用与认知负荷理论相关的可调参数，评估 22 种最先进的推理 LLM。

Result: CogniLoad 发现了 LLM 在任务长度、内在复杂性和干扰比率上的不同表现敏感性，任务长度被识别为主要约束因素。

Conclusion: CogniLoad 是一个新颖的合成基准，可帮助分析长上下文推理中的问题，提供系统的认知负荷控制，为 LLM 的推理限制提供了可重复、可扩展的工具。

Abstract: Current benchmarks for long-context reasoning in Large Language Models (LLMs)
often blur critical factors like intrinsic task complexity, distractor
interference, and task length. To enable more precise failure analysis, we
introduce CogniLoad, a novel synthetic benchmark grounded in Cognitive Load
Theory (CLT). CogniLoad generates natural-language logic puzzles with
independently tunable parameters that reflect CLT's core dimensions: intrinsic
difficulty ($d$) controls intrinsic load; distractor-to-signal ratio ($\rho$)
regulates extraneous load; and task length ($N$) serves as an operational proxy
for conditions demanding germane load. Evaluating 22 SotA reasoning LLMs,
CogniLoad reveals distinct performance sensitivities, identifying task length
as a dominant constraint and uncovering varied tolerances to intrinsic
complexity and U-shaped responses to distractor ratios. By offering systematic,
factorial control over these cognitive load dimensions, CogniLoad provides a
reproducible, scalable, and diagnostically rich tool for dissecting LLM
reasoning limitations and guiding future model development.

</details>


### [143] [LAWCAT: Efficient Distillation from Quadratic to Linear Attention with Convolution across Tokens for Long Context Modeling](https://arxiv.org/abs/2509.18467)
*Zeyu Liu,Souvik Kundu,Lianghao Jiang,Anni Li,Srikanth Ronanki,Sravan Bodapati,Gourav Datta,Peter A. Beerel*

Main category: cs.CL

TL;DR: LAWCAT是一种新颖的线性化框架，旨在高效地将预训练变换器的能力转移到高效的线性注意力架构，针对长上下文应用优化计算性能，减少资源需求。


<details>
  <summary>Details</summary>
Motivation: 尽管变换器架构在各个领域取得了最先进的性能，但其与序列长度相关的二次计算复杂度仍是一个显著瓶颈，特别是在对延迟敏感的长上下文应用中。

Method: LAWCAT集成了因果Conv1D层来增强局部依赖建模，并采用归一化的门控线性注意力以提高对不同上下文长度的泛化能力。

Result: 通过用仅1K长度的序列提炼Mistral-7B，在达到22K令牌时，检索准确率超过90%；Llama3.2-1B LAWCAT变体在S-NIAH及BABILong基准测试中表现出竞争力，同时较少依赖于预训练令牌。

Conclusion: LAWCAT为高效的长上下文线性模型提供了一条有效路径，适合边缘部署，减少对广泛长序列训练数据和计算资源的依赖。

Abstract: Although transformer architectures have achieved state-of-the-art performance
across diverse domains, their quadratic computational complexity with respect
to sequence length remains a significant bottleneck, particularly for
latency-sensitive long-context applications. While recent linear-complexity
alternatives are increasingly powerful, effectively training them from scratch
is still resource-intensive. To overcome these limitations, we propose LAWCAT
(Linear Attention with Convolution Across Time), a novel linearization
framework designed to efficiently transfer the capabilities of pre-trained
transformers into a performant linear attention architecture. LAWCAT integrates
causal Conv1D layers to enhance local dependency modeling and employs
normalized gated linear attention to improve generalization across varying
context lengths. Our comprehensive evaluations demonstrate that, distilling
Mistral-7B with only 1K-length sequences yields over 90\% passkey retrieval
accuracy up to 22K tokens, significantly extending its effective context
window. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance
on S-NIAH 1\&2\&3 tasks (1K-8K context length) and BABILong benchmark
(QA2\&QA3, 0K-16K context length), requiring less than 0.1\% pre-training
tokens compared with pre-training models. Furthermore, LAWCAT exhibits faster
prefill speeds than FlashAttention-2 for sequences exceeding 8K tokens. LAWCAT
thus provides an efficient pathway to high-performance, long-context linear
models suitable for edge deployment, reducing reliance on extensive
long-sequence training data and computational resources.

</details>


### [144] [Actions Speak Louder than Prompts: A Large-Scale Study of LLMs for Graph Inference](https://arxiv.org/abs/2509.18487)
*Ben Finkelshtein,Silviu Cucerzan,Sujay Kumar Jauhar,Ryen White*

Main category: cs.CL

TL;DR: 本研究系统评估了LLM与图数据的交互能力，发现代码生成器在处理图数据时表现最佳，并提出了关键设计原则。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在文本丰富的图机器学习任务中越来越多地使用，但该领域缺乏对于LLM与图数据互动能力的原则性理解。

Method: 通过对大规模控制评估，对LLM在与图数据交互时的不同方式进行系统分析，涵盖了多个变量维度。

Result: 研究发现，作为代码生成器的LLM在图数据上的整体表现最佳，特别是在长文本或高重复度图上；所有交互策略在异质图上均有效；代码生成能够灵活适应其对结构、特征或标签的依赖，以利用最有信息量的输入类型。

Conclusion: 本研究提供了关于LLM与图数据互动模式的强项与弱点的全面视角，并突出了未来方法设计的关键原则。

Abstract: Large language models (LLMs) are increasingly used for text-rich graph
machine learning tasks such as node classification in high-impact domains like
fraud detection and recommendation systems. Yet, despite a surge of interest,
the field lacks a principled understanding of the capabilities of LLMs in their
interaction with graph data. In this work, we conduct a large-scale, controlled
evaluation across several key axes of variability to systematically assess the
strengths and weaknesses of LLM-based graph reasoning methods in text-based
applications. The axes include the LLM-graph interaction mode, comparing
prompting, tool-use, and code generation; dataset domains, spanning citation,
web-link, e-commerce, and social networks; structural regimes contrasting
homophilic and heterophilic graphs; feature characteristics involving both
short- and long-text node attributes; and model configurations with varying LLM
sizes and reasoning capabilities. We further analyze dependencies by
methodically truncating features, deleting edges, and removing labels to
quantify reliance on input types. Our findings provide practical and actionable
guidance. (1) LLMs as code generators achieve the strongest overall performance
on graph data, with especially large gains on long-text or high-degree graphs
where prompting quickly exceeds the token budget. (2) All interaction
strategies remain effective on heterophilic graphs, challenging the assumption
that LLM-based methods collapse under low homophily. (3) Code generation is
able to flexibly adapt its reliance between structure, features, or labels to
leverage the most informative input type. Together, these findings provide a
comprehensive view of the strengths and limitations of current LLM-graph
interaction modes and highlight key design principles for future approaches.

</details>


### [145] [A Rhythm-Aware Phrase Insertion for Classical Arabic Poetry Composition](https://arxiv.org/abs/2509.18514)
*Mohamad Elzohbi,Richard Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种基于ByT5的阿拉伯诗歌韵律插入方法，通过条件去噪目标和课程学习策略，实现了高韵律一致性与语义连贯性。


<details>
  <summary>Details</summary>
Motivation: 为了在阿拉伯诗歌创作中实现在特定韵律下插入短语的能力。

Method: 采用了基于条件去噪目标的ByT5微调，结合了基于规则的图形到节拍转化，以及课程学习策略。

Result: 实验结果表明，模型在韵律对齐方面表现出色，同时保持了语义连贯性。

Conclusion: 该模型在保持语义一致性的同时，实现了高韵律一致性，具有在阿拉伯古典诗词创作中应用的潜力。

Abstract: This paper presents a methodology for inserting phrases in Arabic poems to
conform to a specific rhythm using ByT5, a byte-level multilingual
transformer-based model. Our work discusses a rule-based grapheme-to-beat
transformation tailored for extracting the rhythm from fully diacritized Arabic
script. Our approach employs a conditional denoising objective to fine-tune
ByT5, where the model reconstructs masked words to match a target rhythm. We
adopt a curriculum learning strategy, pre-training on a general Arabic dataset
before fine-tuning on poetic dataset, and explore cross-lingual transfer from
English to Arabic. Experimental results demonstrate that our models achieve
high rhythmic alignment while maintaining semantic coherence. The proposed
model has the potential to be used in co-creative applications in the process
of composing classical Arabic poems.

</details>


### [146] [Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector](https://arxiv.org/abs/2509.18535)
*Mo Mu,Dianqiao Lei,Chang Li*

Main category: cs.CL

TL;DR: 本文提出一种新方法，通过分析文本的内部结构，克服现有检测方法的不足，有效检测AI生成的文本。


<details>
  <summary>Details</summary>
Motivation: 当前的检测方法面临许多挑战，包括对改写和简单提示的脆弱性，以及模型和训练数据内容的偏见，因此有必要开发更有效的检测策略。

Method: 利用预训练语言模型生成句子嵌入，并通过注意力机制建模它们之间的关系，采用对比学习来减轻生成偏见，以及结合因果图和反事实方法来隔离结构特征。

Result: 在两个精心策划的数据集上进行的实验验证了我们方法的有效性。

Conclusion: 我们提出了一种新的轻量级框架，通过分析文本的内部结构来有效检测AI生成文本，包括经过修改的文本。

Abstract: The widespread adoption of ChatGPT has raised concerns about its misuse,
highlighting the need for robust detection of AI-generated text. Current
word-level detectors are vulnerable to paraphrasing or simple prompts (PSP),
suffer from biases induced by ChatGPT's word-level patterns (CWP) and training
data content, degrade on modified text, and often require large models or
online LLM interaction. To tackle these issues, we introduce a novel task to
detect both original and PSP-modified AI-generated texts, and propose a
lightweight framework that classifies texts based on their internal structure,
which remains invariant under word-level changes. Our approach encodes sentence
embeddings from pre-trained language models and models their relationships via
attention. We employ contrastive learning to mitigate embedding biases from
autoregressive generation and incorporate a causal graph with counterfactual
methods to isolate structural features from topic-related biases. Experiments
on two curated datasets, including abstract comparisons and revised life FAQs,
validate the effectiveness of our method.

</details>


### [147] [CCQA: Generating Question from Solution Can Improve Inference-Time Reasoning in SLMs](https://arxiv.org/abs/2509.18536)
*Jin Young Kim,Ji Won Yoon*

Main category: cs.CL

TL;DR: 本研究提出了一种新的推理方法CCQA，专门用于小型语言模型，能够有效提升其在数学和常识推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统推理方法在小型语言模型上的有效性不明确，因此需要新的方法来提升其推理能力。

Method: 利用循环一致性生成问题并评估其与原始问题的相似性，从中选择相似度最高的候选答案。结合使用轻量级的Flan-T5模型来支持问题生成。

Result: 实验结果表明，CCQA方法在八个模型上持续优于现有方法，验证了其有效性。

Conclusion: CCQA方法在数学和常识推理基准测试中优于现有的最先进方法，并为小型语言模型的高效推理建立了新的实践基准。

Abstract: Recently, inference-time reasoning strategies have further improved the
accuracy of large language models (LLMs), but their effectiveness on smaller
models remains unclear. Based on the observation that conventional approaches
often fail to improve performance in this context, we propose
\textbf{C}ycle-\textbf{C}onsistency in \textbf{Q}uestion \textbf{A}nswering
(CCQA), a novel reasoning method that can be effectively applied to SLMs.
Inspired by cycle consistency, CCQA generates a question from each reasoning
path and answer, evaluates each by its similarity to the original question, and
then selects the candidate solution with the highest similarity score as the
final response. Since conventional SLMs struggle to generate accurate questions
from their own reasoning paths and answers, we employ a lightweight Flan-T5
model specialized for question generation to support this process efficiently.
From the experimental results, it is verified that CCQA consistently
outperforms existing state-of-the-art (SOTA) methods across eight models on
mathematical and commonsense reasoning benchmarks. Furthermore, our method
establishes a new practical baseline for efficient reasoning in SLMs. Source
code can be found at https://github.com/scai-research/ccqa_official.

</details>


### [148] [Prior-based Noisy Text Data Filtering: Fast and Strong Alternative For Perplexity](https://arxiv.org/abs/2509.18577)
*Yeongbin Seo,Gayoung Kim,Jaehyung Kim,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 本文提出了一种基于先验的快速数据过滤方法，显著提高了性能并降低了时间成本。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在预训练过程中需要有效的数据筛选以提高学习效率，但现有的基于困惑度的过滤方法耗时较长且不可靠。

Method: 一种基于先验的过滤方法，通过语料库级的词频统计来估计标记的先验概率

Result: 该方法在20个下游基准测试中取得了最佳平均性能，并在处理代码和数学等符号语言以及多语言语料时表现出动态适应性。

Conclusion: 所提的基于先验的数据过滤方法在多个基准测试中表现出色，且其时间成本显著低于基于困惑度的过滤方法。

Abstract: As large language models (LLMs) are pretrained on massive web corpora,
careful selection of data becomes essential to ensure effective and efficient
learning. While perplexity (PPL)-based filtering has shown strong performance,
it suffers from drawbacks: substantial time costs and inherent unreliability of
the model when handling noisy or out-of-distribution samples. In this work, we
propose a simple yet powerful alternative: a prior-based data filtering method
that estimates token priors using corpus-level term frequency statistics,
inspired by linguistic insights on word roles and lexical density. Our approach
filters documents based on the mean and standard deviation of token priors,
serving as a fast proxy to PPL while requiring no model inference. Despite its
simplicity, the prior-based filter achieves the highest average performance
across 20 downstream benchmarks, while reducing time cost by over 1000x
compared to PPL-based filtering. We further demonstrate its applicability to
symbolic languages such as code and math, and its dynamic adaptability to
multilingual corpora without supervision

</details>


### [149] [TsqLoRA: Towards Sensitivity and Quality Low-Rank Adaptation for Efficient Fine-Tuning](https://arxiv.org/abs/2509.18585)
*Yu Chen,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: 提出TsqLoRA，一种新的微调方法，通过选择高质量训练数据和动态调整模型层的秩，提升了微调效率和性能。


<details>
  <summary>Details</summary>
Motivation: 在资源有限的环境中，完全微调大模型参数计算开销大且内存占用高，现有的高效微调方法忽略了模型不同层的敏感性和训练数据的重要性。

Method: TsqLoRA方法结合了基于数据质量的样本选择和敏感性感知的低秩适应，包含质量感知采样机制和动态秩分配模块。

Result: 实验结果表明，TsqLoRA在多种NLP任务上提高了微调效率。

Conclusion: TsqLoRA显著提高了微调效率，同时在各种自然语言处理任务上保持或提高了性能。

Abstract: Fine-tuning large pre-trained models for downstream tasks has become a
fundamental approach in natural language processing. Fully fine-tuning all
model parameters is computationally expensive and memory-intensive, especially
in resource-constrained environments. Existing parameter-efficient fine-tuning
methods reduce the number of trainable parameters but typically overlook the
varying sensitivity of different model layers and the importance of training
data. In this work, we propose TsqLoRA, a novel method that integrates
data-quality-driven selection with sensitivity-aware low-rank adaptation,
consisted of two main components: a quality-aware sampling mechanism for
selecting the most informative training data, and a dynamic rank allocation
module that adjusts the rank of each layer based on its sensitivity to
parameter updates. The experimental results demonstrate that TsqLoRA improves
fine-tuning efficiency while maintaining or even improving performance on a
variety of NLP tasks. Our code will be available at
https://github.com/Benjamin-Ricky/TsqLoRA.

</details>


### [150] [UniECG: Understanding and Generating ECG in One Unified Model](https://arxiv.org/abs/2509.18588)
*Jiarui Jin,Haoyu Wang,Xiang Lan,Jun Li,Gaofeng Cheng,Hongyan Li,Shenda Hong*

Main category: cs.CL

TL;DR: UniECG 是一个全新的 ECG 模型，能同时进行 ECG 解释和生成，采用两阶段训练方法拓展了其能力。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型在 ECG 信号理解与生成方面存在局限性，因此提出 UniECG 来解决这些问题。

Method: 采用解耦的两阶段训练方法，首先学习基于证据的 ECG 解释，然后通过潜在空间对齐注入 ECG 生成能力。

Result: UniECG 能够依据用户输入自主选择进行 ECG 的解释或生成。

Conclusion: UniECG 是首个集 ECG 解释与生成于一体的统一模型，显著扩展了 ECG 模型的能力边界。

Abstract: Recent unified models such as GPT-5 have achieved encouraging progress on
vision-language tasks. However, these unified models typically fail to
correctly understand ECG signals and provide accurate medical diagnoses, nor
can they correctly generate ECG signals. To address these limitations, we
propose UniECG, the first unified model for ECG capable of concurrently
performing evidence-based ECG interpretation and text-conditioned ECG
generation tasks. Through a decoupled two-stage training approach, the model
first learns evidence-based interpretation skills (ECG-to-Text), and then
injects ECG generation capabilities (Text-to-ECG) via latent space alignment.
UniECG can autonomously choose to interpret or generate an ECG based on user
input, significantly extending the capability boundaries of current ECG models.
Our code and checkpoints will be made publicly available at
https://github.com/PKUDigitalHealth/UniECG upon acceptance.

</details>


### [151] [A Good Plan is Hard to Find: Aligning Models with Preferences is Misaligned with What Helps Users](https://arxiv.org/abs/2509.18632)
*Nishant Balepur,Matthew Shu,Yoo Yeon Sung,Seraphina Goldfarb-Tarrant,Shi Feng,Fumeng Yang,Rachel Rudinger,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 这项研究揭示了当前对齐方法在确保LLM计划有用性方面的不足，表明需要通过真实用户交互反馈来改善LLM的对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的对齐方法（如RLHF和ChatbotArena）假设用户偏好反映了有助于他们的解决方案，并进行相关训练和评估。

Method: 使用Planorama界面让126名用户回答300个多步骤问题，通过4388次计划执行和5584次比较来测量计划的有用性和用户偏好。

Result: 找到了用户/模型偏好与代理成功并不能准确预测哪些计划对用户有帮助的证据；用户在使用他们喜欢或不喜欢的计划时同样成功；表面 cues（如简洁性和问题相似性）与用户偏好强相关，但并不能有效预测计划的有用性。

Conclusion: 为了更好地对齐有帮助的LLM，必须根据真实用户交互的反馈进行调整，而不仅仅依赖于用户偏好的表面信息。

Abstract: To assist users in complex tasks, LLMs generate plans: step-by-step
instructions towards a goal. While alignment methods aim to ensure LLM plans
are helpful, they train (RLHF) or evaluate (ChatbotArena) on what users prefer,
assuming this reflects what helps them. We test this with Planorama: an
interface where 126 users answer 300 multi-step questions with LLM plans. We
get 4388 plan executions and 5584 comparisons to measure plan helpfulness (QA
success) and user preferences on plans, and recreate the setup in agents and
reward models to see if they simulate or prefer what helps users. We expose: 1)
user/model preferences and agent success do not accurately predict which plans
help users, so common alignment feedback can misalign with helpfulness; 2) this
gap is not due to user-specific preferences, as users are similarly successful
when using plans they prefer/disprefer; 3) surface-level cues like brevity and
question similarity strongly link to preferences, but such biases fail to
predict helpfulness. In all, we argue aligning helpful LLMs needs feedback from
real user interactions, not just preferences of what looks helpful, so we
discuss the plan NLP researchers can execute to solve this problem.

</details>


### [152] [Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering](https://arxiv.org/abs/2509.18655)
*Lingwen Deng,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: CAPE-KG 是一种新颖的一致性框架，用于优化多跳问答中的参数保持知识编辑，解决了现有方法中的一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于知识图的参数保持知识编辑方法常常缺乏一致性，导致知识污染和不稳定的更新，影响推理的可靠性。

Method: 提出了一种新颖的一致性意识框架，专注于参数保持知识编辑，确保知识图构建、更新和检索与多跳问答任务的需求对齐。

Result: 在 MQuAKE 基准测试中，通过进行广泛实验，证明了 CAPE-KG 提高了多跳问答任务中 PPKE 的准确性。

Conclusion: CAPE-KG 提供了一种一致性意识的框架，显著提高了多跳问答的参数保持知识编辑性能。

Abstract: Parameter-Preserving Knowledge Editing (PPKE) enables updating models with
new or corrected information without retraining or parameter adjustment. Recent
PPKE approaches based on knowledge graphs (KG) to extend knowledge editing (KE)
capabilities to multi-hop question answering (MHQA). However, these methods
often lack consistency, leading to knowledge contamination, unstable updates,
and retrieval behaviors that fail to reflect the intended edits. Such
inconsistencies undermine the reliability of PPKE in multi- hop reasoning. We
present CAPE-KG, Consistency-Aware Parameter-Preserving Editing with Knowledge
Graphs, a novel consistency-aware framework for PPKE on MHQA. CAPE-KG ensures
KG construction, update, and retrieval are always aligned with the requirements
of the MHQA task, maintaining coherent reasoning over both unedited and edited
knowledge. Extensive experiments on the MQuAKE benchmark show accuracy
improvements in PPKE performance for MHQA, demonstrating the effectiveness of
addressing consistency in PPKE.

</details>


### [153] [Analyzing Uncertainty of LLM-as-a-Judge: Interval Evaluations with Conformal Prediction](https://arxiv.org/abs/2509.18658)
*Huanxin Sheng,Xinyi Liu,Hangfeng He,Jieyu Zhao,Jian Kang*

Main category: cs.CL

TL;DR: 本研究提出使用保序预测分析大型语言模型的评估不确定性，提升自然语言生成评估的可靠性，实验验证了预测区间的有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言生成评估中的应用潜力受到评估不确定性缺乏可靠性的限制。

Method: 使用保序预测构建连续预测区间，并为离散评分任务设计了序数边界调整。

Result: 实验表明，保序预测能够提供有效的预测区间，并保证覆盖率，另外，区间中点和判断重提示方法在判断过程中也提高了效果。

Conclusion: 通过使用保序预测来分析大型语言模型的评估不确定性，本研究为评价自然语言生成提供了更高的可靠性。

Abstract: LLM-as-a-judge has become a promising paradigm for using large language
models (LLMs) to evaluate natural language generation (NLG), but the
uncertainty of its evaluation remains underexplored. This lack of reliability
may limit its deployment in many applications. This work presents the first
framework to analyze the uncertainty by offering a prediction interval of
LLM-based scoring via conformal prediction. Conformal prediction constructs
continuous prediction intervals from a single evaluation run, and we design an
ordinal boundary adjustment for discrete rating tasks. We also suggest a
midpoint-based score within the interval as a low-bias alternative to raw model
score and weighted average. We perform extensive experiments and analysis,
which show that conformal prediction can provide valid prediction interval with
coverage guarantees. We also explore the usefulness of interval midpoint and
judge reprompting for better judgment.

</details>


### [154] [MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service](https://arxiv.org/abs/2509.18713)
*Yizhe Huang,Yang Liu,Ruiyu Zhao,Xiaolong Zhong,Xingming Yue,Ling Jiang*

Main category: cs.CL

TL;DR: 论文提出了MemOrb，一种改进LLM代理在客户服务中的长期可靠性的机制，通过结构化反思提升了任务的成功率和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM代理在动态环境中不可靠，缺乏持续自我改进的机制，因此需要改进其成功率和一致性。

Method: 提议了MemOrb，这是一种轻量级的、即插即用的语言强化记忆层，通过将多轮交互提炼为紧凑的策略反思，从而改进决策过程。

Result: MemOrb显著提高了任务成功率和稳定性，在多轮成功率上达到63个百分点的提升，并在重复测试中提供了更一致的性能。

Conclusion: 结构化反思是一种强大的机制，可以增强冻结的LLM代理在客户服务场景中的长期可靠性。

Abstract: Large Language Model-based agents(LLM-based agents) are increasingly deployed
in customer service, yet they often forget across sessions, repeat errors, and
lack mechanisms for continual self-improvement. This makes them unreliable in
dynamic settings where stability and consistency are critical. To better
evaluate these properties, we emphasize two indicators: task success rate as a
measure of overall effectiveness, and consistency metrics such as Pass$^k$ to
capture reliability across multiple trials. To address the limitations of
existing approaches, we propose MemOrb, a lightweight and plug-and-play verbal
reinforcement memory layer that distills multi-turn interactions into compact
strategy reflections. These reflections are stored in a shared memory bank and
retrieved to guide decision-making, without requiring any fine-tuning.
Experiments show that MemOrb significantly improves both success rate and
stability, achieving up to a 63 percentage-point gain in multi-turn success
rate and delivering more consistent performance across repeated trials. Our
results demonstrate that structured reflection is a powerful mechanism for
enhancing long-term reliability of frozen LLM agents in customer service
scenarios.

</details>


### [155] [Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models](https://arxiv.org/abs/2509.18742)
*Yunan Wang,Jianxin Li,Ziwei Zhang*

Main category: cs.CL

TL;DR: DyGRASP是一种新方法，解决了动态文本属性图中的时间语义问题，实现了显著的检索性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注静态文本属性图，忽略了动态图中最近与全局时间语义的复杂性，导致在动态图背景下的推理效率低下。

Method: DyGRASP结合了LLM和时间GNN，通过节点中心的隐式推理方法和滑动窗口机制有效捕捉近期时间语义，同时利用定制提示和RNN链结构捕捉节点的全局语义动态，并通过更新和合并层整合这些信息。

Result: 在DyTAG基准测试中，DyGRASP显示出优越性，在目的节点检索任务中取得最高34%的Hit@10提高。此外，DyGRASP在不同时间GNN和LLM中展现出强泛化能力。

Conclusion: DyGRASP在动态文本属性图上表现出显著的优势，尤其在目的节点检索任务中提高了34%的Hit@10，并且在不同的时间GNN和LLM中具有良好的泛化能力。

Abstract: Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph
interactions and associated text attributes, are prevalent in real-world
applications. Existing methods, such as Graph Neural Networks (GNNs) and Large
Language Models (LLMs), mostly focus on static TAGs. Extending these existing
methods to DyTAGs is challenging as they largely neglect the recent-global
temporal semantics: the recent semantic dependencies among interaction texts
and the global semantic evolution of nodes over time. Furthermore, applying
LLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To
tackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic
Processing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to
efficiently and effectively reason on DyTAGs. Specifically, we first design a
node-centric implicit reasoning method together with a sliding window mechanism
to efficiently capture recent temporal semantics. In addition, to capture
global semantic dynamics of nodes, we leverage explicit reasoning with tailored
prompts and an RNN-like chain structure to infer long-term semantics. Lastly,
we intricately integrate the recent and global temporal semantics as well as
the dynamic graph structural information using updating and merging layers.
Extensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority,
achieving up to 34% improvement in Hit@10 for destination node retrieval task.
Besides, DyGRASP exhibits strong generalization across different temporal GNNs
and LLMs.

</details>


### [156] [False Friends Are Not Foes: Investigating Vocabulary Overlap in Multilingual Language Models](https://arxiv.org/abs/2509.18750)
*Julie Kallini,Dan Jurafsky,Christopher Potts,Martijn Bartelds*

Main category: cs.CL

TL;DR: 本研究探讨多语言词汇重叠对跨语言迁移的影响，结果显示重叠词汇能够促进模型的语义关系捕捉和迁移性能。


<details>
  <summary>Details</summary>
Motivation: 探讨多语言间的标记重叠是否促进跨语言迁移，或引入语言间的干扰。

Method: 进行控制实验，训练双语自回归模型，在系统变化的词汇重叠条件下进行多语言对的实验。

Result: 重叠词汇的模型在XNLI和XQuAD上表现优于不重叠的模型，且随着词汇重叠的增加，迁移性能通常也有所提升。

Conclusion: 我们发现重叠词汇在多语言模型中具有显著优势，且具有实质的共享词汇是多语言标记器一个有益的设计选择。

Abstract: Subword tokenizers trained on multilingual corpora naturally produce
overlapping tokens across languages. Does token overlap facilitate
cross-lingual transfer or instead introduce interference between languages?
Prior work offers mixed evidence, partly due to varied setups and confounders,
such as token frequency or subword segmentation granularity. To address this
question, we devise a controlled experiment where we train bilingual
autoregressive models on multiple language pairs under systematically varied
vocabulary overlap settings. Crucially, we explore a new dimension to
understanding how overlap affects transfer: the semantic similarity of tokens
shared across languages. We first analyze our models' hidden representations
and find that overlap of any kind creates embedding spaces that capture
cross-lingual semantic relationships, while this effect is much weaker in
models with disjoint vocabularies. On XNLI and XQuAD, we find that models with
overlap outperform models with disjoint vocabularies, and that transfer
performance generally improves as overlap increases. Overall, our findings
highlight the advantages of token overlap in multilingual models and show that
substantial shared vocabulary remains a beneficial design choice for
multilingual tokenizers.

</details>


### [157] [When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models](https://arxiv.org/abs/2509.18762)
*Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen*

Main category: cs.CL

TL;DR: 本研究探讨了长上下文微调如何影响短上下文任务的表现，发现长上下文微调能够提升短上下文性能，并揭示了其中的机制与知识偏差，提出混合训练作为解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着实际应用对长上下文窗口的需求增加，继续预训练和长上下文数据的微调成为一种常见的方法，但微调的数据长度对模型行为的影响尚不明确。

Method: 对多头注意力（MHA）和前馈网络（FFN）进行解耦分析，研究长上下文微调对短上下文任务的影响。

Result: 长上下文微调提高了短上下文任务的性能，这与常见的从长上下文预训练中观察到的性能下降相反。

Conclusion: 混合训练可以缓解知识偏好偏差，为大型语言模型的微调提供可解释的指导。

Abstract: Large language models (LLMs) have achieved impressive performance across
natural language processing (NLP) tasks. As real-world applications
increasingly demand longer context windows, continued pretraining and
supervised fine-tuning (SFT) on long-context data has become a common approach.
While the effects of data length in continued pretraining have been extensively
studied, their implications for SFT remain unclear. In this work, we
systematically investigate how SFT data length influences LLM behavior on
short-context tasks. Counterintuitively, we find that long-context SFT improves
short-context performance, contrary to the commonly observed degradation from
long-context pretraining. To uncover the underlying mechanisms of this
phenomenon, we first decouple and analyze two key components, Multi-Head
Attention (MHA) and Feed-Forward Network (FFN), and show that both
independently benefit from long-context SFT. We further study their interaction
and reveal a knowledge preference bias: long-context SFT promotes contextual
knowledge, while short-context SFT favors parametric knowledge, making
exclusive reliance on long-context SFT suboptimal. Finally, we demonstrate that
hybrid training mitigates this bias, offering explainable guidance for
fine-tuning LLMs.

</details>


### [158] [Financial Risk Relation Identification through Dual-view Adaptation](https://arxiv.org/abs/2509.18775)
*Wei-Ning Chiu,Yu-Hsiang Wang,Andy Hsiao,Yu-Shiang Huang,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: 本研究提出了一种新方法，通过分析10-K报告系统性提取跨公司风险关系，以支持投资管理，验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 鉴于传统方法主观且难以扩展，本研究旨在系统性地提取跨公司风险关系，以支持投资决策。

Method: 采用基于10-K报告的无监督微调，提取跨公司风险关系，建立财务编码器。

Result: 通过自然语言处理技术，我们提出的方法能捕捉隐含的风险关系，并提供定量风险关系评分。

Conclusion: 我们的方法在多个评估设置中在性能上优于强基线，证明其有效性。

Abstract: A multitude of interconnected risk events -- ranging from regulatory changes
to geopolitical tensions -- can trigger ripple effects across firms.
Identifying inter-firm risk relations is thus crucial for applications like
portfolio management and investment strategy. Traditionally, such assessments
rely on expert judgment and manual analysis, which are, however, subjective,
labor-intensive, and difficult to scale. To address this, we propose a
systematic method for extracting inter-firm risk relations using Form 10-K
filings -- authoritative, standardized financial documents -- as our data
source. Leveraging recent advances in natural language processing, our approach
captures implicit and abstract risk connections through unsupervised
fine-tuning based on chronological and lexical patterns in the filings. This
enables the development of a domain-specific financial encoder with a deeper
contextual understanding and introduces a quantitative risk relation score for
transparency, interpretable analysis. Extensive experiments demonstrate that
our method outperforms strong baselines across multiple evaluation settings.

</details>


### [159] [AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field](https://arxiv.org/abs/2509.18776)
*Chen Liang,Zhaoqi Huang,Haofen Wang,Fu Chai,Chunying Yu,Huanhuan Wei,Zhengjie Liu,Yanpeng Li,Hongjun Wang,Ruifeng Luo,Xianzhong Zhao*

Main category: cs.CL

TL;DR: 本研究提出了AECBench基准以评估大型语言模型在建筑、工程和施工领域中的强项与弱项，发现其在应用复杂推理和生成领域特定文档方面存在显著性能缺陷。


<details>
  <summary>Details</summary>
Motivation: 鉴于大型语言模型在建筑、工程和施工（AEC）领域的不断应用，评估其在此安全关键领域的鲁棒性和可靠性变得尤为重要。

Method: 建立了AECBench基准，通过定义23个任务和4,800个问题的数据集，利用四轮专家评审对模型进行评估。

Result: 对九个大型语言模型的评估显示，在五个认知层次上性能下降，尤其是在复杂推理、计算及生成专业文件时表现明显不足。

Conclusion: 本研究为将大型语言模型（LLMs）可靠整合到安全-critical的工程实践奠定了基础，并揭示了当前模型在AEC领域的有效性和不足之处。

Abstract: Large language models (LLMs), as a novel information technology, are seeing
increasing adoption in the Architecture, Engineering, and Construction (AEC)
field. They have shown their potential to streamline processes throughout the
building lifecycle. However, the robustness and reliability of LLMs in such a
specialized and safety-critical domain remain to be evaluated. To address this
challenge, this paper establishes AECBench, a comprehensive benchmark designed
to quantify the strengths and limitations of current LLMs in the AEC domain.
The benchmark defines 23 representative tasks within a five-level
cognition-oriented evaluation framework encompassing Knowledge Memorization,
Understanding, Reasoning, Calculation, and Application. These tasks were
derived from authentic AEC practice, with scope ranging from codes retrieval to
specialized documents generation. Subsequently, a 4,800-question dataset
encompassing diverse formats, including open-ended questions, was crafted
primarily by engineers and validated through a two-round expert review.
Furthermore, an LLM-as-a-Judge approach was introduced to provide a scalable
and consistent methodology for evaluating complex, long-form responses
leveraging expert-derived rubrics. Through the evaluation of nine LLMs, a clear
performance decline across five cognitive levels was revealed. Despite
demonstrating proficiency in foundational tasks at the Knowledge Memorization
and Understanding levels, the models showed significant performance deficits,
particularly in interpreting knowledge from tables in building codes, executing
complex reasoning and calculation, and generating domain-specific documents.
Consequently, this study lays the groundwork for future research and
development aimed at the robust and reliable integration of LLMs into
safety-critical engineering practices.

</details>


### [160] [Beyond the Leaderboard: Understanding Performance Disparities in Large Language Models via Model Diffing](https://arxiv.org/abs/2509.18792)
*Sabri Boughorbel,Fahim Dalvi,Nadir Durrani,Majd Hawasly*

Main category: cs.CL

TL;DR: 本研究通过模型差异分析揭示了 Gemma-2-9b-it 和 SimPO增强变体之间的具体能力差异，指出SimPO在多个方面的提升及其训练带来的影响。


<details>
  <summary>Details</summary>
Motivation: 在微调成为提高大型语言模型的主要手段时，理解微调过程中发生的变化变得至关重要。

Method: 采用模型差异分析和交叉编码器来识别和分类不同模型的潜在表征。

Result: 通过分析，发现SimPO在安全机制、多语言能力和指令遵循等方面具有显著提升，同时在模型自我引用和幻觉管理方面有所减弱。

Conclusion: 使用模型差异分析方法可以深入了解语言模型的能力差异，为模型比较提供透明且有针对性的框架。

Abstract: As fine-tuning becomes the dominant paradigm for improving large language
models (LLMs), understanding what changes during this process is increasingly
important. Traditional benchmarking often fails to explain why one model
outperforms another. In this work, we use model diffing, a mechanistic
interpretability approach, to analyze the specific capability differences
between Gemma-2-9b-it and a SimPO-enhanced variant. Using crosscoders, we
identify and categorize latent representations that differentiate the two
models. We find that SimPO acquired latent concepts predominantly enhance
safety mechanisms (+32.8%), multilingual capabilities (+43.8%), and
instruction-following (+151.7%), while its additional training also reduces
emphasis on model self-reference (-44.1%) and hallucination management
(-68.5%). Our analysis shows that model diffing can yield fine-grained insights
beyond leaderboard metrics, attributing performance gaps to concrete
mechanistic capabilities. This approach offers a transparent and targeted
framework for comparing LLMs.

</details>


### [161] [MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction](https://arxiv.org/abs/2509.18813)
*Liting Zhang,Shiwan Zhao,Aobo Kong,Qicheng Li*

Main category: cs.CL

TL;DR: MAPEX是一个引入多代理协作的关键短语提取框架，利用双路径策略适应不同文档长度，实验显示其表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督提示方法对大语言模型的推理和生成能力利用不足，无法适应文档长度变化，限制了关键短语提取的效果。

Method: 引入了多代理协作的框架，包括专家招募、候选提取、主题引导、知识增强和后处理模块，并采用双路径策略。

Result: 在六个基准数据集上的广泛实验表明，MAPEX在F1@5方面平均超越最先进的无监督方法2.44%，超越标准的LLM基线4.01%。

Conclusion: MAPEX框架通过多代理协作有效提升了关键短语提取的性能，展现了优越的泛化能力和通用性。

Abstract: Keyphrase extraction is a fundamental task in natural language processing.
However, existing unsupervised prompt-based methods for Large Language Models
(LLMs) often rely on single-stage inference pipelines with uniform prompting,
regardless of document length or LLM backbone. Such one-size-fits-all designs
hinder the full exploitation of LLMs' reasoning and generation capabilities,
especially given the complexity of keyphrase extraction across diverse
scenarios. To address these challenges, we propose MAPEX, the first framework
that introduces multi-agent collaboration into keyphrase extraction. MAPEX
coordinates LLM-based agents through modules for expert recruitment, candidate
extraction, topic guidance, knowledge augmentation, and post-processing. A
dual-path strategy dynamically adapts to document length: knowledge-driven
extraction for short texts and topic-guided extraction for long texts.
Extensive experiments on six benchmark datasets across three different LLMs
demonstrate its strong generalization and universality, outperforming the
state-of-the-art unsupervised method by 2.44\% and standard LLM baselines by
4.01\% in F1@5 on average. Code is available at
https://github.com/NKU-LITI/MAPEX.

</details>


### [162] [Are Smaller Open-Weight LLMs Closing the Gap to Proprietary Models for Biomedical Question Answering?](https://arxiv.org/abs/2509.18843)
*Damian Stachura,Joanna Konieczna,Artur Nowak*

Main category: cs.CL

TL;DR: 本研究比较开放权重大型语言模型在生物医学问答中的表现，结果显示其在某些情况下超越封闭源模型，尤其是在使用集成策略时。


<details>
  <summary>Details</summary>
Motivation: 研究开放权重大型语言模型是否能够有效替代大型封闭源模型，特别是在生物医学问答领域。

Method: 比较多个开放权重模型与顶级系统的性能，应用检索、上下文学习和结构化输出等技术，针对确切答案问题使用集成方法。

Result: 开放权重模型的性能与专有模型相当，并在某些情况下表现更佳。

Conclusion: 开放权重的大型语言模型在某些情况下甚至超越了其封闭源模型，尤其是采用集成策略时。

Abstract: Open-weight versions of large language models (LLMs) are rapidly advancing,
with state-of-the-art models like DeepSeek-V3 now performing comparably to
proprietary LLMs. This progression raises the question of whether small
open-weight LLMs are capable of effectively replacing larger closed-source
models. We are particularly interested in the context of biomedical
question-answering, a domain we explored by participating in Task 13B Phase B
of the BioASQ challenge. In this work, we compare several open-weight models
against top-performing systems such as GPT-4o, GPT-4.1, Claude 3.5 Sonnet, and
Claude 3.7 Sonnet. To enhance question answering capabilities, we use various
techniques including retrieving the most relevant snippets based on embedding
distance, in-context learning, and structured outputs. For certain submissions,
we utilize ensemble approaches to leverage the diverse outputs generated by
different models for exact-answer questions. Our results demonstrate that
open-weight LLMs are comparable to proprietary ones. In some instances,
open-weight LLMs even surpassed their closed counterparts, particularly when
ensembling strategies were applied. All code is publicly available at
https://github.com/evidenceprime/BioASQ-13b.

</details>


### [163] [Multi-Hierarchical Feature Detection for Large Language Model Generated Text](https://arxiv.org/abs/2509.18862)
*Luyan Zhang,Xinyu Xie*

Main category: cs.CL

TL;DR: 尽管多特征集成理论上有优势，但MHFD方法的实际效果提升有限，计算成本却显著增加，说明现代神经语言模型已有效捕捉大部分检测信号。


<details>
  <summary>Details</summary>
Motivation: 探讨多特征方法是否能够显著改善AI文本检测的效果，尤其是在现代语言模型生成文本的背景下。

Method: 实施多层次特征检测（MHFD），结合基于DeBERTa的语义分析、句法解析和统计概率特征，通过自适应融合进行实验。

Result: MHFD方法在同域检测中达到89.7%的准确率，在跨域检测中保持84.2%的稳定性能，相较于现有方法提升0.4-2.6%。

Conclusion: 现代神经语言模型已经有效地捕捉到大多数相关的检测信号，多特征集成方法虽然在理论上有优势，但实际应用中提升有限且计算成本高。

Abstract: With the rapid advancement of large language model technology, there is
growing interest in whether multi-feature approaches can significantly improve
AI text detection beyond what single neural models achieve. While intuition
suggests that combining semantic, syntactic, and statistical features should
provide complementary signals, this assumption has not been rigorously tested
with modern LLM-generated text. This paper provides a systematic empirical
investigation of multi-hierarchical feature integration for AI text detection,
specifically testing whether the computational overhead of combining multiple
feature types is justified by performance gains. We implement MHFD
(Multi-Hierarchical Feature Detection), integrating DeBERTa-based semantic
analysis, syntactic parsing, and statistical probability features through
adaptive fusion. Our investigation reveals important negative results: despite
theoretical expectations, multi-feature integration provides minimal benefits
(0.4-0.5% improvement) while incurring substantial computational costs (4.2x
overhead), suggesting that modern neural language models may already capture
most relevant detection signals efficiently. Experimental results on multiple
benchmark datasets demonstrate that the MHFD method achieves 89.7% accuracy in
in-domain detection and maintains 84.2% stable performance in cross-domain
detection, showing modest improvements of 0.4-2.6% over existing methods.

</details>


### [164] [Diversity Boosts AI-Generated Text Detection](https://arxiv.org/abs/2509.18880)
*Advik Raj Basani,Pin-Yu Chen*

Main category: cs.CL

TL;DR: DivEye是一个新型AI文本检测框架，通过分析文本的不可预测性来有效识别LLM生成的内容，显示出优于传统方法的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 人类创作的文本在词汇和结构上展现出比LLM输出更丰富的不可预测性变异。

Method: 使用基于惊讶度的特征捕捉文本中的不可预测性波动。

Result: DivEye在多个基准测试中，检测精度比现有的零样本检测器提高了最高33.2%，并在多个领域和模型中具有良好的泛化能力，同时提供了对文本标记原因的可解释见解。

Conclusion: DivEye是一个新颖的检测框架，能有效识别AI生成的文本，并提供可解释性洞见。

Abstract: Detecting AI-generated text is an increasing necessity to combat misuse of
LLMs in education, business compliance, journalism, and social media, where
synthetic fluency can mask misinformation or deception. While prior detectors
often rely on token-level likelihoods or opaque black-box classifiers, these
approaches struggle against high-quality generations and offer little
interpretability. In this work, we propose DivEye, a novel detection framework
that captures how unpredictability fluctuates across a text using
surprisal-based features. Motivated by the observation that human-authored text
exhibits richer variability in lexical and structural unpredictability than LLM
outputs, DivEye captures this signal through a set of interpretable statistical
features. Our method outperforms existing zero-shot detectors by up to 33.2%
and achieves competitive performance with fine-tuned baselines across multiple
benchmarks. DivEye is robust to paraphrasing and adversarial attacks,
generalizes well across domains and models, and improves the performance of
existing detectors by up to 18.7% when used as an auxiliary signal. Beyond
detection, DivEye provides interpretable insights into why a text is flagged,
pointing to rhythmic unpredictability as a powerful and underexplored signal
for LLM detection.

</details>


### [165] [Extractive Fact Decomposition for Interpretable Natural Language Inference in one Forward Pass](https://arxiv.org/abs/2509.18901)
*Nicholas Popovič,Michael Färber*

Main category: cs.CL

TL;DR: JEDI是一种编码器架构，用于提高自然语言推理的可解释性和鲁棒性，成效显著。


<details>
  <summary>Details</summary>
Motivation: 通过原子事实分解提高自然语言推理(NLI)及相关任务的可解释性和鲁棒性，解决资源密集型生成模型的问题。

Method: 提出了一种仅使用编码器的JEDI架构，进行抽取性原子事实分解和可解释推断，而不依赖生成模型。

Result: JEDI在多个NLI基准测试中表现出竞争力的准确性，并在分布外和对抗设置中显著提高了鲁棒性。

Conclusion: JEDI通过使用编码器架构和合成理由，实现了NLI任务中的可解释性和鲁棒性，表现出优越的分布外效果。

Abstract: Recent works in Natural Language Inference (NLI) and related tasks, such as
automated fact-checking, employ atomic fact decomposition to enhance
interpretability and robustness. For this, existing methods rely on
resource-intensive generative large language models (LLMs) to perform
decomposition. We propose JEDI, an encoder-only architecture that jointly
performs extractive atomic fact decomposition and interpretable inference
without requiring generative models during inference. To facilitate training,
we produce a large corpus of synthetic rationales covering multiple NLI
benchmarks. Experimental results demonstrate that JEDI achieves competitive
accuracy in distribution and significantly improves robustness out of
distribution and in adversarial settings over models based solely on extractive
rationale supervision. Our findings show that interpretability and robust
generalization in NLI can be realized using encoder-only architectures and
synthetic rationales. Code and data available at https://jedi.nicpopovic.com

</details>


### [166] [DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment](https://arxiv.org/abs/2509.18987)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本研究提出了一种基于动态时间规整（DTW）的方法，旨在改善终端到终端语音翻译中的语音和文本嵌入对齐，显示出更高的准确性和速度，尤其在低资源语言中效果显著。


<details>
  <summary>Details</summary>
Motivation: 语音和文本模态之间的表示差异促使研究者寻求弥合模态差距的方法。

Method: 通过在训练过程中适应动态时间规整（DTW）算法，对语音和文本嵌入进行对齐。

Result: 实验结果表明，采用DTW对齐的E2E-ST方法生成更准确的对齐结果，并在许多低资源语言方向上超越了之前的研究。

Conclusion: 我们的研究表明，在E2E-ST中，使用动态时间规整（DTW）对语音和文本嵌入进行对齐的方法比以前的作品在准确性和速度上都有显著改善，并在低资源环境下表现出色。

Abstract: End-to-End Speech Translation (E2E-ST) is the task of translating source
speech directly into target text bypassing the intermediate transcription step.
The representation discrepancy between the speech and text modalities has
motivated research on what is known as bridging the modality gap.
State-of-the-art methods addressed this by aligning speech and text
representations on the word or token level. Unfortunately, this requires an
alignment tool that is not available for all languages. Although this issue has
been addressed by aligning speech and text embeddings using nearest-neighbor
similarity search, it does not lead to accurate alignments. In this work, we
adapt Dynamic Time Warping (DTW) for aligning speech and text embeddings during
training. Our experiments demonstrate the effectiveness of our method in
bridging the modality gap in E2E-ST. Compared to previous work, our method
produces more accurate alignments and achieves comparable E2E-ST results while
being significantly faster. Furthermore, our method outperforms previous work
in low resource settings on 5 out of 6 language directions.

</details>


### [167] [Investigating Test-Time Scaling with Reranking for Machine Translation](https://arxiv.org/abs/2509.19020)
*Shaomu Tan,Ryosuke Mitani,Ritvik Choudhary,Toshiyuki Sekiya*

Main category: cs.CL

TL;DR: 本研究系统探索了测试时间缩放（TTS）在机器翻译中的效果，对于高资源语言有效提升翻译质量，但在低资源情况下可能降低质量。


<details>
  <summary>Details</summary>
Motivation: 虽然缩放模型参数是提高NLP系统的有效策略，但计算成本非常高，因此探索替代方法如测试时间缩放（TTS）具有重要意义。

Method: 本文采用了简洁但实用的最佳N框架，进行了一系列实验，包括六个高资源语言对和一个低资源语言对，使用不同的模型规模（3B-72B）和不同的计算预算（N高达1024）。

Result: 实验结果显示：a）对于高资源语言，TTS通常提高翻译质量，且人类评估验证了这些提升；b）使用较大的N来增强小模型可以在更多计算成本下匹配或超过在N=1下的大模型；c）在固定计算预算下，大模型通常更高效，但在低资源情况下，TTS可能由于指标盲点而导致质量下降。

Conclusion: 本研究首次系统地探讨了测试时间缩放（TTS）在机器翻译中的应用，发现对于资源丰富的语言，TTS可以提高翻译质量，但在资源低的情况下可能会降低质量。

Abstract: Scaling model parameters has become the de facto strategy for improving NLP
systems, but it comes with substantial computational costs. Test-Time Scaling
(TTS) offers an alternative by allocating more computation at inference:
generating multiple candidates and selecting the best. While effective in tasks
such as mathematical reasoning, TTS has not been systematically explored for
machine translation (MT). In this paper, we present the first systematic study
of TTS for MT, investigating a simple but practical best-of-N framework on
WMT24 benchmarks. Our experiments cover six high-resource and one low-resource
language pairs, five model sizes (3B-72B), and various TTS compute budget (N up
to 1024). Our results show that a) For high-resource languages, TTS generally
improves translation quality according to multiple neural MT evaluation
metrics, and our human evaluation confirms these gains; b) Augmenting smaller
models with large $N$ can match or surpass larger models at $N{=}1$ with more
compute cost; c) Under fixed compute budgets, larger models are typically more
efficient, and TTS can degrade quality due to metric blind spots in
low-resource cases.

</details>


### [168] [Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus](https://arxiv.org/abs/2509.19033)
*Chiara Alzetta,Serena Auriemma,Alessandro Bondielli,Luca Dini,Chiara Fazzone,Alessio Miaschi,Martina Miliani,Marta Sartor*

Main category: cs.CL

TL;DR: 本研究分析了意大利计算语言学与自然语言处理领域的研究趋势，构建了CLiC-it语料库并揭示了相关变化与发展。


<details>
  <summary>Details</summary>
Motivation: 随着基于Transformer的大型语言模型的兴起，计算语言学和自然语言处理的研究目标与优先级发生了变化，迫切需要了解意大利社区的研究趋势。

Method: 通过汇编CLiC-it会议的前10届论文集，构建CLiC-it语料库，分析元数据及论文内容。

Result: 提供了关于意大利CL和NLP社区的研究趋势、出版物特征及其主题的重要见解，支持进一步的决策和未来方向。

Conclusion: 本研究提供了意大利计算语言学与自然语言处理领域的研究趋势分析，揭示了重大发展和新兴趋势。

Abstract: Over the past decade, Computational Linguistics (CL) and Natural Language
Processing (NLP) have evolved rapidly, especially with the advent of
Transformer-based Large Language Models (LLMs). This shift has transformed
research goals and priorities, from Lexical and Semantic Resources to Language
Modelling and Multimodality. In this study, we track the research trends of the
Italian CL and NLP community through an analysis of the contributions to
CLiC-it, arguably the leading Italian conference in the field. We compile the
proceedings from the first 10 editions of the CLiC-it conference (from 2014 to
2024) into the CLiC-it Corpus, providing a comprehensive analysis of both its
metadata, including author provenance, gender, affiliations, and more, as well
as the content of the papers themselves, which address various topics. Our goal
is to provide the Italian and international research communities with valuable
insights into emerging trends and key developments over time, supporting
informed decisions and future directions in the field.

</details>


### [169] [Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering](https://arxiv.org/abs/2509.19094)
*Alireza Salemi,Cheng Li,Mingyang Zhang,Qiaozhu Mei,Zhuowan Li,Spurthi Amba Hombaiah,Weize Kong,Tao Chen,Hamed Zamani,Michael Bendersky*

Main category: cs.CL

TL;DR: 本文提出了一种叫做Pathways of Thoughts (PoT)的个性化问答方法，展示了在处理用户偏好和生成多样化响应方面的有效性，显著提升了问答系统的性能。


<details>
  <summary>Details</summary>
Motivation: 个性化是提高问答系统准确性和用户满意度的关键，但现有研究受到噪声和隐式上下文的挑战，亟需改进。

Method: 提出了Pathways of Thoughts (PoT)作为一种推理阶段的方法，适用于任何大型语言模型，不需要特定任务的微调。

Result: 在LaMP-QA基准测试上，PoT方法在个性化问答任务中实现了最高13.1%的相对提升，且经人类评估支持该结果，66%的情况下选择PoT输出。

Conclusion: Pathways of Thoughts (PoT)方法在个性化问答系统中有效提升了响应质量，表现优于其他基线方法。

Abstract: Personalization is essential for adapting question answering (QA) systems to
user-specific information needs, thereby improving both accuracy and user
satisfaction. However, personalized QA remains relatively underexplored due to
challenges such as inferring preferences from long, noisy, and implicit
contexts, and generating responses that are simultaneously correct,
contextually appropriate, and aligned with user expectations and background
knowledge. To address these challenges, we propose Pathways of Thoughts (PoT),
an inference-stage method that applies to any large language model (LLM)
without requiring task-specific fine-tuning. The approach models the reasoning
of an LLM as an iterative decision process, where the model dynamically selects
among cognitive operations such as reasoning, revision, personalization, and
clarification. This enables exploration of multiple reasoning trajectories,
producing diverse candidate responses that capture different perspectives. PoT
then aggregates and reweights these candidates according to inferred user
preferences, yielding a final personalized response that benefits from the
complementary strengths of diverse reasoning paths. Experiments on the LaMP-QA
benchmark for personalized QA show that PoT consistently outperforms
competitive baselines, achieving up to a 13.1% relative improvement. Human
evaluation corroborates these results, with annotators preferring outputs from
PoT in 66% of cases and reporting ties in only 15% of cases.

</details>


### [170] [Are most sentences unique? An empirical examination of Chomskyan claims](https://arxiv.org/abs/2509.19108)
*Hiram Ring*

Main category: cs.CL

TL;DR: 本研究使用NLTK库分析不同体裁语料库的句子唯一性，发现句子重复情况在特定体裁中并不罕见。


<details>
  <summary>Details</summary>
Motivation: 检验语言学中关于大多数语言发言是独特的这一重复主张，尤其是在大型语料库可用性增加的背景下。

Method: 利用NLTK Python库解析不同体裁的语料库，提供每个语料库中精确字符串匹配的计数。

Result: 结果显示，尽管完全独特的句子通常占语料库的多数，但这一现象在体裁上受到限制，而重复句子在每个语料库中都是相当重要的组成部分。

Conclusion: 虽然完全独特的句子在语料库中往往占大多数，但这受到体裁的高度限制，并且重复句子在任何单个语料库中都不是微不足道的一部分。

Abstract: A repeated claim in linguistics is that the majority of linguistic utterances
are unique. For example, Pinker (1994: 10), summarizing an argument by Noam
Chomsky, states that "virtually every sentence that a person utters or
understands is a brand-new combination of words, appearing for the first time
in the history of the universe." With the increased availability of large
corpora, this is a claim that can be empirically investigated. The current
paper addresses the question by using the NLTK Python library to parse corpora
of different genres, providing counts of exact string matches in each. Results
show that while completely unique sentences are often the majority of corpora,
this is highly constrained by genre, and that duplicate sentences are not an
insignificant part of any individual corpus.

</details>


### [171] [Human-Annotated NER Dataset for the Kyrgyz Language](https://arxiv.org/abs/2509.19109)
*Timur Turatali,Anton Alekseev,Gulira Jumalieva,Gulnara Kabaeva,Sergey Nikolenko*

Main category: cs.CL

TL;DR: 本文介绍了第一个吉尔吉斯语命名实体识别数据集KyrgyzNER，并评估了多种命名实体识别模型，发现多语言预训练模型在处理资源有限的语言时具有潜力和挑战。


<details>
  <summary>Details</summary>
Motivation: 创建基于吉尔吉斯语的第一个手动注释的命名实体识别数据集，以支持在资源有限的语言处理中使用多语种预训练模型。

Method: 评估多种命名实体识别模型，包括基于条件随机场的传统序列标注方法和基于多语言预训练模型的最新技术。

Result: 所有模型在处理稀有实体类别时表现出困难，但经过大规模多语言语料库预训练的多语种RoBERTa变体取得了最佳结果。

Conclusion: 多语种RoBERTa模型在精确度和召回率之间取得了良好的平衡，尽管在处理较少出现的实体类别时仍然存在挑战。

Abstract: We introduce KyrgyzNER, the first manually annotated named entity recognition
dataset for the Kyrgyz language. Comprising 1,499 news articles from the 24.KG
news portal, the dataset contains 10,900 sentences and 39,075 entity mentions
across 27 named entity classes. We show our annotation scheme, discuss the
challenges encountered in the annotation process, and present the descriptive
statistics. We also evaluate several named entity recognition models, including
traditional sequence labeling approaches based on conditional random fields and
state-of-the-art multilingual transformer-based models fine-tuned on our
dataset. While all models show difficulties with rare entity categories, models
such as the multilingual RoBERTa variant pretrained on a large corpus across
many languages achieve a promising balance between precision and recall. These
findings emphasize both the challenges and opportunities of using multilingual
pretrained models for processing languages with limited resources. Although the
multilingual RoBERTa model performed best, other multilingual models yielded
comparable results. This suggests that future work exploring more granular
annotation schemes may offer deeper insights for Kyrgyz language processing
pipelines evaluation.

</details>


### [172] [Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering](https://arxiv.org/abs/2509.19125)
*Kun Zhu,Lizi Liao,Yuxuan Gu,Lei Huang,Xiaocheng Feng,Bing Qin*

Main category: cs.CL

TL;DR: 我们提出了一种新的分类生成框架，结合了LLM和动态聚类，以提高科学文献的组织效率，实验结果显示其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 科学文献的快速增长需要有效的方法来整理和综合研究结果，而现有的方法在一致性和粒度上存在不足。

Method: 提出了一种新的上下文感知层次化分类生成框架，集成了LLM引导的多方面编码和动态聚类。

Result: 实验结果表明，该方法在层次结构的一致性、粒度和可解释性方面达到了最新的最佳性能。

Conclusion: 该方法在税onomiy的一致性、粒度和可解释性方面显著优于现有方法。

Abstract: The rapid growth of scientific literature demands efficient methods to
organize and synthesize research findings. Existing taxonomy construction
methods, leveraging unsupervised clustering or direct prompting of large
language models (LLMs), often lack coherence and granularity. We propose a
novel context-aware hierarchical taxonomy generation framework that integrates
LLM-guided multi-aspect encoding with dynamic clustering. Our method leverages
LLMs to identify key aspects of each paper (e.g., methodology, dataset,
evaluation) and generates aspect-specific paper summaries, which are then
encoded and clustered along each aspect to form a coherent hierarchy. In
addition, we introduce a new evaluation benchmark of 156 expert-crafted
taxonomies encompassing 11.6k papers, providing the first naturally annotated
dataset for this task. Experimental results demonstrate that our method
significantly outperforms prior approaches, achieving state-of-the-art
performance in taxonomy coherence, granularity, and interpretability.

</details>


### [173] [Anecdoctoring: Automated Red-Teaming Across Language and Place](https://arxiv.org/abs/2509.19143)
*Alejandro Cuevas,Saloni Dash,Bharat Kumar Nayak,Dan Vann,Madeleine I. G. Daepp*

Main category: cs.CL

TL;DR: 该研究提出了一种新型的红队方法'anecdoctoring'，以应对生成性AI在全球范围内导致的虚假信息问题，结果显示该方法在对抗成功率和可解释性方面均优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 考虑到生成性AI可能被用于传播虚假信息，全球范围内的适当评估迫在眉睫，而现有的数据集过于集中于美国及英语背景。

Method: 提出了一种名为“anecdoctoring”的新型红队方法，能够自动生成跨语言和文化的对抗性提示，同时利用知识图谱对信息进行了聚类和分析。

Result: 该方法在对抗成功率上表现出色，并在少量示例提示下具有更好的可解释性，证明其在全球范围内抗击虚假信息的有效性。

Conclusion: 该研究强调全球范围内反对虚假信息的必要性，并提出了一种新方法以适应不同语言和文化的需求。

Abstract: Disinformation is among the top risks of generative artificial intelligence
(AI) misuse. Global adoption of generative AI necessitates red-teaming
evaluations (i.e., systematic adversarial probing) that are robust across
diverse languages and cultures, but red-teaming datasets are commonly US- and
English-centric. To address this gap, we propose "anecdoctoring", a novel
red-teaming approach that automatically generates adversarial prompts across
languages and cultures. We collect misinformation claims from fact-checking
websites in three languages (English, Spanish, and Hindi) and two geographies
(US and India). We then cluster individual claims into broader narratives and
characterize the resulting clusters with knowledge graphs, with which we
augment an attacker LLM. Our method produces higher attack success rates and
offers interpretability benefits relative to few-shot prompting. Results
underscore the need for disinformation mitigations that scale globally and are
grounded in real-world adversarial misuse.

</details>


### [174] [Measuring AI "Slop" in Text](https://arxiv.org/abs/2509.19163)
*Chantal Shaib,Tuhin Chakrabarty,Diego Garcia-Olano,Byron C. Wallace*

Main category: cs.CL

TL;DR: 本研究通过专家访谈构建了AI生成文本"slop"的分类体系，并提出了一种评估框架，揭示了文本质量判断的主观性与潜在维度的相关性。


<details>
  <summary>Details</summary>
Motivation: 目前对AI生成的低质量文本（即"slop"）缺乏公认的定义和测量方法，因此有必要对其进行系统研究。

Method: 通过与NLP、写作和哲学领域的专家访谈，建立了关于AI生成文本质量的分类体系，并进行跨度级注释。

Result: 研究发现，二元"slop"判断在一定程度上具有主观性，但与潜在维度（如连贯性和相关性）存在一定相关性。

Conclusion: 本研究提出了一种评估AI生成文本质量的方法框架，能够揭示语言和风格因素对质量判断的影响。

Abstract: AI "slop" is an increasingly popular term used to describe low-quality
AI-generated text, but there is currently no agreed upon definition of this
term nor a means to measure its occurrence. In this work, we develop a taxonomy
of "slop" through interviews with experts in NLP, writing, and philosophy, and
propose a set of interpretable dimensions for its assessment in text. Through
span-level annotation, we find that binary "slop" judgments are (somewhat)
subjective, but such determinations nonetheless correlate with latent
dimensions such as coherence and relevance. Our framework can be used to
evaluate AI-generated text in both detection and binary preference tasks,
potentially offering new insights into the linguistic and stylistic factors
that contribute to quality judgments.

</details>


### [175] [Soft Tokens, Hard Truths](https://arxiv.org/abs/2509.19170)
*Natasha Butt,Ariel Kwiatkowski,Ismail Labiad,Julia Kempe,Yann Ollivier*

Main category: cs.CL

TL;DR: 本研究提出了一种新方法，通过强化学习学习连续CoT，显著提升了推理模型的多样性和性能，同时保持基础模型的预测能力。


<details>
  <summary>Details</summary>
Motivation: 传统的离散令牌在推理过程中受限于表达能力和训练难度，利用连续令牌的优势可以更高效地模拟多个推理路径。

Method: 通过强化学习学习连续Chain-of-Thought (CoT)，使用'软'令牌在输入嵌入中加入噪声以促进探索，避免了从离散CoT提取的方法。

Result: 在数学推理基准测试中，使用连续CoT训练模型在多个评测指标上超越了传统的离散令牌模型，展示了更高的多样性和鲁棒性。

Conclusion: 引入连续CoT的强化学习方法显著提高了推理模型的多样性和性能，特别是在离域任务中的预测保持上表现优越。

Abstract: The use of continuous instead of discrete tokens during the Chain-of-Thought
(CoT) phase of reasoning LLMs has garnered attention recently, based on the
intuition that a continuous mixture of discrete tokens could simulate a
superposition of several reasoning paths simultaneously. Theoretical results
have formally proven that continuous tokens have much greater expressivity and
can solve specific problems more efficiently. However, practical use of
continuous tokens has been limited by strong training difficulties: previous
works either just use continuous tokens at inference time on a pre-trained
discrete-token model, or must distill the continuous CoT from ground-truth
discrete CoTs and face computational costs that limit the CoT to very few
tokens.
  This is the first work introducing a scalable method to learn continuous CoTs
via reinforcement learning (RL), without distilling from reference discrete
CoTs. We use "soft" tokens: mixtures of tokens together with noise on the input
embedding to provide RL exploration. Computational overhead is minimal,
enabling us to learn continuous CoTs with hundreds of tokens. On math reasoning
benchmarks with Llama and Qwen models up to 8B, training with continuous CoTs
match discrete-token CoTs for pass@1 and surpass them for pass@32, showing
greater CoT diversity. In systematic comparisons, the best-performing scenario
is to train with continuous CoT tokens then use discrete tokens for inference,
meaning the "soft" models can be deployed in a standard way. Finally, we show
continuous CoT RL training better preserves the predictions of the base model
on out-of-domain tasks, thus providing a softer touch to the base model.

</details>


### [176] [Online Process Reward Leanring for Agentic Reinforcement Learning](https://arxiv.org/abs/2509.19199)
*Xiaoqian Liu,Ke Wang,Yuchuan Wu,Fei Huang,Yongbin Li,Junge Zhang,Jianbin Jiao*

Main category: cs.CL

TL;DR: OPRL是一种新的信用分配策略，将隐含过程奖励与标准策略算法结合，展现了在多领域的优越性能和高效样本利用。


<details>
  <summary>Details</summary>
Motivation: 由于稀疏和难以验证的奖励使得时间信用分配极具挑战性，现有方法存在偏倚标注、奖励操控等问题，因此需要新的方法来改进智能体学习。

Method: 提出了一种在线过程奖励学习（OPRL）的策略，通过优化隐含过程奖励模型与智能体策略相结合，使用基于轨迹的DPO目标将轨迹偏好转化为隐含步骤奖励。

Result: OPRL在包括WebShop和VisualSokoban等三个不同的代理基准，以及在具有不可验证奖励的SOTOPIA中的开放式社交交互中进行了验证，取得了优越的性能。

Conclusion: OPRL展示了在多个领域中相较于前沿大型语言模型和强强化学习基线具有更好的性能，具备较高的样本效率和低方差，强调了其在现实场景中的潜力。

Abstract: Large language models (LLMs) are increasingly trained with reinforcement
learning (RL) as autonomous agents that reason and act over long horizons in
interactive environments.
  However, sparse and sometimes unverifiable rewards make temporal credit
assignment extremely challenging.
  Recent work attempts to integrate process supervision into agent learning but
suffers from biased annotation, reward hacking, high-variance from overly
fine-grained signals or failtures when state overlap is rare.
  We therefore introduce Online Process Reward Learning (OPRL), a general
credit-assignment strategy for agentic RL that integrates seamlessly with
standard on-policy algorithms without relying on additional rollouts or
explicit step labels.
  In OPRL, we optimize an implicit process reward model (PRM) alternately with
the agent's policy to transform trajectory preferences into implicit step
rewards through a trajectory-based DPO objective.
  These step rewards are then used to compute step-level advantages, which are
combined with episode-level advantages from outcome rewards for policy update,
creating a self-reinforcing loop.
  Theoretical findings guarantee that the learned step rewards are consistent
with trajectory preferences and act as potential-based shaping rewards,
providing bounded gradients to stabilize training.
  Empirically, we evaluate OPRL on three distinct agent benmarks, including
WebShop and VisualSokoban, as well as open-ended social interactions with
unverfiable rewards in SOTOPIA.
  Crucially, OPRL shows superior performance over frontier LLMs and strong RL
baselines across domains, achieving state-of-the-art results with higher
sample-efficiency and lower variance during training.
  Further analysis also demonstrates the efficient exploration by OPRL using
fewer actions, underscoring its potential for agentic learning in real-world
scenarios.

</details>


### [177] [Steering Multimodal Large Language Models Decoding for Context-Aware Safety](https://arxiv.org/abs/2509.19212)
*Zheyuan Liu,Zhangchen Xu,Guangyao Dou,Xiangchi Yuan,Zhaoxuan Tan,Radha Poovendran,Meng Jiang*

Main category: cs.CL

TL;DR: 提出了一种新的解码框架SafeCoDe，以解决多模态大型语言模型在安全决策过程中的敏感性问题，实验结果表明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型在安全决策时存在过于敏感和不足敏感的问题，因此需要一种新的方法来优化安全对齐。

Method: 引入了一种轻量级的、安全感知的对比解码框架（SafeCoDe），通过对比真实图像和高斯噪声图像来强调与视觉上下文敏感的标记，同时结合全局场景推理与标记级调整来适应拒绝。

Result: 在多种MLLM架构和安全基准上进行的广泛实验表明，SafeCoDe在处理不足敏感性、过敏感性和一般安全评估方面，一致性地改善了拒绝行为。

Conclusion: SafeCoDe显著提升了多模态大型语言模型在安全决策中的上下文敏感拒绝行为，同时保持了模型的实用性。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly deployed in
real-world applications, yet their ability to make context-aware safety
decisions remains limited. Existing methods often fail to balance
oversensitivity (unjustified refusals of benign queries) and undersensitivity
(missed detection of visually grounded risks), leaving a persistent gap in
safety alignment. To address this issue, we introduce Safety-aware Contrastive
Decoding (SafeCoDe), a lightweight and model-agnostic decoding framework that
dynamically adjusts token generation based on multimodal context. SafeCoDe
operates in two stages: (1) a contrastive decoding mechanism that highlights
tokens sensitive to visual context by contrasting real and Gaussian-noised
images, and (2) a global-aware token modulation strategy that integrates
scene-level reasoning with token-level adjustment to adapt refusals according
to the predicted safety verdict. Extensive experiments across diverse MLLM
architectures and safety benchmarks, covering undersensitivity,
oversensitivity, and general safety evaluations, show that SafeCoDe
consistently improves context-sensitive refusal behaviors while preserving
model helpfulness.

</details>


### [178] [Systematic Comparative Analysis of Large Pretrained Language Models on Contextualized Medication Event Extraction](https://arxiv.org/abs/2509.19224)
*Tariq Abdul-Quddoos,Xishuang Dong,Lijun Qian*

Main category: cs.CL

TL;DR: 该研究比较多种预训练的基于注意力的模型在电子健康记录信息提取中的表现，发现临床数据模型更有效，但Bert Base在事件上下文分类上最佳。


<details>
  <summary>Details</summary>
Motivation: 随着医疗语言建模的需求增加，通过比较不同预训练的注意力模型，旨在提高电子健康记录中患者用药事件相关信息的提取效果。

Method: 对多种预训练的基于注意力的模型，包括Bert Base、BioBert、Bio+Clinical Bert的两个变体、RoBerta和Clinical Long- former进行比较分析，并在CMED上进行微调以执行药物提取、医疗事件检测和多维药物事件上下文分类。

Result: 通过在CMED数据集上评估，各模型的表现被量化，发现临床数据预训练模型在药物及其事件检测上效果更佳。

Conclusion: 虽然临床数据预训练模型在检测药物和药物事件方面更有效，但预训练于一般领域数据的Bert Base在分类与药物相关事件的上下文方面表现最好。

Abstract: Attention-based models have become the leading approach in modeling medical
language for Natural Language Processing (NLP) in clinical notes. These models
outperform traditional techniques by effectively capturing contextual rep-
resentations of language. In this research a comparative analysis is done
amongst pre- trained attention based models namely Bert Base, BioBert, two
variations of Bio+Clinical Bert, RoBerta, and Clinical Long- former on task
related to Electronic Health Record (EHR) information extraction. The tasks
from Track 1 of Harvard Medical School's 2022 National Clinical NLP Challenges
(n2c2) are considered for this comparison, with the Contextualized Medication
Event Dataset (CMED) given for these task. CMED is a dataset of unstructured
EHRs and annotated notes that contain task relevant information about the EHRs.
The goal of the challenge is to develop effective solutions for extracting
contextual information related to patient medication events from EHRs using
data driven methods. Each pre-trained model is fine-tuned and applied on CMED
to perform medication extraction, medical event detection, and
multi-dimensional medication event context classification. Pro- cessing methods
are also detailed for breaking down EHRs for compatibility with the applied
models. Performance analysis has been carried out using a script based on
constructing medical terms from the evaluation portion of CMED with metrics
including recall, precision, and F1-Score. The results demonstrate that models
pre-trained on clinical data are more effective in detecting medication and
medication events, but Bert Base, pre- trained on general domain data showed to
be the most effective for classifying the context of events related to
medications.

</details>


### [179] [CompLLM: Compression for Long Context Q&A](https://arxiv.org/abs/2509.19228)
*Gabriele Berton,Jayakrishnan Unnikrishnan,Son Tran,Mubarak Shah*

Main category: cs.CL

TL;DR: CompLLM是一种新型的软压缩技术，通过独立压缩上下文片段，实现了高效性、可扩展性和计算重用，显著提高了大语言模型在长上下文处理中的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在处理长上下文时面临计算挑战，本研究旨在开发一种可落地的高效压缩方法。

Method: 通过将上下文分割成独立的片段进行压缩，而不是整体处理，从而实现线性缩放和计算重用。

Result: CompLLM在2倍压缩率下，在高上下文长度时，可以将首次令牌生成时间加速最多4倍，并减少50%的KV缓存大小，同时保持竞争力的性能。

Conclusion: CompLLM是一种有效的软压缩技术，能够在长上下文处理中显著提高效率并降低计算需求，同时保持或超过未压缩上下文的性能。

Abstract: Large Language Models (LLMs) face significant computational challenges when
processing long contexts due to the quadratic complexity of self-attention.
While soft context compression methods, which map input text to smaller latent
representations, have shown promise, their real-world adoption is limited.
Existing techniques typically compress the context as a single unit, which
leads to quadratic compression complexity and an inability to reuse
computations across queries with overlapping contexts. In this work, we
introduce CompLLM, a soft compression technique designed for practical
deployment. Instead of processing the context holistically, CompLLM divides it
into segments and compresses each one independently. This simple design choice
yields three critical properties: efficiency, as the compression step scales
linearly with the context length; scalability, enabling models trained on short
sequences (e.g., 1k tokens) to generalize to contexts of 100k tokens; and
reusability, allowing compressed segments to be cached and reused across
different queries. Our experiments show that with a 2x compression rate, at
high context lengths CompLLM speeds up Time To First Token (TTFT) by up to 4x
and reduces the KV cache size by 50%. Furthermore, CompLLM achieves performance
comparable to that obtained with the uncompressed context, and even surpasses
it on very long sequences, demonstrating its effectiveness and practical
utility.

</details>


### [180] [Reinforcement Learning on Pre-Training Data](https://arxiv.org/abs/2509.19249)
*Siheng Li,Kejiao Li,Zenan Xu,Guanhua Huang,Evander Yang,Kun Li,Haoyuan Wu,Jiajia Wu,Zihao Zheng,Chenchen Zhang,Kun Shi,Kyrierl Deng,Qi Yi,Ruibin Xiong,Tingqiang Xu,Yuhao Jiang,Jianfeng Yan,Yuyuan Zeng,Guanghui Xu,Jinbao Xue,Zhijiang Xu,Zheng Fang,Shuai Li,Qibin Liu,Xiaoxue Li,Zhuoyu Li,Yangyu Tao,Fei Gao,Cheng Jiang,Bo Chao Wang,Kai Liu,Jianchen Zhu,Wai Lam,Wayyt Wang,Bo Zhou,Di Wang*

Main category: cs.CL

TL;DR: RLPT是一种新的训练方法，通过从预训练数据中自动生成奖励信号，提升了语言模型的推理能力，并在不同基准测试中展示了其优越性。


<details>
  <summary>Details</summary>
Motivation: 由于计算资源的指数增长与高质量文本数据的有限增长之间的差距，传统的扩展方法受到限制，因此需要一种新的训练策略。

Method: 引入了一种新的训练时间扩展范式——在预训练数据上进行强化学习（RLPT），以增强大型语言模型的能力。

Result: 在多个通用和数学推理基准上进行的广泛实验验证了RLPT的有效性，特别是在应用于Qwen3-4B-Base模型时，多个基准的绝对改进达到3.0至8.1。

Conclusion: RLPT通过直接从预训练数据中生成奖励信号，提高了大语言模型的推理能力和表现，为强化学习提供了有力的基础。

Abstract: The growing disparity between the exponential scaling of computational
resources and the finite growth of high-quality text data now constrains
conventional scaling approaches for large language models (LLMs). To address
this challenge, we introduce Reinforcement Learning on Pre-Training data
(RLPT), a new training-time scaling paradigm for optimizing LLMs. In contrast
to prior approaches that scale training primarily through supervised learning,
RLPT enables the policy to autonomously explore meaningful trajectories to
learn from pre-training data and improve its capability through reinforcement
learning (RL). While existing RL strategies such as reinforcement learning from
human feedback (RLHF) and reinforcement learning with verifiable rewards (RLVR)
rely on human annotation for reward construction, RLPT eliminates this
dependency by deriving reward signals directly from pre-training data.
Specifically, it adopts a next-segment reasoning objective, rewarding the
policy for accurately predicting subsequent text segments conditioned on the
preceding context. This formulation allows RL to be scaled on pre-training
data, encouraging the exploration of richer trajectories across broader
contexts and thereby fostering more generalizable reasoning skills. Extensive
experiments on both general-domain and mathematical reasoning benchmarks across
multiple models validate the effectiveness of RLPT. For example, when applied
to Qwen3-4B-Base, RLPT yields absolute improvements of $3.0$, $5.1$, $8.1$,
$6.0$, $6.6$, and $5.3$ on MMLU, MMLU-Pro, GPQA-Diamond, KOR-Bench, AIME24, and
AIME25, respectively. The results further demonstrate favorable scaling
behavior, suggesting strong potential for continued gains with more compute. In
addition, RLPT provides a solid foundation, extending the reasoning boundaries
of LLMs and enhancing RLVR performance.

</details>


### [181] [Extracting Conceptual Spaces from LLMs Using Prototype Embeddings](https://arxiv.org/abs/2509.19269)
*Nitesh Kumar,Usashi Chatterjee,Steven Schockaert*

Main category: cs.CL

TL;DR: 本文提出了一种通过原型描述编码特征并细调LLM的方法，以有效提取概念空间，并通过实证分析验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 概念空间在认知科学和可解释AI中具有重要意义，但学习这些空间的方法仍然不足，而最新的语言模型在捕捉感知特征方面表现出色，因此需要一种有效的提取方法。

Method: 通过细调大规模语言模型，使原型嵌入与相应的概念空间维度对齐，结合特征编码来提取概念空间。

Result: 实证分析表明，所提出的方法在提取概念空间方面效果显著。

Conclusion: 提出了一种新的策略，通过嵌入对应原型的描述来编码特征，优化了从大规模语言模型提取概念空间的方法，并通过实证分析验证了其有效性。

Abstract: Conceptual spaces represent entities and concepts using cognitively
meaningful dimensions, typically referring to perceptual features. Such
representations are widely used in cognitive science and have the potential to
serve as a cornerstone for explainable AI. Unfortunately, they have proven
notoriously difficult to learn, although recent LLMs appear to capture the
required perceptual features to a remarkable extent. Nonetheless, practical
methods for extracting the corresponding conceptual spaces are currently still
lacking. While various methods exist for extracting embeddings from LLMs,
extracting conceptual spaces also requires us to encode the underlying
features. In this paper, we propose a strategy in which features (e.g.
sweetness) are encoded by embedding the description of a corresponding
prototype (e.g. a very sweet food). To improve this strategy, we fine-tune the
LLM to align the prototype embeddings with the corresponding conceptual space
dimensions. Our empirical analysis finds this approach to be highly effective.

</details>


### [182] [WolBanking77: Wolof Banking Speech Intent Classification Dataset](https://arxiv.org/abs/2509.19271)
*Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione*

Main category: cs.CL

TL;DR: 本研究推出了一个针对沃洛夫语的意图分类数据集，旨在支持低资源语言的研究，实验结果显示出积极的效果，并计划进行开放源代码的发布和数据集维护。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在填补低资源语言意图分类模型和以口语为主的地区（如塞内加尔）的研究空白，特别是考虑到该地区的高文盲率。

Method: 进行了各种基准模型的实验，包括文本和语音的最先进模型。

Result: WolBanking77数据集包含9791个银行领域的文本句子和超过4小时的口语句子，在NLP和ASR模型上的f1分数和字错误率进行了评估，取得了良好的成果。

Conclusion: 本研究成功推出了Wolof意图分类数据集（WolBanking77），并在多个基准测试中展示了良好的结果，同时计划进行数据集维护和开源代码的发布。

Abstract: Intent classification models have made a lot of progress in recent years.
However, previous studies primarily focus on high-resource languages datasets,
which results in a gap for low-resource languages and for regions with a high
rate of illiterate people where languages are more spoken than read or written.
This is the case in Senegal, for example, where Wolof is spoken by around 90\%
of the population, with an illiteracy rate of 42\% for the country. Wolof is
actually spoken by more than 10 million people in West African region. To
tackle such limitations, we release a Wolof Intent Classification Dataset
(WolBanking77), for academic research in intent classification. WolBanking77
currently contains 9,791 text sentences in the banking domain and more than 4
hours of spoken sentences. Experiments on various baselines are conducted in
this work, including text and voice state-of-the-art models. The results are
very promising on this current dataset. This paper also provides detailed
analyses of the contents of the data. We report baseline f1-score and word
error rate metrics respectively on NLP and ASR models trained on WolBanking77
dataset and also comparisons between models. We plan to share and conduct
dataset maintenance, updates and to release open-source code.

</details>


### [183] [DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture](https://arxiv.org/abs/2509.19274)
*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Nemil Shah,Abhilekh Borah,Vanshika Shah,Nishant Mishra,Sriparna Saha*

Main category: cs.CL

TL;DR: DRISHTIKON是一个专注于印度文化的多模态基准，评估AI系统在文化理解方面的表现，揭示模型的缺陷，并促进更具文化意识的语言技术的发展。


<details>
  <summary>Details</summary>
Motivation: 创建一个专注于印度文化的多模态、多语言基准，以评估生成性人工智能系统的文化理解能力。

Method: 通过评估多种视觉语言模型在不同设置下的表现，利用包含64,000对文本-图像的数据集进行测试。

Result: 测试结果显示当前模型在处理低资源语言和不太记录的传统时存在重要局限性。

Conclusion: DRISHTIKON为文化感知、多模态的语言技术研究提供了一种新的基准，揭示了当前模型在处理与印度文化相关的多模态内容时的不足之处。

Abstract: We introduce DRISHTIKON, a first-of-its-kind multimodal and multilingual
benchmark centered exclusively on Indian culture, designed to evaluate the
cultural understanding of generative AI systems. Unlike existing benchmarks
with a generic or global scope, DRISHTIKON offers deep, fine-grained coverage
across India's diverse regions, spanning 15 languages, covering all states and
union territories, and incorporating over 64,000 aligned text-image pairs. The
dataset captures rich cultural themes including festivals, attire, cuisines,
art forms, and historical heritage amongst many more. We evaluate a wide range
of vision-language models (VLMs), including open-source small and large models,
proprietary systems, reasoning-specialized VLMs, and Indic-focused models,
across zero-shot and chain-of-thought settings. Our results expose key
limitations in current models' ability to reason over culturally grounded,
multimodal inputs, particularly for low-resource languages and less-documented
traditions. DRISHTIKON fills a vital gap in inclusive AI research, offering a
robust testbed to advance culturally aware, multimodally competent language
technologies.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [184] [XMUspeech Systems for the ASVspoof 5 Challenge](https://arxiv.org/abs/2509.18102)
*Wangjie Li,Xingjia Xie,Yishuang Li,Wenhao Guan,Kaidi Wang,Pengyu Ren,Lin Li,Qingyang Hong*

Main category: cs.SD

TL;DR: 本研究在ASVspoof 5挑战中通过调整音频长度和多级特征融合提升了深度伪造检测性能，融合系统在封闭和开放条件下均表现优异。


<details>
  <summary>Details</summary>
Motivation: 观察到仅仅调整输入音频长度显著提高了系统性能，因此在ASVspoof 5挑战中，探讨如何利用音频时长变化和多级特征捕捉来改进深度伪造检测。

Method: 我们探索了多种模型（如AASIST、HM-Conformer、Hubert和Wav2vec2），使用自监督模型进行特征提取，并应用自适应多尺度特征融合（AMFF）方法来增强检测能力。

Result: 通过自监督模型提取伪造语句特征，采用多种输入特征和损失函数进行性能评估，最后取得了优化后的配置。

Conclusion: 我们的融合系统在封闭条件下实现了0.4783的minDCF和20.45%的EER，在开放条件下分别为0.2245和9.36%。

Abstract: In this paper, we present our submitted XMUspeech systems to the speech
deepfake detection track of the ASVspoof 5 Challenge. Compared to previous
challenges, the audio duration in ASVspoof 5 database has significantly
increased. And we observed that merely adjusting the input audio length can
substantially improve system performance. To capture artifacts at multiple
levels, we explored the performance of AASIST, HM-Conformer, Hubert, and
Wav2vec2 with various input features and loss functions. Specifically, in order
to obtain artifact-related information, we trained self-supervised models on
the dataset containing spoofing utterances as the feature extractors. And we
applied an adaptive multi-scale feature fusion (AMFF) method to integrate
features from multiple Transformer layers with the hand-crafted feature to
enhance the detection capability. In addition, we conducted extensive
experiments on one-class loss functions and provided optimized configurations
to better align with the anti-spoofing task. Our fusion system achieved a
minDCF of 0.4783 and an EER of 20.45% in the closed condition, and a minDCF of
0.2245 and an EER of 9.36% in the open condition.

</details>


### [185] [MNV-17: A High-Quality Performative Mandarin Dataset for Nonverbal Vocalization Recognition in Speech](https://arxiv.org/abs/2509.18196)
*Jialong Mai,Jinxin Ji,Xiaofen Xing,Chen Yang,Weidong Chen,Jingyuan Xing,Xiangmin Xu*

Main category: cs.SD

TL;DR: MNV-17是一个新的普通话演绎语音数据集，专注于非语言发声的识别，支持未来情感化ASR研究。


<details>
  <summary>Details</summary>
Motivation: 现有的ASR系统在识别非言语声音方面存在不足，缺乏高质量和良好标注的数据集。

Method: 通过引入高保真且清晰的非语言发声实例，构建了一个7.55小时的普通话演绎语音数据集，包含17种非语言发声类别，采用四种主流ASR架构进行评估。

Result: MNV-17提供丰富的非语言发声类别，并经过基准测试，其于语义转录和非语言分类上的表现得以评估。

Conclusion: MNV-17数据集是对提高自动语音识别系统对非语言发声识别能力的重要贡献，促进了情感沟通的理解。

Abstract: Mainstream Automatic Speech Recognition (ASR) systems excel at transcribing
lexical content, but largely fail to recognize nonverbal vocalizations (NVs)
embedded in speech, such as sighs, laughs, and coughs. This capability is
important for a comprehensive understanding of human communication, as NVs
convey crucial emotional and intentional cues. Progress in NV-aware ASR has
been hindered by the lack of high-quality, well-annotated datasets. To address
this gap, we introduce MNV-17, a 7.55-hour performative Mandarin speech
dataset. Unlike most existing corpora that rely on model-based detection,
MNV-17's performative nature ensures high-fidelity, clearly articulated NV
instances. To the best of our knowledge, MNV-17 provides the most extensive set
of nonverbal vocalization categories, comprising 17 distinct and well-balanced
classes of common NVs. We benchmarked MNV-17 on four mainstream ASR
architectures, evaluating their joint performance on semantic transcription and
NV classification. The dataset and the pretrained model checkpoints will be
made publicly available to facilitate future research in expressive ASR.

</details>


### [186] [StereoFoley: Object-Aware Stereo Audio Generation from Video](https://arxiv.org/abs/2509.18272)
*Tornike Karchkhadze,Kuan-Lin Chen,Mojtaba,Heydari,Robert Henzel,Alessandro Toso,Mehrez Souden,Joshua Atkins*

Main category: cs.SD

TL;DR: 本文提出了StereoFoley框架，实现视频到音频的立体声生成，具备对象感知能力，克服了数据集局限，设定了新的技术基准。


<details>
  <summary>Details</summary>
Motivation: 近年来生成的视频到音频模型在语义和时间准确性方面表现良好，但仍然限于单声道或未能实现对象感知立体声成像，因缺乏专业混音和空间准确的视频到音频数据集。

Method: 首先开发并训练了一个生成立体声音频的基础模型；其次引入合成数据生成管道，通过视频分析、对象跟踪和音频合成结合动态平移和距离音量控制。最后通过人类听觉研究对模型进行细化和验证。

Result: 建立了能够生成语义对齐、时间同步和空间准确的立体声音频，实现了解耦的对象与音频对应，并通过新提出的立体声对象感知度量进行验证。

Conclusion: 该研究建立了首个端到端的立体声对象感知视频到音频生成框架，填补了领域中的关键空白，并设定了新的基准。

Abstract: We present StereoFoley, a video-to-audio generation framework that produces
semantically aligned, temporally synchronized, and spatially accurate stereo
sound at 48 kHz. While recent generative video-to-audio models achieve strong
semantic and temporal fidelity, they largely remain limited to mono or fail to
deliver object-aware stereo imaging, constrained by the lack of professionally
mixed, spatially accurate video-to-audio datasets. First, we develop and train
a base model that generates stereo audio from video, achieving state-of-the-art
in both semantic accuracy and synchronization. Next, to overcome dataset
limitations, we introduce a synthetic data generation pipeline that combines
video analysis, object tracking, and audio synthesis with dynamic panning and
distance-based loudness controls, enabling spatially accurate object-aware
sound. Finally, we fine-tune the base model on this synthetic dataset, yielding
clear object-audio correspondence. Since no established metrics exist, we
introduce stereo object-awareness measures and validate it through a human
listening study, showing strong correlation with perception. This work
establishes the first end-to-end framework for stereo object-aware
video-to-audio generation, addressing a critical gap and setting a new
benchmark in the field.

</details>


### [187] [A Dimensional Approach to Canine Bark Analysis for Assistance Dog Seizure Signaling](https://arxiv.org/abs/2509.18375)
*Hailin Song,Shelley Brady,Tomás Ward,Alan F. Smeaton*

Main category: cs.SD

TL;DR: 本文提出了一种新方法，通过调整的孪生网络在二维激活-情感空间中进行犬类叫声分析，显著提高了在低数据条件下的分类效果。


<details>
  <summary>Details</summary>
Motivation: 由于样本数据稀缺且变化大，传统的犬类叫声分类在服务犬领域受到限制，需要一种新的分析方法。

Method: 使用调整过的孪生网络进行训练，任务转变为一个连续回归任务，在二维激活-情感空间中进行分析。

Result: 我们的模型在挑战性的情感维度上将转回百分比减少了多达50%。对实际数据集的定性验证表明学习到的空间具有语义意义。

Conclusion: 我们的方法成功地在严重数据限制下对犬类叫声进行分析，提供了有意义的语义空间。

Abstract: Standard classification of canine vocalisations is severely limited for
assistance dogs, where sample data is sparse and variable across dogs and where
capture of the full range of bark types is ethically constrained. We reframe
this problem as a continuous regression task within a two-dimensional
arousal-valence space. Central to our approach is an adjusted Siamese Network
trained not on binary similarity, but on the ordinal and numeric distance
between input sample pairs. Trained on a public dataset, our model reduces
Turn-around Percentage by up to 50% on the challenging valence dimension
compared to a regression baseline. Qualitative validation on a real-world
dataset confirms the learned space is semantically meaningful, establishing a
proof-of-concept for analysing canine barking under severe data limitations.

</details>


### [188] [Identifying birdsong syllables without labelled data](https://arxiv.org/abs/2509.18412)
*Mélisande Teng,Julien Boussard,David Rolnick,Hugo Larochelle*

Main category: cs.SD

TL;DR: 本研究提出了一种无监督算法，成功分解鸟鸣录音并识别鸟类个体，克服了对标记数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 识别鸟鸣中的音节序列对于鸟类个体识别和动物沟通的理解至关重要，现有方法依赖标记数据，限制了应用范围。

Method: 构建了第一个完全无监督的算法，首先检测音节事件，然后进行聚类以提取模板，最后执行匹配追踪以分解录音。

Result: 在孟加拉文鸟的歌曲数据集上，与人工标签进行对比评估，发现该无监督方法表现良好，且能够区分同一物种中不同个体的独特声音特征。

Conclusion: 该方法能有效分解鸟鸣录音，并能区分不同个体的鸟类。

Abstract: Identifying sequences of syllables within birdsongs is key to tackling a wide
array of challenges, including bird individual identification and better
understanding of animal communication and sensory-motor learning. Recently,
machine learning approaches have demonstrated great potential to alleviate the
need for experts to label long audio recordings by hand. However, they still
typically rely on the availability of labelled data for model training,
restricting applicability to a few species and datasets. In this work, we build
the first fully unsupervised algorithm to decompose birdsong recordings into
sequences of syllables. We first detect syllable events, then cluster them to
extract templates --syllable representations-- before performing matching
pursuit to decompose the recording as a sequence of syllables. We evaluate our
automatic annotations against human labels on a dataset of Bengalese finch
songs and find that our unsupervised method achieves high performance. We also
demonstrate that our approach can distinguish individual birds within a species
through their unique vocal signatures, for both Bengalese finches and another
species, the great tit.

</details>


### [189] [Scattering Transformer: A Training-Free Transformer Architecture for Heart Murmur Detection](https://arxiv.org/abs/2509.18424)
*Rami Zewail*

Main category: cs.SD

TL;DR: 本文研究提出了一种轻量级的Scattering Transformer，用于心脏杂音检测，表现优于传统音频基础模型，适合资源有限的环境。


<details>
  <summary>Details</summary>
Motivation: 旨在解决心音解读中对熟练临床医生的需求，并应对训练数据有限情况下的监督学习挑战。

Method: 介绍了一种轻量级的Scattering Transformer架构，用于心脏杂音检测，利用标准的小波散射网络引入上下文依赖，无需回传训练。

Result: Scattering Transformer在CirCor DigiScope数据集上的加权准确率(WAR)为0.786，未加权平均召回率(UAR)为0.697，表现具有高度竞争力。

Conclusion: 该研究提出的Scattering Transformer在资源受限的设置中是一种可行且有前景的替代方案，展现了与当代顶尖方法的竞争力。

Abstract: In an attempt to address the need for skilled clinicians in heart sound
interpretation, recent research efforts on automating cardiac auscultation have
explored deep learning approaches. The majority of these approaches have been
based on supervised learning that is always challenged in occasions where
training data is limited. More recently, there has been a growing interest in
potentials of pre-trained self-supervised audio foundation models for
biomedical end tasks. Despite exhibiting promising results, these foundational
models are typically computationally intensive. Within the context of automatic
cardiac auscultation, this study explores a lightweight alternative to these
general-purpose audio foundation models by introducing the Scattering
Transformer, a novel, training-free transformer architecture for heart murmur
detection. The proposed method leverages standard wavelet scattering networks
by introducing contextual dependencies in a transformer-like architecture
without any backpropagation. We evaluate our approach on the public CirCor
DigiScope dataset, directly comparing it against leading general-purpose
foundational models. The Scattering Transformer achieves a Weighted
Accuracy(WAR) of 0.786 and an Unweighted Average Recall(UAR) of 0.697,
demonstrating performance highly competitive with contemporary state of the art
methods. This study establishes the Scattering Transformer as a viable and
promising alternative in resource-constrained setups.

</details>


### [190] [Explore the Reinforcement Learning for the LLM based ASR and TTS system](https://arxiv.org/abs/2509.18569)
*Changfeng Gao,Yabin Li,Keyu An,Zhifu Gao,Zhihao Du,Han Zhao,Xiangang Li*

Main category: cs.SD

TL;DR: 本文提出了一种轻量级的强化学习框架，以增强自动语音识别和文本到语音系统的性能，实验证明了其有效性，即使在训练数据有限的情况下。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习在文本任务中显著提升了大语言模型的性能，但其在自动语音识别和文本到语音领域的应用研究仍然较为匮乏，主要由于音频模型训练的复杂性。

Method: 我们提出了一种轻量级的强化学习框架，针对音频输入和输出的音频基础大语言模型进行处理，同时评估在自动语音识别和文本到语音任务中的有效性。

Result: 在自动语音识别任务中，我们探索了基于规则的奖励函数在GRPO框架中的不同实验，并研究了强化学习数据构建的影响；在文本到语音任务中，我们将GRPO与可微奖励优化（DiffRO）进行比较，并进一步结合这两种方法以改善性能。

Conclusion: 我们的实验表明，即使在有限的训练数据和较少的优化步骤下，强化学习也能显著提高自动语音识别和文本到语音系统的性能。

Abstract: In recent years, large language models (LLMs) have played an important role
in automatic speech recognition (ASR) and text-to-speech (TTS) systems. While
reinforcement learning (RL) has significantly enhanced LLM performance in
text-based tasks, its application to ASR and TTS remains underexplored due to
the complexity of training audio-based models. In this study, we propose a
lightweight RL framework tailored for audio-based LLMs that can process audio
inputs and generate audio outputs. Based on this framework, we evaluate the
effectiveness of reinforcement learning on both ASR and TTS tasks. For the ASR
task, we experiment with different rule-based reward functions within the Group
Relative Policy Optimization (GRPO) framework and investigate the impact of RL
data construction. For the TTS task, we compare GRPO with Differentiable Reward
Optimization (DiffRO) and further combine the two approaches to achieve
improved performance. Our experiments demonstrate that RL can significantly
enhance the performance of both ASR and TTS systems, even with limited training
data and a small number of optimization steps.

</details>


### [191] [Scalable Evaluation for Audio Identification via Synthetic Latent Fingerprint Generation](https://arxiv.org/abs/2509.18620)
*Aditya Bhattacharjee,Marco Pasini,Emmanouil Benetos*

Main category: cs.SD

TL;DR: 本研究提出了一种音频无关的合成指纹方法，克服了大型音频数据库稀缺的问题，通过合成指纹模拟真实检索性能，为音频指纹评估提供了新的实用工具。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大型公共音乐数据库，音频指纹技术在现实规模上的评估受到限制，因此需要寻找一种不依赖音频材料的解决方案。

Method: 使用经过预训练的神经音频指纹提取系统的嵌入，训练Rectified Flow模型以合成逼真的音频指纹，作为干扰目标实施评测。

Result: 通过将合成指纹与真实数据进行比较，验证了合成指纹的可信度，并通过与多个先进音频指纹框架的检索性能基准测试显示了合成指纹的有效性以及系统扩展性的实用指标。

Conclusion: 合成的指纹数据库能够有效模拟真实环境下的音频指纹检索性能，且不依赖于实际音频数据，从而提供了一种新的评估方法。

Abstract: The evaluation of audio fingerprinting at a realistic scale is limited by the
scarcity of large public music databases. We present an audio-free approach
that synthesises latent fingerprints which approximate the distribution of real
fingerprints. Our method trains a Rectified Flow model on embeddings extracted
by pre-trained neural audio fingerprinting systems. The synthetic fingerprints
generated using our system act as realistic distractors and enable the
simulation of retrieval performance at a large scale without requiring
additional audio. We assess the fidelity of synthetic fingerprints by comparing
the distributions to real data. We further benchmark the retrieval performances
across multiple state-of-the-art audio fingerprinting frameworks by augmenting
real reference databases with synthetic distractors, and show that the scaling
trends obtained with synthetic distractors closely track those obtained with
real distractors. Finally, we scale the synthetic distractor database to model
retrieval performance for very large databases, providing a practical metric of
system scalability that does not depend on access to audio corpora.

</details>


### [192] [An overview of neural architectures for self-supervised audio representation learning from masked spectrograms](https://arxiv.org/abs/2509.18691)
*Sarthak Yadav,Sergios Theodoridis,Zheng-Hua Tan*

Main category: cs.SD

TL;DR: 本文概述了掩蔽谱图建模与序列建模架构（Mamba和xLSTM）的研究，比较了这些方法的效果，为音频分类任务提供了实用的指导。


<details>
  <summary>Details</summary>
Motivation: 由于现有的研究缺乏对掩蔽谱图建模与新兴神经序列建模架构之间的交叉领域的全面概述，本文旨在填补这一空白。

Method: 比较Transformer、Mamba和xLSTM基础的掩蔽谱图模型，在十个不同的音频分类任务上进行评估。

Result: 通过比较不同模型在多个音频分类任务中的表现，本文帮助读者理解各种方法的优缺点和适用性。

Conclusion: 本文提供了关于掩蔽谱图建模与神经序列建模架构之间交叉研究领域的全面概述，并在统一的可重复框架中对不同方法进行了比较，为读者在相似应用中做出明智决策提供了帮助。

Abstract: In recent years, self-supervised learning has amassed significant interest
for training deep neural representations without labeled data. One such
self-supervised learning approach is masked spectrogram modeling, where the
objective is to learn semantically rich contextual representations by
predicting removed or hidden portions of the input audio spectrogram. With the
Transformer neural architecture at its core, masked spectrogram modeling has
emerged as the prominent approach for learning general purpose audio
representations, a.k.a. audio foundation models. Meanwhile, addressing the
issues of the Transformer architecture, in particular the underlying Scaled
Dot-product Attention operation, which scales quadratically with input sequence
length, has led to renewed interest in recurrent sequence modeling approaches.
Among them, Selective structured state space models (such as Mamba) and
extended Long Short-Term Memory (xLSTM) are the two most promising approaches
which have experienced widespread adoption. While the body of work on these two
topics continues to grow, there is currently a lack of an adequate overview
encompassing the intersection of these topics. In this paper, we present a
comprehensive overview of the aforementioned research domains, covering masked
spectrogram modeling and the previously mentioned neural sequence modeling
architectures, Mamba and xLSTM. Further, we compare Transformers, Mamba and
xLSTM based masked spectrogram models in a unified, reproducible framework on
ten diverse downstream audio classification tasks, which will help interested
readers to make informed decisions regarding suitability of the evaluated
approaches to adjacent applications.

</details>


### [193] [Enhancing Automatic Chord Recognition through LLM Chain-of-Thought Reasoning](https://arxiv.org/abs/2509.18700)
*Chih-Cheng Chang,Bo-Yu Chen,Lu-Rong Chen,Li Su*

Main category: cs.SD

TL;DR: 本文探讨了大型语言模型如何作为音乐信息检索工具的整合桥梁，提出一种新的方法，显著提升自动和弦识别的性能。


<details>
  <summary>Details</summary>
Motivation: 基于最近深度学习的进步，探索如何利用大型语言模型来连接和整合来自多个MIR工具的信息。

Method: 提出了一种新的方法，通过将基于文本的LLMs作为智能协调者，处理和整合来自多种最先进MIR工具的输出，并专注于自动和弦识别性能的增强。

Result: 在三个数据集上的实验评估显示，在多个评估指标上均表现出一致的改进，整体准确率在MIREX指标上提高了1-2.77%。

Conclusion: 大语言模型（LLMs）可以有效地作为音乐信息检索（MIR）流程中的整合桥梁，推动多工具协调的新方向。

Abstract: Music Information Retrieval (MIR) encompasses a broad range of computational
techniques for analyzing and understanding musical content, with recent deep
learning advances driving substantial improvements. Building upon these
advances, this paper explores how large language models (LLMs) can serve as an
integrative bridge to connect and integrate information from multiple MIR
tools, with a focus on enhancing automatic chord recognition performance. We
present a novel approach that positions text-based LLMs as intelligent
coordinators that process and integrate outputs from diverse state-of-the-art
MIR tools-including music source separation, key detection, chord recognition,
and beat tracking. Our method converts audio-derived musical information into
textual representations, enabling LLMs to perform reasoning and correction
specifically for chord recognition tasks. We design a 5-stage chain-of-thought
framework that allows GPT-4o to systematically analyze, compare, and refine
chord recognition results by leveraging music-theoretical knowledge to
integrate information across different MIR components. Experimental evaluation
on three datasets demonstrates consistent improvements across multiple
evaluation metrics, with overall accuracy gains of 1-2.77% on the MIREX metric.
Our findings demonstrate that LLMs can effectively function as integrative
bridges in MIR pipelines, opening new directions for multi-tool coordination in
music information retrieval tasks.

</details>


### [194] [MECap-R1: Emotion-aware Policy with Reinforcement Learning for Multimodal Emotion Captioning](https://arxiv.org/abs/2509.18729)
*Haoqin Sun,Chenyang Lyu,Xiangyu Kong,Shiwan Zhao,Jiaming Zhou,Hui Wang,Aobo Kong,Jinghua Zhao,Longyue Wang,Weihua Luo,Kaifu Zhang,Yong Qin*

Main category: cs.SD

TL;DR: 本文提出了一种基于强化学习的情感感知策略 MECap-R1，在情感字幕生成中显示出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的离散分类方法难以充分表示人类语音中情感内容的复杂性，因此使用自然语言描述语音情感成为了一个新的研究方向。

Method: 提出了一种基于强化学习的情感感知策略 MECap-R1，并采用情感感知奖励的 Group Relative Policy Optimization (Emo-GRPO) 方法。

Result: 在 EmotionTalk 数据集上的实验证明，MECap-R1 在生成情感描述方面表现出色，提升了准确性和多样性。

Conclusion: MECap-R1 在生成情感描述方面表现良好，显著提升了准确性和多样性。

Abstract: Speech Emotion Captioning (SEC) has emerged as a notable research direction.
The inherent complexity of emotional content in human speech makes it
challenging for traditional discrete classification methods to provide an
adequate representation. Consequently, utilizing natural language to describe
speech emotions presents a novel avenue for more effectively capturing and
expressing affect. In this paper, we propose MECap-R1, a pioneering
emotion-aware policy with reinforcement learning for multimodal emotion
captioning. By employing Group Relative Policy Optimization with emotion-aware
reward (Emo-GRPO), the framework precisely captures the emotion and semantic
features, thereby addressing the shortcomings of rigid rules in handling the
dynamic and flexible nature of captions. Experimental results on the
EmotionTalk dataset demonstrate that MECap-R1 performs well in generating
emotion descriptions and achieves substantial gains in both accuracy and
diversity.

</details>


### [195] [Pay More Attention To Audio: Mitigating Imbalance of Cross-Modal Attention in Large Audio Language Models](https://arxiv.org/abs/2509.18816)
*Junyu Wang,Ziyang Ma,Zhengding Luo,Tianrui Wang,Meng Ge,Xiaobao Wang,Longbiao Wang*

Main category: cs.SD

TL;DR: 为了解决大规模音频-语言模型中的音频-文本注意力不平衡问题，提出了一种名为MATA的训练无关方法，该方法有效提升了模型在音频推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 大多数LALM在多模态融合过程中表现出音频-文本注意力不平衡，优先考虑文本信息，影响音频推理任务的性能。

Method: MATA是一种训练无关的方法，动态地增加LALM对音频tokens的关注，主要通过在自注意力机制中的最后一个中间层token进行干预。

Result: MATA方法在MMAU和MMAR基准测试中的实验结果表明，MATA能够带来一致的性能提升，尤其是在MMAR上使得开源模型首次超过了专有的Gemini 2.0 Flash。

Conclusion: 提出的MATA方法有效缓解了LALM在音频-文本注意力不平衡问题，提高了多模态模型的音频处理能力。

Abstract: Large Audio-Language Models (LALMs) often suffer from audio-textual attention
imbalance, prioritizing text over acoustic information, particularly in the
multi-modal fusion layers of the Transformer architecture. This bias hinders
their ability to fully utilize acoustic cues, causing suboptimal performance on
audio reasoning tasks. To mitigate this, we propose \textbf{MATA}, a novel
training-free method that dynamically pushes LALMs to pay \textbf{M}ore
\textbf{A}ttention \textbf{T}o \textbf{A}udio tokens within the self-attention
mechanism. Specifically, MATA intervenes post raw attention scoring, targeting
only the last token in intermediate layers without introducing additional
parameters or computational overhead. Experiments on the MMAU and MMAR
benchmarks confirm MATA's effectiveness, with consistent performance gains.
Notably, on MMAR, MATA enables an open-source model to surpass the proprietary
Gemini 2.0 Flash for the first time. Our work provides an efficient solution to
mitigate attention bias and opens a new research direction for enhancing the
audio-processing capabilities of multi-modal models.

</details>


### [196] [Finding My Voice: Generative Reconstruction of Disordered Speech for Automated Clinical Evaluation](https://arxiv.org/abs/2509.19231)
*Karen Rosero,Eunjung Yeo,David R. Mortensen,Cortney Van't Slot,Rami R. Hallac,Carlos Busso*

Main category: cs.SD

TL;DR: ChiReSSD框架通过风格化的TTS重建，不仅改善儿童SSD的发音准确性，还能有效保留其声音特征，且在不同临床人群中表现出良好的适应性。


<details>
  <summary>Details</summary>
Motivation: 针对具有语音音素障碍（SSD）的儿童开发框架，以改善其发音准确性，同时保护其身份特征。

Method: 通过风格化的文本到语音（TTS）重建方法，适应儿童的发音特点，尤其关注音高和韵律。

Result: 在STAR数据集上，ChiReSSD在词汇准确性和发言人身份保留方面取得了显著改进，并在TORGO数据集上展示了对成人言语障碍患者的有效泛化能力。

Conclusion: ChiReSSD是一种能够在保留儿童发言人身份的同时压制错误发音的语音重建框架，显示出在多种临床人群中提供身份保留语音的能力。

Abstract: We present ChiReSSD, a speech reconstruction framework that preserves
children speaker's identity while suppressing mispronunciations. Unlike prior
approaches trained on healthy adult speech, ChiReSSD adapts to the voices of
children with speech sound disorders (SSD), with particular emphasis on pitch
and prosody. We evaluate our method on the STAR dataset and report substantial
improvements in lexical accuracy and speaker identity preservation.
Furthermore, we automatically predict the phonetic content in the original and
reconstructed pairs, where the proportion of corrected consonants is comparable
to the percentage of correct consonants (PCC), a clinical speech assessment
metric. Our experiments show Pearson correlation of 0.63 between automatic and
human expert annotations, highlighting the potential to reduce the manual
transcription burden. In addition, experiments on the TORGO dataset demonstrate
effective generalization for reconstructing adult dysarthric speech. Our
results indicate that disentangled, style-based TTS reconstruction can provide
identity-preserving speech across diverse clinical populations.

</details>

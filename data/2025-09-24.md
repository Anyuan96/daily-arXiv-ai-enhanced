<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 123]
- [cs.CL](#cs.CL) [Total: 60]
- [cs.SD](#cs.SD) [Total: 13]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [PolypSeg-GradCAM: Towards Explainable Computer-Aided Gastrointestinal Disease Detection Using U-Net Based Segmentation and Grad-CAM Visualization on the Kvasir Dataset](https://arxiv.org/abs/2509.18159)
*Akwasi Asare,Ulas Bagci*

Main category: cs.CV

TL;DR: 本研究介绍了一种可解释的深度学习框架PolypSeg-GradCAM，能有效分割结肠镜下的息肉，提升了AI辅助结肠镜的可解释性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 降低结肠癌的发生和发展风险，尤其是通过早期和准确地分割结肠镜下的息肉。

Method: 本研究采用了一种可解释的深度学习框架PolypSeg-GradCAM，结合了U-Net架构和梯度加权类激活映射（Grad-CAM），用于透明的息肉分割。

Result: 在Kvasir-SEG数据集上进行训练和评估，模型在测试集上实现了0.9257的平均交并比(IoU)，训练和验证集上的Dice系数也达到0.96以上，表明了强大的分割性能。

Conclusion: PolypSeg-GradCAM通过高精度的分割和良好的可解释性，推动了AI辅助结肠镜检查的发展，有助于早期预防结直肠癌。

Abstract: Colorectal cancer (CRC) remains one of the leading causes of cancer-related
morbidity and mortality worldwide, with gastrointestinal (GI) polyps serving as
critical precursors according to the World Health Organization (WHO). Early and
accurate segmentation of polyps during colonoscopy is essential for reducing
CRC progression, yet manual delineation is labor-intensive and prone to
observer variability. Deep learning methods have demonstrated strong potential
for automated polyp analysis, but their limited interpretability remains a
barrier to clinical adoption. In this study, we present PolypSeg-GradCAM, an
explainable deep learning framework that integrates the U-Net architecture with
Gradient-weighted Class Activation Mapping (Grad-CAM) for transparent polyp
segmentation. The model was trained and evaluated on the Kvasir-SEG dataset of
1000 annotated endoscopic images. Experimental results demonstrate robust
segmentation performance, achieving a mean Intersection over Union (IoU) of
0.9257 on the test set and consistently high Dice coefficients (F-score > 0.96)
on training and validation sets. Grad-CAM visualizations further confirmed that
predictions were guided by clinically relevant regions, enhancing transparency
and trust in the model's decisions. By coupling high segmentation accuracy with
interpretability, PolypSeg-GradCAM represents a step toward reliable,
trustworthy AI-assisted colonoscopy and improved early colorectal cancer
prevention.

</details>


### [2] [PerceptronCARE: A Deep Learning-Based Intelligent Teleopthalmology Application for Diabetic Retinopathy Diagnosis](https://arxiv.org/abs/2509.18160)
*Akwasi Asare,Isaac Baffour Senkyire,Emmanuel Freeman,Simon Hilary Ayinedenaba Aluze-Ele,Kelvin Kwao*

Main category: cs.CV

TL;DR: 本研究提出了PerceptronCARE，一个基于深度学习的自动化糖尿病视网膜病变检测应用，能够提高筛查的准确性和效率，尤其适合资源有限的地区。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变是成年人视力丧失的主要原因，特别是在服务不足的地区，因此迫切需要有效的检测和筛查方法。

Method: 使用多种卷积神经网络（如ResNet-18、EfficientNet-B0和SqueezeNet）开发和评估自动化糖尿病视网膜病变检测的深度学习应用。

Result: 最终模型能够以85.4%的准确率分类疾病严重程度，实现临床和远程医疗环境中的实时筛查。

Conclusion: PerceptronCARE展现了AI驱动的远程医疗解决方案在糖尿病视网膜病变筛查中的潜力，尤其适用于偏远和资源有限的地区。

Abstract: Diabetic retinopathy is a leading cause of vision loss among adults and a
major global health challenge, particularly in underserved regions. This study
presents PerceptronCARE, a deep learning-based teleophthalmology application
designed for automated diabetic retinopathy detection using retinal images. The
system was developed and evaluated using multiple convolutional neural
networks, including ResNet-18, EfficientNet-B0, and SqueezeNet, to determine
the optimal balance between accuracy and computational efficiency. The final
model classifies disease severity with an accuracy of 85.4%, enabling real-time
screening in clinical and telemedicine settings. PerceptronCARE integrates
cloud-based scalability, secure patient data management, and a multi-user
framework, facilitating early diagnosis, improving doctor-patient interactions,
and reducing healthcare costs. This study highlights the potential of AI-driven
telemedicine solutions in expanding access to diabetic retinopathy screening,
particularly in remote and resource-constrained environments.

</details>


### [3] [Self Identity Mapping](https://arxiv.org/abs/2509.18165)
*Xiuding Cai,Yaoyao Zhu,Linjie Fu,Dong Miao,Yu Yao*

Main category: cs.CV

TL;DR: 本文提出了自我身份映射（SIM）正则化框架，能够在多种任务中提高表示学习效果，并且能够与其他正则化方法结合使用。


<details>
  <summary>Details</summary>
Motivation: 为了提高深度学习模型的泛化能力并减轻过拟合，探索一种可靠有效的正则化方法。

Method: 提出了一种自我身份映射（SIM）机制，以及通过特征采样和投影方法降低计算复杂度的实现形式 $ho$SIM。

Result: 在图像分类、少样本学习和领域泛化等任务上，$ho$SIM 显示出对基线方法的一致改进，并有效保持语义信息。

Conclusion: $ho$SIM 是一种有效的正则化框架，能够在多种任务中增强表示学习，并且与现有方法兼容。

Abstract: Regularization is essential in deep learning to enhance generalization and
mitigate overfitting. However, conventional techniques often rely on
heuristics, making them less reliable or effective across diverse settings. We
propose Self Identity Mapping (SIM), a simple yet effective, data-intrinsic
regularization framework that leverages an inverse mapping mechanism to enhance
representation learning. By reconstructing the input from its transformed
output, SIM reduces information loss during forward propagation and facilitates
smoother gradient flow. To address computational inefficiencies, We instantiate
SIM as $ \rho\text{SIM} $ by incorporating patch-level feature sampling and
projection-based method to reconstruct latent features, effectively lowering
complexity. As a model-agnostic, task-agnostic regularizer, SIM can be
seamlessly integrated as a plug-and-play module, making it applicable to
different network architectures and tasks.
  We extensively evaluate $\rho\text{SIM}$ across three tasks: image
classification, few-shot prompt learning, and domain generalization.
Experimental results show consistent improvements over baseline methods,
highlighting $\rho\text{SIM}$'s ability to enhance representation learning
across various tasks. We also demonstrate that $\rho\text{SIM}$ is orthogonal
to existing regularization methods, boosting their effectiveness. Moreover, our
results confirm that $\rho\text{SIM}$ effectively preserves semantic
information and enhances performance in dense-to-dense tasks, such as semantic
segmentation and image translation, as well as in non-visual domains including
audio classification and time series anomaly detection. The code is publicly
available at https://github.com/XiudingCai/SIM-pytorch.

</details>


### [4] [MAGIA: Sensing Per-Image Signals from Single-Round Averaged Gradients for Label-Inference-Free Gradient Inversion](https://arxiv.org/abs/2509.18170)
*Zhanting Zhou,Jinbo Wang,Zeqin Wu,Fengli Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为 MAGIA 的新方法，用于在单轮平均梯度环境中进行高效的图像重构，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 研究在单轮平均梯度 SAG 机制下的梯度反演问题，并探索如何在不需要标签推理的情况下感知潜在的每张图像信号。

Method: 提出了一种基于动量的自适应校正方法，结合了组合重标定和全批次与子集损失的动量混合。

Result: 通过广泛的实验，验证了 MAGIA 能够以紧凑的计算开销在大批量情况下实现高保真度的图像重构。

Conclusion: MAGIA 方法在大批量场景下显著优于现有先进方法，能够实现高保真度的多图像重构。

Abstract: We study gradient inversion in the challenging single round averaged gradient
SAG regime where per sample cues are entangled within a single batch mean
gradient. We introduce MAGIA a momentum based adaptive correction on gradient
inversion attack a novel label inference free framework that senses latent per
image signals by probing random data subsets. MAGIA objective integrates two
core innovations 1 a closed form combinatorial rescaling that creates a
provably tighter optimization bound and 2 a momentum based mixing of whole
batch and subset losses to ensure reconstruction robustness. Extensive
experiments demonstrate that MAGIA significantly outperforms advanced methods
achieving high fidelity multi image reconstruction in large batch scenarios
where prior works fail. This is all accomplished with a computational footprint
comparable to standard solvers and without requiring any auxiliary information.

</details>


### [5] [Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR](https://arxiv.org/abs/2509.18174)
*Khalil Hennara,Muhammad Hreden,Mohamed Motasim Hamed,Ahmad Bastati,Zeina Aldallal,Sara Chrouf,Safwan AlModhayan*

Main category: cs.CV

TL;DR: 本研究提出了Baseer，一个为阿拉伯文档OCR专门调整的视觉语言模型，表现优异，达到了新的领域最佳结果。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯文档OCR由于其书写方式、字体多样性和右至左书写方向而面临挑战，因此需要专门的模型来提高性能。

Method: 使用解码器仅的微调策略，对预训练的多模态大型语言模型进行调整，并通过大型数据集进行训练。

Result: Baseer在方法上实现了0.25的错误率，显示出针对阿拉伯文档OCR的领域特定适应的优势。

Conclusion: Baseer模型在阿拉伯文档OCR领域创下新纪录，显著超越了现有的开源和商业解决方案。

Abstract: Arabic document OCR remains a challenging task due to the language's cursive
script, diverse fonts, diacritics, and right-to-left orientation. While modern
Multimodal Large Language Models (MLLMs) have advanced document understanding
for high-resource languages, their performance on Arabic remains limited. In
this work, we introduce Baseer, a vision-language model fine- tuned
specifically for Arabic document OCR. Leveraging a large-scale dataset
combining synthetic and real-world documents, Baseer is trained using a
decoder-only fine-tuning strategy to adapt a pre-trained MLLM while preserving
general visual features. We also present Misraj-DocOCR, a high-quality,
expert-verified benchmark designed for rigorous evaluation of Arabic OCR
systems. Our experiments show that Baseer significantly outperforms existing
open-source and commercial solutions, achieving a WER of 0.25 and establishing
a new state-of-the-art in the domain of Arabic document OCR. Our results
highlight the benefits of domain-specific adaptation of general-purpose MLLMs
and establish a strong baseline for high-accuracy OCR on morphologically rich
languages like Arabic.

</details>


### [6] [A Deep Learning Approach for Spatio-Temporal Forecasting of InSAR Ground Deformation in Eastern Ireland](https://arxiv.org/abs/2509.18176)
*Wendong Yao,Saeed Azadnejad,Binhua Huang,Shane Donohue,Soumyabrata Dev*

Main category: cs.CV

TL;DR: 本论文提出了一种新颖的深度学习框架，通过生成密集时空张量来预测地面变形，利用CNN-LSTM模型提高预测准确性，表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 监测地面位移对城市基础设施的稳定性和减轻地质灾害至关重要，但从稀疏的干涉合成孔径雷达（InSAR）时间序列数据预测未来变形仍然是一个重大挑战。

Method: 本文提出了一种混合卷积神经网络和长短期记忆网络（CNN-LSTM）模型，该模型专门设计用于从生成的数据张量中同时学习空间模式和时间依赖性。

Result: 模型在使用东爱尔兰的Sentinel-1数据时，与强大的机器学习基线（如Light Gradient Boosting Machine和LASSO回归）进行比较，其表现显著更准确且空间一致性更强，从而建立了该任务的新性能基准。

Conclusion: 本研究证明了时空深度学习在高分辨率变形预测方面的有效性和潜力。

Abstract: Monitoring ground displacement is crucial for urban infrastructure stability
and mitigating geological hazards. However, forecasting future deformation from
sparse Interferometric Synthetic Aperture Radar (InSAR) time-series data
remains a significant challenge. This paper introduces a novel deep learning
framework that transforms these sparse point measurements into a dense
spatio-temporal tensor. This methodological shift allows, for the first time,
the direct application of advanced computer vision architectures to this
forecasting problem. We design and implement a hybrid Convolutional Neural
Network and Long-Short Term Memory (CNN-LSTM) model, specifically engineered to
simultaneously learn spatial patterns and temporal dependencies from the
generated data tensor. The model's performance is benchmarked against powerful
machine learning baselines, Light Gradient Boosting Machine and LASSO
regression, using Sentinel-1 data from eastern Ireland. Results demonstrate
that the proposed architecture provides significantly more accurate and
spatially coherent forecasts, establishing a new performance benchmark for this
task. Furthermore, an interpretability analysis reveals that baseline models
often default to simplistic persistence patterns, highlighting the necessity of
our integrated spatio-temporal approach to capture the complex dynamics of
ground deformation. Our findings confirm the efficacy and potential of
spatio-temporal deep learning for high-resolution deformation forecasting.

</details>


### [7] [A Framework for Generating Artificial Datasets to Validate Absolute and Relative Position Concepts](https://arxiv.org/abs/2509.18177)
*George Corrêa de Araújo,Helena de Almeida Maia,Helio Pedrini*

Main category: cs.CV

TL;DR: Scrapbook框架是一个新方法，用以生成数据集评估AI模型对基本概念的理解，发现模型在位置理解及复杂问题应答上有待改进。


<details>
  <summary>Details</summary>
Motivation: 旨在验证AI模型对基本概念的理解，尤其是在处理更复杂任务之前。

Method: 提出了Scrapbook框架，通过生成关于人工智能基本概念的大量问题的数据集。

Result: 实验结果显示，现有模型在物体识别上表现较好，但在理解位置和处理附加约束的问题上存在困难，特别是在MobileVLM-V2模型中表现明显。

Conclusion: Scrapbook框架能够有效生成多样化数据集，从而系统评估和提升AI模型的性能。

Abstract: In this paper, we present the Scrapbook framework, a novel methodology
designed to generate extensive datasets for probing the learned concepts of
artificial intelligence (AI) models. The framework focuses on fundamental
concepts such as object recognition, absolute and relative positions, and
attribute identification. By generating datasets with a large number of
questions about individual concepts and a wide linguistic variation, the
Scrapbook framework aims to validate the model's understanding of these basic
elements before tackling more complex tasks. Our experimental findings reveal
that, while contemporary models demonstrate proficiency in recognizing and
enumerating objects, they encounter challenges in comprehending positional
information and addressing inquiries with additional constraints. Specifically,
the MobileVLM-V2 model showed significant answer disagreements and plausible
wrong answers, while other models exhibited a bias toward affirmative answers
and struggled with questions involving geometric shapes and positional
information, indicating areas for improvement in understanding and consistency.
The proposed framework offers a valuable instrument for generating diverse and
comprehensive datasets, which can be utilized to systematically assess and
enhance the performance of AI models.

</details>


### [8] [The Describe-Then-Generate Bottleneck: How VLM Descriptions Alter Image Generation Outcomes](https://arxiv.org/abs/2509.18179)
*Sai Varun Kodathala,Rakesh Vunnam*

Main category: cs.CV

TL;DR: 本文提供了对describe-then-generate瓶颈的实证分析，揭示了视觉内容通过文本中介过程中的信息损失，显示出多模态系统中的限制。


<details>
  <summary>Details</summary>
Motivation: 随着多模态AI系统在创意工作流程中的逐渐整合，理解视觉-语言-视觉管道中的信息损失变得尤为重要，以便评估系统的局限性。

Method: 通过describe-then-generate管道生成150对图像，并应用现有的度量标准（LPIPS、SSIM和颜色距离）来测量信息在感知、结构和色彩维度上的保留。

Result: 评估表明99.3%的样本存在显著的感知退化，91.5%的样本显示出明显的结构信息损失。

Conclusion: describe-then-generate瓶颈在当前多模态系统中为一个可测量且一致的限制，99.3%的样本表现出显著的感知退化，91.5%显示出重要的结构信息损失。

Abstract: With the increasing integration of multimodal AI systems in creative
workflows, understanding information loss in vision-language-vision pipelines
has become important for evaluating system limitations. However, the
degradation that occurs when visual content passes through textual
intermediation remains poorly quantified. In this work, we provide empirical
analysis of the describe-then-generate bottleneck, where natural language
serves as an intermediate representation for visual information. We generated
150 image pairs through the describe-then-generate pipeline and applied
existing metrics (LPIPS, SSIM, and color distance) to measure information
preservation across perceptual, structural, and chromatic dimensions. Our
evaluation reveals that 99.3% of samples exhibit substantial perceptual
degradation and 91.5% demonstrate significant structural information loss,
providing empirical evidence that the describe-then-generate bottleneck
represents a measurable and consistent limitation in contemporary multimodal
systems.

</details>


### [9] [AI-Derived Structural Building Intelligence for Urban Resilience: An Application in Saint Vincent and the Grenadines](https://arxiv.org/abs/2509.18182)
*Isabelle Tingzon,Yoji Toriumi,Caroline Gevaert*

Main category: cs.CV

TL;DR: 本研究通过AI技术自动推断小岛屿发展中国家的建筑屋顶属性，为提高城市抗灾能力提供了新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 在气候脆弱地区的小岛屿发展中国家，详细的建筑结构信息通常缺乏，这对城市抗灾规划和风险减少至关重要。

Method: 利用高分辨率卫星图像，通过AI驱动的工作流程自动推断屋顶属性，并比较不同模型的表现。

Result: 最佳模型在屋顶坡度和屋顶材料分类上分别达到了F1分数0.88和0.83。

Conclusion: 本研究为小岛屿发展中国家提供了利用人工智能和地球观测数据进行城市治理的能力，以提高抗灾能力和灾害风险管理。

Abstract: Detailed structural building information is used to estimate potential damage
from hazard events like cyclones, floods, and landslides, making them critical
for urban resilience planning and disaster risk reduction. However, such
information is often unavailable in many small island developing states (SIDS)
in climate-vulnerable regions like the Caribbean. To address this data gap, we
present an AI-driven workflow to automatically infer rooftop attributes from
high-resolution satellite imagery, with Saint Vincent and the Grenadines as our
case study. Here, we compare the utility of geospatial foundation models
combined with shallow classifiers against fine-tuned deep learning models for
rooftop classification. Furthermore, we assess the impact of incorporating
additional training data from neighboring SIDS to improve model performance.
Our best models achieve F1 scores of 0.88 and 0.83 for roof pitch and roof
material classification, respectively. Combined with local capacity building,
our work aims to provide SIDS with novel capabilities to harness AI and Earth
Observation (EO) data to enable more efficient, evidence-based urban
governance.

</details>


### [10] [VLA-LPAF: Lightweight Perspective-Adaptive Fusion for Vision-Language-Action to Enable More Unconstrained Robotic Manipulation](https://arxiv.org/abs/2509.18183)
*Jinyue Bian,Zhaoxing Zhang,Zhengyu Liang,Shiwei Zheng,Shengtao Zhang,Rong Shen,Chen Yang,Anzhou Hou*

Main category: cs.CV

TL;DR: 针对VLA模型的视角异质性问题，提出了VLA-LPAF模块，通过2D数据微调提高了多任务成功率。


<details>
  <summary>Details</summary>
Motivation: 传统的VLA模型在处理不同环境中的视角异质性时效果有限，导致模型的泛化能力受限。

Method: 提出了轻量级模块VLA-LPAF，通过使用2D数据进行微调，并在潜在空间中融合多个视角的观察。

Result: RoboFlamingo-LPAF在CALVIN上平均提高8%的任务成功率，LIBERO上提高15%，在定制的仿真基准上提高30%。

Conclusion: RoboFlamingo-LPAF模型在各类任务中的成功率显著提高，展示了其视角适应能力。

Abstract: The Visual-Language-Action (VLA) models can follow text instructions
according to visual observations of the surrounding environment. This ability
to map multimodal inputs to actions is derived from the training of the VLA
model on extensive standard demonstrations. These visual observations captured
by third-personal global and in-wrist local cameras are inevitably varied in
number and perspective across different environments, resulting in significant
differences in the visual features. This perspective heterogeneity constrains
the generality of VLA models. In light of this, we first propose the
lightweight module VLA-LPAF to foster the perspective adaptivity of VLA models
using only 2D data. VLA-LPAF is finetuned using images from a single view and
fuses other multiview observations in the latent space, which effectively and
efficiently bridge the gap caused by perspective inconsistency. We instantiate
our VLA-LPAF framework with the VLA model RoboFlamingo to construct
RoboFlamingo-LPAF. Experiments show that RoboFlamingo-LPAF averagely achieves
around 8% task success rate improvement on CALVIN, 15% on LIBERO, and 30% on a
customized simulation benchmark. We also demonstrate the developed viewadaptive
characteristics of the proposed RoboFlamingo-LPAF through real-world tasks.

</details>


### [11] [URNet: Uncertainty-aware Refinement Network for Event-based Stereo Depth Estimation](https://arxiv.org/abs/2509.18184)
*Yifeng Cheng,Alois Knoll,Hu Cao*

Main category: cs.CV

TL;DR: URNet是一种用于事件基础立体深度估计的不确定性感知细化网络，显著提升了预测可靠性，实验结果显示其优于最先进方法。


<details>
  <summary>Details</summary>
Motivation: 事件相机提供高时间分辨率、高动态范围和低延迟，能够提升相较于传统帧基摄像机的性能。

Method: 引入不确定性感知的细化网络URNet，包括局部-全球细化模块和基于KL散度的不确定性建模方法。

Result: URNet在DSEC数据集上的实验表明，其在定性和定量评估上均优于现有最先进方法。

Conclusion: URNet在事件基础立体深度估计中优于现有的最先进方法，提升了预测的可靠性。

Abstract: Event cameras provide high temporal resolution, high dynamic range, and low
latency, offering significant advantages over conventional frame-based cameras.
In this work, we introduce an uncertainty-aware refinement network called URNet
for event-based stereo depth estimation. Our approach features a local-global
refinement module that effectively captures fine-grained local details and
long-range global context. Additionally, we introduce a Kullback-Leibler (KL)
divergence-based uncertainty modeling method to enhance prediction reliability.
Extensive experiments on the DSEC dataset demonstrate that URNet consistently
outperforms state-of-the-art (SOTA) methods in both qualitative and
quantitative evaluations.

</details>


### [12] [Visionerves: Automatic and Reproducible Hybrid AI for Peripheral Nervous System Recognition Applied to Endometriosis Cases](https://arxiv.org/abs/2509.18185)
*Giammarco La Barbera,Enzo Bonnot,Thomas Isla,Juan Pablo de la Plata,Joy-Rose Dunoyer de Segonzac,Jennifer Attali,Cécile Lozach,Alexandre Bellucci,Louis Marcellin,Laure Fournier,Sabine Sarnacki,Pietro Gori,Isabelle Bloch*

Main category: cs.CV

TL;DR: Visionerves是一种新的AI框架，用于提高内异症患者外周神经的成像和识别，展示了较传统技术的显著优势。


<details>
  <summary>Details</summary>
Motivation: 在内异症患者中，外周神经的成像仍然是一项挑战，而现有的追踪方法效果有限。

Method: 引入了一种新的混合AI框架，该框架通过深度学习模型进行解剖结构的自动分割，并利用符号空间推理进行神经追踪和识别。

Result: 在10名确认或疑似内异症女性中应用Visionerves，Dice得分提升了高达25%，空间误差减少到5毫米以内。

Conclusion: Visionerves显著提升了外周神经的识别能力，并为与神经相关的疾病提供非侵入性诊断途径。

Abstract: Endometriosis often leads to chronic pelvic pain and possible nerve
involvement, yet imaging the peripheral nerves remains a challenge. We
introduce Visionerves, a novel hybrid AI framework for peripheral nervous
system recognition from multi-gradient DWI and morphological MRI data. Unlike
conventional tractography, Visionerves encodes anatomical knowledge through
fuzzy spatial relationships, removing the need for selection of manual ROIs.
The pipeline comprises two phases: (A) automatic segmentation of anatomical
structures using a deep learning model, and (B) tractography and nerve
recognition by symbolic spatial reasoning. Applied to the lumbosacral plexus in
10 women with (confirmed or suspected) endometriosis, Visionerves demonstrated
substantial improvements over standard tractography, with Dice score
improvements of up to 25% and spatial errors reduced to less than 5 mm. This
automatic and reproducible approach enables detailed nerve analysis and paves
the way for non-invasive diagnosis of endometriosis-related neuropathy, as well
as other conditions with nerve involvement.

</details>


### [13] [V-SenseDrive: A Privacy-Preserving Road Video and In-Vehicle Sensor Fusion Framework for Road Safety & Driver Behaviour Modelling](https://arxiv.org/abs/2509.18187)
*Muhammad Naveed,Nazia Perwaiz,Sidra Sultana,Mohaira Ahmad,Muhammad Moazam Fraz*

Main category: cs.CV

TL;DR: V-SenseDrive是一个隐私保护的多模态驾驶行为数据集，专为巴基斯坦驾驶环境设计，提供了正常、激进和危险驾驶行为的记录，支撑未来的交通安全和辅助系统研究。


<details>
  <summary>Details</summary>
Motivation: 在多种道路条件和混合交通流下，检测不安全驾驶行为是提升道路安全、支持保险和车队管理决策的基础。

Method: 利用自定义安卓应用收集智能手机基于惯性和 GPS 传感器数据与同步的路面对视频，记录正常、激进和危险的三种驾驶行为。

Result: V-SenseDrive是第一个完全在巴基斯坦驾驶环境中收集的隐私保护多模态驾驶行为数据集，包含了高频加速度计、陀螺仪和GPS流以及连续的视频。

Conclusion: V-SenseDrive 数据集填补了在巴基斯坦驾驶环境中驾驶行为数据的空白，为未来的驾驶行为分类、交通安全分析和高级驾驶辅助系统开发提供了基础。

Abstract: Road traffic accidents remain a major public health challenge, particularly
in countries with heterogeneous road conditions, mixed traffic flow, and
variable driving discipline, such as Pakistan. Reliable detection of unsafe
driving behaviours is a prerequisite for improving road safety, enabling
advanced driver assistance systems (ADAS), and supporting data driven decisions
in insurance and fleet management. Most of existing datasets originate from the
developed countries with limited representation of the behavioural diversity
observed in emerging economies and the driver's face recording voilates the
privacy preservation. We present V-SenseDrive, the first privacy-preserving
multimodal driver behaviour dataset collected entirely within the Pakistani
driving environment. V-SenseDrive combines smartphone based inertial and GPS
sensor data with synchronized road facing video to record three target driving
behaviours (normal, aggressive, and risky) on multiple types of roads,
including urban arterials, secondary roads, and motorways. Data was gathered
using a custom Android application designed to capture high frequency
accelerometer, gyroscope, and GPS streams alongside continuous video, with all
sources precisely time aligned to enable multimodal analysis. The focus of this
work is on the data acquisition process, covering participant selection,
driving scenarios, environmental considerations, and sensor video
synchronization techniques. The dataset is structured into raw, processed, and
semantic layers, ensuring adaptability for future research in driver behaviour
classification, traffic safety analysis, and ADAS development. By representing
real world driving in Pakistan, V-SenseDrive fills a critical gap in the global
landscape of driver behaviour datasets and lays the groundwork for context
aware intelligent transportation solutions.

</details>


### [14] [Qianfan-VL: Domain-Enhanced Universal Vision-Language Models](https://arxiv.org/abs/2509.18189)
*Daxiang Dong,Mingming Zheng,Dong Xu,Bairong Zhuang,Wenyu Zhang,Chunhua Luo,Haoran Wang,Zijian Zhao,Jie Li,Yuxuan Li,Hanjun Zhong,Mengyue Liu,Jieting Chen,Shupeng Li,Lun Tian,Yaping Feng,Xin Li,Donggang Jiang,Yong Chen,Yehua Xu,Duohao Qin,Chen Feng,Dan Wang,Henghua Zhang,Jingjing Ha,Jinhui He,Yanfeng Zhai,Chengxin Zheng,Jiayi Mao,Jiacheng Chen,Ruchang Yao,Ziye Yuan,Jianmin Wu,Guangjun Xie,Dou Shen*

Main category: cs.CV

TL;DR: Qianfan-VL是一个多模态大语言模型系列，通过领域增强技术实现了SOTA性能，对多种企业场景具有适用性。


<details>
  <summary>Details</summary>
Motivation: 在保持强大通用性能的同时，增强领域特定能力。

Method: 采用多阶段渐进训练和高精度数据合成管道。

Result: Qianfan-VL在多个基准测试中表现出色，尤其是在OCR和文档理解领域。

Conclusion: Qianfan-VL在跨模态任务中实现了SOTA性能，并建立了有效的领域增强模型开发方法。

Abstract: We present Qianfan-VL, a series of multimodal large language models ranging
from 3B to 70B parameters, achieving state-of-the-art performance through
innovative domain enhancement techniques. Our approach employs multi-stage
progressive training and high-precision data synthesis pipelines, which prove
to be critical technologies for enhancing domain-specific capabilities while
maintaining strong general performance. Qianfan-VL achieves comparable results
to leading open-source models on general benchmarks, with state-of-the-art
performance on benchmarks such as CCBench, SEEDBench IMG, ScienceQA, and
MMStar. The domain enhancement strategy delivers significant advantages in OCR
and document understanding, validated on both public benchmarks (OCRBench 873,
DocVQA 94.75%) and in-house evaluations. Notably, Qianfan-VL-8B and 70B
variants incorporate long chain-of-thought capabilities, demonstrating superior
performance on mathematical reasoning (MathVista 78.6%) and logical inference
tasks. All models are trained entirely on Baidu's Kunlun P800 chips, validating
the capability of large-scale AI infrastructure to train SOTA-level multimodal
models with over 90% scaling efficiency on 5000 chips for a single task. This
work establishes an effective methodology for developing domain-enhanced
multimodal models suitable for diverse enterprise deployment scenarios.

</details>


### [15] [HazeFlow: Revisit Haze Physical Model as ODE and Non-Homogeneous Haze Generation for Real-World Dehazing](https://arxiv.org/abs/2509.18190)
*Junseong Shin,Seungwoo Chung,Yunjeong Yang,Tae Hyun Kim*

Main category: cs.CV

TL;DR: HazeFlow是一种基于ODE的去雾框架，通过生成真实的雾霾模式，提升了去雾性能，处理复杂的真实世界场景。


<details>
  <summary>Details</summary>
Motivation: 目前深度学习方法在去雾任务中受限于缺乏配对的真实世界训练数据，而物理基础学习变得尤为重要。

Method: HazeFlow将大气散射模型重新表述为常微分方程（ODE），并通过学习最优ODE轨迹实现图像去雾。

Result: HazeFlow在多个真实世界的去雾基准数据集中展现了最先进的表现，改善了去雾效果并增强了适应性。

Conclusion: HazeFlow通过利用ODE框架和MCBM生成真实的雾霾模式，显著提升了图像去雾效果，并在多种基准数据集中表现出色。

Abstract: Dehazing involves removing haze or fog from images to restore clarity and
improve visibility by estimating atmospheric scattering effects. While deep
learning methods show promise, the lack of paired real-world training data and
the resulting domain gap hinder generalization to real-world scenarios. In this
context, physics-grounded learning becomes crucial; however, traditional
methods based on the Atmospheric Scattering Model (ASM) often fall short in
handling real-world complexities and diverse haze patterns. To solve this
problem, we propose HazeFlow, a novel ODE-based framework that reformulates ASM
as an ordinary differential equation (ODE). Inspired by Rectified Flow (RF),
HazeFlow learns an optimal ODE trajectory to map hazy images to clean ones,
enhancing real-world dehazing performance with only a single inference step.
Additionally, we introduce a non-homogeneous haze generation method using
Markov Chain Brownian Motion (MCBM) to address the scarcity of paired
real-world data. By simulating realistic haze patterns through MCBM, we enhance
the adaptability of HazeFlow to diverse real-world scenarios. Through extensive
experiments, we demonstrate that HazeFlow achieves state-of-the-art performance
across various real-world dehazing benchmark datasets.

</details>


### [16] [TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection](https://arxiv.org/abs/2509.18193)
*Omar H. Khater,Abdul Jabbar Siddiqui,Aiman El-Maleh,M. Shamim Hossain*

Main category: cs.CV

TL;DR: 本研究通过压缩EcoWeedNet模型，提升了其在精准农业中的应用性能和速度。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在农业中的部署受到边缘设备资源限制的挑战。

Method: 采用结构化通道剪枝、量化感知训练(QAT)和NVIDIA TensorRT加速，应用于Jetson Orin Nano。

Result: EcoWeedNet模型大小减少了68.5%，计算量减少至3.2 GFLOPs，推理速度达到184 FPS，且在CottonWeedDet12数据集上以39.5%的剪枝率超越YOLO11n和YOLO12n，达到83.7%的准确率和85.9%的mAP50。

Conclusion: 经过压缩处理的EcoWeedNet在精度农业中表现出色。

Abstract: Deploying deep learning models in agriculture is difficult because edge
devices have limited resources, but this work presents a compressed version of
EcoWeedNet using structured channel pruning, quantization-aware training (QAT),
and acceleration with NVIDIA's TensorRT on the Jetson Orin Nano. Despite the
challenges of pruning complex architectures with residual shortcuts, attention
mechanisms, concatenations, and CSP blocks, the model size was reduced by up to
68.5% and computations by 3.2 GFLOPs, while inference speed reached 184 FPS at
FP16, 28.7% faster than the baseline. On the CottonWeedDet12 dataset, the
pruned EcoWeedNet with a 39.5% pruning ratio outperformed YOLO11n and YOLO12n
(with only 20% pruning), achieving 83.7% precision, 77.5% recall, and 85.9%
mAP50, proving it to be both efficient and effective for precision agriculture.

</details>


### [17] [Learning Contrastive Multimodal Fusion with Improved Modality Dropout for Disease Detection and Prediction](https://arxiv.org/abs/2509.18284)
*Yi Gu,Kuniaki Saito,Jiaxin Ma*

Main category: cs.CV

TL;DR: 提出了一种新型多模态学习框架，通过增强模态丢弃和对比学习，解决模态失衡和缺失问题，展示了在临床数据集上的先进性能和广泛的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 针对医疗诊断中多模态数据利用的挑战，特别是模态不平衡和缺失问题，提出创新的方法。

Method: 提出了一种新的多模态学习框架，结合增强的模态丢弃和对比学习，使用可学习的模态标记以实现缺失感知的模态融合。

Result: 在大规模临床数据集上，我们的方法实现了最先进的性能，特别在仅有单一模态的情况下依然表现良好，并且成功集成了最近的CT基础模型。

Conclusion: 我们的框架在多模态学习中表现出色，特别是在仅有单一模态可用的情况下，展示出良好的适应性和效率，具有广泛的临床应用潜力。

Abstract: As medical diagnoses increasingly leverage multimodal data, machine learning
models are expected to effectively fuse heterogeneous information while
remaining robust to missing modalities. In this work, we propose a novel
multimodal learning framework that integrates enhanced modalities dropout and
contrastive learning to address real-world limitations such as modality
imbalance and missingness. Our approach introduces learnable modality tokens
for improving missingness-aware fusion of modalities and augments conventional
unimodal contrastive objectives with fused multimodal representations. We
validate our framework on large-scale clinical datasets for disease detection
and prediction tasks, encompassing both visual and tabular modalities.
Experimental results demonstrate that our method achieves state-of-the-art
performance, particularly in challenging and practical scenarios where only a
single modality is available. Furthermore, we show its adaptability through
successful integration with a recent CT foundation model. Our findings
highlight the effectiveness, efficiency, and generalizability of our approach
for multimodal learning, offering a scalable, low-cost solution with
significant potential for real-world clinical applications. The code is
available at https://github.com/omron-sinicx/medical-modality-dropout.

</details>


### [18] [Rethinking Pulmonary Embolism Segmentation: A Study of Current Approaches and Challenges with an Open Weight Model](https://arxiv.org/abs/2509.18308)
*Yixin Zhang,Ryan Chamberlain,Lawrance Ngo,Kevin Kramer,Maciej A. Mazurowski*

Main category: cs.CV

TL;DR: 研究分析了490个CTPA扫描的分割模型，发现3D U-Net表现最佳，CNN模型性能优于ViT，分类预训练可能影响分割结果，远端栓子分割困难。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在通过评估不同分割架构的性能，改善肺栓塞（PE）分割的准确性，推动该领域的研究进展。

Method: 系统评估了9种广泛使用的分割架构，分别来自CNN和视觉变换器（ViT）家族，使用490个CTPA扫描的密集注释内部数据集，在统一的测试框架下进行性能审计。

Result: 我们的研究表明，3D U-Net与ResNet编码器结合在PE分割中仍是高效架构，3D模型适合此任务，CNN模型在性能上普遍优于ViT，分类预训练可能对分割性能产生负面影响，不同模型在相同数据上表现一致，中心和大栓子可较好分割，而远端栓子因任务复杂性和高质量数据集稀缺仍具有挑战性。

Conclusion: 我们的最佳模型在分割任务中取得了平均Dice分数为0.7131，并且在60个内部测试扫描中检测到181个栓子，产生49个假阳性和28个假阴性，具有良好的泛化能力。

Abstract: In this study, we curated a densely annotated in-house dataset comprising 490
CTPA scans. Using this dataset, we systematically evaluated nine widely used
segmentation architectures from both the CNN and Vision Transformer (ViT)
families, initialized with either pretrained or random weights, under a unified
testing framework as a performance audit. Our study leads to several important
observations: (1) 3D U-Net with a ResNet encoder remains a highly effective
architecture for PE segmentation; (2) 3D models are particularly well-suited to
this task given the morphological characteristics of emboli; (3) CNN-based
models generally yield superior performance compared to their ViT-based
counterparts in PE segmentation; (4) classification-based pretraining, even on
large PE datasets, can adversely impact segmentation performance compared to
training from scratch, suggesting that PE classification and segmentation may
rely on different sets of discriminative features; (5) different model
architectures show a highly consistent pattern of segmentation performance when
trained on the same data; and (6) while central and large emboli can be
segmented with satisfactory accuracy, distal emboli remain challenging due to
both task complexity and the scarcity of high-quality datasets. Besides these
findings, our best-performing model achieves a mean Dice score of 0.7131 for
segmentation. It detects 181 emboli with 49 false positives and 28 false
negatives from 60 in-house testing scans. Its generalizability is further
validated on public datasets.

</details>


### [19] [Improving Handshape Representations for Sign Language Processing: A Graph Neural Network Approach](https://arxiv.org/abs/2509.18309)
*Alessa Carbo,Eric Nalisnick*

Main category: cs.CV

TL;DR: 手型在手语中起着重要的音位作用，但现有计算方法缺乏手型的明确建模。本文介绍了一种新型的图神经网络，通过解剖学信息图结构和对比学习来提高手型识别的准确性和分析能力，达成46%的准确率。


<details>
  <summary>Details</summary>
Motivation: 计算方法很少明确建模手型，这限制了识别准确性和语言分析。

Method: 采用新的图神经网络，将时间动态与静态手型配置分离，并结合解剖学信息的图结构和对比学习。

Result: 在37个手型类别中，我们的模型达到了46%的准确率，而基线方法仅达到25%。

Conclusion: 我们的模型在手型识别任务中取得了显著的效果，并建立了结构化手型识别的基准。

Abstract: Handshapes serve a fundamental phonological role in signed languages, with
American Sign Language employing approximately 50 distinct shapes.
However,computational approaches rarely model handshapes explicitly, limiting
both recognition accuracy and linguistic analysis.We introduce a novel graph
neural network that separates temporal dynamics from static handshape
configurations. Our approach combines anatomically-informed graph structures
with contrastive learning to address key challenges in handshape recognition,
including subtle interclass distinctions and temporal variations. We establish
the first benchmark for structured handshape recognition in signing sequences,
achieving 46% accuracy across 37 handshape classes (with baseline methods
achieving 25%).

</details>


### [20] [Influence of Classification Task and Distribution Shift Type on OOD Detection in Fetal Ultrasound](https://arxiv.org/abs/2509.18326)
*Chun Kit Wong,Anders N. Christensen,Cosmin I. Bercea,Julia A. Schnabel,Martin G. Tolsgaard,Aasa Feragen*

Main category: cs.CV

TL;DR: 本文探讨了分类任务对深度学习模型在胎儿超声图像中OOD检测的影响，并强调选择合适的任务与不确定性量化策略的重要性。


<details>
  <summary>Details</summary>
Motivation: 在胎儿超声图像中实现可靠的OOD检测，以应对异构图像特征和临床环境的挑战。

Method: 通过对四个分类任务中的八种不确定性量化方法进行实验。

Result: OOD检测性能在不同分类任务中显著变化，最佳任务依赖于定义的ID-OOD标准。

Conclusion: 选择与特定下游应用相符合的分类任务和不确定性策略，对于医疗图像分析中的OOD检测非常重要。

Abstract: Reliable out-of-distribution (OOD) detection is important for safe deployment
of deep learning models in fetal ultrasound amidst heterogeneous image
characteristics and clinical settings. OOD detection relies on estimating a
classification model's uncertainty, which should increase for OOD samples.
While existing research has largely focused on uncertainty quantification
methods, this work investigates the impact of the classification task itself.
Through experiments with eight uncertainty quantification methods across four
classification tasks, we demonstrate that OOD detection performance
significantly varies with the task, and that the best task depends on the
defined ID-OOD criteria; specifically, whether the OOD sample is due to: i) an
image characteristic shift or ii) an anatomical feature shift. Furthermore, we
reveal that superior OOD detection does not guarantee optimal abstained
prediction, underscoring the necessity to align task selection and uncertainty
strategies with the specific downstream application in medical image analysis.

</details>


### [21] [OrthoLoC: UAV 6-DoF Localization and Calibration Using Orthographic Geodata](https://arxiv.org/abs/2509.18350)
*Oussema Dhaouadi,Riccardo Marin,Johannes Meier,Jacques Kaiser,Daniel Cremers*

Main category: cs.CV

TL;DR: 该论文介绍了OrthoLoC数据集和AdHoP技术，旨在通过分析无人机图像和地理数据之间的关系，提高在有限资源下的视觉定位精度。


<details>
  <summary>Details</summary>
Motivation: 在无人机图像定位的有用性和现有方法的局限性之间填补空白，尤其是在不依赖于高资源环境（如GPS）的情况下。

Method: 创建一个包含16425个来自德国和美国的无人机图像的多模态大规模数据集，并引入配对结构以支持公平基准测试。同时开发了一种名为AdHoP的改进技术。

Result: 该数据集展示了无人机图像与地理空间数据之间的领域转移对定位准确性的影响，且AdHoP显著提高了图像匹配和减少了翻译误差。

Conclusion: 提出的OrthoLoC数据集及AdHoP技术能够显著提高无人机图像的定位精度，证明了地理数据的潜力。

Abstract: Accurate visual localization from aerial views is a fundamental problem with
applications in mapping, large-area inspection, and search-and-rescue
operations. In many scenarios, these systems require high-precision
localization while operating with limited resources (e.g., no internet
connection or GNSS/GPS support), making large image databases or heavy 3D
models impractical. Surprisingly, little attention has been given to leveraging
orthographic geodata as an alternative paradigm, which is lightweight and
increasingly available through free releases by governmental authorities (e.g.,
the European Union). To fill this gap, we propose OrthoLoC, the first
large-scale dataset comprising 16,425 UAV images from Germany and the United
States with multiple modalities. The dataset addresses domain shifts between
UAV imagery and geospatial data. Its paired structure enables fair benchmarking
of existing solutions by decoupling image retrieval from feature matching,
allowing isolated evaluation of localization and calibration performance.
Through comprehensive evaluation, we examine the impact of domain shifts, data
resolutions, and covisibility on localization accuracy. Finally, we introduce a
refinement technique called AdHoP, which can be integrated with any feature
matcher, improving matching by up to 95% and reducing translation error by up
to 63%. The dataset and code are available at:
https://deepscenario.github.io/OrthoLoC.

</details>


### [22] [A Single Image Is All You Need: Zero-Shot Anomaly Localization Without Training Data](https://arxiv.org/abs/2509.18354)
*Mehrdad Moradi,Shengzhe Chen,Hao Yan,Kamran Paynabar*

Main category: cs.CV

TL;DR: SSDnet是一种在零样本环境下进行图像异常检测的方法，通过自重建机制实现异常定位，并在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 在许多实际场景中，缺乏可用的训练数据，仅提供测试图像，因此需要一个能够在零样本环境下进行异常检测的方法。

Method: 提出了一种基于单张图像的异常定位方法SSDnet，该方法利用了卷积神经网络的归纳偏差，通过自重建图像学习深度图像优先，并设计了一个基于补丁的训练框架。

Result: 在MVTec-AD数据集上，SSDnet达到了0.99的AUROC和0.60的AUPRC，而在fabric数据集上则达到了0.98的AUROC和0.67的AUPRC，优于现有的各种先进方法。

Conclusion: SSDnet方法在无外部训练数据情况下，成功实现了对图像中的异常定位，并在多个基准数据集上超越了现有最先进的方法。

Abstract: Anomaly detection in images is typically addressed by learning from
collections of training data or relying on reference samples. In many
real-world scenarios, however, such training data may be unavailable, and only
the test image itself is provided. We address this zero-shot setting by
proposing a single-image anomaly localization method that leverages the
inductive bias of convolutional neural networks, inspired by Deep Image Prior
(DIP). Our method is named Single Shot Decomposition Network (SSDnet). Our key
assumption is that natural images often exhibit unified textures and patterns,
and that anomalies manifest as localized deviations from these repetitive or
stochastic patterns. To learn the deep image prior, we design a patch-based
training framework where the input image is fed directly into the network for
self-reconstruction, rather than mapping random noise to the image as done in
DIP. To avoid the model simply learning an identity mapping, we apply masking,
patch shuffling, and small Gaussian noise. In addition, we use a perceptual
loss based on inner-product similarity to capture structure beyond pixel
fidelity. Our approach needs no external training data, labels, or references,
and remains robust in the presence of noise or missing pixels. SSDnet achieves
0.99 AUROC and 0.60 AUPRC on MVTec-AD and 0.98 AUROC and 0.67 AUPRC on the
fabric dataset, outperforming state-of-the-art methods. The implementation code
will be released at https://github.com/mehrdadmoradi124/SSDnet

</details>


### [23] [Align Where the Words Look: Cross-Attention-Guided Patch Alignment with Contrastive and Transport Regularization for Bengali Captioning](https://arxiv.org/abs/2509.18369)
*Riad Ahmed Anonto,Sardar Md. Saffat Zabin,M. Saifur Rahman*

Main category: cs.CV

TL;DR: 本文提出一种新颖的方法通过三重损失目标提升了低资源语言的视觉-语言模型效果，特别是在孟加拉语中取得了显著进展。


<details>
  <summary>Details</summary>
Motivation: 为了解决低资源语言中的视觉-语言模型在对象识别中的不准确性和英语中心的预训练问题。

Method: 设计了一种计算感知的孟加拉语标题生成管道，使用了三重损失目标：Patch-Alignment Loss (PAL)、InfoNCE 和基于 Sinkhorn 的 OT。

Result: 在Flickr30k-1k和MSCOCO-1k数据集上显著提高了BLEU-4，METEOR和BERTScore-F1等指标，且优于传统基线。

Conclusion: 提出的三重损失目标有效提高了视觉-语言模型在低资源语言中的表现，减小了真实和合成模态之间的差距。

Abstract: Grounding vision--language models in low-resource languages remains
challenging, as they often produce fluent text about the wrong objects. This
stems from scarce paired data, translation pivots that break alignment, and
English-centric pretraining that ignores target-language semantics. We address
this with a compute-aware Bengali captioning pipeline trained on LaBSE-verified
EN--BN pairs and 110k bilingual-prompted synthetic images. A frozen MaxViT
yields stable visual patches, a Bengali-native mBART-50 decodes, and a
lightweight bridge links the modalities. Our core novelty is a tri-loss
objective: Patch-Alignment Loss (PAL) aligns real and synthetic patch
descriptors using decoder cross-attention, InfoNCE enforces global
real--synthetic separation, and Sinkhorn-based OT ensures balanced fine-grained
patch correspondence. This PAL+InfoNCE+OT synergy improves grounding, reduces
spurious matches, and drives strong gains on Flickr30k-1k (BLEU-4 12.29, METEOR
27.98, BERTScore-F1 71.20) and MSCOCO-1k (BLEU-4 12.00, METEOR 28.14,
BERTScore-F1 75.40), outperforming strong CE baselines and narrowing the
real--synthetic centroid gap by 41%.

</details>


### [24] [TinyBEV: Cross Modal Knowledge Distillation for Efficient Multi Task Bird's Eye View Perception and Planning](https://arxiv.org/abs/2509.18372)
*Reeshad Khan,John Gauch*

Main category: cs.CV

TL;DR: TinyBEV是一个轻量级的全摄像头鸟瞰视图框架，能在资源限制条件下实现完整的自动驾驶功能，比之前的方法减少了参数数量，并显著提高了性能和速度。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术的发展，如何在资源有限的情况下实现完整的自主驾驶能力成为一个重要的研究课题。

Method: 本研究采用了一种模型无关的多阶段蒸馏策略，结合了特征级、输出级以及适应性区域意识的监督，来有效地将高容量多模态知识转移到轻量级的BEV表示。

Result: TinyBEV在nuScenes数据集上实现了39.0的检测mAP，1.08的最小平均距离误差（minADE）用于运动预测，以及仅0.32的碰撞率，同时运行速度是传统方法的5倍（11 FPS），且只需摄像头输入。

Conclusion: TinyBEV能够在资源有限的环境中保留完整的驾驶智能，成功实现了从大型多模态感知规划模型到可实时部署自主驾驶的转变。

Abstract: We present TinyBEV, a unified, camera only Bird's Eye View (BEV) framework
that distills the full-stack capabilities of a large planning-oriented teacher
(UniAD [19]) into a compact, real-time student model. Unlike prior efficient
camera only baselines such as VAD[23] and VADv2[7], TinyBEV supports the
complete autonomy stack 3D detection, HD-map segmentation, motion forecasting,
occupancy prediction, and goal-directed planning within a streamlined
28M-parameter backbone, achieving a 78% reduction in parameters over UniAD
[19]. Our model-agnostic, multi-stage distillation strategy combines
feature-level, output-level, and adaptive region-aware supervision to
effectively transfer high-capacity multi-modal knowledge to a lightweight BEV
representation. On nuScenes[4], Tiny-BEV achieves 39.0 mAP for detection, 1.08
minADE for motion forecasting, and a 0.32 collision rate, while running 5x
faster (11 FPS) and requiring only camera input. These results demonstrate that
full-stack driving intelligence can be retained in resource-constrained
settings, bridging the gap between large-scale, multi-modal perception-planning
models and deployment-ready real-time autonomy.

</details>


### [25] [BlurBall: Joint Ball and Motion Blur Estimation for Table Tennis Ball Tracking](https://arxiv.org/abs/2509.18387)
*Thomas Gossard,Filip Radovic,Andreas Ziegler,Andrea Zell*

Main category: cs.CV

TL;DR: 运动模糊影响快速物体检测，本文提出一种新标签策略，将球标记在模糊中心，提升多种模型的检测性能，并介绍BlurBall模型以实现最佳检测结果。


<details>
  <summary>Details</summary>
Motivation: 现有的标签方法无法有效捕捉快速运动物体的运动信息，而新的标签策略可以更好地利用运动线索来提高检测精度。

Method: 提出了一种新的标签策略，将球定位于模糊条纹的中心，并注释模糊属性，使用Squeeze-and-Excitation等注意力机制的BlurBall模型进行位置和模糊属性的联合估计。

Result: 新的标签策略在多个模型中一致地增强了检测性能，同时BlurBall模型在乒乓球检测中实现了最先进的结果。

Conclusion: 新的标签策略和BlurBall模型显著提高了摩擦运动物体的检测性能，特别是在乒乓球检测中。

Abstract: Motion blur reduces the clarity of fast-moving objects, posing challenges for
detection systems, especially in racket sports, where balls often appear as
streaks rather than distinct points. Existing labeling conventions mark the
ball at the leading edge of the blur, introducing asymmetry and ignoring
valuable motion cues correlated with velocity. This paper introduces a new
labeling strategy that places the ball at the center of the blur streak and
explicitly annotates blur attributes. Using this convention, we release a new
table tennis ball detection dataset. We demonstrate that this labeling approach
consistently enhances detection performance across various models. Furthermore,
we introduce BlurBall, a model that jointly estimates ball position and motion
blur attributes. By incorporating attention mechanisms such as
Squeeze-and-Excitation over multi-frame inputs, we achieve state-of-the-art
results in ball detection. Leveraging blur not only improves detection accuracy
but also enables more reliable trajectory prediction, benefiting real-time
sports analytics.

</details>


### [26] [MVP: Motion Vector Propagation for Zero-Shot Video Object Detection](https://arxiv.org/abs/2509.18388)
*Binhua Huang,Ni Wang,Wendong Yao,Soumyabrata Dev*

Main category: cs.CV

TL;DR: 提出了一种基于压缩域运动矢量的无训练检测方法，通过在关键帧上调用OWLv2，降低了计算成本，同时保持了良好的检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统的开放词汇检测在每帧上进行处理会导致高昂的计算成本，因此需要寻找更高效的检测方法。

Method: 引入了一种无训练的管道，仅在固定间隔的关键帧上调用OWLv2，并通过压缩域运动矢量传播检测结果。

Result: 该方法在ILSVRC2015-VID验证集上取得了mAP@0.5=0.609和mAP@[0.5:0.95]=0.316的成绩，显著优于传统的跟踪传播方法。

Conclusion: 该方法提供了一种在保持准确性的同时，以低成本对视频帧进行检测的有效方案，特别适用于大规模开放词汇检测。

Abstract: Running a large open-vocabulary (Open-vocab) detector on every video frame is
accurate but expensive. We introduce a training-free pipeline that invokes
OWLv2 only on fixed-interval keyframes and propagates detections to
intermediate frames using compressed-domain motion vectors (MV). A simple 3x3
grid aggregation of motion vectors provides translation and uniform-scale
updates, augmented with an area-growth check and an optional single-class
switch. The method requires no labels, no fine-tuning, and uses the same prompt
list for all open-vocabulary methods. On ILSVRC2015-VID (validation dataset),
our approach (MVP) attains mAP@0.5=0.609 and mAP@[0.5:0.95]=0.316. At loose
intersection-over-union (IoU) thresholds it remains close to framewise
OWLv2-Large (0.747/0.721 at 0.2/0.3 versus 0.784/0.780), reflecting that coarse
localization is largely preserved. Under the same keyframe schedule, MVP
outperforms tracker-based propagation (MOSSE, KCF, CSRT) at mAP@0.5. A
supervised reference (YOLOv12x) reaches 0.631 at mAP@0.5 but requires labeled
training, whereas our method remains label-free and open-vocabulary. These
results indicate that compressed-domain propagation is a practical way to
reduce detector invocations while keeping strong zero-shot coverage in videos.
Our code and models are available at https://github.com/microa/MVP.

</details>


### [27] [Improving the color accuracy of lighting estimation models](https://arxiv.org/abs/2509.18390)
*Zitian Zhang,Joshua Urban Davis,Jeanne Phuong Anh Vu,Jiangtao Kuang,Jean-François Lalonde*

Main category: cs.CV

TL;DR: 本研究探讨了通过简单的适应技术提高HDR照明估计的颜色鲁棒性，重点是在不重新训练模型的条件下，利用预训练的白平衡网络对输入图像进行预处理的效果。


<details>
  <summary>Details</summary>
Motivation: 探讨HDR照明估计中的色彩准确性对增强现实应用中的视觉真实性的重要性。

Method: 研究色彩鲁棒性，并系统评估几种适应策略，以提高现有照明估计模型的颜色准确性。

Result: 预处理输入图像的白平衡网络在所有测试场景中都优于其他策略，提高了颜色鲁棒性，并在三种最新的照明估计方法上验证了这一发现的通用性。

Conclusion: 使用预训练的白平衡网络对输入图像进行预处理可以显著提高现有HDR照明估计模型的颜色准确性，而无需重新训练模型。

Abstract: Advances in high dynamic range (HDR) lighting estimation from a single image
have opened new possibilities for augmented reality (AR) applications.
Predicting complex lighting environments from a single input image allows for
the realistic rendering and compositing of virtual objects. In this work, we
investigate the color robustness of such methods -- an often overlooked yet
critical factor for achieving visual realism. While most evaluations conflate
color with other lighting attributes (e.g., intensity, direction), we isolate
color as the primary variable of interest. Rather than introducing a new
lighting estimation algorithm, we explore whether simple adaptation techniques
can enhance the color accuracy of existing models. Using a novel HDR dataset
featuring diverse lighting colors, we systematically evaluate several
adaptation strategies. Our results show that preprocessing the input image with
a pre-trained white balance network improves color robustness, outperforming
other strategies across all tested scenarios. Notably, this approach requires
no retraining of the lighting estimation model. We further validate the
generality of this finding by applying the technique to three state-of-the-art
lighting estimation methods from recent literature.

</details>


### [28] [Check Field Detection Agent (CFD-Agent) using Multimodal Large Language and Vision Language Models](https://arxiv.org/abs/2509.18405)
*Sourav Halder,Jinjun Tong,Xinyu Wu*

Main category: cs.CV

TL;DR: 本论文提出了一种创新的无训练支票字段检测框架，通过结合视觉语言模型和多模态大语言模型，实现了零-shot检测，显著降低了部署门槛，并在多个支票格式中表现优异。


<details>
  <summary>Details</summary>
Motivation: 支票在金融生态系统中仍是重要的工具，但由于其易受欺诈攻击，急需有效的支票欺诈检测机制。

Method: 本研究引入了一种新的无训练框架，结合了视觉语言模型（VLM）和多模态大语言模型（MLLM），用于自动化支票字段检测。

Result: 在多种格式和布局的110张手工挑选支票的数据集上进行的定量评估表明，我们的模型具有强大的性能和泛化能力。

Conclusion: 我们提出的无训练框架在支票字段检测中表现出色，能够显著降低在实际金融环境中部署的门槛，并为生成高质量标签数据集提供了基础。

Abstract: Checks remain a foundational instrument in the financial ecosystem,
facilitating substantial transaction volumes across institutions. However,
their continued use also renders them a persistent target for fraud,
underscoring the importance of robust check fraud detection mechanisms. At the
core of such systems lies the accurate identification and localization of
critical fields, such as the signature, magnetic ink character recognition
(MICR) line, courtesy amount, legal amount, payee, and payer, which are
essential for subsequent verification against reference checks belonging to the
same customer. This field-level detection is traditionally dependent on object
detection models trained on large, diverse, and meticulously labeled datasets,
a resource that is scarce due to proprietary and privacy concerns. In this
paper, we introduce a novel, training-free framework for automated check field
detection, leveraging the power of a vision language model (VLM) in conjunction
with a multimodal large language model (MLLM). Our approach enables zero-shot
detection of check components, significantly lowering the barrier to deployment
in real-world financial settings. Quantitative evaluation of our model on a
hand-curated dataset of 110 checks spanning multiple formats and layouts
demonstrates strong performance and generalization capability. Furthermore,
this framework can serve as a bootstrap mechanism for generating high-quality
labeled datasets, enabling the development of specialized real-time object
detection models tailored to institutional needs.

</details>


### [29] [Losing the Plot: How VLM responses degrade on imperfect charts](https://arxiv.org/abs/2509.18425)
*Philip Wootaek Shin,Jack Sampson,Vijaykrishnan Narayanan,Andres Marquez,Mahantesh Halappanavar*

Main category: cs.CV

TL;DR: 该研究揭示了视觉语言模型在理解带有干扰的图表时的局限性，并提出了CHART NOISe数据集和改进策略，以增强模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 针对目前现有基准过于理想化，且未能充分测试模型在现实世界图表理解中的表现，提出该研究以填补这一空白。

Method: 通过对现有视觉语言模型在遭遇图表损坏和遮挡时进行评估，并构建带有干扰和反向不一致性的多项选择题数据集以测试模型的推理能力。

Result: 实验结果显示，模型在处理含有噪声和遮挡的图表时，表现显著下降，且出现了许多幻觉现象，如值伪造和趋势误解等。

Conclusion: 本文提出的CHART NOISe数据集和基准测试显示了当前视觉语言模型在丑化和遮挡情况下的脆弱性，同时为后续研究提供了切实可行的改进策略。

Abstract: Vision language models (VLMs) show strong results on chart understanding, yet
existing benchmarks assume clean figures and fact based queries. Real world
charts often contain distortions and demand reasoning beyond simple matching.
We evaluate ChatGPT 4o, Claude Sonnet 4, and Gemini 2.5 Pro, finding sharp
performance drops under corruption or occlusion, with hallucinations such as
value fabrication, trend misinterpretation, and entity confusion becoming more
frequent. Models remain overconfident in degraded settings, generating
plausible but unsupported explanations.
  To address this gap, we introduce CHART NOISe(Chart Hallucinations, Answers,
and Reasoning Testing on Noisy and Occluded Input Selections), a dataset
combining chart corruptions, occlusions, and exam style multiple choice
questions inspired by Korea's CSAT English section. A key innovation is prompt
reverse inconsistency, where models contradict themselves when asked to confirm
versus deny the same statement. Our contributions are threefold: (1)
benchmarking state of the art VLMs, exposing systematic vulnerabilities in
chart reasoning; (2) releasing CHART NOISe, the first dataset unifying
corruption, occlusion, and reverse inconsistency; and (3) proposing baseline
mitigation strategies such as quality filtering and occlusion detection.
Together, these efforts establish a rigorous testbed for advancing robustness
and reliability in chart understanding.

</details>


### [30] [CPT-4DMR: Continuous sPatial-Temporal Representation for 4D-MRI Reconstruction](https://arxiv.org/abs/2509.18427)
*Xinyang Wu,Muheng Li,Xia Li,Orso Pusterla,Sairos Safai,Philippe C. Cattin,Antony J. Lomax,Ye Zhang*

Main category: cs.CV

TL;DR: 本研究提出了一种基于神经网络的4D-MRI重建方法，显著提高了放射治疗中的时间效率和解剖精确性，适用于实时自适应治疗。


<details>
  <summary>Details</summary>
Motivation: 现有的4D重建方法在捕捉时间变异性和计算负担方面表现不佳，需提出高效的新方法。

Method: 通过神经表征框架融合运动建模与图像重建，采用空间解剖网络(SAN)和时间运动网络(TMN)。

Result: 使用19名志愿者的自由呼吸数据集进行评估，结果显示该方法准确捕捉呼吸模式，保持高解剖保真度，大幅提高处理效率。

Conclusion: 该方法显著提高了4D-MRI在放射治疗中的效率和准确性，适用于实时自适应治疗。

Abstract: Four-dimensional MRI (4D-MRI) is an promising technique for capturing
respiratory-induced motion in radiation therapy planning and delivery.
Conventional 4D reconstruction methods, which typically rely on phase binning
or separate template scans, struggle to capture temporal variability,
complicate workflows, and impose heavy computational loads. We introduce a
neural representation framework that considers respiratory motion as a smooth,
continuous deformation steered by a 1D surrogate signal, completely replacing
the conventional discrete sorting approach. The new method fuses motion
modeling with image reconstruction through two synergistic networks: the
Spatial Anatomy Network (SAN) encodes a continuous 3D anatomical
representation, while a Temporal Motion Network (TMN), guided by
Transformer-derived respiratory signals, produces temporally consistent
deformation fields. Evaluation using a free-breathing dataset of 19 volunteers
demonstrates that our template- and phase-free method accurately captures both
regular and irregular respiratory patterns, while preserving vessel and
bronchial continuity with high anatomical fidelity. The proposed method
significantly improves efficiency, reducing the total processing time from
approximately five hours required by conventional discrete sorting methods to
just 15 minutes of training. Furthermore, it enables inference of each 3D
volume in under one second. The framework accurately reconstructs 3D images at
any respiratory state, achieves superior performance compared to conventional
methods, and demonstrates strong potential for application in 4D radiation
therapy planning and real-time adaptive treatment.

</details>


### [31] [An Analysis of Kalman Filter based Object Tracking Methods for Fast-Moving Tiny Objects](https://arxiv.org/abs/2509.18451)
*Prithvi Raj Singh,Raju Gottumukkala,Anthony Maida*

Main category: cs.CV

TL;DR: 本研究评估了五种基于卡尔曼滤波器的跟踪方法在快速移动小物体跟踪中的性能，结果显示现有方法表现不佳，需要专门化改进。


<details>
  <summary>Details</summary>
Motivation: 应对快速移动小物体（如羽球）的不可预测运动模式，实现精确跟踪，以改善运动机器人在感知和规划能力方面的表现。

Method: 使用自定义数据集评估五种基于卡尔曼滤波器的最先进跟踪方法，分别是OCSORT、DeepOCSORT、ByteTrack、BoTSORT和StrongSORT。

Result: DeepOCSORT的跟踪错误最低，平均ADE为31.15像素，而ByteTrack则在处理速度上表现最快，平均推理时间为26.6毫秒。不过，所有方法的跟踪漂移显著，空间误差范围在3-11厘米（ADE值：31-114像素）。

Conclusion: 当前基于卡尔曼滤波器的跟踪方法在处理快速移动微小物体时存在显著局限性，错误率比标准物体跟踪基准高出3-4倍，需要专门的技术改进。

Abstract: Unpredictable movement patterns and small visual mark make precise tracking
of fast-moving tiny objects like a racquetball one of the challenging problems
in computer vision. This challenge is particularly relevant for sport robotics
applications, where lightweight and accurate tracking systems can improve robot
perception and planning capabilities. While Kalman filter-based tracking
methods have shown success in general object tracking scenarios, their
performance degrades substantially when dealing with rapidly moving objects
that exhibit irregular bouncing behavior. In this study, we evaluate the
performance of five state-of-the-art Kalman filter-based tracking
methods-OCSORT, DeepOCSORT, ByteTrack, BoTSORT, and StrongSORT-using a custom
dataset containing 10,000 annotated racquetball frames captured at 720p-1280p
resolution. We focus our analysis on two critical performance factors:
inference speed and update frequency per image, examining how these parameters
affect tracking accuracy and reliability for fast-moving tiny objects. Our
experimental evaluation across four distinct scenarios reveals that DeepOCSORT
achieves the lowest tracking error with an average ADE of 31.15 pixels compared
to ByteTrack's 114.3 pixels, while ByteTrack demonstrates the fastest
processing at 26.6ms average inference time versus DeepOCSORT's 26.8ms.
However, our results show that all Kalman filter-based trackers exhibit
significant tracking drift with spatial errors ranging from 3-11cm (ADE values:
31-114 pixels), indicating fundamental limitations in handling the
unpredictable motion patterns of fast-moving tiny objects like racquetballs.
Our analysis demonstrates that current tracking approaches require substantial
improvements, with error rates 3-4x higher than standard object tracking
benchmarks, highlighting the need for specialized methodologies for fast-moving
tiny object tracking applications.

</details>


### [32] [MoCrop: Training Free Motion Guided Cropping for Efficient Video Action Recognition](https://arxiv.org/abs/2509.18473)
*Binhua Huang,Wendong Yao,Shaowu Chen,Guoxin Wang,Qingyuan Wang,Soumyabrata Dev*

Main category: cs.CV

TL;DR: MoCrop是一个高效的自适应裁剪模块，专为视频动作识别设计，通过使用H.264中的运动矢量来优化计算效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 为了改善视频动作识别的有效性和效率，同时减少计算开销。

Method: 使用H.264视频中的运动矢量定位运动密集区域，通过训练无关的模块进行自适应裁剪。

Result: 在UCF101数据集上，MoCrop提高了准确率或减少了计算需求，尤其在ResNet-50上，显著提升了Top-1准确率或减少了FLOPs。

Conclusion: MoCrop在压缩域中实现了高效的视频动作识别，并在各主流模型中展现出较强的通用性，适合实时应用。

Abstract: We introduce MoCrop, a motion-aware adaptive cropping module for efficient
video action recognition in the compressed domain. MoCrop uses motion vectors
that are available in H.264 video to locate motion-dense regions and produces a
single clip-level crop that is applied to all I-frames at inference. The module
is training free, adds no parameters, and can be plugged into diverse
backbones. A lightweight pipeline that includes denoising & merge (DM), Monte
Carlo sampling (MCS), and adaptive cropping (AC) via a motion-density submatrix
search yields robust crops with negligible overhead. On UCF101, MoCrop improves
accuracy or reduces compute. With ResNet-50, it delivers +3.5% Top-1 accuracy
at equal FLOPs (attention setting), or +2.4% Top-1 accuracy with 26.5% fewer
FLOPs (efficiency setting). Applied to CoViAR, it reaches 89.2% Top-1 accuracy
at the original cost and 88.5% Top-1 accuracy while reducing compute from 11.6
to 8.5 GFLOPs. Consistent gains on MobileNet-V3, EfficientNet-B1, and Swin-B
indicate strong generality and make MoCrop practical for real-time deployment
in the compressed domain. Our code and models are available at
https://github.com/microa/MoCrop.

</details>


### [33] [Codebook-Based Adaptive Feature Compression With Semantic Enhancement for Edge-Cloud Systems](https://arxiv.org/abs/2509.18481)
*Xinyu Wang,Zikun Zhou,Yingjian Li,Xin An,Hongpeng Wang*

Main category: cs.CV

TL;DR: CAFC-SE通过向量量化减少冗余细节，提高边缘云系统在低比特率下的图像分析性能。


<details>
  <summary>Details</summary>
Motivation: 当前低比特率的情况下，现有图像编码方法在分析性能上存在明显不足，需要更有效的特征压缩方法。

Method: 提出了一种基于代码簿的自适应特征压缩框架CAFC-SE，通过向量量化将连续的视觉特征映射到离散索引，并选择性传输。

Result: 实验结果表明，CAFC-SE在比特率和准确性方面优于其他方法。

Conclusion: CAFC-SE方法在低比特率条件下展现出优秀的性能，优于传统方法。

Abstract: Coding images for machines with minimal bitrate and strong analysis
performance is key to effective edge-cloud systems. Several approaches deploy
an image codec and perform analysis on the reconstructed image. Other methods
compress intermediate features using entropy models and subsequently perform
analysis on the decoded features. Nevertheless, these methods both perform
poorly under low-bitrate conditions, as they retain many redundant details or
learn over-concentrated symbol distributions. In this paper, we propose a
Codebook-based Adaptive Feature Compression framework with Semantic
Enhancement, named CAFC-SE. It maps continuous visual features to discrete
indices with a codebook at the edge via Vector Quantization (VQ) and
selectively transmits them to the cloud. The VQ operation that projects feature
vectors onto the nearest visual primitives enables us to preserve more
informative visual patterns under low-bitrate conditions. Hence, CAFC-SE is
less vulnerable to low-bitrate conditions. Extensive experiments demonstrate
the superiority of our method in terms of rate and accuracy.

</details>


### [34] [MK-UNet: Multi-kernel Lightweight CNN for Medical Image Segmentation](https://arxiv.org/abs/2509.18493)
*Md Mostafijur Rahman,Radu Marculescu*

Main category: cs.CV

TL;DR: MK-UNet是一种新型超轻量级医学图像分割CNN，通过多核卷积和注意力机制，在分割准确性和计算资源方面都表现出色。


<details>
  <summary>Details</summary>
Motivation: 针对医学图像分割的需求，开发一种轻量级且高效的网络结构，以提高分割准确性，同时降低计算资源消耗。

Method: 引入了多核深度卷积块（MKDC）和复杂的注意力机制，优化了图像特征的提取和多分辨率空间关系的捕捉。

Result: MK-UNet在六个二元医学影像基准测试中表现超过了现有最先进技术，并且在保持更少参数和计算量的同时显著提高了DICE得分。

Conclusion: MK-UNet是一种超轻量、多核U型CNN，用于医学图像分割，表现出优越的性能和极低的计算资源需求。

Abstract: In this paper, we introduce MK-UNet, a paradigm shift towards
ultra-lightweight, multi-kernel U-shaped CNNs tailored for medical image
segmentation. Central to MK-UNet is the multi-kernel depth-wise convolution
block (MKDC) we design to adeptly process images through multiple kernels,
while capturing complex multi-resolution spatial relationships. MK-UNet also
emphasizes the images salient features through sophisticated attention
mechanisms, including channel, spatial, and grouped gated attention. Our
MK-UNet network, with a modest computational footprint of only 0.316M
parameters and 0.314G FLOPs, represents not only a remarkably lightweight, but
also significantly improved segmentation solution that provides higher accuracy
over state-of-the-art (SOTA) methods across six binary medical imaging
benchmarks. Specifically, MK-UNet outperforms TransUNet in DICE score with
nearly 333$\times$ and 123$\times$ fewer parameters and FLOPs, respectively.
Similarly, when compared against UNeXt, MK-UNet exhibits superior segmentation
performance, improving the DICE score up to 6.7% margins while operating with
4.7$\times$ fewer #Params. Our MK-UNet also outperforms other recent
lightweight networks, such as MedT, CMUNeXt, EGE-UNet, and Rolling-UNet, with
much lower computational resources. This leap in performance, coupled with
drastic computational gains, positions MK-UNet as an unparalleled solution for
real-time, high-fidelity medical diagnostics in resource-limited settings, such
as point-of-care devices. Our implementation is available at
https://github.com/SLDGroup/MK-UNet.

</details>


### [35] [BridgeSplat: Bidirectionally Coupled CT and Non-Rigid Gaussian Splatting for Deformable Intraoperative Surgical Navigation](https://arxiv.org/abs/2509.18501)
*Maximilian Fehrentz,Alexander Winkler,Thomas Heiliger,Nazim Haouchine,Christian Heiliger,Nassir Navab*

Main category: cs.CV

TL;DR: 本文提出了BridgeSplat，一种结合了术中3D重建和术前CT数据的外科导航新方法，能够有效地更新和优化CT数据。


<details>
  <summary>Details</summary>
Motivation: 为了解决外科视频与体积患者数据之间的差距。

Method: 使用3D高斯与CT网格进行结合，实施联合优化，包括高斯参数和网格变形。

Result: 在猪的内脏手术和人示肝的合成数据上，展示了预手术CT的合理变形。

Conclusion: BridgeSplat能够有效进行可变形的外科导航，通过光度监督实现CT数据的更新和优化。

Abstract: We introduce BridgeSplat, a novel approach for deformable surgical navigation
that couples intraoperative 3D reconstruction with preoperative CT data to
bridge the gap between surgical video and volumetric patient data. Our method
rigs 3D Gaussians to a CT mesh, enabling joint optimization of Gaussian
parameters and mesh deformation through photometric supervision. By
parametrizing each Gaussian relative to its parent mesh triangle, we enforce
alignment between Gaussians and mesh and obtain deformations that can be
propagated back to update the CT. We demonstrate BridgeSplat's effectiveness on
visceral pig surgeries and synthetic data of a human liver under simulation,
showing sensible deformations of the preoperative CT on monocular RGB data.
Code, data, and additional resources can be found at
https://maxfehrentz.github.io/ct-informed-splatting/ .

</details>


### [36] [Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment](https://arxiv.org/abs/2509.18502)
*Wenjie Liu,Hongmin Liu,Lixin Zhang,Bin Fan*

Main category: cs.CV

TL;DR: 本论文提出了一个新颖的伪标签优化框架DGLE，通过高质量伪标签的初始种子和扩散模型的传播，显著提高了无源域适应中的目标域性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有伪标签方法中存在的噪声问题，从而提高源无关域适应中的自我训练效果。

Method: 采用基于置信度过滤和超分辨率增强的伪标签融合方法结合扩散模型进行伪标签传播。

Result: 通过改进伪标签的质量，DGLE方法在目标域上显著提升了模型的性能。

Conclusion: 提出的Diffusion-Guided Label Enrichment (DGLE)框架显著提升了目标域模型性能。

Abstract: Research on unsupervised domain adaptation (UDA) for semantic segmentation of
remote sensing images has been extensively conducted. However, research on how
to achieve domain adaptation in practical scenarios where source domain data is
inaccessible namely, source-free domain adaptation (SFDA) remains limited.
Self-training has been widely used in SFDA, which requires obtaining as many
high-quality pseudo-labels as possible to train models on target domain data.
Most existing methods optimize the entire pseudo-label set to obtain more
supervisory information. However, as pseudo-label sets often contain
substantial noise, simultaneously optimizing all labels is challenging. This
limitation undermines the effectiveness of optimization approaches and thus
restricts the performance of self-training. To address this, we propose a novel
pseudo-label optimization framework called Diffusion-Guided Label Enrichment
(DGLE), which starts from a few easily obtained high-quality pseudo-labels and
propagates them to a complete set of pseudo-labels while ensuring the quality
of newly generated labels. Firstly, a pseudo-label fusion method based on
confidence filtering and super-resolution enhancement is proposed, which
utilizes cross-validation of details and contextual information to obtain a
small number of high-quality pseudo-labels as initial seeds. Then, we leverage
the diffusion model to propagate incomplete seed pseudo-labels with irregular
distributions due to its strong denoising capability for randomly distributed
noise and powerful modeling capacity for complex distributions, thereby
generating complete and high-quality pseudo-labels. This method effectively
avoids the difficulty of directly optimizing the complete set of pseudo-labels,
significantly improves the quality of pseudo-labels, and thus enhances the
model's performance in the target domain.

</details>


### [37] [Hyperbolic Coarse-to-Fine Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2509.18504)
*Jiaxin Dai,Xiang Xiang*

Main category: cs.CV

TL;DR: 本研究提出一种在双曲空间进行的少样本类增量学习方法，通过采用双曲距离和最大熵分布来优化特征提取，取得了明显的性能提升。


<details>
  <summary>Details</summary>
Motivation: 探讨双曲空间在层次数据的表示能力，聚焦于粗到细的少样本类增量学习任务。

Method: 提出嵌入特征提取器到双曲空间，使用双曲对比损失和双曲全连接层，应用最大熵分布来估计细类特征向量的概率分布，并生成增强特征。

Result: 我们的实验在C2FSCIL基准上展示了方法在粗类和细类准确性上的有效提升。

Conclusion: 我们的方法有效提高了粗类和细类的准确性。

Abstract: In the field of machine learning, hyperbolic space demonstrates superior
representation capabilities for hierarchical data compared to conventional
Euclidean space. This work focuses on the Coarse-To-Fine Few-Shot
Class-Incremental Learning (C2FSCIL) task. Our study follows the Knowe
approach, which contrastively learns coarse class labels and subsequently
normalizes and freezes the classifier weights of learned fine classes in the
embedding space. To better interpret the "coarse-to-fine" paradigm, we propose
embedding the feature extractor into hyperbolic space. Specifically, we employ
the Poincar\'e ball model of hyperbolic space, enabling the feature extractor
to transform input images into feature vectors within the Poincar\'e ball
instead of Euclidean space. We further introduce hyperbolic contrastive loss
and hyperbolic fully-connected layers to facilitate model optimization and
classification in hyperbolic space. Additionally, to enhance performance under
few-shot conditions, we implement maximum entropy distribution in hyperbolic
space to estimate the probability distribution of fine-class feature vectors.
This allows generation of augmented features from the distribution to mitigate
overfitting during training with limited samples. Experiments on C2FSCIL
benchmarks show that our method effectively improves both coarse and fine class
accuracies.

</details>


### [38] [GeoRemover: Removing Objects and Their Causal Visual Artifacts](https://arxiv.org/abs/2509.18538)
*Zixin Zhu,Haoxiang Li,Xuelu Feng,He Wu,Chunming Qiao,Junsong Yuan*

Main category: cs.CV

TL;DR: 为了实现智能图像编辑，本研究提出一种几何感知的双阶段框架，有效解决了现有目标去除技术在视觉效果处理上的不足，取得了显著的进展。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在去除目标物体时可能忽视物体几何存在与其视觉效果之间的因果关系，导致处理不彻底或控制不足。

Method: 框架分为两个阶段：第一阶段直接从几何数据中去除物体，采用严格的掩码对齐监督；第二阶段基于更新后的几何图像进行逼真的RGB图像渲染，隐含考虑因几何变化带来的主要视觉效果。

Result: 通过对两常见基准的广泛实验，我们的方法在去除物体及其伪影方面达到了最先进的性能。

Conclusion: 我们提出的几何感知双阶段框架在去除目标物体及其相关视觉伪影方面表现出色，超越了现有的方法。

Abstract: Towards intelligent image editing, object removal should eliminate both the
target object and its causal visual artifacts, such as shadows and reflections.
However, existing image appearance-based methods either follow strictly
mask-aligned training and fail to remove these causal effects which are not
explicitly masked, or adopt loosely mask-aligned strategies that lack
controllability and may unintentionally over-erase other objects. We identify
that these limitations stem from ignoring the causal relationship between an
object's geometry presence and its visual effects. To address this limitation,
we propose a geometry-aware two-stage framework that decouples object removal
into (1) geometry removal and (2) appearance rendering. In the first stage, we
remove the object directly from the geometry (e.g., depth) using strictly
mask-aligned supervision, enabling structure-aware editing with strong
geometric constraints. In the second stage, we render a photorealistic RGB
image conditioned on the updated geometry, where causal visual effects are
considered implicitly as a result of the modified 3D geometry. To guide
learning in the geometry removal stage, we introduce a preference-driven
objective based on positive and negative sample pairs, encouraging the model to
remove objects as well as their causal visual artifacts while avoiding new
structural insertions. Extensive experiments demonstrate that our method
achieves state-of-the-art performance in removing both objects and their
associated artifacts on two popular benchmarks. The code is available at
https://github.com/buxiangzhiren/GeoRemover.

</details>


### [39] [SEGA: A Transferable Signed Ensemble Gaussian Black-Box Attack against No-Reference Image Quality Assessment Models](https://arxiv.org/abs/2509.18546)
*Yujia Liu,Dingquan Li,Tiejun Huang*

Main category: cs.CV

TL;DR: 本研究提出一种新的SEGA方法，用于提升在黑箱环境下对NR-IQA模型的攻击可传递性，通过高斯平滑技术和扰动过滤改善攻击效果。


<details>
  <summary>Details</summary>
Motivation: 针对NR-IQA模型的低可传递性攻击的挑战，尤其是在黑箱场景下的有效性不足，进行深入研究。

Method: 提出了一种可传递的Signed Ensemble Gaussian黑箱攻击（SEGA），通过对源模型应用高斯平滑处理并集合其平滑梯度来近似目标模型的梯度，并使用专门设计的扰动过滤掩码去除不适当的扰动，以确保对抗性干扰的隐匿性。

Result: 实验结果显示在CLIVE数据集上，SEGA在黑箱攻击NR-IQA模型中表现出良好的传递性，验证了其成功进行传递基础攻击的有效性。

Conclusion: SEGA方法在黑箱攻击NR-IQA模型中具有优越的可传递性和有效性。

Abstract: No-Reference Image Quality Assessment (NR-IQA) models play an important role
in various real-world applications. Recently, adversarial attacks against
NR-IQA models have attracted increasing attention, as they provide valuable
insights for revealing model vulnerabilities and guiding robust system design.
Some effective attacks have been proposed against NR-IQA models in white-box
settings, where the attacker has full access to the target model. However,
these attacks often suffer from poor transferability to unknown target models
in more realistic black-box scenarios, where the target model is inaccessible.
This work makes the first attempt to address the challenge of low
transferability in attacking NR-IQA models by proposing a transferable Signed
Ensemble Gaussian black-box Attack (SEGA). The main idea is to approximate the
gradient of the target model by applying Gaussian smoothing to source models
and ensembling their smoothed gradients. To ensure the imperceptibility of
adversarial perturbations, SEGA further removes inappropriate perturbations
using a specially designed perturbation filter mask. Experimental results on
the CLIVE dataset demonstrate the superior transferability of SEGA, validating
its effectiveness in enabling successful transfer-based black-box attacks
against NR-IQA models.

</details>


### [40] [HadaSmileNet: Hadamard fusion of handcrafted and deep-learning features for enhancing facial emotion recognition of genuine smiles](https://arxiv.org/abs/2509.18550)
*Mohammad Junayed Hasan,Nabeel Mohammed,Shafin Rahman,Philipp Koehn*

Main category: cs.CV

TL;DR: HadaSmileNet是一个高效的特征融合框架，通过无参数乘法交互，结合变换器表示和生理特征，实现了多个数据集的最优情感识别性能，适合实时应用。


<details>
  <summary>Details</summary>
Motivation: 在社交科学、医疗保健和人机交互的数据挖掘应用中，准确区分真实与摆拍情感是一项重要的模式识别挑战。

Method: 引入HadaSmileNet框架，通过无参数的乘法交互将基于变换器的表示与生理基础的D-Marker特征相结合，采用Hadamard乘法融合策略。

Result: 在UvA-NEMO（88.7%，+0.8）、MMI（99.7%）、SPOS（98.5%，+0.7）和BBC（100%，+5.0）四个基准数据集上，HadaSmileNet展示了新的最优深度学习结果，并且与多任务替代方案相比，参数减少了26%，训练过程更加简化。

Conclusion: HadaSmileNet通过高效的特征融合方法在多个基准数据集上达到了深度学习的新最优结果，并兼具计算效率与有效性，适用于实时情感计算应用。

Abstract: The distinction between genuine and posed emotions represents a fundamental
pattern recognition challenge with significant implications for data mining
applications in social sciences, healthcare, and human-computer interaction.
While recent multi-task learning frameworks have shown promise in combining
deep learning architectures with handcrafted D-Marker features for smile facial
emotion recognition, these approaches exhibit computational inefficiencies due
to auxiliary task supervision and complex loss balancing requirements. This
paper introduces HadaSmileNet, a novel feature fusion framework that directly
integrates transformer-based representations with physiologically grounded
D-Markers through parameter-free multiplicative interactions. Through
systematic evaluation of 15 fusion strategies, we demonstrate that Hadamard
multiplicative fusion achieves optimal performance by enabling direct feature
interactions while maintaining computational efficiency. The proposed approach
establishes new state-of-the-art results for deep learning methods across four
benchmark datasets: UvA-NEMO (88.7 percent, +0.8), MMI (99.7 percent), SPOS
(98.5 percent, +0.7), and BBC (100 percent, +5.0). Comprehensive computational
analysis reveals 26 percent parameter reduction and simplified training
compared to multi-task alternatives, while feature visualization demonstrates
enhanced discriminative power through direct domain knowledge integration. The
framework's efficiency and effectiveness make it particularly suitable for
practical deployment in multimedia data mining applications that require
real-time affective computing capabilities.

</details>


### [41] [Event-guided 3D Gaussian Splatting for Dynamic Human and Scene Reconstruction](https://arxiv.org/abs/2509.18566)
*Xiaoting Yin,Hao Shi,Kailun Yang,Jiajun Zhai,Shangwei Guo,Lin Wang,Kaiwei Wang*

Main category: cs.CV

TL;DR: 本文提出了一种事件引导的动态人类与静态场景重建框架，通过3D高斯建模和事件引导损失，在快速运动情况下实现了优越的重建效果，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尝试克服传统RGB帧因快速运动导致的模糊问题，利用事件相机的微妙时间分辨率实现更高质量的人体与场景重建。

Method: 利用单个单目事件相机，通过3D高斯点云建模人和场景，采用事件引导损失来改善动态模糊区域的重建效果。

Result: 在ZJU-MoCap-Blur和MMHPSD-Blur两个基准数据集上，该方法在PSNR/SSIM上取得了显著的优越表现，并减少了LPIPS值，特别是在高速运动的对象上。

Conclusion: 该研究提出了一种新颖的事件引导人体与场景重建框架，成功实现了动态人类与静态场景的重建，尤其是在快速运动情况下表现优异。

Abstract: Reconstructing dynamic humans together with static scenes from monocular
videos remains difficult, especially under fast motion, where RGB frames suffer
from motion blur. Event cameras exhibit distinct advantages, e.g., microsecond
temporal resolution, making them a superior sensing choice for dynamic human
reconstruction. Accordingly, we present a novel event-guided human-scene
reconstruction framework that jointly models human and scene from a single
monocular event camera via 3D Gaussian Splatting. Specifically, a unified set
of 3D Gaussians carries a learnable semantic attribute; only Gaussians
classified as human undergo deformation for animation, while scene Gaussians
stay static. To combat blur, we propose an event-guided loss that matches
simulated brightness changes between consecutive renderings with the event
stream, improving local fidelity in fast-moving regions. Our approach removes
the need for external human masks and simplifies managing separate Gaussian
sets. On two benchmark datasets, ZJU-MoCap-Blur and MMHPSD-Blur, it delivers
state-of-the-art human-scene reconstruction, with notable gains over strong
baselines in PSNR/SSIM and reduced LPIPS, especially for high-speed subjects.

</details>


### [42] [Live-E2T: Real-time Threat Monitoring in Video via Deduplicated Event Reasoning and Chain-of-Thought](https://arxiv.org/abs/2509.18571)
*Yuhan Wang,Cheng Liu,Zihan Zhao,Weichao Wu*

Main category: cs.CV

TL;DR: 本文提出的Live-E2T框架通过结构化语义表示和语言模型调优，解决了实时威胁监测中的性能和可解释性问题，测试结果显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了应对目前基于监督学习和生成模型的方法在实时性能和决策可解释性之间的矛盾，提出一种新的统一框架。

Method: 通过将视频帧解构为结构化的语义元组，并引入高效的在线事件去重机制和基于Chain-of-Thought的语言模型调优，实现实时威胁监测与决策可解释性。

Result: Live-E2T在XD-Violence和UCF-Crime等基准数据集上进行了广泛实验，结果表明其在威胁检测准确性和实时响应方面显著优于最新的研究方法。

Conclusion: Live-E2T在面对威胁检测方面优于现有的方法，尤其在准确性、实时效率和可解释性方面表现突出。

Abstract: Real-time threat monitoring identifies threatening behaviors in video streams
and provides reasoning and assessment of threat events through explanatory
text. However, prevailing methodologies, whether based on supervised learning
or generative models, struggle to concurrently satisfy the demanding
requirements of real-time performance and decision explainability. To bridge
this gap, we introduce Live-E2T, a novel framework that unifies these two
objectives through three synergistic mechanisms. First, we deconstruct video
frames into structured Human-Object-Interaction-Place semantic tuples. This
approach creates a compact, semantically focused representation, circumventing
the information degradation common in conventional feature compression. Second,
an efficient online event deduplication and updating mechanism is proposed to
filter spatio-temporal redundancies, ensuring the system's real time
responsiveness. Finally, we fine-tune a Large Language Model using a
Chain-of-Thought strategy, endow it with the capability for transparent and
logical reasoning over event sequences to produce coherent threat assessment
reports. Extensive experiments on benchmark datasets, including XD-Violence and
UCF-Crime, demonstrate that Live-E2T significantly outperforms state-of-the-art
methods in terms of threat detection accuracy, real-time efficiency, and the
crucial dimension of explainability.

</details>


### [43] [The Photographer Eye: Teaching Multimodal Large Language Models to See and Critique like Photographers](https://arxiv.org/abs/2509.18582)
*Daiqing Qi,Handong Zhao,Jing Shi,Simon Jenni,Yifei Fan,Franck Dernoncourt,Scott Cohen,Sheng Li*

Main category: cs.CV

TL;DR: 本文旨在提升多模态大语言模型对图像美学的理解，通过新数据集和模型，提高了分析和描述的能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在处理图像美学时面临挑战，尤其是在真实世界场景中缺乏专业知识。

Method: 提出了一种新颖的模型PhotoEye，结合了语言引导的多视角视觉融合机制，以从多个角度理解图像美学。

Result: 在现有基准测试及PhotoBench上，PhotoEye模型在美学视觉理解上相较于现有模型有明显优势。

Conclusion: 本研究通过引入PhotoCritique数据集和PhotoEye模型，显著提升了对图像美学的理解能力，并在现有基准测试中表现优越。

Abstract: While editing directly from life, photographers have found it too difficult
to see simultaneously both the blue and the sky. Photographer and curator,
Szarkowski insightfully revealed one of the notable gaps between general and
aesthetic visual understanding: while the former focuses on identifying the
factual element in an image (sky), the latter transcends such object
identification, viewing it instead as an aesthetic component--a pure color
block (blue). Such fundamental distinctions between general (detection,
localization, etc.) and aesthetic (color, lighting, composition, etc.) visual
understanding present a significant challenge for Multimodal Large Language
Models (MLLMs). Although some recent works have made initial explorations, they
are often limited to general and basic aesthetic commonsense. As a result, they
frequently fall short in real-world scenarios (Fig. 1), which require extensive
expertise--including photographic techniques, photo pre/post-processing
knowledge, and more, to provide a detailed analysis and description. To
fundamentally enhance the aesthetics understanding of MLLMs, we first introduce
a novel dataset, PhotoCritique, derived from extensive discussions among
professional photographers and enthusiasts, and characterized by the large
scale, expertise, and diversity. Then, to better learn visual aesthetics from
PhotoCritique, we furthur propose a novel model, PhotoEye, featuring a
languageguided multi-view vision fusion mechanism to understand image
aesthetics from multiple perspectives. Finally, we present a novel benchmark,
PhotoBench, a comprehensive and professional benchmark for aesthetic visual
understanding. On existing benchmarks and PhotoBench, our model demonstrates
clear advantages over existing models.

</details>


### [44] [Enhancing Video Object Segmentation in TrackRAD Using XMem Memory Network](https://arxiv.org/abs/2509.18591)
*Pengchao Deng,Shengqi Chen*

Main category: cs.CV

TL;DR: 本文提出了一种基于XMem的肿瘤分割框架，旨在提高MRI引导放疗过程中的肿瘤追踪精度，已展现出良好的分割性能。


<details>
  <summary>Details</summary>
Motivation: 提高在MRI引导放疗中的肿瘤追踪精度，以增强癌症治疗的准确性和安全性。

Method: 使用XMem模型作为基础，整合记忆机制进行肿瘤分割。

Result: 尽管具体定量结果缺失，但早期开发阶段表明该框架具有合理的分割性能。

Conclusion: 该研究提出的基于XMem模型的肿瘤分割框架在临床实时要求上取得了合理的分割性能，尽管缺乏具体的实验数据。

Abstract: This paper presents an advanced tumor segmentation framework for real-time
MRI-guided radiotherapy, designed for the TrackRAD2025 challenge. Our method
leverages the XMem model, a memory-augmented architecture, to segment tumors
across long cine-MRI sequences. The proposed system efficiently integrates
memory mechanisms to track tumor motion in real-time, achieving high
segmentation accuracy even under challenging conditions with limited annotated
data. Unfortunately, the detailed experimental records have been lost,
preventing us from reporting precise quantitative results at this stage.
Nevertheless, From our preliminary impressions during development, the
XMem-based framework demonstrated reasonable segmentation performance and
satisfied the clinical real-time requirement. Our work contributes to improving
the precision of tumor tracking during MRI-guided radiotherapy, which is
crucial for enhancing the accuracy and safety of cancer treatments.

</details>


### [45] [SSCM: A Spatial-Semantic Consistent Model for Multi-Contrast MRI Super-Resolution](https://arxiv.org/abs/2509.18593)
*Xiaoman Wu,Lubin Gan,Siying Wu,Jing Zhang,Yunwei Ou,Xiaoyan Sun*

Main category: cs.CV

TL;DR: 本论文提出空间语义一致模型（SSCM），旨在提高多对比度磁共振成像超分辨率的效率和效果，克服传统方法在空间和语义一致性上的不足。


<details>
  <summary>Details</summary>
Motivation: MC-MRI SR旨在利用高分辨率参考增强低分辨率对比度，提高成像效率，并保持解剖细节，但存有保持空间语义一致性的挑战。

Method: 提出了一个空间语义一致模型（SSCM），集成动态空间扭曲模块、语义感知令牌聚合块以及空间频率融合块。

Result: SSCM在公私数据集上进行的实验表明，其在空间和语义一致的重建上达到了最新的性能。

Conclusion: SSCM在保持空间和语义一致性的重建效果上实现了最先进的性能，同时参数数量更少。

Abstract: Multi-contrast Magnetic Resonance Imaging super-resolution (MC-MRI SR) aims
to enhance low-resolution (LR) contrasts leveraging high-resolution (HR)
references, shortening acquisition time and improving imaging efficiency while
preserving anatomical details. The main challenge lies in maintaining
spatial-semantic consistency, ensuring anatomical structures remain
well-aligned and coherent despite structural discrepancies and motion between
the target and reference images. Conventional methods insufficiently model
spatial-semantic consistency and underuse frequency-domain information, which
leads to poor fine-grained alignment and inadequate recovery of high-frequency
details. In this paper, we propose the Spatial-Semantic Consistent Model
(SSCM), which integrates a Dynamic Spatial Warping Module for inter-contrast
spatial alignment, a Semantic-Aware Token Aggregation Block for long-range
semantic consistency, and a Spatial-Frequency Fusion Block for fine structure
restoration. Experiments on public and private datasets show that SSCM achieves
state-of-the-art performance with fewer parameters while ensuring spatially and
semantically consistent reconstructions.

</details>


### [46] [OraPO: Oracle-educated Reinforcement Learning for Data-efficient and Factual Radiology Report Generation](https://arxiv.org/abs/2509.18600)
*Zhuoxiao Chen,Hongyang Yu,Ying Xu,Yadan Luo,Long Duong,Yuan-Fang Li*

Main category: cs.CV

TL;DR: 本文提出了一种新方法OraPO，结合FactScore奖励机制，旨在提高放射学报告生成的学习效率，并在资源有限的情况下取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有的放射学报告生成方法的数据和计算资源消耗过大的问题，尤其是在面对稀有或困难的案例时。

Method: 采用单阶段强化学习训练，通过轻量级的oracle步骤将失败的GRPO探索转化为直接的偏好监督。

Result: 在CheXpert Plus数据集上取得了新的SOTA性能，F1得分为0.341，且训练数据减少了2-3个数量级。

Conclusion: 提出的OraPO和FactS框架在有限预算下有效提升了放射学报告生成的学习效率，并在CheXpert Plus数据集上取得了新的SOTA表现。

Abstract: Radiology report generation (RRG) aims to automatically produce clinically
faithful reports from chest X-ray images. Prevailing work typically follows a
scale-driven paradigm, by multi-stage training over large paired corpora and
oversized backbones, making pipelines highly data- and compute-intensive. In
this paper, we propose Oracle-educated GRPO {OraPO) with a FactScore-based
reward (FactS) to tackle the RRG task under constrained budgets. OraPO enables
single-stage, RL-only training by converting failed GRPO explorations on rare
or difficult studies into direct preference supervision via a lightweight
oracle step. FactS grounds learning in diagnostic evidence by extracting atomic
clinical facts and checking entailment against ground-truth labels, yielding
dense, interpretable sentence-level rewards. Together, OraPO and FactS create a
compact and powerful framework that significantly improves learning efficiency
on clinically challenging cases, setting the new SOTA performance on the
CheXpert Plus dataset (0.341 in F1) with 2--3 orders of magnitude less training
data using a small base VLM on modest hardware.

</details>


### [47] [Training-Free Multi-Style Fusion Through Reference-Based Adaptive Modulation](https://arxiv.org/abs/2509.18602)
*Xu Liu,Yibo Lu,Xinxian Wang,Xinyu Wu*

Main category: cs.CV

TL;DR: AMSF提出了一种无训练、可控的多风格融合框架，解决现有方法的局限性，表现优越且可扩展。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅支持单一风格图像，限制了混合审美和风格扩展，同时缺乏合理的机制来平衡多种风格的影响。

Method: 通过对风格图像和文本提示的语义标记解构，结合相似性感知的重标定模块，在无微调的情况下辅助每个交叉注意力层，进行可控的多风格融合。

Result: AMSF在定性和定量评估中证明了其在多风格融合结果上的优越性，能够实现用户可控的平衡融合。

Conclusion: AMSF在多风格融合上表现优于现有方法，并能够灵活扩展至多个风格，具有实用性。

Abstract: We propose Adaptive Multi-Style Fusion (AMSF), a reference-based
training-free framework that enables controllable fusion of multiple reference
styles in diffusion models. Most of the existing reference-based methods are
limited by (a) acceptance of only one style image, thus prohibiting hybrid
aesthetics and scalability to more styles, and (b) lack of a principled
mechanism to balance several stylistic influences. AMSF mitigates these
challenges by encoding all style images and textual hints with a semantic token
decomposition module that is adaptively injected into every cross-attention
layer of an frozen diffusion model. A similarity-aware re-weighting module then
recalibrates, at each denoising step, the attention allocated to every style
component, yielding balanced and user-controllable blends without any
fine-tuning or external adapters. Both qualitative and quantitative evaluations
show that AMSF produces multi-style fusion results that consistently outperform
the state-of-the-art approaches, while its fusion design scales seamlessly to
two or more styles. These capabilities position AMSF as a practical step toward
expressive multi-style generation in diffusion models.

</details>


### [48] [MLF-4DRCNet: Multi-Level Fusion with 4D Radar and Camera for 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2509.18613)
*Yuzhi Wu,Li Xiao,Jun Liu,Guangfeng Jiang,XiangGen Xia*

Main category: cs.CV

TL;DR: MLF-4DRCNet是一种新颖的三维物体检测框架，利用雷达和摄像头的多层次融合，克服了4D雷达点云的缺陷，展示了卓越的性能。


<details>
  <summary>Details</summary>
Motivation: 4D毫米波雷达在自主驾驶中的应用受限于其点云稀疏和噪声问题，现有的融合方法未能有效解决这些缺陷。

Method: 提出一种新的两阶段框架，利用多层次融合4D雷达与摄像头图像进行3D物体检测。

Result: 在View-of-Delft和TJ4DRadSet数据集上，实验结果显示MLF-4DRCNet达到了当前最先进的性能。

Conclusion: MLF-4DRCNet在3D物体检测方面表现出色，性能可与基于LiDAR的模型相媲美。

Abstract: The emerging 4D millimeter-wave radar, measuring the range, azimuth,
elevation, and Doppler velocity of objects, is recognized for its
cost-effectiveness and robustness in autonomous driving. Nevertheless, its
point clouds exhibit significant sparsity and noise, restricting its standalone
application in 3D object detection. Recent 4D radar-camera fusion methods have
provided effective perception. Most existing approaches, however, adopt
explicit Bird's-Eye-View fusion paradigms originally designed for LiDAR-camera
fusion, neglecting radar's inherent drawbacks. Specifically, they overlook the
sparse and incomplete geometry of radar point clouds and restrict fusion to
coarse scene-level integration. To address these problems, we propose
MLF-4DRCNet, a novel two-stage framework for 3D object detection via
multi-level fusion of 4D radar and camera images. Our model incorporates the
point-, scene-, and proposal-level multi-modal information, enabling
comprehensive feature representation. It comprises three crucial components:
the Enhanced Radar Point Encoder (ERPE) module, the Hierarchical Scene Fusion
Pooling (HSFP) module, and the Proposal-Level Fusion Enhancement (PLFE) module.
Operating at the point-level, ERPE densities radar point clouds with 2D image
instances and encodes them into voxels via the proposed Triple-Attention Voxel
Feature Encoder. HSFP dynamically integrates multi-scale voxel features with 2D
image features using deformable attention to capture scene context and adopts
pooling to the fused features. PLFE refines region proposals by fusing image
features, and further integrates with the pooled features from HSFP.
Experimental results on the View-of-Delft (VoD) and TJ4DRadSet datasets
demonstrate that MLF-4DRCNet achieves the state-of-the-art performance.
Notably, it attains performance comparable to LiDAR-based models on the VoD
dataset.

</details>


### [49] [Prompt-Guided Dual Latent Steering for Inversion Problems](https://arxiv.org/abs/2509.18619)
*Yichen Wu,Xu Liu,Chenxuan Zhao,Xinyu Wu*

Main category: cs.CV

TL;DR: 本文提出了PDLS框架，通过结构和语义路径的双重引导，有效提升了被腐蚀图像的重建质量，优于传统单潜在方法。


<details>
  <summary>Details</summary>
Motivation: 反演被腐蚀图像到扩散模型的潜在空间存在挑战，需要平衡结构保真度与语义准确性，以避免语义漂移。

Method: 使用Prompt-Guided Dual Latent Steering (PDLS)框架，通过结构路径和语义路径分解反演过程，并采用线性二次调节器（LQR）动态引导生成轨迹。

Result: 在多项反演任务下，PDLS在生成图像的结构和语义保真度上均表现出显著提升。

Conclusion: PDLS框架在保持图像结构完整性和语义准确性方面表现优于单潜在基线，能够有效地重建被腐蚀的图像。

Abstract: Inverting corrupted images into the latent space of diffusion models is
challenging. Current methods, which encode an image into a single latent
vector, struggle to balance structural fidelity with semantic accuracy, leading
to reconstructions with semantic drift, such as blurred details or incorrect
attributes. To overcome this, we introduce Prompt-Guided Dual Latent Steering
(PDLS), a novel, training-free framework built upon Rectified Flow models for
their stable inversion paths. PDLS decomposes the inversion process into two
complementary streams: a structural path to preserve source integrity and a
semantic path guided by a prompt. We formulate this dual guidance as an optimal
control problem and derive a closed-form solution via a Linear Quadratic
Regulator (LQR). This controller dynamically steers the generative trajectory
at each step, preventing semantic drift while ensuring the preservation of fine
detail without costly, per-image optimization. Extensive experiments on FFHQ-1K
and ImageNet-1K under various inversion tasks, including Gaussian deblurring,
motion deblurring, super-resolution and freeform inpainting, demonstrate that
PDLS produces reconstructions that are both more faithful to the original image
and better aligned with the semantic information than single-latent baselines.

</details>


### [50] [Learning neuroimaging models from health system-scale data](https://arxiv.org/abs/2509.18638)
*Yiwei Lyu,Samir Harake,Asadur Chowdury,Soumyanil Banerjee,Rachel Gologorsky,Shixuan Liu,Anna-Katharina Meissner,Akshay Rao,Chenhui Zhao,Akhil Kondepudi,Cheng Jiang,Xinhai Hou,Rushikesh S. Joshi,Volker Neuschmelting,Ashok Srinivasan,Dawn Kleindorfer,Brian Athey,Vikas Gulani,Aditya Pandey,Honglak Lee,Todd Hollon*

Main category: cs.CV

TL;DR: 该研究开发了Prima，一个基于视觉语言模型的AI工具，通过分析大量MRI研究数据，显著提升了神经影像学的诊断效率和公平性。


<details>
  <summary>Details</summary>
Motivation: 考虑到神经影像学领域中MRI需求的不断增加，尤其是在资源匮乏和农村地区，该研究旨在开发一种AI驱动的模型以提高诊断效率和公平性。

Method: 使用大型学术健康系统的数据，引入了新的视觉语言模型Prima，通过对超过220,000个MRI研究的训练，提供了可转移的MRI特征。

Result: Prima在518种主要神经疾病的放射诊断中达到92.0的平均ROC曲线区域，超越了其他先进的AI模型，并展示了在多个患者群体和MRI系统中的应用潜力。

Conclusion: Prima展示了在神经影像学领域中应用视觉语言模型的巨大潜力，能够提高诊断准确性并改善医疗服务的公平性。

Abstract: Neuroimaging is a ubiquitous tool for evaluating patients with neurological
diseases. The global demand for magnetic resonance imaging (MRI) studies has
risen steadily, placing significant strain on health systems, prolonging
turnaround times, and intensifying physician burnout \cite{Chen2017-bt,
Rula2024-qp-1}. These challenges disproportionately impact patients in
low-resource and rural settings. Here, we utilized a large academic health
system as a data engine to develop Prima, the first vision language model (VLM)
serving as an AI foundation for neuroimaging that supports real-world, clinical
MRI studies as input. Trained on over 220,000 MRI studies, Prima uses a
hierarchical vision architecture that provides general and transferable MRI
features. Prima was tested in a 1-year health system-wide study that included
30K MRI studies. Across 52 radiologic diagnoses from the major neurologic
disorders, including neoplastic, inflammatory, infectious, and developmental
lesions, Prima achieved a mean diagnostic area under the ROC curve of 92.0,
outperforming other state-of-the-art general and medical AI models. Prima
offers explainable differential diagnoses, worklist priority for radiologists,
and clinical referral recommendations across diverse patient demographics and
MRI systems. Prima demonstrates algorithmic fairness across sensitive groups
and can help mitigate health system biases, such as prolonged turnaround times
for low-resource populations. These findings highlight the transformative
potential of health system-scale VLMs and Prima's role in advancing AI-driven
healthcare.

</details>


### [51] [Understanding-in-Generation: Reinforcing Generative Capability of Unified Model via Infusing Understanding into Generation](https://arxiv.org/abs/2509.18639)
*Yuanhuiyi Lyu,Chi Kit Wong,Chenfei Liao,Lutao Jiang,Xu Zheng,Zexin Lu,Linfeng Zhang,Xuming Hu*

Main category: cs.CV

TL;DR: 本文提出一种新的理解与生成整合框架UiG，通过新的图像编辑策略提升文本到图像生成的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的推理方法将理解与生成过程分开，限制了统一模型在生成能力上的改进。

Method: 提出了一种名为Understanding-in-Generation (UiG)的新颖推理框架，用于增强统一模型的生成性能。

Result: 在TIIF基准的长提示设置下，UiG框架实现了3.92%的性能提升。

Conclusion: UiG框架在文本到图像生成方面显著改善了已有的方法，尤其是在长提示设置下。

Abstract: Recent works have made notable advancements in enhancing unified models for
text-to-image generation through the Chain-of-Thought (CoT). However, these
reasoning methods separate the processes of understanding and generation, which
limits their ability to guide the reasoning of unified models in addressing the
deficiencies of their generative capabilities. To this end, we propose a novel
reasoning framework for unified models, Understanding-in-Generation (UiG),
which harnesses the robust understanding capabilities of unified models to
reinforce their performance in image generation. The core insight of our UiG is
to integrate generative guidance by the strong understanding capabilities
during the reasoning process, thereby mitigating the limitations of generative
abilities. To achieve this, we introduce "Image Editing" as a bridge to infuse
understanding into the generation process. Initially, we verify the generated
image and incorporate the understanding of unified models into the editing
instructions. Subsequently, we enhance the generated image step by step,
gradually infusing the understanding into the generation process. Our UiG
framework demonstrates a significant performance improvement in text-to-image
generation over existing text-to-image reasoning methods, e.g., a 3.92% gain on
the long prompt setting of the TIIF benchmark. The project code:
https://github.com/QC-LY/UiG

</details>


### [52] [Zero-shot Monocular Metric Depth for Endoscopic Images](https://arxiv.org/abs/2509.18642)
*Nicolas Toussaint,Emanuele Colleoni,Ricardo Sanchez-Matilla,Joshua Sutcliffe,Vanessa Thompson,Muhammad Asad,Imanol Luengo,Danail Stoyanov*

Main category: cs.CV

TL;DR: 本论文提供了内镜图像深度估计的基准测试和合成数据集，促进了该领域的发展并显著提高了深度估计模型在真实数据上的准确性。


<details>
  <summary>Details</summary>
Motivation: 受益于基础模型和变压器网络的快速发展，本研究旨在弥补内镜图像深度估计中的基准测试和高质量数据集的不足。

Method: 提出了一个全面的基准测试，评估了最先进的深度估计模型，并介绍了一个新的合成数据集（EndoSynth），配有真实的度量深度和分割掩膜。

Result: 通过使用我们的合成数据集进行深度基础模型的微调，显著提高了在大多数未见真实数据上的准确性。

Conclusion: 本研究通过提供一个基准测试和一个合成数据集，促进了内镜图像深度估计领域的进步，并为未来研究提供了重要资源。

Abstract: Monocular relative and metric depth estimation has seen a tremendous boost in
the last few years due to the sharp advancements in foundation models and in
particular transformer based networks. As we start to see applications to the
domain of endoscopic images, there is still a lack of robust benchmarks and
high-quality datasets in that area. This paper addresses these limitations by
presenting a comprehensive benchmark of state-of-the-art (metric and relative)
depth estimation models evaluated on real, unseen endoscopic images, providing
critical insights into their generalisation and performance in clinical
scenarios. Additionally, we introduce and publish a novel synthetic dataset
(EndoSynth) of endoscopic surgical instruments paired with ground truth metric
depth and segmentation masks, designed to bridge the gap between synthetic and
real-world data. We demonstrate that fine-tuning depth foundation models using
our synthetic dataset boosts accuracy on most unseen real data by a significant
margin. By providing both a benchmark and a synthetic dataset, this work
advances the field of depth estimation for endoscopic images and serves as an
important resource for future research. Project page, EndoSynth dataset and
trained weights are available at https://github.com/TouchSurgery/EndoSynth.

</details>


### [53] [LEAF-Mamba: Local Emphatic and Adaptive Fusion State Space Model for RGB-D Salient Object Detection](https://arxiv.org/abs/2509.18683)
*Lanhu Wu,Zilin Gao,Hao Fei,Mong-Li Lee,Wynne Hsu*

Main category: cs.CV

TL;DR: 本文提出了一种新的LEAF-Mamba模型，用于RGB-D显著目标检测，解决了现有方法的局部语义和跨模态融合不足的问题，展现出更好的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的RGB-D显著目标检测方法主要依赖于CNN或Vision Transformers，存在性能与计算效率之间的平衡挑战。同时，直接应用状态空间模型会导致局部语义不足和跨模态融合不充分。

Method: 提出了一种局部强调与自适应融合的状态空间模型（LEAF-Mamba），包含局部强调状态空间模块（LE-SSM）和自适应融合模块（AFM）。

Result: 通过大量实验，LEAF-Mamba在效能和效率上持续超越16种最先进的RGB-D显著目标检测方法。

Conclusion: LEAF-Mamba在RGB-D显著目标检测中表现优越，且能有效推广至RGB-T任务，显示出强大的泛化能力。

Abstract: RGB-D salient object detection (SOD) aims to identify the most conspicuous
objects in a scene with the incorporation of depth cues. Existing methods
mainly rely on CNNs, limited by the local receptive fields, or Vision
Transformers that suffer from the cost of quadratic complexity, posing a
challenge in balancing performance and computational efficiency. Recently,
state space models (SSM), Mamba, have shown great potential for modeling
long-range dependency with linear complexity. However, directly applying SSM to
RGB-D SOD may lead to deficient local semantics as well as the inadequate
cross-modality fusion. To address these issues, we propose a Local Emphatic and
Adaptive Fusion state space model (LEAF-Mamba) that contains two novel
components: 1) a local emphatic state space module (LE-SSM) to capture
multi-scale local dependencies for both modalities. 2) an SSM-based adaptive
fusion module (AFM) for complementary cross-modality interaction and reliable
cross-modality integration. Extensive experiments demonstrate that the
LEAF-Mamba consistently outperforms 16 state-of-the-art RGB-D SOD methods in
both efficacy and efficiency. Moreover, our method can achieve excellent
performance on the RGB-T SOD task, proving a powerful generalization ability.

</details>


### [54] [Lightweight Vision Transformer with Window and Spatial Attention for Food Image Classification](https://arxiv.org/abs/2509.18692)
*Xinle Gao,Linghui Ye,Zhiyong Xiao*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级的食品图像分类算法，结合WMHAM和SAM，有效提高了分类的准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 随着食品行业对生产质量和效率要求的提高，自动化质量控制和食品安全监督的需求也不断增加。

Method: 结合窗口多头注意力机制（WMHAM）和空间注意力机制（SAM）来提高食品图像分类的效率和准确性。

Result: 在Food-101和Vireo Food-172数据集上的实验表明，模型实现了95.24%和94.33%的分类准确率，同时参数和FLOPs显著低于基线方法。

Conclusion: 本研究提出的轻量级食品图像分类算法在计算效率和分类性能之间实现了有效平衡，适合在资源受限的环境中部署。

Abstract: With the rapid development of society and continuous advances in science and
technology, the food industry increasingly demands higher production quality
and efficiency. Food image classification plays a vital role in enabling
automated quality control on production lines, supporting food safety
supervision, and promoting intelligent agricultural production. However, this
task faces challenges due to the large number of parameters and high
computational complexity of Vision Transformer models. To address these issues,
we propose a lightweight food image classification algorithm that integrates a
Window Multi-Head Attention Mechanism (WMHAM) and a Spatial Attention Mechanism
(SAM). The WMHAM reduces computational cost by capturing local and global
contextual features through efficient window partitioning, while the SAM
adaptively emphasizes key spatial regions to improve discriminative feature
representation. Experiments conducted on the Food-101 and Vireo Food-172
datasets demonstrate that our model achieves accuracies of 95.24% and 94.33%,
respectively, while significantly reducing parameters and FLOPs compared with
baseline methods. These results confirm that the proposed approach achieves an
effective balance between computational efficiency and classification
performance, making it well-suited for deployment in resource-constrained
environments.

</details>


### [55] [OSDA: A Framework for Open-Set Discovery and Automatic Interpretation of Land-cover in Remote Sensing Imagery](https://arxiv.org/abs/2509.18693)
*Siyi Chen,Kai Wang,Weicong Pang,Ruiming Yang,Ziru Chen,Renjun Gao,Alexis Kai Hon Lau,Dasa Gu,Chenchen Zhang,Cheng Li*

Main category: cs.CV

TL;DR: 本研究提出了一种新框架OSDA，用于开放集土地覆盖的发现、分割和描述，旨在实现无需注释的精确监测和分析。


<details>
  <summary>Details</summary>
Motivation: 开放集土地覆盖分析需要在没有类别监督的情况下检测和分割新型物体，并通过多模态推理赋予可解释的语义标签。

Method: OSDA框架包括三个阶段：使用精细调整的分割模型进行精准发现和掩模提取，利用多模态大型语言模型进行语义属性和上下文描述，以及LLM作为评审者和对评估结果的人工评分。

Result: OSDA通过结合像素级准确性和高级语义理解，解决了开放世界遥感解释中的关键挑战，并支持跨多种卫星图像的鲁棒评估，而无需人工注释。

Conclusion: 本研究提出的OSDA框架为动态土地覆盖监测提供了一种可扩展和可解释的解决方案，显示出自动化地图更新和大规模地球观测分析的强大潜力。

Abstract: Open-set land-cover analysis in remote sensing requires the ability to
achieve fine-grained spatial localization and semantically open categorization.
This involves not only detecting and segmenting novel objects without
categorical supervision but also assigning them interpretable semantic labels
through multimodal reasoning. In this study, we introduce OSDA, an integrated
three-stage framework for annotation-free open-set land-cover discovery,
segmentation, and description. The pipeline consists of: (1) precise discovery
and mask extraction with a promptable fine-tuned segmentation model (SAM), (2)
semantic attribution and contextual description via a two-phase fine-tuned
multimodal large language model (MLLM), and (3) LLM-as-judge and manual scoring
of the MLLMs evaluation. By combining pixel-level accuracy with high-level
semantic understanding, OSDA addresses key challenges in open-world remote
sensing interpretation. Designed to be architecture-agnostic and label-free,
the framework supports robust evaluation across diverse satellite imagery
without requiring manual annotation. Our work provides a scalable and
interpretable solution for dynamic land-cover monitoring, showing strong
potential for automated cartographic updating and large-scale earth observation
analysis.

</details>


### [56] [Overview of PlantCLEF 2021: cross-domain plant identification](https://arxiv.org/abs/2509.18697)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: 本研究通过利用植物标本馆的数据，提升了自动植物识别在热带地区的能力，并评估了相关方法和成果。


<details>
  <summary>Details</summary>
Motivation: 目前的自动植物识别主要集中在特定地区，而热带地区的多样性受到忽视，因此需要利用已有的植物标本数据提高识别准确性。

Method: 通过跨领域分类任务，结合植物标本的图像和元数据，以及5种形态和功能特征，进行训练和评估。

Result: 在南美圭亚那盾地区的数据集中，本挑战显示了基于植物标本的模型在植物识别中的有效性。

Conclusion: 本研究通过使用植物标本馆的收藏，显著提高了在数据匮乏地区的植物自动识别能力。

Abstract: Automated plant identification has improved considerably thanks to recent
advances in deep learning and the availability of training data with more and
more field photos. However, this profusion of data concerns only a few tens of
thousands of species, mainly located in North America and Western Europe, much
less in the richest regions in terms of biodiversity such as tropical
countries. On the other hand, for several centuries, botanists have
systematically collected, catalogued and stored plant specimens in herbaria,
especially in tropical regions, and recent efforts by the biodiversity
informatics community have made it possible to put millions of digitised
records online. The LifeCLEF 2021 plant identification challenge (or "PlantCLEF
2021") was designed to assess the extent to which automated identification of
flora in data-poor regions can be improved by using herbarium collections. It
is based on a dataset of about 1,000 species mainly focused on the Guiana
Shield of South America, a region known to have one of the highest plant
diversities in the world. The challenge was evaluated as a cross-domain
classification task where the training set consisted of several hundred
thousand herbarium sheets and a few thousand photos to allow learning a
correspondence between the two domains. In addition to the usual metadata
(location, date, author, taxonomy), the training data also includes the values
of 5 morphological and functional traits for each species. The test set
consisted exclusively of photos taken in the field. This article presents the
resources and evaluations of the assessment carried out, summarises the
approaches and systems used by the participating research groups and provides
an analysis of the main results.

</details>


### [57] [AGSwap: Overcoming Category Boundaries in Object Fusion via Adaptive Group Swapping](https://arxiv.org/abs/2509.18699)
*Zedong Zhang,Ying Tai,Jianjun Qian,Jian Yang,Jun Li*

Main category: cs.CV

TL;DR: 本文提出了自适应组交换（AGSwap）方法及跨类别对象融合（COF）数据集，以解决文本到图像生成中的问题，并在多个实验中取得了优异的表现。


<details>
  <summary>Details</summary>
Motivation: 目前的生成方法存在偏见、视觉混乱和语义不一致的问题，且缺乏全面的基准数据集。

Method: 提出了自适应组交换（AGSwap），包括组内嵌入交换和自适应组更新两个关键组件。

Result: AGSwap在多种简单和复杂的提示下，超过了当前最先进的组合文本到图像生成方法。

Conclusion: AGSwap在生成文本到图像的任务中展现了优越性，能有效融合跨类别对象。

Abstract: Fusing cross-category objects to a single coherent object has gained
increasing attention in text-to-image (T2I) generation due to its broad
applications in virtual reality, digital media, film, and gaming. However,
existing methods often produce biased, visually chaotic, or semantically
inconsistent results due to overlapping artifacts and poor integration.
Moreover, progress in this field has been limited by the absence of a
comprehensive benchmark dataset. To address these problems, we propose
\textbf{Adaptive Group Swapping (AGSwap)}, a simple yet highly effective
approach comprising two key components: (1) Group-wise Embedding Swapping,
which fuses semantic attributes from different concepts through feature
manipulation, and (2) Adaptive Group Updating, a dynamic optimization mechanism
guided by a balance evaluation score to ensure coherent synthesis.
Additionally, we introduce \textbf{Cross-category Object Fusion (COF)}, a
large-scale, hierarchically structured dataset built upon ImageNet-1K and
WordNet. COF includes 95 superclasses, each with 10 subclasses, enabling
451,250 unique fusion pairs. Extensive experiments demonstrate that AGSwap
outperforms state-of-the-art compositional T2I methods, including GPT-Image-1
using simple and complex prompts.

</details>


### [58] [Overview of LifeCLEF Plant Identification task 2019: diving into data deficient tropical countries](https://arxiv.org/abs/2509.18705)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: 本文讨论了PlantCLEF 2019挑战赛对自动植物识别的评估，强调了在数据稀缺区域进行植物识别的重要性与实际成果。


<details>
  <summary>Details</summary>
Motivation: 在深度学习和训练数据的进步下，尽管植物自动识别有所改善，但仍有大量物种未被充分研究，尤其是在数据匮乏的地区。

Method: 通过对来自多个研究团队的系统进行比较，并与最佳热带植物专家的表现进行对比，评估植物自动识别的效果。

Result: 挑战赛基于针对十万个物种的特定数据集，集中在植物和动物多样性极高的地区，结果分析揭示了系统性能及其与专家表现的比较。

Conclusion: 本文总结了PlantCLEF 2019挑战赛的资源、评估和主要结果，展示了植物自动识别领域的进展与现状。

Abstract: Automated identification of plants has improved considerably thanks to the
recent progress in deep learning and the availability of training data.
However, this profusion of data only concerns a few tens of thousands of
species, while the planet has nearly 369K. The LifeCLEF 2019 Plant
Identification challenge (or "PlantCLEF 2019") was designed to evaluate
automated identification on the flora of data deficient regions. It is based on
a dataset of 10K species mainly focused on the Guiana shield and the Northern
Amazon rainforest, an area known to have one of the greatest diversity of
plants and animals in the world. As in the previous edition, a comparison of
the performance of the systems evaluated with the best tropical flora experts
was carried out. This paper presents the resources and assessments of the
challenge, summarizes the approaches and systems employed by the participating
research groups, and provides an analysis of the main outcomes.

</details>


### [59] [RSVG-ZeroOV: Exploring a Training-Free Framework for Zero-Shot Open-Vocabulary Visual Grounding in Remote Sensing Images](https://arxiv.org/abs/2509.18711)
*Ke Li,Di Wang,Ting Wang,Fuyu Dong,Yiming Zhang,Luyao Zhang,Xiangyu Wang,Shaofeng Li,Quan Wang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为RSVG-ZeroOV的框架，旨在提高远程感知视觉定位中开放词汇的性能，特别是在不依赖大量高质量数据集和复杂训练的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有的远程感知视觉定位方法受限于封闭词汇，难以在开放世界情境中应用，且依赖昂贵的数据集和复杂的微调。

Method: 结合视觉-语言模型和扩散模型，设计了三个关键阶段：获取图像-文本的交互注意力图、利用扩散模型填补物体的结构和形状信息空白，以及引入注意力演化模块优化分割结果。

Result: RSVG-ZeroOV在不进行任务特定训练的情况下，通过三个阶段处理，显著提高了弱监督和零-shot方法的性能。

Conclusion: RSVG-ZeroOV提供了一种高效且可扩展的解决方案，在不需繁琐的特定任务训练下，成功实现了零-shot的开放词汇视觉定位。

Abstract: Remote sensing visual grounding (RSVG) aims to localize objects in remote
sensing images based on free-form natural language expressions. Existing
approaches are typically constrained to closed-set vocabularies, limiting their
applicability in open-world scenarios. While recent attempts to leverage
generic foundation models for open-vocabulary RSVG, they overly rely on
expensive high-quality datasets and time-consuming fine-tuning. To address
these limitations, we propose \textbf{RSVG-ZeroOV}, a training-free framework
that aims to explore the potential of frozen generic foundation models for
zero-shot open-vocabulary RSVG. Specifically, RSVG-ZeroOV comprises three key
stages: (i) Overview: We utilize a vision-language model (VLM) to obtain
cross-attention\footnote[1]{In this paper, although decoder-only VLMs use
self-attention over all tokens, we refer to the image-text interaction part as
cross-attention to distinguish it from pure visual self-attention.}maps that
capture semantic correlations between text queries and visual regions. (ii)
Focus: By leveraging the fine-grained modeling priors of a diffusion model
(DM), we fill in gaps in structural and shape information of objects, which are
often overlooked by VLM. (iii) Evolve: A simple yet effective attention
evolution module is introduced to suppress irrelevant activations, yielding
purified segmentation masks over the referred objects. Without cumbersome
task-specific training, RSVG-ZeroOV offers an efficient and scalable solution.
Extensive experiments demonstrate that the proposed framework consistently
outperforms existing weakly-supervised and zero-shot methods.

</details>


### [60] [What Makes You Unique? Attribute Prompt Composition for Object Re-Identification](https://arxiv.org/abs/2509.18715)
*Yingquan Wang,Pingping Zhang,Chong Sun,Dong Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: 提出了APC框架，通过属性提示生成和快速-慢速训练策略，提升了物体重识别（ReID）在各种场景下的辨别和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有模型在单域或跨域场景下的局限性，导致在真实世界应用中的效果不佳，尤其是模型容易过拟合域特定特征或抑制身份特征的辨别信号。

Method: 采用了属性提示生成器（APG）和快速-慢速训练策略（FSTS），结合了语义属性字典和提示组合模块，以增强ReID的辨别和泛化能力。

Result: 在传统和域泛化ReID数据集上的广泛实验，显示出APC框架在辨别和泛化方面的优越性能。

Conclusion: 实验结果表明，所提出的APC框架在单域和跨域场景下均优于现有最先进方法，兼具良好的辨别能力和泛化能力。

Abstract: Object Re-IDentification (ReID) aims to recognize individuals across
non-overlapping camera views. While recent advances have achieved remarkable
progress, most existing models are constrained to either single-domain or
cross-domain scenarios, limiting their real-world applicability. Single-domain
models tend to overfit to domain-specific features, whereas cross-domain models
often rely on diverse normalization strategies that may inadvertently suppress
identity-specific discriminative cues. To address these limitations, we propose
an Attribute Prompt Composition (APC) framework, which exploits textual
semantics to jointly enhance discrimination and generalization. Specifically,
we design an Attribute Prompt Generator (APG) consisting of a Semantic
Attribute Dictionary (SAD) and a Prompt Composition Module (PCM). SAD is an
over-complete attribute dictionary to provide rich semantic descriptions, while
PCM adaptively composes relevant attributes from SAD to generate discriminative
attribute-aware features. In addition, motivated by the strong generalization
ability of Vision-Language Models (VLM), we propose a Fast-Slow Training
Strategy (FSTS) to balance ReID-specific discrimination and generalizable
representation learning. Specifically, FSTS adopts a Fast Update Stream (FUS)
to rapidly acquire ReID-specific discriminative knowledge and a Slow Update
Stream (SUS) to retain the generalizable knowledge inherited from the
pre-trained VLM. Through a mutual interaction, the framework effectively
focuses on ReID-relevant features while mitigating overfitting. Extensive
experiments on both conventional and Domain Generalized (DG) ReID datasets
demonstrate that our framework surpasses state-of-the-art methods, exhibiting
superior performances in terms of both discrimination and generalization. The
source code is available at https://github.com/AWangYQ/APC.

</details>


### [61] [Pre-training CLIP against Data Poisoning with Optimal Transport-based Matching and Alignment](https://arxiv.org/abs/2509.18717)
*Tong Zhang,Kuofeng Gao,Jiawang Bai,Leo Yu Zhang,Xin Yin,Zonghui Wang,Shouling Ji,Wenzhi Chen*

Main category: cs.CV

TL;DR: 本研究提出了一种基于最优传输的OTCCLIP框架，改进了CLIP模型对抗数据中毒和后门攻击的防御能力。


<details>
  <summary>Details</summary>
Motivation: 针对CLIP模型受到的数据中毒和后门攻击弊端，传统的防御方法仅依赖全局表示，忽视了细粒度特征，可能导致错误的图像-文本对。

Method: 提出了一种基于最优传输的框架（OTCCLIP），通过优化距离度量重构图像-文本对，并使用最优传输目标函数促进细粒度对齐。

Result: OTCCLIP通过基于细粒度特征集的最优传输距离新匹配图像-文本对，有效提升了模型的表现。

Conclusion: OTCCLIP显著降低了数据中毒攻击的成功率，并提高了CLIP在被污染数据集上零-shot和线性探测的性能。

Abstract: Recent studies have shown that Contrastive Language-Image Pre-training (CLIP)
models are threatened by targeted data poisoning and backdoor attacks due to
massive training image-caption pairs crawled from the Internet. Previous
defense methods correct poisoned image-caption pairs by matching a new caption
for each image. However, the matching process relies solely on the global
representations of images and captions, overlooking fine-grained features of
visual and textual features. It may introduce incorrect image-caption pairs and
harm the CLIP pre-training. To address their limitations, we propose an Optimal
Transport-based framework to reconstruct image-caption pairs, named OTCCLIP. We
propose a new optimal transport-based distance measure between fine-grained
visual and textual feature sets and re-assign new captions based on the
proposed optimal transport distance. Additionally, to further reduce the
negative impact of mismatched pairs, we encourage the inter- and intra-modality
fine-grained alignment by employing optimal transport-based objective
functions. Our experiments demonstrate that OTCCLIP can successfully decrease
the attack success rates of poisoning attacks. Also, compared to previous
methods, OTCCLIP significantly improves CLIP's zero-shot and linear probing
performance trained on poisoned datasets.

</details>


### [62] [Knowledge Transfer from Interaction Learning](https://arxiv.org/abs/2509.18733)
*Yilin Gao,Kangyi Chen,Zhongxing Peng,Hengjie Lu,Shugong Xu*

Main category: cs.CV

TL;DR: 本研究提出了一种新的学习交互的框架，通过更有效的知识转移和模型优化，提升了视觉基础模型的性能，尤其在跨域任务中表现突出。


<details>
  <summary>Details</summary>
Motivation: 解决视觉基础模型在知识转移方面的基本局限，提升其对多样化视觉任务的泛化能力。

Method: 提出了交互查询和基于交互的监督作为两项技术创新，利用VLM中的交叉模态注意机制。

Result: 在多个基准测试中实现了一致的性能提升，特别是在TinyImageNet分类和COCO检测/分割上，分别获得了3.3 mAP和2.4 AP的增益，同时具备最小的参数开销和更快的收敛速度。

Conclusion: 提出的LFI框架通过显式建模视觉理解的交互过程，实现了知识的有效转移和更好的通用性，尤其在跨域场景中表现优异。

Abstract: Current visual foundation models (VFMs) face a fundamental limitation in
transferring knowledge from vision language models (VLMs), while VLMs excel at
modeling cross-modal interactions through unified representation spaces,
existing VFMs predominantly adopt result-oriented paradigms that neglect the
underlying interaction processes. This representational discrepancy hinders
effective knowledge transfer and limits generalization across diverse vision
tasks. We propose Learning from Interactions (LFI), a cognitive-inspired
framework that addresses this gap by explicitly modeling visual understanding
as an interactive process. Our key insight is that capturing the dynamic
interaction patterns encoded in pre-trained VLMs enables more faithful and
efficient knowledge transfer to VFMs. The approach centers on two technical
innovations, Interaction Queries, which maintain persistent relational
structures across network layers, and interaction-based supervision, derived
from the cross-modal attention mechanisms of VLMs. Comprehensive experiments
demonstrate consistent improvements across multiple benchmarks, achieving 3.3
and 1.6mAP/2.4AP absolute gains on TinyImageNet classification and COCO
detection/segmentation respectively, with minimal parameter overhead and faster
convergence. The framework particularly excels in cross-domain settings,
delivering 2.4 and 9.3 zero-shot improvements on PACS and VLCS. Human
evaluations further confirm its cognitive alignment, outperforming
result-oriented methods by 2.7 times in semantic consistency metrics.

</details>


### [63] [HyPSAM: Hybrid Prompt-driven Segment Anything Model for RGB-Thermal Salient Object Detection](https://arxiv.org/abs/2509.18738)
*Ruichao Hou,Xingyuan Li,Tongwei Ren,Dongming Zhou,Gangshan Wu,Jinde Cao*

Main category: cs.CV

TL;DR: HyPSAM 是一种新型 RGB-T SOD 模型，通过动态融合网络和插件优化网络，克服了特征融合和数据稀缺的问题，表现出色。


<details>
  <summary>Details</summary>
Motivation: RGB-T SOD 中，由于特征融合不足和数据稀缺，精确边界和完整物体的检测仍然具有挑战性。

Method: 提出了一种新颖的混合提示驱动的模型 HyPSAM，使用 DFNet 生成初始显著性图，并通过 P2RNet 进行显著性图的优化。

Result: 在三个公共数据集上的大量实验表明，我们的方法在性能上达到了最先进的水平，并显著增强了不同 RGB-T SOD 方法的性能。

Conclusion: HyPSAM 在 RGB-T SOD 上展现了最先进的性能，证明了提示工程在这一领域的重要性和潜力。

Abstract: RGB-thermal salient object detection (RGB-T SOD) aims to identify prominent
objects by integrating complementary information from RGB and thermal
modalities. However, learning the precise boundaries and complete objects
remains challenging due to the intrinsic insufficient feature fusion and the
extrinsic limitations of data scarcity. In this paper, we propose a novel
hybrid prompt-driven segment anything model (HyPSAM), which leverages the
zero-shot generalization capabilities of the segment anything model (SAM) for
RGB-T SOD. Specifically, we first propose a dynamic fusion network (DFNet) that
generates high-quality initial saliency maps as visual prompts. DFNet employs
dynamic convolution and multi-branch decoding to facilitate adaptive
cross-modality interaction, overcoming the limitations of fixed-parameter
kernels and enhancing multi-modal feature representation. Moreover, we propose
a plug-and-play refinement network (P2RNet), which serves as a general
optimization strategy to guide SAM in refining saliency maps by using hybrid
prompts. The text prompt ensures reliable modality input, while the mask and
box prompts enable precise salient object localization. Extensive experiments
on three public datasets demonstrate that our method achieves state-of-the-art
performance. Notably, HyPSAM has remarkable versatility, seamlessly integrating
with different RGB-T SOD methods to achieve significant performance gains,
thereby highlighting the potential of prompt engineering in this field. The
code and results of our method are available at:
https://github.com/milotic233/HyPSAM.

</details>


### [64] [Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions](https://arxiv.org/abs/2509.18847)
*Junhao Su,Yuanliang Wan,Junwei Yang,Hengyu Shi,Tianyang Han,Junfeng Luo,Yurui Qiu*

Main category: cs.CV

TL;DR: 本研究提出结构化反思机制，优化工具调用过程，提高了模型在多轮交互中的可靠性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前的自我反思方法脆弱，容易在多轮交互中重复错误。本研究旨在通过结构化反思改善模型的错误诊断与修复能力。

Method: 采用结构化反思方法，结合DAPO与GSPO目标，并设计专门的奖励机制，通过实验验证反思过程的有效性。

Result: 在BFCL v3和Tool-Reflection-Bench上的实验表明，采用结构化反思机制后，模型在多轮工具调用的成功率和错误恢复能力上显著提升，同时减少了重复调用。

Conclusion: 通过明确的反思机制和目标导向训练，模型在工具调用的成功率和错误恢复能力上有显著提升，同时减少了多余的调用。这为提升代理在执行任务时的可靠性提供了可重复的学习路径。

Abstract: Tool-augmented large language models (LLMs) are usually trained with
supervised imitation or coarse-grained reinforcement learning that optimizes
single tool calls. Current self-reflection practices rely on heuristic prompts
or one-way reasoning: the model is urged to 'think more' instead of learning
error diagnosis and repair. This is fragile in multi-turn interactions; after a
failure the model often repeats the same mistake. We propose structured
reflection, which turns the path from error to repair into an explicit,
controllable, and trainable action. The agent produces a short yet precise
reflection: it diagnoses the failure using evidence from the previous step and
then proposes a correct, executable follow-up call. For training we combine
DAPO and GSPO objectives with a reward scheme tailored to tool use, optimizing
the stepwise strategy Reflect, then Call, then Final. To evaluate, we introduce
Tool-Reflection-Bench, a lightweight benchmark that programmatically checks
structural validity, executability, parameter correctness, and result
consistency. Tasks are built as mini trajectories of erroneous call,
reflection, and corrected call, with disjoint train and test splits.
Experiments on BFCL v3 and Tool-Reflection-Bench show large gains in multi-turn
tool-call success and error recovery, and a reduction of redundant calls. These
results indicate that making reflection explicit and optimizing it directly
improves the reliability of tool interaction and offers a reproducible path for
agents to learn from failure.

</details>


### [65] [TriFusion-AE: Language-Guided Depth and LiDAR Fusion for Robust Point Cloud Processing](https://arxiv.org/abs/2509.18743)
*Susmit Neogi*

Main category: cs.CV

TL;DR: 本研究提出的TriFusion-AE模型通过结合文本、深度图和LiDAR点云来增强对抗攻击和噪声的鲁棒性，取得优于传统CNN自编码器的性能。


<details>
  <summary>Details</summary>
Motivation: LiDAR点云在自动驾驶和机器人领域至关重要，但受到噪声、遮挡和对抗性干扰的影响。

Method: 提出了一个多模态的交叉注意力自编码器TriFusion-AE，结合文本先验、单目深度图和LiDAR点云，旨在提高鲁棒性。

Result: TriFusion-AE能够学习到对随机噪声和对抗扰动具有韧性的表示，并在nuScenes-mini数据集上进行评估，反映出真实低数据部署场景。

Conclusion: TriFusion-AE模型在强对抗攻击和重噪声条件下，能够显著提升重建的鲁棒性，而CNN基础的自编码器则面临崩溃。

Abstract: LiDAR-based perception is central to autonomous driving and robotics, yet raw
point clouds remain highly vulnerable to noise, occlusion, and adversarial
corruptions. Autoencoders offer a natural framework for denoising and
reconstruction, but their performance degrades under challenging real-world
conditions. In this work, we propose TriFusion-AE, a multimodal cross-attention
autoencoder that integrates textual priors, monocular depth maps from
multi-view images, and LiDAR point clouds to improve robustness. By aligning
semantic cues from text, geometric (depth) features from images, and spatial
structure from LiDAR, TriFusion-AE learns representations that are resilient to
stochastic noise and adversarial perturbations. Interestingly, while showing
limited gains under mild perturbations, our model achieves significantly more
robust reconstruction under strong adversarial attacks and heavy noise, where
CNN-based autoencoders collapse. We evaluate on the nuScenes-mini dataset to
reflect realistic low-data deployment scenarios. Our multimodal fusion
framework is designed to be model-agnostic, enabling seamless integration with
any CNN-based point cloud autoencoder for joint representation learning.

</details>


### [66] [VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction](https://arxiv.org/abs/2509.19002)
*Hao Wang,Eiki Murata,Lingfang Zhang,Ayako Sato,So Fukuda,Ziqi Yin,Wentao Hu,Keisuke Nakao,Yusuke Nakamura,Sebastian Zwirner,Yi-Chia Chen,Hiroyuki Otomo,Hiroki Ouchi,Daisuke Kawahara*

Main category: cs.CV

TL;DR: 我们提出VIR-Bench基准，评估MLLM在长途旅行视频上的表现，结果显示模型面临挑战，且我们的旅行规划代理展示了评估协议的实际应用效果。


<details>
  <summary>Details</summary>
Motivation: 现有视频基准主要集中于室内场景或短途户外活动，而长途旅行的挑战尚未被充分探索。掌握广泛的地理时间轨迹对下一代MLLM至关重要。

Method: 我们提出了VIR-Bench，一个新基准，包含200个旅行视频，以行程重构为任务，评估MLLM的地理和时间智能。

Result: 实验结果显示，现有的最先进MLLM，包括一些专有模型，在处理跨越较大空间和时间尺度的视频时难以取得高分。通过对比分析，我们开发了一个旅行规划代理，其行程建议显著改善。

Conclusion: 我们的评估协议不仅有效评估模型，还在用户应用中带来了具体的性能提升。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly enhanced video understanding capabilities, opening new
possibilities for practical applications. Yet current video benchmarks focus
largely on indoor scenes or short-range outdoor activities, leaving the
challenges associated with long-distance travel largely unexplored. Mastering
extended geospatial-temporal trajectories is critical for next-generation
MLLMs, underpinning real-world tasks such as embodied-AI planning and
navigation. To bridge this gap, we present VIR-Bench, a novel benchmark
consisting of 200 travel videos that frames itinerary reconstruction as a
challenging task designed to evaluate and push forward MLLMs'
geospatial-temporal intelligence. Experimental results reveal that
state-of-the-art MLLMs, including proprietary ones, struggle to achieve high
scores, underscoring the difficulty of handling videos that span extended
spatial and temporal scales. Moreover, we conduct an in-depth case study in
which we develop a prototype travel-planning agent that leverages the insights
gained from VIR-Bench. The agent's markedly improved itinerary recommendations
verify that our evaluation protocol not only benchmarks models effectively but
also translates into concrete performance gains in user-facing applications.

</details>


### [67] [COLT: Enhancing Video Large Language Models with Continual Tool Usage](https://arxiv.org/abs/2509.18754)
*Yuyang Liu,Xinyuan Shi,Bang Yang,Peilin Zhou,Jiahua Dong,Long Chen,Ian Reid,Xiaondan Liang*

Main category: cs.CV

TL;DR: 本文提出COLT方法，通过持续的工具使用学习，改善视频LLM在动态工具环境中的性能，避免了过去工具学习的遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设工具库是固定的，难以应对工具数据在现实环境中不断发展的挑战，因此需要一种新方法来实现持续的工具使用和学习。

Method: COLT方法结合了可学习的工具代码本作为工具特定的记忆系统，动态选择相关工具以满足用户指令需求。

Result: COLT在视频理解领域展示了增强工具使用能力的创新，通过避免'灾难性遗忘'，实现工具的逐步学习和使用。

Conclusion: 我们的COLT方法在视频LLM基准测试和工具使用特定的数据集上展示了最先进的性能，证明了其有效性。

Abstract: The success of Large Language Models (LLMs) has significantly propelled the
research of video understanding. To harvest the benefits of well-trained expert
models (i.e., tools), video LLMs prioritize the exploration of tool usage
capabilities. Existing methods either prompt closed-source LLMs or employ the
instruction tuning paradigm for tool-use fine-tuning. These methods, however,
assume an established repository of fixed tools and struggle to generalize to
real-world environments where tool data is perpetually evolving and streaming
in. To this end, we propose to enhance open-source video LLMs with COntinuaL
Tool usage (termed COLT), which automatically acquires tool-use ability in a
successive tool stream without suffering 'catastrophic forgetting' of the past
learned tools. Specifically, our COLT incorporates a learnable tool codebook as
a tool-specific memory system. Then relevant tools are dynamically selected
based on the similarity between user instruction and tool features within the
codebook. To unleash the tool usage potential of video LLMs, we collect a
video-centric tool-use instruction tuning dataset VideoToolBench. Extensive
experiments on both previous video LLM benchmarks and the tool-use-specific
VideoToolBench dataset demonstrate the state-of-the-art performance of our
proposed COLT.

</details>


### [68] [ColorBlindnessEval: Can Vision-Language Models Pass Color Blindness Tests?](https://arxiv.org/abs/2509.19070)
*Zijian Ling,Han Zhang,Yazhuo Zhou,Jiahao Cui*

Main category: cs.CV

TL;DR: 本文提出的 ColorBlindnessEval 基准旨在评估视觉-语言模型在视觉对抗情境中的鲁棒性，强调改进模型在复杂环境中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 开发 ColorBlindnessEval 的动机是评估视觉-语言模型在复杂视觉模式中识别数字信息的能力，并应对模型在对抗环境中的局限性。

Method: 通过构建一个包含 500 幅类似于石原色盲测试的图像的数据集，评估 9 种视觉-语言模型的表现，并与人类参与者进行比较。

Result: 实验结果显示，视觉-语言模型在对抗上下文中的数字解释能力存在局限性，尤其是显著的幻觉问题。

Conclusion: ColorBlindnessEval 是一个用于评估视觉-语言模型在视觉对抗场景中的鲁棒性的基准工具，强调了在复杂视觉环境中提高模型可靠性的必要性。

Abstract: This paper presents ColorBlindnessEval, a novel benchmark designed to
evaluate the robustness of Vision-Language Models (VLMs) in visually
adversarial scenarios inspired by the Ishihara color blindness test. Our
dataset comprises 500 Ishihara-like images featuring numbers from 0 to 99 with
varying color combinations, challenging VLMs to accurately recognize numerical
information embedded in complex visual patterns. We assess 9 VLMs using Yes/No
and open-ended prompts and compare their performance with human participants.
Our experiments reveal limitations in the models' ability to interpret numbers
in adversarial contexts, highlighting prevalent hallucination issues. These
findings underscore the need to improve the robustness of VLMs in complex
visual environments. ColorBlindnessEval serves as a valuable tool for
benchmarking and improving the reliability of VLMs in real-world applications
where accuracy is critical.

</details>


### [69] [FixingGS: Enhancing 3D Gaussian Splatting via Training-Free Score Distillation](https://arxiv.org/abs/2509.18759)
*Zhaorui Wang,Yi Gu,Deming Zhou,Renjing Xu*

Main category: cs.CV

TL;DR: FixingGS 是一种新型的无训练 3D 重建方法，通过优化扩散模型以提高稀疏视图的重建质量，克服了传统方法的伪影和多视图一致性问题。


<details>
  <summary>Details</summary>
Motivation: 解决从稀疏视角重建 3D 场景时由于信息不足导致的可见伪影和多视图一致性问题。

Method: 提出了一种无训练的方法，通过蒸馏方法提供更准确并且跨视图一致的扩散先验，从而提高稀疏视图 3DGS 重建的质量。

Result: FixingGS 显著提升了 3D 重建结果的视觉质量和性能，尤其在受限区域的修复和伪影去除上表现优异。

Conclusion: FixingGS 方法在视觉质量和重建性能上优于现有的最先进方法，并将公开发布代码。

Abstract: Recently, 3D Gaussian Splatting (3DGS) has demonstrated remarkable success in
3D reconstruction and novel view synthesis. However, reconstructing 3D scenes
from sparse viewpoints remains highly challenging due to insufficient visual
information, which results in noticeable artifacts persisting across the 3D
representation. To address this limitation, recent methods have resorted to
generative priors to remove artifacts and complete missing content in
under-constrained areas. Despite their effectiveness, these approaches struggle
to ensure multi-view consistency, resulting in blurred structures and
implausible details. In this work, we propose FixingGS, a training-free method
that fully exploits the capabilities of the existing diffusion model for
sparse-view 3DGS reconstruction enhancement. At the core of FixingGS is our
distillation approach, which delivers more accurate and cross-view coherent
diffusion priors, thereby enabling effective artifact removal and inpainting.
In addition, we propose an adaptive progressive enhancement scheme that further
refines reconstructions in under-constrained regions. Extensive experiments
demonstrate that FixingGS surpasses existing state-of-the-art methods with
superior visual quality and reconstruction performance. Our code will be
released publicly.

</details>


### [70] [Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning](https://arxiv.org/abs/2509.19090)
*Guoxin Wang,Jun Zhao,Xinyi Liu,Yanbo Liu,Xuyang Cao,Chao Li,Zhuoyun Liu,Qintian Sun,Fangru Zhou,Haoqiang Xing,Zhenhong Yang*

Main category: cs.CV

TL;DR: Citrus-V是一种新型的多模态医疗基础模型，将图像分析与文本推理相结合，展示了在医学成像领域的强大能力与广泛应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的医学成像模型通常较为狭窄，依赖于多个专业网络，这限制了它们的泛化能力。随着语言和多模态模型的快速发展，临床应用对精确的视觉定位和多模态整合的需求日益增长。

Method: Citrus-V结合了图像分析和文本推理，通过检测、分割和多模态链式推理，实现了像素级病灶定位、结构化报告生成和医生级诊断推断，采用了一种新颖的多模态训练方法。

Result: Citrus-V在多个基准测试中超越现有的开源医疗模型和专家级成像系统，实现了精确的病变量化、自动报告生成和可靠的第二意见。

Conclusion: Citrus-V模型在多个基准测试中优于现有的医疗成像模型，提供了从视觉基础到临床推理的统一流程，对医学影像的诊断和处理具有重要意义。

Abstract: Medical imaging provides critical evidence for clinical diagnosis, treatment
planning, and surgical decisions, yet most existing imaging models are narrowly
focused and require multiple specialized networks, limiting their
generalization. Although large-scale language and multimodal models exhibit
strong reasoning and multi-task capabilities, real-world clinical applications
demand precise visual grounding, multimodal integration, and chain-of-thought
reasoning. We introduce Citrus-V, a multimodal medical foundation model that
combines image analysis with textual reasoning. The model integrates detection,
segmentation, and multimodal chain-of-thought reasoning, enabling pixel-level
lesion localization, structured report generation, and physician-like
diagnostic inference in a single framework. We propose a novel multimodal
training approach and release a curated open-source data suite covering
reasoning, detection, segmentation, and document understanding tasks.
Evaluations demonstrate that Citrus-V outperforms existing open-source medical
models and expert-level imaging systems across multiple benchmarks, delivering
a unified pipeline from visual grounding to clinical reasoning and supporting
precise lesion quantification, automated reporting, and reliable second
opinions.

</details>


### [71] [Bi-VLM: Pushing Ultra-Low Precision Post-Training Quantization Boundaries in Vision-Language Models](https://arxiv.org/abs/2509.18763)
*Xijun Wang,Junyun Huang,Rayyan Abdalla,Chengyuan Zhang,Ruiqi Xian,Dinesh Manocha*

Main category: cs.CV

TL;DR: 本研究提出了Bi-VLM，通过显著性意识的混合量化和权重量化策略，显著提高了视觉语言模型的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是解决视觉语言模型在计算和内存需求方面的挑战，以便在硬件受限的环境中应用。

Method: 提出了一种基于高斯分位数的非均匀模型权重分离方法，并设计了一个关注显著性的混合量化算法。

Result: Bi-VLM在不同视觉语言模型的语言模型部分取得了3%-47%的性能提升，而整体VLM的表现提升为4%-45%。同时，还通过对模型进行标记剪枝，进一步提高了效率。

Conclusion: 本论文提出的Bi-VLM在视觉问答任务中显著优于当前最先进技术，并通过有效的权重量化和视觉标记剪枝提升计算效率。

Abstract: We address the critical gap between the computational demands of
vision-language models and the possible ultra-low-bit weight precision
(bitwidth $\leq2$ bits) we can use for higher efficiency. Our work is motivated
by the substantial computational cost and memory requirements of VLMs, which
restrict their applicability in hardware-constrained environments. We propose
Bi-VLM, which separates model weights non-uniformly based on the Gaussian
quantiles. Our formulation groups the model weights into outlier (salient) and
multiple inlier (unsalient) subsets, ensuring that each subset contains a
proportion of weights corresponding to its quantile in the distribution. We
propose a saliency-aware hybrid quantization algorithm and use it to quantize
weights by imposing different constraints on the scaler and binary matrices
based on the saliency metric and compression objective. We have evaluated our
approach on different VLMs. For the language model part of the VLM, our Bi-VLM
outperforms the SOTA by 3%-47% on the visual question answering task in terms
of four different benchmarks and three different models. For the overall VLM,
our Bi-VLM outperforms the SOTA by 4%-45%. We also perform token pruning on the
quantized models and observe that there is redundancy of image tokens 90% - 99%
in the quantized models. This helps us to further prune the visual tokens to
improve efficiency.

</details>


### [72] [DiSSECT: Structuring Transfer-Ready Medical Image Representations through Discrete Self-Supervision](https://arxiv.org/abs/2509.18765)
*Azad Singh,Deepak Mishra*

Main category: cs.CV

TL;DR: 本文提出DiSSECT框架，旨在提高医学图像自监督学习的表征转移能力，特别是在低标签情况下表现出色，并具有优越的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 应对现有SSL方法在有限标签数据环境中的复杂性与可扩展性问题，同时减少模型对快捷学习的依赖，特别是在解剖相似且病理细微的医疗影像中。

Method: 提出了一种集成多尺度矢量量化的框架，以施加离散表示瓶颈，从而促进模型学习可重复且结构感知的特征。

Result: DiSSECT在多个医学图像数据集上验证，通过较少或不需要微调，提升了任务和领域间的表征转移能力。

Conclusion: DiSSECT培训的SSL框架在医学图像分类和分割任务中表现出色，特别是在低标签情况下具有高标签效率，同时展示了优越的鲁棒性和泛化能力。

Abstract: Self-supervised learning (SSL) has emerged as a powerful paradigm for medical
image representation learning, particularly in settings with limited labeled
data. However, existing SSL methods often rely on complex architectures,
anatomy-specific priors, or heavily tuned augmentations, which limit their
scalability and generalizability. More critically, these models are prone to
shortcut learning, especially in modalities like chest X-rays, where anatomical
similarity is high and pathology is subtle. In this work, we introduce DiSSECT
-- Discrete Self-Supervision for Efficient Clinical Transferable
Representations, a framework that integrates multi-scale vector quantization
into the SSL pipeline to impose a discrete representational bottleneck. This
constrains the model to learn repeatable, structure-aware features while
suppressing view-specific or low-utility patterns, improving representation
transfer across tasks and domains. DiSSECT achieves strong performance on both
classification and segmentation tasks, requiring minimal or no fine-tuning, and
shows particularly high label efficiency in low-label regimes. We validate
DiSSECT across multiple public medical imaging datasets, demonstrating its
robustness and generalizability compared to existing state-of-the-art
approaches.

</details>


### [73] [Real-time Deer Detection and Warning in Connected Vehicles via Thermal Sensing and Deep Learning](https://arxiv.org/abs/2509.18779)
*Hemanth Puppala,Wayne Sarasua,Srinivas Biyaguda,Farhad Farzinpour,Mashrur Chowdhury*

Main category: cs.CV

TL;DR: 本研究提出了一种基于热成像和车辆通信技术的实时检测与警告系统，有效减少鹿与车辆的碰撞，实验证明具有高准确性和快速响应。


<details>
  <summary>Details</summary>
Motivation: 鹿与车辆碰撞在美国造成重大安全隐患和经济损失，同时影响鹿的数量，因此需要一种有效的解决方案来减轻这一问题。

Method: 提出一种集成热成像、深度学习和车对一切通信的实时检测与驾驶员警告系统，使用超过12000张热成像鹿图像进行训练和验证。

Result: 实验证明系统的准确率极高，具有卓越的实时预警性能，特别是在恶劣天气下也能保持较好的检测能力。

Conclusion: 该系统通过热成像和连接车辆技术有效减少鹿与车辆碰撞事件，建立了减少此问题的技术路径。

Abstract: Deer-vehicle collisions represent a critical safety challenge in the United
States, causing nearly 2.1 million incidents annually and resulting in
approximately 440 fatalities, 59,000 injuries, and 10 billion USD in economic
damages. These collisions also contribute significantly to declining deer
populations. This paper presents a real-time detection and driver warning
system that integrates thermal imaging, deep learning, and
vehicle-to-everything communication to help mitigate deer-vehicle collisions.
Our system was trained and validated on a custom dataset of over 12,000 thermal
deer images collected in Mars Hill, North Carolina. Experimental evaluation
demonstrates exceptional performance with 98.84 percent mean average precision,
95.44 percent precision, and 95.96 percent recall. The system was field tested
during a follow-up visit to Mars Hill and readily sensed deer providing the
driver with advanced warning. Field testing validates robust operation across
diverse weather conditions, with thermal imaging maintaining between 88 and 92
percent detection accuracy in challenging scenarios where conventional visible
light based cameras achieve less than 60 percent effectiveness. When a high
probability threshold is reached sensor data sharing messages are broadcast to
surrounding vehicles and roadside units via cellular vehicle to everything
(CV2X) communication devices. Overall, our system achieves end to end latency
consistently under 100 milliseconds from detection to driver alert. This
research establishes a viable technological pathway for reducing deer-vehicle
collisions through thermal imaging and connected vehicles.

</details>


### [74] [Towards Application Aligned Synthetic Surgical Image Synthesis](https://arxiv.org/abs/2509.18796)
*Danush Kumar Venkatesh,Stefanie Speidel*

Main category: cs.CV

TL;DR: SAADi框架通过与下游模型优先样本对齐来解决手术数据稀缺，显著提升深度学习性能。


<details>
  <summary>Details</summary>
Motivation: 为了克服手术数据注释稀缺的问题，并优化计算机辅助干预中的深度学习系统效果。

Method: SAADi通过构建	extit{preferred}和	extit{non-preferred}合成图像对，并对扩散模型进行轻量级微调，从而实现图像生成过程与下游目标的明确对齐。

Result: 在三个手术数据集上的实验表明，分类任务性能提高$7$--$9	ext{	hinspace}	ext{％}$，分割任务性能提高$2$--$10	ext{	hinspace}	ext{％}$，特别是在代表性不足的类别上显著改善。

Conclusion: SAADi方法通过与下游模型对齐合成图像，显著提高了分类和分割任务的性能，特别是在代表性不足的类别上。

Abstract: The scarcity of annotated surgical data poses a significant challenge for
developing deep learning systems in computer-assisted interventions. While
diffusion models can synthesize realistic images, they often suffer from data
memorization, resulting in inconsistent or non-diverse samples that may fail to
improve, or even harm, downstream performance. We introduce \emph{Surgical
Application-Aligned Diffusion} (SAADi), a new framework that aligns diffusion
models with samples preferred by downstream models. Our method constructs pairs
of \emph{preferred} and \emph{non-preferred} synthetic images and employs
lightweight fine-tuning of diffusion models to align the image generation
process with downstream objectives explicitly. Experiments on three surgical
datasets demonstrate consistent gains of $7$--$9\%$ in classification and
$2$--$10\%$ in segmentation tasks, with the considerable improvements observed
for underrepresented classes. Iterative refinement of synthetic samples further
boosts performance by $4$--$10\%$. Unlike baseline approaches, our method
overcomes sample degradation and establishes task-aware alignment as a key
principle for mitigating data scarcity and advancing surgical vision
applications.

</details>


### [75] [A Kernel Space-based Multidimensional Sparse Model for Dynamic PET Image Denoising](https://arxiv.org/abs/2509.18801)
*Kuang Xiaodong,Li Bingxuan,Li Yuan,Rao Fan,Ma Gege,Xie Qingguo,Mok Greta S P,Liu Huafeng,Zhu Wentao*

Main category: cs.CV

TL;DR: 本文提出了一种基于神经网络的动态PET图像去噪方法，神经KMDS-Net，显示出优越的去噪性能并可实现高时空分辨率。


<details>
  <summary>Details</summary>
Motivation: 动态PET图像中，短帧的统计量有限，导致高图像质量的实现具有挑战性，因此探索深度学习在医学图像去噪中的潜力，特别是在动态PET图像去噪方面。

Method: 通过模型基础的神经网络进行动态PET图像去噪，利用帧间空间相关性和帧内结构一致性建立KMDS模型，并用神经网络替代参数估计的固有形式，使得参数优化具备自适应性，形成端到端的神经KMDS-Net。

Result: 大量模拟和真实数据的实验结果表明，神经KMDS-Net在动态PET图像去噪方面具有较强的性能，优于以前的基线方法。

Conclusion: 所提的神经KMDS-Net在动态正电子发射影像去噪上表现优于以前的基线方法，提供了高时空分辨率。

Abstract: Achieving high image quality for temporal frames in dynamic positron emission
tomography (PET) is challenging due to the limited statistic especially for the
short frames. Recent studies have shown that deep learning (DL) is useful in a
wide range of medical image denoising tasks. In this paper, we propose a
model-based neural network for dynamic PET image denoising. The inter-frame
spatial correlation and intra-frame structural consistency in dynamic PET are
used to establish the kernel space-based multidimensional sparse (KMDS) model.
We then substitute the inherent forms of the parameter estimation with neural
networks to enable adaptive parameters optimization, forming the end-to-end
neural KMDS-Net. Extensive experimental results from simulated and real data
demonstrate that the neural KMDS-Net exhibits strong denoising performance for
dynamic PET, outperforming previous baseline methods. The proposed method may
be used to effectively achieve high temporal and spatial resolution for dynamic
PET. Our source code is available at
https://github.com/Kuangxd/Neural-KMDS-Net/tree/main.

</details>


### [76] [Surgical Video Understanding with Label Interpolation](https://arxiv.org/abs/2509.18802)
*Garam Kim,Tae Kyeong Jeong,Juyoun Park*

Main category: cs.CV

TL;DR: 本研究提出了一种新的框架，结合光流标签插值与多任务学习，以解决手术场景理解中的时间和空间不平衡问题，显著提升了机器人辅助手术的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的外科研究多集中于单一任务，对复杂的时间动态和多样的工具交互的理解不足，因此需要一种更全面的方法来处理手术场景数据。

Method: 结合光流基础的分割标签插值与多任务学习，以促进标签在相邻未标记帧之间的传播。

Result: 通过光流估计对标签的传播，有效平衡了短期和长期注释的数据，提升了外科场景的理解能力。

Conclusion: 该研究提出了一种新颖的框架，通过光流估计和多任务学习相结合，改善了外科场景理解的准确性和效率，从而提高机器人辅助手术的效用。

Abstract: Robot-assisted surgery (RAS) has become a critical paradigm in modern
surgery, promoting patient recovery and reducing the burden on surgeons through
minimally invasive approaches. To fully realize its potential, however, a
precise understanding of the visual data generated during surgical procedures
is essential. Previous studies have predominantly focused on single-task
approaches, but real surgical scenes involve complex temporal dynamics and
diverse instrument interactions that limit comprehensive understanding.
Moreover, the effective application of multi-task learning (MTL) requires
sufficient pixel-level segmentation data, which are difficult to obtain due to
the high cost and expertise required for annotation. In particular, long-term
annotations such as phases and steps are available for every frame, whereas
short-term annotations such as surgical instrument segmentation and action
detection are provided only for key frames, resulting in a significant
temporal-spatial imbalance. To address these challenges, we propose a novel
framework that combines optical flow-based segmentation label interpolation
with multi-task learning. optical flow estimated from annotated key frames is
used to propagate labels to adjacent unlabeled frames, thereby enriching sparse
spatial supervision and balancing temporal and spatial information for
training. This integration improves both the accuracy and efficiency of
surgical scene understanding and, in turn, enhances the utility of RAS.

</details>


### [77] [Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation](https://arxiv.org/abs/2509.18824)
*Yanzuo Lu,Xin Xia,Manlin Zhang,Huafeng Kuang,Jianbin Zheng,Yuxi Ren,Xuefeng Xiao*

Main category: cs.CV

TL;DR: Hyper-Bagel是一个加速多模态理解和生成任务的框架，显著提高运算效率。


<details>
  <summary>Details</summary>
Motivation: 解决多模态模型在处理大量交错多模态Token时计算开销大的问题。

Method: 采用了分而治之的策略，结合投机解码和多阶段蒸馏过程。

Result: 在多模态理解上实现了2倍的加速，生成任务中的文本到图像生成加速达16.67倍，图像编辑加速达22倍。

Conclusion: Hyper-Bagel 提供了一种高效的框架，通过多重蒸馏和投机解码加速多模态理解和生成任务。

Abstract: Unified multimodal models have recently attracted considerable attention for
their remarkable abilities in jointly understanding and generating diverse
content. However, as contexts integrate increasingly numerous interleaved
multimodal tokens, the iterative processes of diffusion denoising and
autoregressive decoding impose significant computational overhead. To address
this, we propose Hyper-Bagel, a unified acceleration framework designed to
simultaneously speed up both multimodal understanding and generation tasks. Our
approach uses a divide-and-conquer strategy, employing speculative decoding for
next-token prediction and a multi-stage distillation process for diffusion
denoising. The framework delivers substantial performance gains, achieving over
a 2x speedup in multimodal understanding. For generative tasks, our resulting
lossless 6-NFE model yields a 16.67x speedup in text-to-image generation and a
22x speedup in image editing, all while preserving the high-quality output of
the original model. We further develop a highly efficient 1-NFE model that
enables near real-time interactive editing and generation. By combining
advanced adversarial distillation with human feedback learning, this model
achieves ultimate cost-effectiveness and responsiveness, making complex
multimodal interactions seamless and instantaneous.

</details>


### [78] [Benchmarking Vision-Language and Multimodal Large Language Models in Zero-shot and Few-shot Scenarios: A study on Christian Iconography](https://arxiv.org/abs/2509.18839)
*Gianmarco Spinaci,Lukas Klic,Giovanni Colavizza*

Main category: cs.CV

TL;DR: 本研究评估了多模态大语言模型在基督教图像分类任务中的表现，结果表明它们在文化遗产领域的分类能力较强，为数字人文学科的元数据策划提供了支持。


<details>
  <summary>Details</summary>
Motivation: 评估通用的视觉语言模型和大语言模型在基督教图像学分类任务中的有效性，探索模型在上下文信息和少量示例增强输入时的表现差异。

Method: 通过基准测试研究评估多模态大语言模型和视觉语言模型在基督教图像单标签分类任务中的表现，包括使用类别标签、图像描述和少量示例的三种条件进行分类。

Result: Gemini-2.5 Pro和GPT-4o在分类任务上超越了ResNet50基准，尽管在Wikidata数据集上的准确性显著下降，Siglip在该数据集上表现最佳，显示出模型对图像大小和元数据对齐的敏感性。

Conclusion: 通用的多模态大语言模型能够在视觉复杂的文化遗产领域进行分类，并支持将这些模型作为数字人文学科工作流中的元数据策划工具。

Abstract: This study evaluates the capabilities of Multimodal Large Language Models
(LLMs) and Vision Language Models (VLMs) in the task of single-label
classification of Christian Iconography. The goal was to assess whether
general-purpose VLMs (CLIP and SigLIP) and LLMs, such as GPT-4o and Gemini 2.5,
can interpret the Iconography, typically addressed by supervised classifiers,
and evaluate their performance. Two research questions guided the analysis:
(RQ1) How do multimodal LLMs perform on image classification of Christian
saints? And (RQ2), how does performance vary when enriching input with
contextual information or few-shot exemplars? We conducted a benchmarking study
using three datasets supporting Iconclass natively: ArtDL, ICONCLASS, and
Wikidata, filtered to include the top 10 most frequent classes. Models were
tested under three conditions: (1) classification using class labels, (2)
classification with Iconclass descriptions, and (3) few-shot learning with five
exemplars. Results were compared against ResNet50 baselines fine-tuned on the
same datasets. The findings show that Gemini-2.5 Pro and GPT-4o outperformed
the ResNet50 baselines. Accuracy dropped significantly on the Wikidata dataset,
where Siglip reached the highest accuracy score, suggesting model sensitivity
to image size and metadata alignment. Enriching prompts with class descriptions
generally improved zero-shot performance, while few-shot learning produced
lower results, with only occasional and minimal increments in accuracy. We
conclude that general-purpose multimodal LLMs are capable of classification in
visually complex cultural heritage domains. These results support the
application of LLMs as metadata curation tools in digital humanities workflows,
suggesting future research on prompt optimization and the expansion of the
study to other classification strategies and models.

</details>


### [79] [ViG-LRGC: Vision Graph Neural Networks with Learnable Reparameterized Graph Construction](https://arxiv.org/abs/2509.18840)
*Ismael Elsharkawi,Hossam Sharara,Ahmed Rafea*

Main category: cs.CV

TL;DR: 本文提出了可学习的重参数化图构建方法（LRGC），能够有效构建图像表示，克服已有方法的局限性，且在ImageNet-1k上得到更优结果。


<details>
  <summary>Details</summary>
Motivation: 解决现有图形构建方法难以自学习和不存在超参数的挑战，以提供更优的图节点关系表示。

Method: 提出了可学习的重参数化图构建（LRGC）方法，通过在每对节点之间应用键查询注意力，并使用软阈值重参数化进行边缘选择。

Result: LRGC能够通过训练数据调整每层的阈值，去除偏差，采用可学习的参数选择邻域。

Conclusion: 所提出的ViG-LRGC方法在ImageNet-1k基准数据集上的表现优于同类最先进的ViG模型。

Abstract: Image Representation Learning is an important problem in Computer Vision.
Traditionally, images were processed as grids, using Convolutional Neural
Networks or as a sequence of visual tokens, using Vision Transformers.
Recently, Vision Graph Neural Networks (ViG) have proposed the treatment of
images as a graph of nodes; which provides a more intuitive image
representation. The challenge is to construct a graph of nodes in each layer
that best represents the relations between nodes and does not need a
hyper-parameter search. ViG models in the literature depend on
non-parameterized and non-learnable statistical methods that operate on the
latent features of nodes to create a graph. This might not select the best
neighborhood for each node. Starting from k-NN graph construction to HyperGraph
Construction and Similarity-Thresholded graph construction, these methods lack
the ability to provide a learnable hyper-parameter-free graph construction
method. To overcome those challenges, we present the Learnable Reparameterized
Graph Construction (LRGC) for Vision Graph Neural Networks. LRGC applies
key-query attention between every pair of nodes; then uses soft-threshold
reparameterization for edge selection, which allows the use of a differentiable
mathematical model for training. Using learnable parameters to select the
neighborhood removes the bias that is induced by any clustering or thresholding
methods previously introduced in the literature. In addition, LRGC allows
tuning the threshold in each layer to the training data since the thresholds
are learnable through training and are not provided as hyper-parameters to the
model. We demonstrate that the proposed ViG-LRGC approach outperforms
state-of-the-art ViG models of similar sizes on the ImageNet-1k benchmark
dataset.

</details>


### [80] [Attack for Defense: Adversarial Agents for Point Prompt Optimization Empowering Segment Anything Model](https://arxiv.org/abs/2509.18891)
*Xueyu Liu,Xiaoyi Zhang,Guangze Shi,Meilin Liu,Yexin Lai,Yongfei Wu,Mingqiang Wei*

Main category: cs.CV

TL;DR: 提出Point Prompt Defender框架，通过对抗性强化学习自动优化分割提示，提升SAM模型的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于启发式或手动制作的提示，限制了其可扩展性和泛化能力，因此需要一种新的方法来优化提示质量。

Method: 采用对抗性强化学习框架，通过攻击与防御的方式自动优化点提示。

Result: 通过构建任务无关的点提示环境，并训练攻击者和防御者代理，Point Prompt Defender在不重训练的情况下提升了SAM的分割性能。

Conclusion: Point Prompt Defender有效提高了SAM的鲁棒性和泛化能力，建立了一个灵活、可解释且即插即用的框架用于基于提示的分割任务。

Abstract: Prompt quality plays a critical role in the performance of the Segment
Anything Model (SAM), yet existing approaches often rely on heuristic or
manually crafted prompts, limiting scalability and generalization. In this
paper, we propose Point Prompt Defender, an adversarial reinforcement learning
framework that adopts an attack-for-defense paradigm to automatically optimize
point prompts. We construct a task-agnostic point prompt environment by
representing image patches as nodes in a dual-space graph, where edges encode
both physical and semantic distances. Within this environment, an attacker
agent learns to activate a subset of prompts that maximally degrade SAM's
segmentation performance, while a defender agent learns to suppress these
disruptive prompts and restore accuracy. Both agents are trained using Deep
Q-Networks with a reward signal based on segmentation quality variation. During
inference, only the defender is deployed to refine arbitrary coarse prompt
sets, enabling enhanced SAM segmentation performance across diverse tasks
without retraining. Extensive experiments show that Point Prompt Defender
effectively improves SAM's robustness and generalization, establishing a
flexible, interpretable, and plug-and-play framework for prompt-based
segmentation.

</details>


### [81] [SmartWilds: Multimodal Wildlife Monitoring Dataset](https://arxiv.org/abs/2509.18894)
*Jenna Kline,Anirudh Potlapally,Bharath Pillai,Tanishka Wani,Rugved Katole,Vedant Patil,Penelope Covey,Hari Subramoni,Tanya Berger-Wolf,Christopher Stewart*

Main category: cs.CV

TL;DR: SmartWilds是一个多模态野生动物监测数据集，结合了无人机影像、相机照片和生物声学录音，为环境监测和保护研究提供支持。


<details>
  <summary>Details</summary>
Motivation: 满足濒危物种研究、保护生态学和栖息地管理等领域的关键需求，推动多模态AI研究。

Method: 通过无人机影像、相机捕捉的照片和视频、生物声学记录等多种传感器收集数据，进行同步监测。

Result: 提供了220英亩的牧场中不同物种的同步监测数据，包括对传感器性能的比较分析，展示了在土地使用模式、物种检测、行为分析和栖息地监测中的互补优势。

Conclusion: SmartWilds数据集为多模态野生动物监测提供了基础，促进了环境监测和物种保护研究，同时建立了可重复的监测协议。

Abstract: We present the first release of SmartWilds, a multimodal wildlife monitoring
dataset. SmartWilds is a synchronized collection of drone imagery, camera trap
photographs and videos, and bioacoustic recordings collected during summer 2025
at The Wilds safari park in Ohio. This dataset supports multimodal AI research
for comprehensive environmental monitoring, addressing critical needs in
endangered species research, conservation ecology, and habitat management. Our
pilot deployment captured four days of synchronized monitoring across three
modalities in a 220-acre pasture containing Pere David's deer, Sichuan takin,
Przewalski's horses, as well as species native to Ohio, including bald eagles,
white-tailed deer, and coyotes. We provide a comparative analysis of sensor
modality performance, demonstrating complementary strengths for landuse
patterns, species detection, behavioral analysis, and habitat monitoring. This
work establishes reproducible protocols for multimodal wildlife monitoring
while contributing open datasets to advance conservation computer vision
research. Future releases will include synchronized GPS tracking data from
tagged individuals, citizen science data, and expanded temporal coverage across
multiple seasons.

</details>


### [82] [RS3DBench: A Comprehensive Benchmark for 3D Spatial Perception in Remote Sensing](https://arxiv.org/abs/2509.18897)
*Jiayu Wang,Ruizhi Wang,Jie Song,Haofei Zhang,Mingli Song,Zunlei Feng,Li Sun*

Main category: cs.CV

TL;DR: 本文介绍了RS3DBench数据集，旨在通过提供精准的深度信息与遥感图像对齐，促进3D视觉模型的进展，并展示了一种新型的深度估计模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有遥感数据集在深度信息和图像对齐上的不足，以促进3D视觉感知模型的发展。

Method: 介绍了RS3DBench数据集，包括图片和像素级对齐的深度图，并利用多模态融合能力开发了一种深度估计模型。

Result: RS3DBench包含54951对遥感图像与深度图，并提供周全的地理背景信息，且提出的深度估计模型在此数据集上表现出色。

Conclusion: 该研究设计了一种新型基准数据集RS3DBench，以推动遥感图像的通用大规模3D视觉模型的进展，并提出了一种基于稳定扩散的深度估计模型。

Abstract: In this paper, we introduce a novel benchmark designed to propel the
advancement of general-purpose, large-scale 3D vision models for remote sensing
imagery. While several datasets have been proposed within the realm of remote
sensing, many existing collections either lack comprehensive depth information
or fail to establish precise alignment between depth data and remote sensing
images. To address this deficiency, we present a visual Benchmark for 3D
understanding of Remotely Sensed images, dubbed RS3DBench. This dataset
encompasses 54,951 pairs of remote sensing images and pixel-level aligned depth
maps, accompanied by corresponding textual descriptions, spanning a broad array
of geographical contexts. It serves as a tool for training and assessing 3D
visual perception models within remote sensing image spatial understanding
tasks. Furthermore, we introduce a remotely sensed depth estimation model
derived from stable diffusion, harnessing its multimodal fusion capabilities,
thereby delivering state-of-the-art performance on our dataset. Our endeavor
seeks to make a profound contribution to the evolution of 3D visual perception
models and the advancement of geographic artificial intelligence within the
remote sensing domain. The dataset, models and code will be accessed on the
https://rs3dbench.github.io.

</details>


### [83] [DeblurSplat: SfM-free 3D Gaussian Splatting with Event Camera for Robust Deblurring](https://arxiv.org/abs/2509.18898)
*Pengteng Li,Yunfan Lu,Pinhao Song,Weiyu Guo,Huizai Yao,F. Richard Yu,Hui Xiong*

Main category: cs.CV

TL;DR: 本文提出了一种新的无结构运动的去模糊3D高斯散射方法DeblurSplat，通过直接获取点云和引入事件流来优化场景重建，显著提高了新视图生成的质量和渲染效率。


<details>
  <summary>Details</summary>
Motivation: 解决运动模糊问题，并避免因摄像机姿态不准确导致的初始点云位置错误。

Method: 通过利用预训练的密集立体模块(DUSt3R)直接从模糊图像获取点云，并引入事件流来优化重建。

Result: DeblurSplat 在多种场景下表现出出色的性能，能够生成高保真的新视图，且在渲染效率上显著优于其他现有方法。

Conclusion: DeblurSplat 方法在生成高保真新视图和渲染效率方面优于现有技术。

Abstract: In this paper, we propose the first Structure-from-Motion (SfM)-free
deblurring 3D Gaussian Splatting method via event camera, dubbed DeblurSplat.
We address the motion-deblurring problem in two ways. First, we leverage the
pretrained capability of the dense stereo module (DUSt3R) to directly obtain
accurate initial point clouds from blurred images. Without calculating camera
poses as an intermediate result, we avoid the cumulative errors transfer from
inaccurate camera poses to the initial point clouds' positions. Second, we
introduce the event stream into the deblur pipeline for its high sensitivity to
dynamic change. By decoding the latent sharp images from the event stream and
blurred images, we can provide a fine-grained supervision signal for scene
reconstruction optimization. Extensive experiments across a range of scenes
demonstrate that DeblurSplat not only excels in generating high-fidelity novel
views but also achieves significant rendering efficiency compared to the SOTAs
in deblur 3D-GS.

</details>


### [84] [MoiréNet: A Compact Dual-Domain Network for Image Demoiréing](https://arxiv.org/abs/2509.18910)
*Shuwei Guo,Simin Luan,Yan Ke,Zeyd Boukhers,John See,Cong Yang*

Main category: cs.CV

TL;DR: MoiréNet是一种新型卷积神经网络，用于去除显示与摄像头之间产生的莫尔纹理，具有高效的参数使用和卓越的恢复质量。


<details>
  <summary>Details</summary>
Motivation: 解决显示像素晶格与相机传感器网格之间的光谱混叠所导致的莫尔纹理伪影问题。

Method: 基于卷积神经网络的U-Net框架，通过方向差分卷积和特征自适应抑制进行高效去模糊处理。

Result: MoiréNet在公共数据集上展现了最先进的性能，且参数量显著减少。

Conclusion: MoiréNet在资源限制的应用中表现出色，结合了高质量恢复和高参数效率。

Abstract: Moir\'e patterns arise from spectral aliasing between display pixel lattices
and camera sensor grids, manifesting as anisotropic, multi-scale artifacts that
pose significant challenges for digital image demoir\'eing. We propose
Moir\'eNet, a convolutional neural U-Net-based framework that synergistically
integrates frequency and spatial domain features for effective artifact
removal. Moir\'eNet introduces two key components: a Directional
Frequency-Spatial Encoder (DFSE) that discerns moir\'e orientation via
directional difference convolution, and a Frequency-Spatial Adaptive Selector
(FSAS) that enables precise, feature-adaptive suppression. Extensive
experiments demonstrate that Moir\'eNet achieves state-of-the-art performance
on public and actively used datasets while being highly parameter-efficient.
With only 5.513M parameters, representing a 48% reduction compared to ESDNet-L,
Moir\'eNet combines superior restoration quality with parameter efficiency,
making it well-suited for resource-constrained applications including
smartphone photography, industrial imaging, and augmented reality.

</details>


### [85] [Frequency-Domain Decomposition and Recomposition for Robust Audio-Visual Segmentation](https://arxiv.org/abs/2509.18912)
*Yunzhe Shen,Kai Peng,Leiye Liu,Wei Ji,Jingjing Li,Miao Zhang,Yongri Piao,Huchuan Lu*

Main category: cs.CV

TL;DR: 提出了一种新颖的频率意识音视频分割框架（FAVS），通过考虑音频和视觉模态间的频率域矛盾，实现了音视频分割任务的显著提升。


<details>
  <summary>Details</summary>
Motivation: 重新思考音视频分割任务，考虑音频和视觉模态之间的频率域矛盾，针对这一问题进行频率域的分解和重组。

Method: 引入一个新的频率意识音视频分割框架，由频率域增强分解器和协同跨模态一致性模块组成。

Result: 通过残差基础的迭代频率分解和混合专家结构实现模态特定的语义和结构特征的辨别与保留。

Conclusion: FAVS框架在三个基准数据集上达到了最先进的性能，验证了FDED和SCMC模块的有效性。

Abstract: Audio-visual segmentation (AVS) plays a critical role in multimodal machine
learning by effectively integrating audio and visual cues to precisely segment
objects or regions within visual scenes. Recent AVS methods have demonstrated
significant improvements. However, they overlook the inherent frequency-domain
contradictions between audio and visual modalities--the pervasively interfering
noise in audio high-frequency signals vs. the structurally rich details in
visual high-frequency signals. Ignoring these differences can result in
suboptimal performance. In this paper, we rethink the AVS task from a deeper
perspective by reformulating AVS task as a frequency-domain decomposition and
recomposition problem. To this end, we introduce a novel Frequency-Aware
Audio-Visual Segmentation (FAVS) framework consisting of two key modules:
Frequency-Domain Enhanced Decomposer (FDED) module and Synergistic Cross-Modal
Consistency (SCMC) module. FDED module employs a residual-based iterative
frequency decomposition to discriminate modality-specific semantics and
structural features, and SCMC module leverages a mixture-of-experts
architecture to reinforce semantic consistency and modality-specific feature
preservation through dynamic expert routing. Extensive experiments demonstrate
that our FAVS framework achieves state-of-the-art performance on three
benchmark datasets, and abundant qualitative visualizations further verify the
effectiveness of the proposed FDED and SCMC modules. The code will be released
as open source upon acceptance of the paper.

</details>


### [86] [xAI-CV: An Overview of Explainable Artificial Intelligence in Computer Vision](https://arxiv.org/abs/2509.18913)
*Nguyen Van Tu,Pham Nguyen Hai Long,Vo Hoai Viet*

Main category: cs.CV

TL;DR: 本文调查了四种xAI方法，旨在解决深度学习模型的可解释性问题，提供对视觉感知任务的全面概述。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习在图像分析任务中的广泛应用，需要理解AI模型的决策过程，以应对其“黑箱”特性带来的可靠性问题。

Method: 通过调查四种代表性的方法，分析其机制、优缺点和评估指标。

Result: 对四种xAI方法进行了详尽分析，提供了对视觉感知任务的理解。

Conclusion: 本文为未来的研究和应用提供了全面的概述。

Abstract: Deep learning has become the de facto standard and dominant paradigm in image
analysis tasks, achieving state-of-the-art performance. However, this approach
often results in "black-box" models, whose decision-making processes are
difficult to interpret, raising concerns about reliability in critical
applications. To address this challenge and provide human a method to
understand how AI model process and make decision, the field of xAI has
emerged. This paper surveys four representative approaches in xAI for visual
perception tasks: (i) Saliency Maps, (ii) Concept Bottleneck Models (CBM),
(iii) Prototype-based methods, and (iv) Hybrid approaches. We analyze their
underlying mechanisms, strengths and limitations, as well as evaluation
metrics, thereby providing a comprehensive overview to guide future research
and applications.

</details>


### [87] [LiDAR Point Cloud Image-based Generation Using Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2509.18917)
*Amirhesam Aghanouri,Cristina Olaverri-Monreal*

Main category: cs.CV

TL;DR: 本研究提出一种去噪扩散概率模型，旨在通过生成高质量合成LiDAR数据来增强自动驾驶汽车的环境感知性能。


<details>
  <summary>Details</summary>
Motivation: 提高自动驾驶汽车在感知任务中的性能，克服现实世界LiDAR数据的噪声和稀疏问题。

Method: 应用去噪扩散概率模型（DDPM），增强噪声调度和时间步嵌入技术，以生成高质量的合成数据进行数据增强。

Result: 该方法在IAMCV和KITTI-360数据集上进行了广泛评估，模型的性能优于大多数现有基准，并有效减轻了嘈杂和稀疏LiDAR数据的影响。

Conclusion: 该模型在处理嘈杂和稀疏LiDAR数据方面表现优越，能够生成多样的点云，具备丰富的空间关系和结构细节。

Abstract: Autonomous vehicles (AVs) are expected to revolutionize transportation by
improving efficiency and safety. Their success relies on 3D vision systems that
effectively sense the environment and detect traffic agents. Among sensors AVs
use to create a comprehensive view of surroundings, LiDAR provides
high-resolution depth data enabling accurate object detection, safe navigation,
and collision avoidance. However, collecting real-world LiDAR data is
time-consuming and often affected by noise and sparsity due to adverse weather
or sensor limitations. This work applies a denoising diffusion probabilistic
model (DDPM), enhanced with novel noise scheduling and time-step embedding
techniques to generate high-quality synthetic data for augmentation, thereby
improving performance across a range of computer vision tasks, particularly in
AV perception. These modifications impact the denoising process and the model's
temporal awareness, allowing it to produce more realistic point clouds based on
the projection. The proposed method was extensively evaluated under various
configurations using the IAMCV and KITTI-360 datasets, with four performance
metrics compared against state-of-the-art (SOTA) methods. The results
demonstrate the model's superior performance over most existing baselines and
its effectiveness in mitigating the effects of noisy and sparse LiDAR data,
producing diverse point clouds with rich spatial relationships and structural
detail.

</details>


### [88] [Advancing Metallic Surface Defect Detection via Anomaly-Guided Pretraining on a Large Industrial Dataset](https://arxiv.org/abs/2509.18919)
*Chuni Liu,Hongjie Li,Jiaqi Du,Yangyang Hou,Qian Sun,Lei Jin,Ke Xu*

Main category: cs.CV

TL;DR: 本研究提出异常引导自监督预训练（AGSSP），有效提升了金属表面缺陷检测的性能，弥补了自然图像和工业数据间的域差。


<details>
  <summary>Details</summary>
Motivation: 为了解决自然图像数据集预训练与工业数据巨大域差的问题，以及现有自监督学习目标无法有效区分微小缺陷与复杂背景噪声的挑战。

Method: AGSSP采用两阶段框架：首先，通过异常图引导模型骨干网络的预训练，其次，利用这些图生成伪缺陷框进行检测器的预训练。

Result: AGSSP在各类实验中都显示出一致的性能提升，相比于基于ImageNet的模型，mAP@0.5提高了10%，mAP@0.5:0.95提高了11.4%。

Conclusion: AGSSP显著提升了金属表面缺陷检测的性能，尤其是在处理数据稀缺和复杂背景噪声的情况下。

Abstract: The pretraining-finetuning paradigm is a crucial strategy in metallic surface
defect detection for mitigating the challenges posed by data scarcity. However,
its implementation presents a critical dilemma. Pretraining on natural image
datasets such as ImageNet, faces a significant domain gap. Meanwhile, naive
self-supervised pretraining on in-domain industrial data is often ineffective
due to the inability of existing learning objectives to distinguish subtle
defect patterns from complex background noise and textures. To resolve this, we
introduce Anomaly-Guided Self-Supervised Pretraining (AGSSP), a novel paradigm
that explicitly guides representation learning through anomaly priors. AGSSP
employs a two-stage framework: (1) it first pretrains the model's backbone by
distilling knowledge from anomaly maps, encouraging the network to capture
defect-salient features; (2) it then pretrains the detector using pseudo-defect
boxes derived from these maps, aligning it with localization tasks. To enable
this, we develop a knowledge-enhanced method to generate high-quality anomaly
maps and collect a large-scale industrial dataset of 120,000 images.
Additionally, we present two small-scale, pixel-level labeled metallic surface
defect datasets for validation. Extensive experiments demonstrate that AGSSP
consistently enhances performance across various settings, achieving up to a
10\% improvement in mAP@0.5 and 11.4\% in mAP@0.5:0.95 compared to
ImageNet-based models. All code, pretrained models, and datasets are publicly
available at https://clovermini.github.io/AGSSP-Dev/.

</details>


### [89] [Audio-Driven Universal Gaussian Head Avatars](https://arxiv.org/abs/2509.18924)
*Kartik Teotia,Helge Rhodin,Mohit Mendiratta,Hyeongwoo Kim,Marc Habermann,Christian Theobalt*

Main category: cs.CV

TL;DR: 提出了一种新的音频驱动虚拟形象合成方法，第一时间实现了详细的外观建模和渲染，并在相关评估中表现优异。


<details>
  <summary>Details</summary>
Motivation: 旨在克服以前方法对音频特征的依赖仅限于几何形变，忽视音频依赖的外观变化。

Method: 结合无特定人物的语音模型和新型的通用头部虚拟形象先验 (UHAP)，并通过单目编码器实现个性化。

Result: 生成高度逼真的虚拟形象，具有精确的唇部同步和细致的表情细节，并在唇部同步准确度、定量图像质量和感知真实性等指标上优于基于几何的方法。

Conclusion: 该方法是第一个通用的音频驱动的虚拟形象合成模型，能够捕捉详细的外观建模和渲染效果，并在多个指标上超越竞争对手。

Abstract: We introduce the first method for audio-driven universal photorealistic
avatar synthesis, combining a person-agnostic speech model with our novel
Universal Head Avatar Prior (UHAP). UHAP is trained on cross-identity
multi-view videos. In particular, our UHAP is supervised with neutral scan
data, enabling it to capture the identity-specific details at high fidelity. In
contrast to previous approaches, which predominantly map audio features to
geometric deformations only while ignoring audio-dependent appearance
variations, our universal speech model directly maps raw audio inputs into the
UHAP latent expression space. This expression space inherently encodes, both,
geometric and appearance variations. For efficient personalization to new
subjects, we employ a monocular encoder, which enables lightweight regression
of dynamic expression variations across video frames. By accounting for these
expression-dependent changes, it enables the subsequent model fine-tuning stage
to focus exclusively on capturing the subject's global appearance and geometry.
Decoding these audio-driven expression codes via UHAP generates highly
realistic avatars with precise lip synchronization and nuanced expressive
details, such as eyebrow movement, gaze shifts, and realistic mouth interior
appearance as well as motion. Extensive evaluations demonstrate that our method
is not only the first generalizable audio-driven avatar model that can account
for detailed appearance modeling and rendering, but it also outperforms
competing (geometry-only) methods across metrics measuring lip-sync accuracy,
quantitative image quality, and perceptual realism.

</details>


### [90] [SynapFlow: A Modular Framework Towards Large-Scale Analysis of Dendritic Spines](https://arxiv.org/abs/2509.18926)
*Pamela Osuna-Vargas,Altug Kamacioglu,Dominik F. Aschauer,Petros E. Vlachos,Sercan Alipek,Jochen Triesch,Simon Rumpel,Matthias Kaschube*

Main category: cs.CV

TL;DR: 本研究开发了一个模块化的机器学习管道，能够自动检测和追踪树突棘，促进对神经元学习和记忆机制的深入研究。


<details>
  <summary>Details</summary>
Motivation: 树突棘是兴奋性突触的关键结构成分，其大小可以反映突触效能，因此其检测和跟踪对于学习和记忆的神经基础研究至关重要。

Method: 该方法结合了基于变换器的检测模块、深度追踪组件、时间追踪模块和特征提取单元，以处理生物数据的复杂性。

Result: 我们在开源标注的树突棘数据集上验证了我们的方法，并发布了两个补充的标注数据集，支持检测、深度追踪和时间追踪。

Conclusion: 我们的研究提供了一个模块化的机器学习管道，可以自动化检测、时间追踪和特征提取，从而推动树突棘动态分析的进展。

Abstract: Dendritic spines are key structural components of excitatory synapses in the
brain. Given the size of dendritic spines provides a proxy for synaptic
efficacy, their detection and tracking across time is important for studies of
the neural basis of learning and memory. Despite their relevance, large-scale
analyses of the structural dynamics of dendritic spines in 3D+time microscopy
data remain challenging and labor-intense. Here, we present a modular machine
learning-based pipeline designed to automate the detection, time-tracking, and
feature extraction of dendritic spines in volumes chronically recorded with
two-photon microscopy. Our approach tackles the challenges posed by biological
data by combining a transformer-based detection module, a depth-tracking
component that integrates spatial features, a time-tracking module to associate
3D spines across time by leveraging spatial consistency, and a feature
extraction unit that quantifies biologically relevant spine properties. We
validate our method on open-source labeled spine data, and on two complementary
annotated datasets that we publish alongside this work: one for detection and
depth-tracking, and one for time-tracking, which, to the best of our knowledge,
is the first data of this kind. To encourage future research, we release our
data, code, and pre-trained weights at
https://github.com/pamelaosuna/SynapFlow, establishing a baseline for scalable,
end-to-end analysis of dendritic spine dynamics.

</details>


### [91] [No Labels Needed: Zero-Shot Image Classification with Collaborative Self-Learning](https://arxiv.org/abs/2509.18938)
*Matheus Vinícius Todescato,Joel Luís Carbonera*

Main category: cs.CV

TL;DR: 本文提出一种零样本图像分类框架，通过结合视觉语言模型和预训练视觉模型，使用置信度基伪标签进行无监督学习，有效解决了标注数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习在分类性能上取得了显著进展，但其对大量标注数据的依赖在许多实际场景中成为障碍，尤其是数据稀缺时。

Method: 提出了一种新的零样本图像分类框架，结合了视觉语言模型和预训练视觉模型，采用基于置信度的伪标签策略，直接在测试数据上训练轻量级分类器。

Result: 结合视觉语言模型和预训练视觉模型，实现动态适应，增强视觉表示，从而允许系统无监督地捕捉互补的语义和视觉线索。

Conclusion: 该方法在十个多样化的数据集上的实验评估中，表现超过了基线零样本方法。

Abstract: While deep learning, including Convolutional Neural Networks (CNNs) and
Vision Transformers (ViTs), has significantly advanced classification
performance, its typical reliance on extensive annotated datasets presents a
major obstacle in many practical scenarios where such data is scarce.
Vision-language models (VLMs) and transfer learning with pre-trained visual
models appear as promising techniques to deal with this problem. This paper
proposes a novel zero-shot image classification framework that combines a VLM
and a pre-trained visual model within a self-learning cycle. Requiring only the
set of class names and no labeled training data, our method utilizes a
confidence-based pseudo-labeling strategy to train a lightweight classifier
directly on the test data, enabling dynamic adaptation. The VLM identifies
high-confidence samples, and the pre-trained visual model enhances their visual
representations. These enhanced features then iteratively train the classifier,
allowing the system to capture complementary semantic and visual cues without
supervision. Notably, our approach avoids VLM fine-tuning and the use of large
language models, relying on the visual-only model to reduce the dependence on
semantic representation. Experimental evaluations on ten diverse datasets
demonstrate that our approach outperforms the baseline zero-shot method.

</details>


### [92] [Seeing Through Reflections: Advancing 3D Scene Reconstruction in Mirror-Containing Environments with Gaussian Splatting](https://arxiv.org/abs/2509.18956)
*Zijing Guo,Yunyang Zhao,Lin Wang*

Main category: cs.CV

TL;DR: 在镜面丰富的环境中，提出了MirrorScene3D数据集和ReflectiveGS方法，显著提高了3D重建的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 解决镜面环境中的3D重建和新视角合成中的挑战，利用镜面反射提供的信息来增强重建质量。

Method: 提出ReflectiveGS，利用镜面反射作为补充视角来改善场景几何形状和恢复缺失细节。

Result: 在MirrorScene3D上的实验表明，ReflectiveGS在SSIM、PSNR、LPIPS和训练速度上超越了现有方法。

Conclusion: ReflectiveGS超越了现有方法，在镜面丰富环境中的3D重建设置了新基准。

Abstract: Mirror-containing environments pose unique challenges for 3D reconstruction
and novel view synthesis (NVS), as reflective surfaces introduce view-dependent
distortions and inconsistencies. While cutting-edge methods such as Neural
Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) excel in typical
scenes, their performance deteriorates in the presence of mirrors. Existing
solutions mainly focus on handling mirror surfaces through symmetry mapping but
often overlook the rich information carried by mirror reflections. These
reflections offer complementary perspectives that can fill in absent details
and significantly enhance reconstruction quality. To advance 3D reconstruction
in mirror-rich environments, we present MirrorScene3D, a comprehensive dataset
featuring diverse indoor scenes, 1256 high-quality images, and annotated mirror
masks, providing a benchmark for evaluating reconstruction methods in
reflective settings. Building on this, we propose ReflectiveGS, an extension of
3D Gaussian Splatting that utilizes mirror reflections as complementary
viewpoints rather than simple symmetry artifacts, enhancing scene geometry and
recovering absent details. Experiments on MirrorScene3D show that
ReflectiveGaussian outperforms existing methods in SSIM, PSNR, LPIPS, and
training speed, setting a new benchmark for 3D reconstruction in mirror-rich
environments.

</details>


### [93] [Generative data augmentation for biliary tract detection on intraoperative images](https://arxiv.org/abs/2509.18958)
*Cristina Iacono,Mariarosaria Meola,Federica Conte,Laura Mecozzi,Umberto Bracale,Pietro Falco,Fanny Ficuciello*

Main category: cs.CV

TL;DR: 本研究通过深度学习改进腹腔镜手术中胆道定位，采用Yolo算法和GAN技术提升视觉效果，进而降低胆道损伤风险。


<details>
  <summary>Details</summary>
Motivation: 为了降低胆囊切除术中胆道损伤的风险，提高手术过程中的胆道可视化。

Method: 利用Yolo检测算法训练图像数据库，并结合经典的数据增强技术和生成对抗网络（GAN）生成训练数据集的一部分合成图像。

Result: 实验结果表明，采用深度学习方法能够有效提升术中胆道的定位精度，进而降低胆道损伤的发生率。

Conclusion: 该研究提出了一种基于深度学习的胆道定位方法，旨在降低腹腔镜胆囊切除术中胆道损伤的风险，提高手术安全性。

Abstract: Cholecystectomy is one of the most frequently performed procedures in
gastrointestinal surgery, and the laparoscopic approach is the gold standard
for symptomatic cholecystolithiasis and acute cholecystitis. In addition to the
advantages of a significantly faster recovery and better cosmetic results, the
laparoscopic approach bears a higher risk of bile duct injury, which has a
significant impact on quality of life and survival. To avoid bile duct injury,
it is essential to improve the intraoperative visualization of the bile duct.
This work aims to address this problem by leveraging a deep-learning approach
for the localization of the biliary tract from white-light images acquired
during the surgical procedures. To this end, the construction and annotation of
an image database to train the Yolo detection algorithm has been employed.
Besides classical data augmentation techniques, the paper proposes Generative
Adversarial Network (GAN) for the generation of a synthetic portion of the
training dataset. Experimental results have been discussed along with ethical
considerations.

</details>


### [94] [Prompt-DAS: Annotation-Efficient Prompt Learning for Domain Adaptive Semantic Segmentation of Electron Microscopy Images](https://arxiv.org/abs/2509.18973)
*Jiabao Chen,Shan Xiong,Jialin Peng*

Main category: cs.CV

TL;DR: Prompt-DAS是一种灵活的多任务框架，用于电子显微镜下细胞器的域适应分割，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了提高电子显微镜中细胞器实例的域自适应分割效率，减少对标注的依赖。

Method: 提出了一种可提示的多任务框架，结合了辅助中心点检测任务和新的提示引导对比学习。

Result: 通过对比实验验证了Prompt-DAS在各种场景下的有效性。

Conclusion: Prompt-DAS在无监督和弱监督领域适应以及交互式分割方面表现优越，优于现有方法。

Abstract: Domain adaptive segmentation (DAS) of numerous organelle instances from
large-scale electron microscopy (EM) is a promising way to enable
annotation-efficient learning. Inspired by SAM, we propose a promptable
multitask framework, namely Prompt-DAS, which is flexible enough to utilize any
number of point prompts during the adaptation training stage and testing stage.
Thus, with varying prompt configurations, Prompt-DAS can perform unsupervised
domain adaptation (UDA) and weakly supervised domain adaptation (WDA), as well
as interactive segmentation during testing. Unlike the foundation model SAM,
which necessitates a prompt for each individual object instance, Prompt-DAS is
only trained on a small dataset and can utilize full points on all instances,
sparse points on partial instances, or even no points at all, facilitated by
the incorporation of an auxiliary center-point detection task. Moreover, a
novel prompt-guided contrastive learning is proposed to enhance discriminative
feature learning. Comprehensive experiments conducted on challenging benchmarks
demonstrate the effectiveness of the proposed approach over existing UDA, WDA,
and SAM-based approaches.

</details>


### [95] [Unveiling Chain of Step Reasoning for Vision-Language Models with Fine-grained Rewards](https://arxiv.org/abs/2509.19003)
*Honghao Chen,Xingzhou Lou,Xiaokun Feng,Kaiqi Huang,Xinlong Wang*

Main category: cs.CV

TL;DR: 本研究探讨了视觉语言模型中的逐步推理，提出了一种透明的框架，通过强化学习提升推理质量，具有显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言推理中的粗粒度推理问题，以支持细粒度结构化推理和中间推理的质量评估。

Method: 使用逐步推理框架，包括步骤级推理数据、过程奖励模型（PRM）和强化学习训练。

Result: 模型在视觉语言基准上设定了强基准，并取得了一致的改善，同时通过实验分析揭示了各组件的影响。

Conclusion: 本研究提出了一种针对视觉语言模型的逐步推理方法，提供了有效的结构化推理评估和强化学习效果，并为未来的多模态推理研究奠定了基础。

Abstract: Chain of thought reasoning has demonstrated remarkable success in large
language models, yet its adaptation to vision-language reasoning remains an
open challenge with unclear best practices. Existing attempts typically employ
reasoning chains at a coarse-grained level, which struggles to perform
fine-grained structured reasoning and, more importantly, are difficult to
evaluate the reward and quality of intermediate reasoning. In this work, we
delve into chain of step reasoning for vision-language models, enabling
assessing reasoning step quality accurately and leading to effective
reinforcement learning and inference-time scaling with fine-grained rewards. We
present a simple, effective, and fully transparent framework, including the
step-level reasoning data, process reward model (PRM), and reinforcement
learning training. With the proposed approaches, our models set strong
baselines with consistent improvements on challenging vision-language
benchmarks. More importantly, we conduct a thorough empirical analysis and
ablation study, unveiling the impact of each component and several intriguing
properties of inference-time scaling. We believe this paper serves as a
baseline for vision-language models and offers insights into more complex
multimodal reasoning. Our dataset, PRM, and code will be available at
https://github.com/baaivision/CoS.

</details>


### [96] [Weakly Supervised Food Image Segmentation using Vision Transformers and Segment Anything Model](https://arxiv.org/abs/2509.19028)
*Ioannis Sarafis,Alexandros Papadopoulos,Anastasios Delopoulos*

Main category: cs.CV

TL;DR: 提出了一种弱监督的食品图像语义分割方法，利用ViT和SAM的优点，实现了高效的标注任务。


<details>
  <summary>Details</summary>
Motivation: 旨在减少食品图像分割中对像素级标注的依赖，同时提高分割质量。

Method: 使用图像级别标注训练Swin Transformer模型，通过ViT生成的类激活图来生成SAM模型的提示，结合图像预处理技术和单层/多层SAM生成策略。

Result: 在FoodSeg103数据集上，平均每张图片生成2.4个分割掩膜（不包括背景），多掩膜场景下的mIoU达0.54。

Conclusion: 提出的方法有效地加速了食品图像的标注任务，并可作为食品与营养追踪应用的集成组件。

Abstract: In this paper, we propose a weakly supervised semantic segmentation approach
for food images which takes advantage of the zero-shot capabilities and
promptability of the Segment Anything Model (SAM) along with the attention
mechanisms of Vision Transformers (ViTs). Specifically, we use class activation
maps (CAMs) from ViTs to generate prompts for SAM, resulting in masks suitable
for food image segmentation. The ViT model, a Swin Transformer, is trained
exclusively using image-level annotations, eliminating the need for pixel-level
annotations during training. Additionally, to enhance the quality of the
SAM-generated masks, we examine the use of image preprocessing techniques in
combination with single-mask and multi-mask SAM generation strategies. The
methodology is evaluated on the FoodSeg103 dataset, generating an average of
2.4 masks per image (excluding background), and achieving an mIoU of 0.54 for
the multi-mask scenario. We envision the proposed approach as a tool to
accelerate food image annotation tasks or as an integrated component in food
and nutrition tracking applications.

</details>


### [97] [A DyL-Unet framework based on dynamic learning for Temporally Consistent Echocardiographic Segmentation](https://arxiv.org/abs/2509.19052)
*Jierui Qu,Jianchun Zhao*

Main category: cs.CV

TL;DR: 提出了DyL-UNet，一种新的能有效处理心脏超声图像分割的深度学习架构，重点改善时间一致性，实验证明其优越性能。


<details>
  <summary>Details</summary>
Motivation: 心脏超声的准确分割对心血管的诊断和治疗至关重要，但受限于变形和噪声，导致分割不稳定。

Method: DyL-UNet是一种基于动态学习的U-Net架构，利用Echo-Dynamics图和Swin-Transformer编码解码分支进行超声图像的处理。

Result: DyL-UNet在CAMUS和EchoNet-Dynamic数据集上展示了与现有方法相当的分割精度和更好的时间一致性。

Conclusion: DyL-UNet在实现心脏超声图像分割的高精度和优越的时间一致性方面提供了可靠的解决方案。

Abstract: Accurate segmentation of cardiac anatomy in echocardiography is essential for
cardiovascular diagnosis and treatment. Yet echocardiography is prone to
deformation and speckle noise, causing frame-to-frame segmentation jitter. Even
with high accuracy in single-frame segmentation, temporal instability can
weaken functional estimates and impair clinical interpretability. To address
these issues, we propose DyL-UNet, a dynamic learning-based temporal
consistency U-Net segmentation architecture designed to achieve temporally
stable and precise echocardiographic segmentation. The framework constructs an
Echo-Dynamics Graph (EDG) through dynamic learning to extract dynamic
information from videos. DyL-UNet incorporates multiple Swin-Transformer-based
encoder-decoder branches for processing single-frame images. It further
introduces Cardiac Phase-Dynamics Attention (CPDA) at the skip connections,
which uses EDG-encoded dynamic features and cardiac-phase cues to enforce
temporal consistency during segmentation. Extensive experiments on the CAMUS
and EchoNet-Dynamic datasets demonstrate that DyL-UNet maintains segmentation
accuracy comparable to existing methods while achieving superior temporal
consistency, providing a reliable solution for automated clinical
echocardiography.

</details>


### [98] [WaveletGaussian: Wavelet-domain Diffusion for Sparse-view 3D Gaussian Object Reconstruction](https://arxiv.org/abs/2509.19073)
*Hung Nguyen,Runfa Li,An Le,Truong Nguyen*

Main category: cs.CV

TL;DR: WaveletGaussian 提出了更高效的稀疏视角 3D 高斯物体重建方法，通过将扩散转移到小波域以减少计算负担。


<details>
  <summary>Details</summary>
Motivation: 3DGS 在稀疏视角情况下性能下降，现有依赖扩散模型的修复方法计算量较大。

Method: 将扩散模型应用于小波域，主要在低分辨率 LL 子带上进行扩散，而高频子带则由一个轻量级网络进行细化，并提出了一种高效的在线随机掩蔽策略以生成训练对。

Result: WaveletGaussian 在两个基准数据集上的实验证明了其具备竞争性的渲染质量和显著减少的训练时间。

Conclusion: WaveletGaussian 在稀疏视角 3D 高斯物体重建中有效提高了渲染质量，同时显著减少了训练时间。

Abstract: 3D Gaussian Splatting (3DGS) has become a powerful representation for
image-based object reconstruction, yet its performance drops sharply in
sparse-view settings. Prior works address this limitation by employing
diffusion models to repair corrupted renders, subsequently using them as pseudo
ground truths for later optimization. While effective, such approaches incur
heavy computation from the diffusion fine-tuning and repair steps. We present
WaveletGaussian, a framework for more efficient sparse-view 3D Gaussian object
reconstruction. Our key idea is to shift diffusion into the wavelet domain:
diffusion is applied only to the low-resolution LL subband, while
high-frequency subbands are refined with a lightweight network. We further
propose an efficient online random masking strategy to curate training pairs
for diffusion fine-tuning, replacing the commonly used, but inefficient,
leave-one-out strategy. Experiments across two benchmark datasets, Mip-NeRF 360
and OmniObject3D, show WaveletGaussian achieves competitive rendering quality
while substantially reducing training time.

</details>


### [99] [3rd Place Report of LSVOS 2025 MeViS Track: Sa2VA-i: Improving Sa2VA Results with Consistent Training and Inference](https://arxiv.org/abs/2509.19082)
*Alexey Nekrasov,Ali Athar,Daan de Geus,Alexander Hermans,Bastian Leibe*

Main category: cs.CV

TL;DR: Sa2VA-i改进了原有Sa2VA模型在视频分割任务中的表现，解决了训练和推理过程中的不一致性，成为新的最佳模型。


<details>
  <summary>Details</summary>
Motivation: 识别Sa2VA在视频对象分割任务中的表现不佳是由于训练与推理过程的不一致。

Method: 提出改进模型Sa2VA-i，通过修正训练与推理过程中的不一致性。

Result: Sa2VA-i在多个数据集上显著提升了性能，如MeViS上提高了11.6，Ref-YT-VOS提高了1.4等。

Conclusion: Sa2VA-i改进模型在多个视频基准上设立了新的最优标准，并展示了实施细节的重要性。

Abstract: Sa2VA is a recent model for language-guided dense grounding in images and
video that achieves state-of-the-art results on multiple segmentation
benchmarks and that has become widely popular. However, we found that Sa2VA
does not perform according to its full potential for referring video object
segmentation tasks. We identify inconsistencies between training and inference
procedures as the key factor holding it back. To mitigate this issue, we
propose an improved version of Sa2VA, Sa2VA-i, that rectifies these issues and
improves the results. In fact, Sa2VA-i sets a new state of the art for multiple
video benchmarks and achieves improvements of up to +11.6 J&F on MeViS, +1.4 on
Ref-YT-VOS, +3.3 on Ref-DAVIS and +4.1 on ReVOS using the same Sa2VA
checkpoints. With our fixes, the Sa2VA-i-1B model even performs on par with the
original Sa2VA-26B model on the MeViS benchmark. We hope that this work will
show the importance of seemingly trivial implementation details and that it
will provide valuable insights for the referring video segmentation field. We
provide the code and updated models at https://github.com/kumuji/sa2va-i

</details>


### [100] [Zero-Shot Multi-Spectral Learning: Reimagining a Generalist Multimodal Gemini 2.5 Model for Remote Sensing Applications](https://arxiv.org/abs/2509.19087)
*Ganesh Mallya,Yotam Gigi,Dahun Kim,Maxim Neumann,Genady Beryozkin,Tomer Shekel,Anelia Angelova*

Main category: cs.CV

TL;DR: 本研究提出了一种无训练的方式，利用多模态模型在零样本模式下处理多光谱数据，从而提高遥感领域的分类性能。


<details>
  <summary>Details</summary>
Motivation: 目前对多光谱数据的自动分析主要依赖专门训练的机器学习模型，训练成本高且无法与强大的通用多模态模型结合，因此需要一种新的方法来克服这一局限性。

Method: 提出一种无训练的方法，将新的多光谱数据以零样本模式作为输入，适应于旨在处理仅RGB输入的通用多模态模型，并将领域特定信息作为指令注入模型中。

Result: 在流行的遥感基准测试上，Gemini2.5模型在土地覆盖和土地利用分类方面显示出显著的零样本性能提升，并且能够快速适应新输入。

Conclusion: 通过引入零样本模式的多光谱数据，Gemini2.5模型在土地覆盖和土地利用分类上显示出强大的性能提升，表明其在处理非标准专用输入方面的潜力。

Abstract: Multi-spectral imagery plays a crucial role in diverse Remote Sensing
applications including land-use classification, environmental monitoring and
urban planning. These images are widely adopted because their additional
spectral bands correlate strongly with physical materials on the ground, such
as ice, water, and vegetation. This allows for more accurate identification,
and their public availability from missions, such as Sentinel-2 and Landsat,
only adds to their value. Currently, the automatic analysis of such data is
predominantly managed through machine learning models specifically trained for
multi-spectral input, which are costly to train and support. Furthermore,
although providing a lot of utility for Remote Sensing, such additional inputs
cannot be used with powerful generalist large multimodal models, which are
capable of solving many visual problems, but are not able to understand
specialized multi-spectral signals.
  To address this, we propose a training-free approach which introduces new
multi-spectral data in a Zero-Shot-only mode, as inputs to generalist
multimodal models, trained on RGB-only inputs. Our approach leverages the
multimodal models' understanding of the visual space, and proposes to adapt to
inputs to that space, and to inject domain-specific information as instructions
into the model. We exemplify this idea with the Gemini2.5 model and observe
strong Zero-Shot performance gains of the approach on popular Remote Sensing
benchmarks for land cover and land use classification and demonstrate the easy
adaptability of Gemini2.5 to new inputs. These results highlight the potential
for geospatial professionals, working with non-standard specialized inputs, to
easily leverage powerful multimodal models, such as Gemini2.5, to accelerate
their work, benefiting from their rich reasoning and contextual capabilities,
grounded in the specialized sensor data.

</details>


### [101] [Investigating Traffic Accident Detection Using Multimodal Large Language Models](https://arxiv.org/abs/2509.19096)
*Ilhan Skender,Kailin Tong,Selim Solmaz,Daniel Watzenig*

Main category: cs.CV

TL;DR: 本研究探讨了多模态大语言模型在自动检测和描述交通事故中的应用潜力，结果显示Pixtral模型表现最佳，结合可视分析技术的整合提升了模型的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 交通安全是全球重要问题，及时准确的事故检测对于减少危害和快速响应至关重要，利用基础设施视觉传感器进行实时监控是一种有效的解决方案。

Method: 评估了多模态大语言模型在检测和描述交通事故中的有效性，采用了CARLA提供的模拟DeepAccident数据集，并进行了模型性能比较。

Result: 主要结果表明，Pixtral模型在识别准确性上表现最佳，F1-score为0.71，召回率为83%；Gemini模型在采用改进提示后提高了精准度，但F1和召回率有所下降。

Conclusion: 研究展示了多模态大语言模型（MLLMs）与先进可视分析技术的整合潜力，提高了其在实际自动交通监测系统中的适用性。

Abstract: Traffic safety remains a critical global concern, with timely and accurate
accident detection essential for hazard reduction and rapid emergency response.
Infrastructure-based vision sensors offer scalable and efficient solutions for
continuous real-time monitoring, facilitating automated detection of acci-
dents directly from captured images. This research investigates the zero-shot
capabilities of multimodal large language models (MLLMs) for detecting and
describing traffic accidents using images from infrastructure cameras, thus
minimizing reliance on extensive labeled datasets. Main contributions include:
(1) Evaluation of MLLMs using the simulated DeepAccident dataset from CARLA,
explicitly addressing the scarcity of diverse, realistic, infrastructure-based
accident data through controlled simulations; (2) Comparative performance
analysis between Gemini 1.5 and 2.0, Gemma 3 and Pixtral models in acci- dent
identification and descriptive capabilities without prior fine-tuning; and (3)
Integration of advanced visual analytics, specifically YOLO for object
detection, Deep SORT for multi- object tracking, and Segment Anything (SAM) for
instance segmentation, into enhanced prompts to improve model accuracy and
explainability. Key numerical results show Pixtral as the top performer with an
F1-score of 0.71 and 83% recall, while Gemini models gained precision with
enhanced prompts (e.g., Gemini 1.5 rose to 90%) but suffered notable F1 and
recall losses. Gemma 3 offered the most balanced performance with minimal
metric fluctuation. These findings demonstrate the substantial potential of
integrating MLLMs with advanced visual analytics techniques, enhancing their
applicability in real-world automated traffic monitoring systems.

</details>


### [102] [Track-On2: Enhancing Online Point Tracking with Memory](https://arxiv.org/abs/2509.19115)
*Görkay Aydemir,Weidi Xie,Fatma Güney*

Main category: cs.CV

TL;DR: 本文提出Track-On2模型，解决了视频帧中长期点跟踪的挑战，在效率和性能上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决长期点跟踪的问题，要求在视频帧中在重大外观变化、运动和遮挡下持续识别点。

Method: 使用简单高效的变换器模型Track-On2进行在线长期跟踪，采用因果处理帧和内存机制以维持时间一致性。

Result: Track-On2在性能和效率上有所提升，超越了先前的在线跟踪器以及依赖双向上下文的强离线方法。

Conclusion: Track-On2在五个基准上实现了最先进的结果，表明因果和基于记忆的架构在真实世界点跟踪中的有效性。

Abstract: In this paper, we consider the problem of long-term point tracking, which
requires consistent identification of points across video frames under
significant appearance changes, motion, and occlusion. We target the online
setting, i.e. tracking points frame-by-frame, making it suitable for real-time
and streaming applications. We extend our prior model Track-On into Track-On2,
a simple and efficient transformer-based model for online long-term tracking.
Track-On2 improves both performance and efficiency through architectural
refinements, more effective use of memory, and improved synthetic training
strategies. Unlike prior approaches that rely on full-sequence access or
iterative updates, our model processes frames causally and maintains temporal
coherence via a memory mechanism, which is key to handling drift and occlusions
without requiring future frames. At inference, we perform coarse patch-level
classification followed by refinement. Beyond architecture, we systematically
study synthetic training setups and their impact on memory behavior, showing
how they shape temporal robustness over long sequences. Through comprehensive
experiments, Track-On2 achieves state-of-the-art results across five synthetic
and real-world benchmarks, surpassing prior online trackers and even strong
offline methods that exploit bidirectional context. These results highlight the
effectiveness of causal, memory-based architectures trained purely on synthetic
data as scalable solutions for real-world point tracking. Project page:
https://kuis-ai.github.io/track_on2

</details>


### [103] [KAMERA: Enhancing Aerial Surveys of Ice-associated Seals in Arctic Environments](https://arxiv.org/abs/2509.19129)
*Adam Romlein,Benjamin X. Hou,Yuval Boss,Cynthia L. Christman,Stacie Koslovsky,Erin E. Moreland,Jason Parham,Anthony Hoogs*

Main category: cs.CV

TL;DR: KAMERA是一个多摄像头、多光谱同步的实时检测系统，可有效提高对阿拉斯加海域海豹和北极熊的检测效率，并减少数据处理时间80%。


<details>
  <summary>Details</summary>
Motivation: 旨在提高对阿拉斯加海域内冰-associated海豹的检测效率，推动科学界的测绘和检测工作。

Method: 利用严谨的校准和硬件同步，KAMERA实现了多个光谱的物体检测，并将所有数据标注上元数据便于后期引用。

Result: KAMERA系统能够快速准确地估算调查区域，并提取调查结果，所有软件、模型和方案均完全开源。

Conclusion: KAMERA系统通过多摄像头和多光谱同步，显著提高了海豹和北极熊的检测效率，并且数据处理时间减少了80%。

Abstract: We introduce KAMERA: a comprehensive system for multi-camera, multi-spectral
synchronization and real-time detection of seals and polar bears. Utilized in
aerial surveys for ice-associated seals in the Bering, Chukchi, and Beaufort
seas around Alaska, KAMERA provides up to an 80% reduction in dataset
processing time over previous methods. Our rigorous calibration and hardware
synchronization enable using multiple spectra for object detection. All
collected data are annotated with metadata so they can be easily referenced
later. All imagery and animal detections from a survey are mapped onto a world
plane for accurate surveyed area estimates and quick assessment of survey
results. We hope KAMERA will inspire other mapping and detection efforts in the
scientific community, with all software, models, and schematics fully
open-sourced.

</details>


### [104] [NeuCODEX: Edge-Cloud Co-Inference with Spike-Driven Compression and Dynamic Early-Exit](https://arxiv.org/abs/2509.19156)
*Maurf Hassan,Steven Davy,Muhammad Zawish,Owais Bin Zuber,Nouman Ashraf*

Main category: cs.CV

TL;DR: NeuCODEX是一种高效的脉冲神经网络边缘推理架构，能显著降低延迟和能耗，同时优化数据传输。


<details>
  <summary>Details</summary>
Motivation: 为了解决边缘计算中由于固定高时间步长导致的延迟和能量限制问题，提升脉冲神经网络的推理效率。

Method: 提出了一种神经形态共推理架构NeuCODEX，通过学习的脉冲驱动压缩模块和动态提前退出机制来优化空间和时间冗余。

Result: NeuCODEX在保持较小的准确率下降的同时，数据传输量减少了高达2048倍，边缘能耗降低超过90%，端到端延迟减少至最多3倍。

Conclusion: NeuCODEX有效提高了边缘计算环境中脉冲神经网络的性能，显著降低了数据传输和能耗，同时延迟也有所减少，且几乎未影响准确性。

Abstract: Spiking Neural Networks (SNNs) offer significant potential for enabling
energy-efficient intelligence at the edge. However, performing full SNN
inference at the edge can be challenging due to the latency and energy
constraints arising from fixed and high timestep overheads. Edge-cloud
co-inference systems present a promising solution, but their deployment is
often hindered by high latency and feature transmission costs. To address these
issues, we introduce NeuCODEX, a neuromorphic co-inference architecture that
jointly optimizes both spatial and temporal redundancy. NeuCODEX incorporates a
learned spike-driven compression module to reduce data transmission and employs
a dynamic early-exit mechanism to adaptively terminate inference based on
output confidence. We evaluated NeuCODEX on both static images (CIFAR10 and
Caltech) and neuromorphic event streams (CIFAR10-DVS and N-Caltech). To
demonstrate practicality, we prototyped NeuCODEX on ResNet-18 and VGG-16
backbones in a real edge-to-cloud testbed. Our proposed system reduces data
transfer by up to 2048x and edge energy consumption by over 90%, while reducing
end-to-end latency by up to 3x compared to edge-only inference, all with a
negligible accuracy drop of less than 2%. In doing so, NeuCODEX enables
practical, high-performance SNN deployment in resource-constrained
environments.

</details>


### [105] [RoSe: Robust Self-supervised Stereo Matching under Adverse Weather Conditions](https://arxiv.org/abs/2509.19165)
*Yun Wang,Junjie Hu,Junhui Hou,Chenghao Zhang,Renwei Yang,Dapeng Oliver Wu*

Main category: cs.CV

TL;DR: 本研究提出一种通过引入视觉基础模型的鲁棒先验来改善自监督立体匹配方法在恶劣天气条件下性能的方案，包括构建合成数据集和鲁棒训练流程。


<details>
  <summary>Details</summary>
Motivation: 自监督立体匹配方法在恶劣天气条件下表现不佳，主要由于噪声和可见度降低导致的特征提取困难及像素对应不准确。

Method: 引入基于视觉基础模型的鲁棒先验，构建合成的立体数据集，并采用鲁棒自监督场景对应学习和恶劣天气蒸馏的训练范式。

Result: 我们的实验结果证明了方法的有效性和多样性，能够在恶劣天气条件下改善立体匹配性能。

Conclusion: 我们提出的解决方案在恶劣天气条件下有效改善了模型的视差估计，超越了现有最先进的自监督方法。

Abstract: Recent self-supervised stereo matching methods have made significant
progress, but their performance significantly degrades under adverse weather
conditions such as night, rain, and fog. We identify two primary weaknesses
contributing to this performance degradation. First, adverse weather introduces
noise and reduces visibility, making CNN-based feature extractors struggle with
degraded regions like reflective and textureless areas. Second, these degraded
regions can disrupt accurate pixel correspondences, leading to ineffective
supervision based on the photometric consistency assumption. To address these
challenges, we propose injecting robust priors derived from the visual
foundation model into the CNN-based feature extractor to improve feature
representation under adverse weather conditions. We then introduce scene
correspondence priors to construct robust supervisory signals rather than
relying solely on the photometric consistency assumption. Specifically, we
create synthetic stereo datasets with realistic weather degradations. These
datasets feature clear and adverse image pairs that maintain the same semantic
context and disparity, preserving the scene correspondence property. With this
knowledge, we propose a robust self-supervised training paradigm, consisting of
two key steps: robust self-supervised scene correspondence learning and adverse
weather distillation. Both steps aim to align underlying scene results from
clean and adverse image pairs, thus improving model disparity estimation under
adverse weather effects. Extensive experiments demonstrate the effectiveness
and versatility of our proposed solution, which outperforms existing
state-of-the-art self-supervised methods. Codes are available at
\textcolor{blue}{https://github.com/cocowy1/RoSe-Robust-Self-supervised-Stereo-Matching-under-Adverse-Weather-Conditions}.

</details>


### [106] [YOLO-LAN: Precise Polyp Detection via Optimized Loss, Augmentations and Negatives](https://arxiv.org/abs/2509.19166)
*Siddharth Gupta,Jitin Singla*

Main category: cs.CV

TL;DR: YOLO-LAN通过深度学习实现了对结肠腺瘤的高效检测，显著提高了腺瘤检测精度，具有临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统结肠镜检查中人工检测的不一致性和疏漏，提供更准确实时的腺瘤诊断。

Method: 基于YOLO的多种数据增强和负样本训练，采用M2IoU损失函数进行多腺瘤检测。

Result: 在Kvasir-seg和BKAI-IGH NeoPolyp数据集上，YOLO-LAN取得了显著的mAP$_{50}$和mAP$_{50:95}$评分，显示出其在腺瘤检测中的高精度和稳健性。

Conclusion: YOLO-LAN显示出优越的多种表现，证明了深度学习在结肠癌筛查中的有效性和临床适用性。

Abstract: Colorectal cancer (CRC), a lethal disease, begins with the growth of abnormal
mucosal cell proliferation called polyps in the inner wall of the colon. When
left undetected, polyps can become malignant tumors. Colonoscopy is the
standard procedure for detecting polyps, as it enables direct visualization and
removal of suspicious lesions. Manual detection by colonoscopy can be
inconsistent and is subject to oversight. Therefore, object detection based on
deep learning offers a better solution for a more accurate and real-time
diagnosis during colonoscopy. In this work, we propose YOLO-LAN, a YOLO-based
polyp detection pipeline, trained using M2IoU loss, versatile data
augmentations and negative data to replicate real clinical situations. Our
pipeline outperformed existing methods for the Kvasir-seg and BKAI-IGH NeoPolyp
datasets, achieving mAP$_{50}$ of 0.9619, mAP$_{50:95}$ of 0.8599 with YOLOv12
and mAP$_{50}$ of 0.9540, mAP$_{50:95}$ of 0.8487 with YOLOv8 on the Kvasir-seg
dataset. The significant increase is achieved in mAP$_{50:95}$ score, showing
the precision of polyp detection. We show robustness based on polyp size and
precise location detection, making it clinically relevant in AI-assisted
colorectal screening.

</details>


### [107] [The 1st Solution for MOSEv2 Challenge 2025: Long-term and Concept-aware Video Segmentation via SeC](https://arxiv.org/abs/2509.19183)
*Mingqi Gao,Jingkun Chen,Yunqi Miao,Gengshen Wu,Zhijin Qin,Jungong Han*

Main category: cs.CV

TL;DR: 本报告探讨了LSVOS挑战中的MOSEv2轨道，提出了通过分析和适应增强的SAM-2框架的方法，实现了在视频对象分割上的优异表现。


<details>
  <summary>Details</summary>
Motivation: 针对LSVOS挑战中的半监督视频对象分割问题进行深入研究，并解决其核心挑战。

Method: 对SeC和增强的SAM-2框架进行了分析和适应，研究其长期记忆和概念意识记忆的特性。

Result: 我们的解决方案在测试集上获得了39.89%的JF分数，在LSVOS挑战的MOSEv2轨道中排名第一。

Conclusion: 该研究提出了一种在MOSEv2轨道中表现优秀的解决方案，在复杂的半监督视频对象分割中取得了显著的成果。

Abstract: This technical report explores the MOSEv2 track of the LSVOS Challenge, which
targets complex semi-supervised video object segmentation. By analysing and
adapting SeC, an enhanced SAM-2 framework, we conduct a detailed study of its
long-term memory and concept-aware memory, showing that long-term memory
preserves temporal continuity under occlusion and reappearance, while
concept-aware memory supplies semantic priors that suppress distractors;
together, these traits directly benefit several MOSEv2's core challenges. Our
solution achieves a JF score of 39.89% on the test set, ranking 1st in the
MOSEv2 track of the LSVOS Challenge.

</details>


### [108] [Reading Images Like Texts: Sequential Image Understanding in Vision-Language Models](https://arxiv.org/abs/2509.19191)
*Yueyan Li,Chenggong Zhao,Zeyuan Zang,Caixia Yuan,Xiaojie Wang*

Main category: cs.CV

TL;DR: 本研究通过解构视觉语言模型，分析物体识别与空间感知，提出新算法和技术，以提升模型的解码效率和空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLM的视觉处理方法与人类的并行视觉方式不符，内部机制的复杂性妨碍了对其的深入理解和架构创新。

Method: 通过对视觉处理进行解构，将其分为物体识别和空间感知，采用的技术包括文本标记映射、几何结构推导以及无指令的标记压缩算法。

Result: 通过实验验证对象识别的两阶段过程和空间感知的几何结构，提出了改进解码效率的算法和增强空间推理技术，验证了相关分析。

Conclusion: 本研究提供了对视觉语言模型(VLM)内部机制的深入理解，并为未来架构的设计提供了明确的原则。

Abstract: Vision-Language Models (VLMs) have demonstrated remarkable performance across
a variety of real-world tasks. However, existing VLMs typically process visual
information by serializing images, a method that diverges significantly from
the parallel nature of human vision. Moreover, their opaque internal mechanisms
hinder both deeper understanding and architectural innovation. Inspired by the
dual-stream hypothesis of human vision, which distinguishes the "what" and
"where" pathways, we deconstruct the visual processing in VLMs into object
recognition and spatial perception for separate study. For object recognition,
we convert images into text token maps and find that the model's perception of
image content unfolds as a two-stage process from shallow to deep layers,
beginning with attribute recognition and culminating in semantic
disambiguation. For spatial perception, we theoretically derive and empirically
verify the geometric structure underlying the positional representation in
VLMs. Based on these findings, we introduce an instruction-agnostic token
compression algorithm based on a plug-and-play visual decoder to improve
decoding efficiency, and a RoPE scaling technique to enhance spatial reasoning.
Through rigorous experiments, our work validates these analyses, offering a
deeper understanding of VLM internals and providing clear principles for
designing more capable future architectures.

</details>


### [109] [Vision-Free Retrieval: Rethinking Multimodal Search with Textual Scene Descriptions](https://arxiv.org/abs/2509.19203)
*Ioanna Ntinou,Alexandros Xenos,Yassine Ouali,Adrian Bulat,Georgios Tzimiropoulos*

Main category: cs.CV

TL;DR: 本文提出一种无视觉的单编码器检索方法，采用文本到文本的转换并利用结构化图像描述，克服了传统视觉语言模型的缺陷，展示出优越的性能和更好的隐私保护。


<details>
  <summary>Details</summary>
Motivation: 针对现有视觉语言模型在语言理解上的不足、双编码器设计导致的模态差距，以及训练数据的隐私和计算成本等问题，提出新的检索方法。

Method: 引入一种无视觉的单编码器检索管道，通过迁移到文本到文本的范式，利用VLLM生成的结构化图像描述来改善检索性能。

Result: 通过新的范式，我们显著减少了模态间差距，提高了组合能力，在短和长文本查询上的表现有所提升，且只需在两块GPU上进行几个小时的校准。

Conclusion: 我们的无视觉检索方法在多个检索和组合基准测试中实现了最先进的零-shot性能，其模型参数量小至0.3B，超越了传统的多模态模型。

Abstract: Contrastively-trained Vision-Language Models (VLMs), such as CLIP, have
become the standard approach for learning discriminative vision-language
representations. However, these models often exhibit shallow language
understanding, manifesting bag-of-words behaviour. These limitations are
reinforced by their dual-encoder design, which induces a modality gap.
Additionally, the reliance on vast web-collected data corpora for training
makes the process computationally expensive and introduces significant privacy
concerns. To address these limitations, in this work, we challenge the
necessity of vision encoders for retrieval tasks by introducing a vision-free,
single-encoder retrieval pipeline. Departing from the traditional text-to-image
retrieval paradigm, we migrate to a text-to-text paradigm with the assistance
of VLLM-generated structured image descriptions. We demonstrate that this
paradigm shift has significant advantages, including a substantial reduction of
the modality gap, improved compositionality, and better performance on short
and long caption queries, all attainable with only a few hours of calibration
on two GPUs. Additionally, substituting raw images with textual descriptions
introduces a more privacy-friendly alternative for retrieval. To further assess
generalisation and address some of the shortcomings of prior compositionality
benchmarks, we release two benchmarks derived from Flickr30k and COCO,
containing diverse compositional queries made of short captions, which we coin
subFlickr and subCOCO. Our vision-free retriever matches and often surpasses
traditional multimodal models. Importantly, our approach achieves
state-of-the-art zero-shot performance on multiple retrieval and
compositionality benchmarks, with models as small as 0.3B parameters. Code is
available at: https://github.com/IoannaNti/LexiCLIP

</details>


### [110] [Long Story Short: Disentangling Compositionality and Long-Caption Understanding in VLMs](https://arxiv.org/abs/2509.19207)
*Israfel Salazar,Desmond Elliott,Yova Kementchedjhieva*

Main category: cs.CV

TL;DR: 本文研究组合性和长文本理解的交互，发现二者可以共同提升，但挑战在于数据质量和模型设计。


<details>
  <summary>Details</summary>
Motivation: 探索组合性与长文本理解之间的互动，假设组合性是理解长文本的关键。

Method: 训练和评估一系列针对组合性和长文本理解能力的模型。

Result: 组合训练提高了长文本检索的性能，而长文本训练又促进了组合性，但这些提升对数据质量和模型设计敏感。

Conclusion: 组合理解和长文本理解是相互交织的能力，可以通过训练密集的、基于实例的描述来共同学习。

Abstract: Contrastive vision-language models (VLMs) have made significant progress in
binding visual and textual information, but understanding long, dense captions
remains an open challenge. We hypothesize that compositionality, the capacity
to reason about object-attribute bindings and inter-object relationships, is
key to understanding longer captions. In this paper, we investigate the
interaction between compositionality and long-caption understanding, asking
whether training for one property enhances the other. We train and evaluate a
range of models that target each of these capabilities. Our results reveal a
bidirectional relationship: compositional training improves performance on
long-caption retrieval, and training on long captions promotes
compositionality. However, these gains are sensitive to data quality and model
design. We find that training on poorly structured captions, or with limited
parameter updates, fails to support generalization. Likewise, strategies that
aim at retaining general alignment, such as freezing positional embeddings, do
not improve compositional understanding. Overall, we find that compositional
understanding and long-caption understanding are intertwined capabilities that
can be jointly learned through training on dense, grounded descriptions.
Despite these challenges, we show that models trained on high-quality,
long-caption data can achieve strong performance in both tasks, offering
practical guidance for improving VLM generalization.

</details>


### [111] [Enabling Plant Phenotyping in Weedy Environments using Multi-Modal Imagery via Synthetic and Generated Training Data](https://arxiv.org/abs/2509.19208)
*Earl Ranario,Ismael Mayanja,Heesup Yun,Brian N. Bailey,J. Mason Earles*

Main category: cs.CV

TL;DR: 本研究提出了一种框架，通过合成数据和有限的真实标注，结合GAN基础的跨模态对齐，显著提高了热成像中的植物分割性能。


<details>
  <summary>Details</summary>
Motivation: 在高通量田间表型评估中，准确的植物分割在热成像中面临挑战，特别是在植物与杂草对比度低和频繁遮挡的户外环境中。

Method: 使用合成RGB影像和少量真实注释，采用GAN基础的跨模态对齐来增强热成像中的语义分割。

Result: 与完整的真实数据基线相比，结合所有合成图像和少数标记的真实图像，杂草类和植物类的相对改善最大分别为22%和17%。

Conclusion: 结合合成数据、有限的人工标注和生成模型的跨域翻译可以显著提升复杂田野环境下多模型影像的分割性能。

Abstract: Accurate plant segmentation in thermal imagery remains a significant
challenge for high throughput field phenotyping, particularly in outdoor
environments where low contrast between plants and weeds and frequent
occlusions hinder performance. To address this, we present a framework that
leverages synthetic RGB imagery, a limited set of real annotations, and
GAN-based cross-modality alignment to enhance semantic segmentation in thermal
images. We trained models on 1,128 synthetic images containing complex mixtures
of crop and weed plants in order to generate image segmentation masks for crop
and weed plants. We additionally evaluated the benefit of integrating as few as
five real, manually segmented field images within the training process using
various sampling strategies. When combining all the synthetic images with a few
labeled real images, we observed a maximum relative improvement of 22% for the
weed class and 17% for the plant class compared to the full real-data baseline.
Cross-modal alignment was enabled by translating RGB to thermal using
CycleGAN-turbo, allowing robust template matching without calibration. Results
demonstrated that combining synthetic data with limited manual annotations and
cross-domain translation via generative models can significantly boost
segmentation performance in complex field environments for multi-model imagery.

</details>


### [112] [HyKid: An Open MRI Dataset with Expert-Annotated Multi-Structure and Choroid Plexus in Pediatric Hydrocephalus](https://arxiv.org/abs/2509.19218)
*Yunzhi Xu,Yushuang Ding,Hu Sun,Hongxi Zhang,Li Zhao*

Main category: cs.CV

TL;DR: HyKid是一个公开的脑积水儿童MRI数据集，包含高质量的手动分割，提供了脑脊液总量和脑脉络丛之间的相关性，具有预测功能。


<details>
  <summary>Details</summary>
Motivation: 儿童脑积水的评估具有挑战性，缺乏公开的专家注释数据集，尤其是缺少脑脉络丛分割的数据集。

Method: 从48名脑积水儿童患者的3D MRI中提取数据，包括脑白质、灰质、侧脑室、外部脑脊液和脑脉络丛的手动分割。使用增强检索生成框架从临床放射学报告中提取结构化数据。

Result: 脑脉络丛体积与总脑脊液体积之间的强相关性提供了一种潜在的脑积水评估生物标志物，预测模型的AUC达到了0.87。

Conclusion: HyKid数据集为脑积水的神经影像算法开发提供了高质量的基准，并揭示了脑脉络丛在脑积水评估中的相关特征。

Abstract: Evaluation of hydrocephalus in children is challenging, and the related
research is limited by a lack of publicly available, expert-annotated datasets,
particularly those with segmentation of the choroid plexus. To address this, we
present HyKid, an open-source dataset from 48 pediatric patients with
hydrocephalus. 3D MRIs were provided with 1mm isotropic resolution, which was
reconstructed from routine low-resolution images using a slice-to-volume
algorithm. Manually corrected segmentations of brain tissues, including white
matter, grey matter, lateral ventricle, external CSF, and the choroid plexus,
were provided by an experienced neurologist. Additionally, structured data was
extracted from clinical radiology reports using a Retrieval-Augmented
Generation framework. The strong correlation between choroid plexus volume and
total CSF volume provided a potential biomarker for hydrocephalus evaluation,
achieving excellent performance in a predictive model (AUC = 0.87). The
proposed HyKid dataset provided a high-quality benchmark for neuroimaging
algorithms development, and it revealed the choroid plexus-related features in
hydrocephalus assessments. Our datasets are publicly available at
https://www.synapse.org/Synapse:syn68544889.

</details>


### [113] [MsFIN: Multi-scale Feature Interaction Network for Traffic Accident Anticipation](https://arxiv.org/abs/2509.19227)
*Tongshuai Wu,Chao Lu,Ze Song,Yunlong Lin,Sizhe Fan,Xuemei Chen*

Main category: cs.CV

TL;DR: 本研究提出的MsFIN模型通过多尺度特征处理和变换器架构，解决了事故预测中的特征交互和复杂行为捕捉问题，并在多个数据集上实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 在车辆记录仪（dashcam）广泛应用和计算机视觉进步的背景下，开发能从车载视角预防事故的模型变得至关重要。

Method: 提出了一种多尺度特征交互网络（MsFIN），包括多尺度特征聚合、时间特征处理和多尺度特征后融合三个层次。

Result: MsFIN在DAD和DADA数据集上的实验表明，该模型在预测的正确性和及时性上显著优于现有的单尺度特征提取模型。

Conclusion: MsFIN模型在事故预测上表现优越，通过多尺度特征融合和上下文交互建模显著提升了预测的准确性和及时性。

Abstract: With the widespread deployment of dashcams and advancements in computer
vision, developing accident prediction models from the dashcam perspective has
become critical for proactive safety interventions. However, two key challenges
persist: modeling feature-level interactions among traffic participants (often
occluded in dashcam views) and capturing complex, asynchronous multi-temporal
behavioral cues preceding accidents. To deal with these two challenges, a
Multi-scale Feature Interaction Network (MsFIN) is proposed for early-stage
accident anticipation from dashcam videos. MsFIN has three layers for
multi-scale feature aggregation, temporal feature processing and multi-scale
feature post fusion, respectively. For multi-scale feature aggregation, a
Multi-scale Module is designed to extract scene representations at short-term,
mid-term and long-term temporal scales. Meanwhile, the Transformer architecture
is leveraged to facilitate comprehensive feature interactions. Temporal feature
processing captures the sequential evolution of scene and object features under
causal constraints. In the multi-scale feature post fusion stage, the network
fuses scene and object features across multiple temporal scales to generate a
comprehensive risk representation. Experiments on DAD and DADA datasets show
that MsFIN significantly outperforms state-of-the-art models with single-scale
feature extraction in both prediction correctness and earliness. Ablation
studies validate the effectiveness of each module in MsFIN, highlighting how
the network achieves superior performance through multi-scale feature fusion
and contextual interaction modeling.

</details>


### [114] [DevFD: Developmental Face Forgery Detection by Learning Shared and Orthogonal LoRA Subspaces](https://arxiv.org/abs/2509.19230)
*Tianshuo Zhang,Li Gao,Siran Peng,Xiangyu Zhu,Zhen Lei*

Main category: cs.CV

TL;DR: 面部伪造检测面临技术演变带来的挑战，本文通过开发性专家混合架构，以有限资源有效应对新伪造类型。


<details>
  <summary>Details</summary>
Motivation: 随着数字面孔生成和操纵技术的发展，存在显著的社会风险，迫切需要能够快速适应新伪造类型的检测模型。

Method: 本文采用开发性专家混合（MoE）架构，使用LoRA模型作为个体专家，通过组织Real-LoRA和多种Fake-LoRA来应对真实与伪造面孔的学习。

Result: 在多种数据集和操纵类型的增量协议下，实验结果表明我们的方法显著有效。

Conclusion: 我们的方法在面部伪造检测中有效地应对了伪造技术的不断演变，特别是在有限的计算和数据条件下保持了学习性能。

Abstract: The rise of realistic digital face generation and manipulation poses
significant social risks. The primary challenge lies in the rapid and diverse
evolution of generation techniques, which often outstrip the detection
capabilities of existing models. To defend against the ever-evolving new types
of forgery, we need to enable our model to quickly adapt to new domains with
limited computation and data while avoiding forgetting previously learned
forgery types. In this work, we posit that genuine facial samples are abundant
and relatively stable in acquisition methods, while forgery faces continuously
evolve with the iteration of manipulation techniques. Given the practical
infeasibility of exhaustively collecting all forgery variants, we frame face
forgery detection as a continual learning problem and allow the model to
develop as new forgery types emerge. Specifically, we employ a Developmental
Mixture of Experts (MoE) architecture that uses LoRA models as its individual
experts. These experts are organized into two groups: a Real-LoRA to learn and
refine knowledge of real faces, and multiple Fake-LoRAs to capture incremental
information from different forgery types. To prevent catastrophic forgetting,
we ensure that the learning direction of Fake-LoRAs is orthogonal to the
established subspace. Moreover, we integrate orthogonal gradients into the
orthogonal loss of Fake-LoRAs, preventing gradient interference throughout the
training process of each task. Experimental results under both the datasets and
manipulation types incremental protocols demonstrate the effectiveness of our
method.

</details>


### [115] [Lavida-O: Elastic Masked Diffusion Models for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2509.19244)
*Shufan Li,Jiuxiang Gu,Kangning Liu,Zhe Lin,Zijun Wei,Aditya Grover,Jason Kuen*

Main category: cs.CV

TL;DR: Lavida-O是一个统一的多模态Masked Diffusion Model，具备强大的图像理解与生成能力，超越当前模型并提高推理速度。


<details>
  <summary>Details</summary>
Motivation: 旨在克服现有多模态扩散语言模型的局限性，提供更复杂的图像理解和生成能力，包括物体定位、图像编辑和高分辨率图像合成。

Method: 引入了多种新技术，如弹性混合变换器架构、通用文本调节和分层采样，以实现高效的训练和采样。

Result: Lavida-O在RefCOCO目标定位、GenEval文本到图像生成和ImgEdit图像编辑等多个基准测试中取得了最先进的性能，超过了现有的自回归和连续扩散模型。

Conclusion: Lavida-O在多个基准测试中表现出色，展示了其在图像理解和生成方面的先进能力，超越了现有的大多数模型，且推理速度显著提升。

Abstract: We proposed Lavida-O, a unified multi-modal Masked Diffusion Model (MDM)
capable of image understanding and generation tasks. Unlike existing multimodal
diffsion language models such as MMaDa and Muddit which only support simple
image-level understanding tasks and low-resolution image generation, Lavida-O
exhibits many new capabilities such as object grounding, image-editing, and
high-resolution (1024px) image synthesis. It is also the first unified MDM that
uses its understanding capabilities to improve image generation and editing
results through planning and iterative self-reflection. To allow effective and
efficient training and sampling, Lavida-O ntroduces many novel techniques such
as Elastic Mixture-of-Transformer architecture, universal text conditioning,
and stratified sampling. \ours~achieves state-of-the-art performance on a wide
range of benchmarks such as RefCOCO object grounding, GenEval text-to-image
generation, and ImgEdit image editing, outperforming existing autoregressive
and continuous diffusion models such as Qwen2.5-VL and FluxKontext-dev, while
offering considerable speedup at inference.

</details>


### [116] [ConViS-Bench: Estimating Video Similarity Through Semantic Concepts](https://arxiv.org/abs/2509.19245)
*Benedetta Liberatori,Alessandro Conti,Lorenzo Vaquero,Yiming Wang,Elisa Ricci,Paolo Rota*

Main category: cs.CV

TL;DR: 提出了一种新的视频相似性估计任务ConViS，通过关键概念计算相似性得分，并推出新基准ConViS-Bench，提升视频理解研究。


<details>
  <summary>Details</summary>
Motivation: 探讨视频相似性的多样性，通过不同方面进行比较，但现有模型往往依赖于广泛的全球相似性评分。

Method: 引入基于概念的视频相似性估计（ConViS）任务，通过一组预定义的关键语义概念计算可解释的相似性得分。

Result: 在ConViS上对多种最先进模型进行基准测试，显示它们与人类判断的一致性存在显著差异，某些概念对视频相似性估计具有更大挑战。

Conclusion: ConViS-Bench将成为语言驱动视频理解研究的宝贵资源。

Abstract: What does it mean for two videos to be similar? Videos may appear similar
when judged by the actions they depict, yet entirely different if evaluated
based on the locations where they were filmed. While humans naturally compare
videos by taking different aspects into account, this ability has not been
thoroughly studied and presents a challenge for models that often depend on
broad global similarity scores. Large Multimodal Models (LMMs) with video
understanding capabilities open new opportunities for leveraging natural
language in comparative video tasks. We introduce Concept-based Video
Similarity estimation (ConViS), a novel task that compares pairs of videos by
computing interpretable similarity scores across a predefined set of key
semantic concepts. ConViS allows for human-like reasoning about video
similarity and enables new applications such as concept-conditioned video
retrieval. To support this task, we also introduce ConViS-Bench, a new
benchmark comprising carefully annotated video pairs spanning multiple domains.
Each pair comes with concept-level similarity scores and textual descriptions
of both differences and similarities. Additionally, we benchmark several
state-of-the-art models on ConViS, providing insights into their alignment with
human judgments. Our results reveal significant performance differences on
ConViS, indicating that some concepts present greater challenges for estimating
video similarity. We believe that ConViS-Bench will serve as a valuable
resource for advancing research in language-driven video understanding.

</details>


### [117] [Adversarially-Refined VQ-GAN with Dense Motion Tokenization for Spatio-Temporal Heatmaps](https://arxiv.org/abs/2509.19252)
*Gabriel Maldonado,Narges Rashvand,Armin Danesh Pazho,Ghazal Alinezhad Noghre,Vinit Katariya,Hamed Tabkhi*

Main category: cs.CV

TL;DR: 本研究介绍了一种新的对抗性精炼VQ-GAN框架，通过密集运动标记化有效压缩人类运动的时空热图，显著提高了重建质量并减少了时间不稳定性。


<details>
  <summary>Details</summary>
Motivation: 由于人类运动的高维性和固有冗余性，持续的人类运动理解是计算机视觉中的核心挑战，需要有效的压缩和表示方法来分析复杂运动动态。

Method: 采用对抗性精炼的VQ-GAN框架，结合密集运动标记化技术，压缩时间空间热图。

Result: 在CMU Panoptic数据集上的实验证明，该方法在SSIM上比dVAE基线提高了9.31%，并且减少了37.1%的时间不稳定性。2D运动可以用128个标记词汇紧凑表示，而3D运动则需要更大的1024个标记词汇。

Conclusion: 本研究提出的对抗性精炼VQ-GAN框架在运动理解方面具有优越性，尤其在保持人类动作细节和减少时间不稳定性上表现出色。

Abstract: Continuous human motion understanding remains a core challenge in computer
vision due to its high dimensionality and inherent redundancy. Efficient
compression and representation are crucial for analyzing complex motion
dynamics. In this work, we introduce an adversarially-refined VQ-GAN framework
with dense motion tokenization for compressing spatio-temporal heatmaps while
preserving the fine-grained traces of human motion. Our approach combines dense
motion tokenization with adversarial refinement, which eliminates
reconstruction artifacts like motion smearing and temporal misalignment
observed in non-adversarial baselines. Our experiments on the CMU Panoptic
dataset provide conclusive evidence of our method's superiority, outperforming
the dVAE baseline by 9.31% SSIM and reducing temporal instability by 37.1%.
Furthermore, our dense tokenization strategy enables a novel analysis of motion
complexity, revealing that 2D motion can be optimally represented with a
compact 128-token vocabulary, while 3D motion's complexity demands a much
larger 1024-token codebook for faithful reconstruction. These results establish
practical deployment feasibility across diverse motion analysis applications.
The code base for this work is available at
https://github.com/TeCSAR-UNCC/Pose-Quantization.

</details>


### [118] [Graph-Radiomic Learning (GrRAiL) Descriptor to Characterize Imaging Heterogeneity in Confounding Tumor Pathologies](https://arxiv.org/abs/2509.19258)
*Dheerendranath Battalapalli,Apoorva Safai,Maria Jaramillo,Hyemin Um,Gustavo Adalfo Pineda Ortiz,Ulas Bagci,Manmeet Singh Ahluwalia,Marwa Ismail,Pallavi Tiwari*

Main category: cs.CV

TL;DR: GrRAiL是一种新的图波动学习方法，在区分肿瘤复发和风险分层方面有效提高了影像学诊断的准确性，对临床应用具有良好前景。


<details>
  <summary>Details</summary>
Motivation: 目前常规影像学中区分恶性肿瘤与其他混淆病理组织存在巨大挑战，而传统的放射组学方法无法有效捕捉复杂的空间关系，因此需要寻求新的方法来提升诊断准确性。

Method: 提出了一种新的图波动学习（GrRAiL）描述符，通过对每个像素的放射组学测量识别亚区域集群，并计算图论指标以量化这些集群之间的空间关系。

Result: 在947名患者中，GrRAiL在区分肿瘤复发与辐射效应（GBM和脑转移）以及胰腺肿瘤（IPMN）的风险分层方面均实现了显著的准确性提升，超过了现有的最先进基线模型。

Conclusion: GrRAiL 相较于传统方法在肿瘤复发与伪进展、辐射坏死的区分，以及胰腺肿瘤风险分层中均表现出显著的准确性提升，证明其在临床应用中的可行性与有效性。

Abstract: A significant challenge in solid tumors is reliably distinguishing
confounding pathologies from malignant neoplasms on routine imaging. While
radiomics methods seek surrogate markers of lesion heterogeneity on CT/MRI,
many aggregate features across the region of interest (ROI) and miss complex
spatial relationships among varying intensity compositions. We present a new
Graph-Radiomic Learning (GrRAiL) descriptor for characterizing intralesional
heterogeneity (ILH) on clinical MRI scans. GrRAiL (1) identifies clusters of
sub-regions using per-voxel radiomic measurements, then (2) computes
graph-theoretic metrics to quantify spatial associations among clusters. The
resulting weighted graphs encode higher-order spatial relationships within the
ROI, aiming to reliably capture ILH and disambiguate confounding pathologies
from malignancy. To assess efficacy and clinical feasibility, GrRAiL was
evaluated in n=947 subjects spanning three use cases: differentiating tumor
recurrence from radiation effects in glioblastoma (GBM; n=106) and brain
metastasis (n=233), and stratifying pancreatic intraductal papillary mucinous
neoplasms (IPMNs) into no+low vs high risk (n=608). In a multi-institutional
setting, GrRAiL consistently outperformed state-of-the-art baselines - Graph
Neural Networks (GNNs), textural radiomics, and intensity-graph analysis. In
GBM, cross-validation (CV) and test accuracies for recurrence vs
pseudo-progression were 89% and 78% with >10% test-accuracy gains over
comparators. In brain metastasis, CV and test accuracies for recurrence vs
radiation necrosis were 84% and 74% (>13% improvement). For IPMN risk
stratification, CV and test accuracies were 84% and 75%, showing >10%
improvement.

</details>


### [119] [Moving by Looking: Towards Vision-Driven Avatar Motion Generation](https://arxiv.org/abs/2509.19259)
*Markos Diomataris,Berat Mert Albaba,Giorgio Becherini,Partha Ghosh,Omid Taheri,Michael J. Black*

Main category: cs.CV

TL;DR: 本研究提出CLOPS，一个通过自我中心视觉感知环境并导航的虚拟人类头像，证明了这种方式可以生成更人类化的运动行为。


<details>
  <summary>Details</summary>
Motivation: 现有的人类运动生成方法忽视了感知与动作之间的互依性，因此需要研发人类感知方式以生成更真实的虚拟头像行为。

Method: 首先在大型运动捕捉数据集上训练运动先验模型，然后利用Q学习来将自我中心视觉输入映射到运动控制命令。

Result: 实验表明，自我中心视觉能够使头像展现出人类特有的运动特征，如避免视觉范围内的障碍物。

Conclusion: 通过使用人类感知方式（尤其是自我中心视觉），我们能够训练出像人类一样行为的虚拟头像。

Abstract: The way we perceive the world fundamentally shapes how we move, whether it is
how we navigate in a room or how we interact with other humans. Current human
motion generation methods, neglect this interdependency and use task-specific
``perception'' that differs radically from that of humans. We argue that the
generation of human-like avatar behavior requires human-like perception.
Consequently, in this work we present CLOPS, the first human avatar that solely
uses egocentric vision to perceive its surroundings and navigate. Using vision
as the primary driver of motion however, gives rise to a significant challenge
for training avatars: existing datasets have either isolated human motion,
without the context of a scene, or lack scale. We overcome this challenge by
decoupling the learning of low-level motion skills from learning of high-level
control that maps visual input to motion. First, we train a motion prior model
on a large motion capture dataset. Then, a policy is trained using Q-learning
to map egocentric visual inputs to high-level control commands for the motion
prior. Our experiments empirically demonstrate that egocentric vision can give
rise to human-like motion characteristics in our avatars. For example, the
avatars walk such that they avoid obstacles present in their visual field.
These findings suggest that equipping avatars with human-like sensors,
particularly egocentric vision, holds promise for training avatars that behave
like humans.

</details>


### [120] [OverLayBench: A Benchmark for Layout-to-Image Generation with Dense Overlaps](https://arxiv.org/abs/2509.19282)
*Bingnan Li,Chen-Yu Wang,Haiyang Xu,Xiang Zhang,Ethan Armand,Divyansh Srivastava,Xiaojun Shan,Zeyuan Chen,Jianwen Xie,Zhuowen Tu*

Main category: cs.CV

TL;DR: 本文识别出布局到图像生成中的重叠挑战，提出新的评估标准OverLayScore和基准OverLayBench，以及一个微调模型，提高复杂重叠情况下的生成表现。


<details>
  <summary>Details</summary>
Motivation: 目前的布局到图像生成方法在处理重叠边界框时仍存在困难，特别是当重叠区域大且实例间语义区别小的情况下。

Method: 通过引入OverLayScore和OverLayBench来量化和评估重叠边界框的复杂性，并提出CreatiLayout-AM模型进行微调。

Result: 通过定性示例和定量分析，本文展示了当前方法在复杂重叠情况下生成质量的下降，并提出了新的评估工具和基准。

Conclusion: 本研究为布局到图像生成领域提供了新的评估标准和基准，强调了在复杂重叠情况下模型性能评估的重要性。

Abstract: Despite steady progress in layout-to-image generation, current methods still
struggle with layouts containing significant overlap between bounding boxes. We
identify two primary challenges: (1) large overlapping regions and (2)
overlapping instances with minimal semantic distinction. Through both
qualitative examples and quantitative analysis, we demonstrate how these
factors degrade generation quality. To systematically assess this issue, we
introduce OverLayScore, a novel metric that quantifies the complexity of
overlapping bounding boxes. Our analysis reveals that existing benchmarks are
biased toward simpler cases with low OverLayScore values, limiting their
effectiveness in evaluating model performance under more challenging
conditions. To bridge this gap, we present OverLayBench, a new benchmark
featuring high-quality annotations and a balanced distribution across different
levels of OverLayScore. As an initial step toward improving performance on
complex overlaps, we also propose CreatiLayout-AM, a model fine-tuned on a
curated amodal mask dataset. Together, our contributions lay the groundwork for
more robust layout-to-image generation under realistic and challenging
scenarios. Project link: https://mlpc-ucsd.github.io/OverLayBench.

</details>


### [121] [Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation](https://arxiv.org/abs/2509.19296)
*Sherwin Bahmani,Tianchang Shen,Jiawei Ren,Jiahui Huang,Yifeng Jiang,Haithem Turki,Andrea Tagliasacchi,David B. Lindell,Zan Gojcic,Sanja Fidler,Huan Ling,Jun Gao,Xuanchi Ren*

Main category: cs.CV

TL;DR: 提出了一种自蒸馏框架，将视频扩散模型的3D知识转化为3D高斯点云表示，从而在无多视图训练数据的情况下，实现静态和动态3D场景的高性能生成。


<details>
  <summary>Details</summary>
Motivation: 生成虚拟环境对游戏、机器人、自主驾驶和工业AI等应用至关重要，但现有的3D重建方法依赖实际多视图数据，限制了应用范围。

Method: 提出了一种自蒸馏框架，将视频扩散模型中的隐式3D知识蒸馏为显式的3D高斯点云表示，训练时使用合成数据。

Result: 实验结果表明，框架在静态和动态3D场景生成中实现了最先进的性能。

Conclusion: 该框架在静态和动态3D场景生成中表现出色，达到了最先进的性能。

Abstract: The ability to generate virtual environments is crucial for applications
ranging from gaming to physical AI domains such as robotics, autonomous
driving, and industrial AI. Current learning-based 3D reconstruction methods
rely on the availability of captured real-world multi-view data, which is not
always readily available. Recent advancements in video diffusion models have
shown remarkable imagination capabilities, yet their 2D nature limits the
applications to simulation where a robot needs to navigate and interact with
the environment. In this paper, we propose a self-distillation framework that
aims to distill the implicit 3D knowledge in the video diffusion models into an
explicit 3D Gaussian Splatting (3DGS) representation, eliminating the need for
multi-view training data. Specifically, we augment the typical RGB decoder with
a 3DGS decoder, which is supervised by the output of the RGB decoder. In this
approach, the 3DGS decoder can be purely trained with synthetic data generated
by video diffusion models. At inference time, our model can synthesize 3D
scenes from either a text prompt or a single image for real-time rendering. Our
framework further extends to dynamic 3D scene generation from a monocular input
video. Experimental results show that our framework achieves state-of-the-art
performance in static and dynamic 3D scene generation.

</details>


### [122] [VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction](https://arxiv.org/abs/2509.19297)
*Weijie Wang,Yeqing Chen,Zeyu Zhang,Hengyu Liu,Haoxiao Wang,Zhiyuan Feng,Wenkang Qin,Zheng Zhu,Donny Y. Chen,Bohan Zhuang*

Main category: cs.CV

TL;DR: VolSplat提出了一种更为可靠的多视图3D重建方法，通过体素对齐Gaussian克服了传统方法的局限性，从而提升了重建质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 重新思考传统的像素对齐Gaussian预测范式，识别其在3D模型重建中存在的多项局限性，如视图数量依赖和对齐误差。

Method: 提出了一种新的多视图前馈范式VolSplat，将像素对齐替换为体素对齐的Gaussian，直接从预测的3D体素网格预测Gaussian。

Result: 在RealEstate10K和ScanNet等基准测试中，VolSplat达到了最佳性能，生成了更可信和一致的Gaussian重建。

Conclusion: VolSplat方法在重建3D模型及其新视图合成中具有显著优势，提供了更一致和可靠的Gaussian重建。

Abstract: Feed-forward 3D Gaussian Splatting (3DGS) has emerged as a highly effective
solution for novel view synthesis. Existing methods predominantly rely on a
pixel-aligned Gaussian prediction paradigm, where each 2D pixel is mapped to a
3D Gaussian. We rethink this widely adopted formulation and identify several
inherent limitations: it renders the reconstructed 3D models heavily dependent
on the number of input views, leads to view-biased density distributions, and
introduces alignment errors, particularly when source views contain occlusions
or low texture. To address these challenges, we introduce VolSplat, a new
multi-view feed-forward paradigm that replaces pixel alignment with
voxel-aligned Gaussians. By directly predicting Gaussians from a predicted 3D
voxel grid, it overcomes pixel alignment's reliance on error-prone 2D feature
matching, ensuring robust multi-view consistency. Furthermore, it enables
adaptive control over Gaussian density based on 3D scene complexity, yielding
more faithful Gaussian point clouds, improved geometric consistency, and
enhanced novel-view rendering quality. Experiments on widely used benchmarks
including RealEstate10K and ScanNet demonstrate that VolSplat achieves
state-of-the-art performance while producing more plausible and view-consistent
Gaussian reconstructions. In addition to superior results, our approach
establishes a more scalable framework for feed-forward 3D reconstruction with
denser and more robust representations, paving the way for further research in
wider communities. The video results, code and trained models are available on
our project page: https://lhmd.top/volsplat.

</details>


### [123] [CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching](https://arxiv.org/abs/2509.19300)
*Chen Chen,Pengsheng Guo,Liangchen Song,Jiasen Lu,Rui Qian,Xinze Wang,Tsu-Jui Fu,Wei Liu,Yinfei Yang,Alex Schwing*

Main category: cs.CV

TL;DR: CAR-Flow通过条件重新参数化技术提高了生成模型的效率和性能，有效减少了训练时间和复杂度。


<details>
  <summary>Details</summary>
Motivation: 为了提高条件生成建模的训练效率，尤其是在处理高维数据时，减少模型学习所需的复杂性。

Method: 提议了一种轻量级的条件感知重新参数化方法，称为CAR-Flow，旨在改善生成模型的训练效率和效果。

Result: 在合成数据和高维自然图像数据集（ImageNet-256）上验证了CAR-Flow的有效性，显著降低了FID评分，显示出良好的生成性能，同时增加的参数量极少。

Conclusion: CAR-Flow通过条件重新参数化实现了高效的流匹配，在多个数据集上提升了生成质量，并且仅增加了少量参数。

Abstract: Conditional generative modeling aims to learn a conditional data distribution
from samples containing data-condition pairs. For this, diffusion and
flow-based methods have attained compelling results. These methods use a
learned (flow) model to transport an initial standard Gaussian noise that
ignores the condition to the conditional data distribution. The model is hence
required to learn both mass transport and conditional injection. To ease the
demand on the model, we propose Condition-Aware Reparameterization for Flow
Matching (CAR-Flow) -- a lightweight, learned shift that conditions the source,
the target, or both distributions. By relocating these distributions, CAR-Flow
shortens the probability path the model must learn, leading to faster training
in practice. On low-dimensional synthetic data, we visualize and quantify the
effects of CAR. On higher-dimensional natural image data (ImageNet-256),
equipping SiT-XL/2 with CAR-Flow reduces FID from 2.07 to 1.68, while
introducing less than 0.6% additional parameters.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [124] [Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs](https://arxiv.org/abs/2509.18113)
*Xin Hu,Yue Kang,Guanzi Yao,Tianze Kang,Mengjie Wang,Heyao Liu*

Main category: cs.CL

TL;DR: 本研究通过动态提示调度机制，提高了大语言模型在多任务和跨领域设置中的泛化能力，显著改善了模型的性能与稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在多任务和跨领域设置中普遍存在的泛化限制问题。

Method: 采用动态提示调度机制，通过任务嵌入和门控机制来控制提示信号，并设计了自动学习策略来优化多任务学习目标。

Result: 在语言理解和知识推理任务中，提示调度方法显著提高了模型的性能和稳定性，证明了其在统一多任务建模和跨领域适应中的有效性。

Conclusion: 该研究提出了一种统一的多任务学习框架，结合动态提示调度机制，有效改善了大语言模型在多任务和跨领域环境中的泛化能力。

Abstract: This study addresses the generalization limitations commonly observed in
large language models under multi-task and cross-domain settings. Unlike prior
methods such as SPoT, which depends on fixed prompt templates, our study
introduces a unified multi-task learning framework with dynamic prompt
scheduling mechanism. By introducing a prompt pool and a task-aware scheduling
strategy, the method dynamically combines and aligns prompts for different
tasks. This enhances the model's ability to capture semantic differences across
tasks. During prompt fusion, the model uses task embeddings and a gating
mechanism to finely control the prompt signals. This ensures alignment between
prompt content and task-specific demands. At the same time, it builds flexible
sharing pathways across tasks. In addition, the proposed optimization objective
centers on joint multi-task learning. It incorporates an automatic learning
strategy for scheduling weights, which effectively mitigates task interference
and negative transfer. To evaluate the effectiveness of the method, a series of
sensitivity experiments were conducted. These experiments examined the impact
of prompt temperature parameters and task number variation. The results confirm
the advantages of the proposed mechanism in maintaining model stability and
enhancing transferability. Experimental findings show that the prompt
scheduling method significantly improves performance on a range of language
understanding and knowledge reasoning tasks. These results fully demonstrate
its applicability and effectiveness in unified multi-task modeling and
cross-domain adaptation.

</details>


### [125] [GAUSS: Benchmarking Structured Mathematical Skills for Large Language Models](https://arxiv.org/abs/2509.18122)
*Yue Zhang,Jiaxin Zhang,Qiuyu Ren,Tahsin Saffat,Xiaoxuan Liu,Zitong Yang,Banghua Zhu,Yi Ma*

Main category: cs.CL

TL;DR: GAUSS是一个评估大型语言模型数学能力的基准，涵盖了12个核心技能维度，能够提供详细和可解释的能力画像，并展示了不同模型之间的比较。


<details>
  <summary>Details</summary>
Motivation: 为了全面评估大型语言模型在数学方面的能力，并为其提供可解释的技能分析。

Method: 通过将问题按照认知技能分类，并设计针对具体能力的任务，GAUSS构建了模型数学能力的全面、细致且可解释的画像。

Result: GAUSS能够揭示模型的数学能力特征，并通过具体实例展示模型的优势和劣势，促进多维度评估的重要性。

Conclusion: GAUSS提供了一种多维的技能评估方式，为大型语言模型的数学能力提供了清晰的画像。同时，其具体应用示例展示了不同模型之间的能力比较。

Abstract: We introduce \textbf{GAUSS} (\textbf{G}eneral \textbf{A}ssessment of
\textbf{U}nderlying \textbf{S}tructured \textbf{S}kills in Mathematics), a
benchmark that evaluates LLMs' mathematical abilities across twelve core skill
dimensions, grouped into three domains: knowledge and understanding, problem
solving and communication, and meta-skills and creativity. By categorizing
problems according to cognitive skills and designing tasks that isolate
specific abilities, GAUSS constructs comprehensive, fine-grained, and
interpretable profiles of models' mathematical abilities. These profiles
faithfully represent their underlying mathematical intelligence. To exemplify
how to use the \textsc{GAUSS} benchmark, we have derived the skill profile of
\textsc{GPT-5-thinking}, revealing its strengths and weaknesses as well as its
differences relative to \textsc{o4-mini-high}, thereby underscoring the value
of multidimensional, skill-based evaluation.

</details>


### [126] [Event Causality Identification with Synthetic Control](https://arxiv.org/abs/2509.18156)
*Haoyu Wang,Fengze Liu,Jiayao Zhang,Dan Roth,Kyle Richardson*

Main category: cs.CL

TL;DR: 本研究提出一种新的事件因果性识别方法，通过合成对照组提升识别的准确性，超越了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的事件因果性识别方法容易受因果关系的不当使用和不准确的图形推理的影响，需要一种更可靠的方法。

Method: 采用Rubin因果模型，通过生成合成的对照组来识别事件的因果关系。

Result: 通过合成控制方法，构建出与主角具有相似背景的对照组，从而更准确地识别因果关系。

Conclusion: 该研究提出的基于合成控制方法的事件因果性识别方法，比以往的方法更稳健，并在COPES-hard基准测试中进行了验证。

Abstract: Event causality identification (ECI), a process that extracts causal
relations between events from text, is crucial for distinguishing causation
from correlation. Traditional approaches to ECI have primarily utilized
linguistic patterns and multi-hop relational inference, risking false causality
identification due to informal usage of causality and specious graphical
inference. In this paper, we adopt the Rubin Causal Model to identify event
causality: given two temporally ordered events, we see the first event as the
treatment and the second one as the observed outcome. Determining their
causality involves manipulating the treatment and estimating the resultant
change in the likelihood of the outcome. Given that it is only possible to
implement manipulation conceptually in the text domain, as a work-around, we
try to find a twin for the protagonist from existing corpora. This twin should
have identical life experiences with the protagonist before the treatment but
undergoes an intervention of treatment. However, the practical difficulty of
locating such a match limits its feasibility. Addressing this issue, we use the
synthetic control method to generate such a twin' from relevant historical
data, leveraging text embedding synthesis and inversion techniques. This
approach allows us to identify causal relations more robustly than previous
methods, including GPT-4, which is demonstrated on a causality benchmark,
COPES-hard.

</details>


### [127] [ZERA: Zero-init Instruction Evolving Refinement Agent - From Zero Instructions to Structured Prompts via Principle-based Optimization](https://arxiv.org/abs/2509.18158)
*Seungyoun Yi,Minsoo Khang,Sungrae Park*

Main category: cs.CL

TL;DR: 本研究提出了一种新框架ZER A，通过优化用户和系统提示，显著提高大型语言模型的表现，且以较少的示例和更短的迭代周期实现高质量提示的快速收敛。


<details>
  <summary>Details</summary>
Motivation: 现有的自动提示优化方法通常依赖于非结构化反馈，并且需要大量样本和较长的迭代周期，导致其成本高且脆弱，因此需要一种更有效的优化框架。

Method: 通过精细化的、有原则的低开销优化，联合优化系统与用户提示，并使用八个可推广的标准和自动推导的权重进行评分和修订。

Result: ZER A在五个大型语言模型和九个不同的数据集上得到评估，覆盖推理、摘要和代码生成任务，结果表明ZER A在提示优化方面持续性优于强基线。

Conclusion: 实验证明，ZER A在优化提示方面比现有的基线方法具有一致性改进，且各个组件的贡献也得到了进一步验证。

Abstract: Automatic Prompt Optimization (APO) improves large language model (LLM)
performance by refining prompts for specific tasks. However, prior APO methods
typically focus only on user prompts, rely on unstructured feedback, and
require large sample sizes and long iteration cycles-making them costly and
brittle. We propose ZERA (Zero-init Instruction Evolving Refinement Agent), a
novel framework that jointly optimizes both system and user prompts through
principled, low-overhead refinement. ZERA scores prompts using eight
generalizable criteria with automatically inferred weights, and revises prompts
based on these structured critiques. This enables fast convergence to
high-quality prompts using minimal examples and short iteration cycles. We
evaluate ZERA across five LLMs and nine diverse datasets spanning reasoning,
summarization, and code generation tasks. Experimental results demonstrate
consistent improvements over strong baselines. Further ablation studies
highlight the contribution of each component to more effective prompt
construction. Our implementation including all prompts is publicly available at
https://github.com/younatics/zera-agent.

</details>


### [128] [Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning](https://arxiv.org/abs/2509.18163)
*Haodong Zhao,Chenyan Zhao,Yansi Li,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.CL

TL;DR: 本文揭示LLM在面对外部信息时的脆弱性，指出思维模式在误导信息下会加剧推理错误，强调提升信息评估能力的重要性。


<details>
  <summary>Details</summary>
Motivation: 探讨外部信息如何影响LLM的推理能力，尤其是复杂知识领域中的应用。

Method: 通过构建SciAux数据集系统测试LLM在获取辅助信息时的推理过程。

Result: 建立了SciAux数据集，实验证明误导性信息在思考过程中显著降低模型性能。

Conclusion: LLM的思维能力在面临错误信息时会加剧表现下降，强调了提高模型信息评估能力的重要性。

Abstract: The capacity of Large Language Models (LLMs) to reason is fundamental to
their application in complex, knowledge-intensive domains. In real-world
scenarios, LLMs are often augmented with external information that can be
helpful, irrelevant, or even misleading. This paper investigates the causal
impact of such auxiliary information on the reasoning process of LLMs with
explicit step-by-step thinking capabilities. We introduce SciAux, a new dataset
derived from ScienceQA, to systematically test the robustness of the model
against these types of information. Our findings reveal a critical
vulnerability: the model's deliberative "thinking mode" is a double-edged
sword. While helpful context improves accuracy, misleading information causes a
catastrophic drop in performance, which is amplified by the thinking process.
Instead of conferring robustness, thinking reinforces the degree of error when
provided with misinformation. This highlights that the challenge is not merely
to make models "think", but to endow them with the critical faculty to evaluate
the information upon which their reasoning is based. The SciAux dataset is
available at https://huggingface.co/datasets/billhdzhao/SciAux.

</details>


### [129] [SIRAG: Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework](https://arxiv.org/abs/2509.18167)
*Junlin Wang,Zehao Wu,Shaowei Lu,Yanlan Li,Xinghao Huang*

Main category: cs.CL

TL;DR: 提出了一种新的框架，通过加强检索器与生成器之间的协调，提高了RAG模型的性能，且具有良好的实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG模型中检索器与生成器独立发展，导致二者的交互不佳，影响模型的整体性能。

Method: 采用过程监督的多智能体框架，包含决策者和知识选择器，使用大语言模型作为评判者进行细粒度监督。

Result: 在单跳和多跳问题回答基准上，提高了准确性，收敛性更稳定，生成的推理轨迹更具可解释性。

Conclusion: 提出的多智能体框架提高了RAG模型的准确性和稳定性，并提升了推理的可解释性，且具有模块化特性，便于实际应用。

Abstract: Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to
access external knowledge sources, but the effectiveness of RAG relies on the
coordination between the retriever and the generator. Since these components
are developed independently, their interaction is often suboptimal: the
retriever may return irrelevant or redundant documents, while the generator may
fail to fully leverage retrieved evidence. In this work, we propose a
process-supervised multi-agent framework to bridge the gap between retriever
and generator. The framework introduces two lightweight agents: a Decision
Maker, which determines when to continue retrieval or stop for answer
generation, and a Knowledge Selector, which filters retrieved documents to
retain only the most useful evidence. To provide fine-grained supervision, we
employ an LLM-as-a-Judge that evaluates each intermediate action with
process-level rewards, ensuring more accurate credit assignment than relying
solely on final answer correctness. We further adopt a tree-structured rollout
strategy to explore diverse reasoning paths, and train both agents with
Proximal Policy Optimization (PPO) in an end-to-end manner. Experiments on
single-hop and multi-hop question answering benchmarks show that our approach
achieves higher accuracy, more stable convergence, and produces more
interpretable reasoning trajectories compared with standard RAG baselines.
Importantly, the proposed framework is modular and plug-and-play, requiring no
modification to the retriever or generator, making it practical for real-world
RAG applications.

</details>


### [130] [ERFC: Happy Customers with Emotion Recognition and Forecasting in Conversation in Call Centers](https://arxiv.org/abs/2509.18175)
*Aditi Debsharma,Bhushan Jagyasi,Surajit Sen,Priyanka Pandey,Devicharith Dovari,Yuvaraj V. C,Rosalin Parida,Gopali Contractor*

Main category: cs.CL

TL;DR: 本论文提出了一种新的情感识别与预测架构（ERFC），应用于呼叫中心等领域，通过理解并预测客户情感来提升客户体验。


<details>
  <summary>Details</summary>
Motivation: 在通话中心等场景中，通过了解客户的情感来改善客户体验，使代理能够及时提供适当的解决方案。

Method: 提出了一种新的情感识别和预测架构（ERFC），综合考虑多种模态、情感属性、上下文及讲话者之间的相互依赖关系。

Result: 在IEMOCAP数据集上的广泛实验显示，所提出的ERFC架构的可行性和有效性。

Conclusion: 提出的ERFC架构能够有效识别和预测对话中的情感，从而提升客户服务体验，特别是在呼叫中心等行业具有重要的商业价值。

Abstract: Emotion Recognition in Conversation has been seen to be widely applicable in
call center analytics, opinion mining, finance, retail, healthcare, and other
industries. In a call center scenario, the role of the call center agent is not
just confined to receiving calls but to also provide good customer experience
by pacifying the frustration or anger of the customers. This can be achieved by
maintaining neutral and positive emotion from the agent. As in any
conversation, the emotion of one speaker is usually dependent on the emotion of
other speaker. Hence the positive emotion of an agent, accompanied with the
right resolution will help in enhancing customer experience. This can change an
unhappy customer to a happy one. Imparting the right resolution at right time
becomes easier if the agent has the insight of the emotion of future
utterances. To predict the emotions of the future utterances we propose a novel
architecture, Emotion Recognition and Forecasting in Conversation. Our proposed
ERFC architecture considers multi modalities, different attributes of emotion,
context and the interdependencies of the utterances of the speakers in the
conversation. Our intensive experiments on the IEMOCAP dataset have shown the
feasibility of the proposed ERFC. This approach can provide a tremendous
business value for the applications like call center, where the happiness of
customer is utmost important.

</details>


### [131] [Evaluating Large Language Models for Detecting Antisemitism](https://arxiv.org/abs/2509.18293)
*Jay Patel,Hrudayangam Mehta,Jeremy Blackburn*

Main category: cs.CL

TL;DR: 本研究评估了八个开源LLMs在检测反犹太主义内容方面的能力，提出了Guided-CoT提示，提高了模型性能，发现Llama 3.1 70B超越了GPT-3.5，并揭示了LLMs在效用和可解释性方面的差异。


<details>
  <summary>Details</summary>
Motivation: 检测仇恨内容是一个重要且具有挑战性的问题，冷静学习模型需要持续训练，以适应不断变化的社交媒体环境。

Method: 评估八种开源大型语言模型（LLMs）检测反犹太主义内容的能力，同时利用上下文定义作为政策指南，并探索多种提示技术，设计了新的Guided-CoT提示。

Result: Guided-CoT能够很好地处理上下文政策，提高了所有评估模型的性能。Llama 3.1 70B的表现超越了微调后的GPT-3.5。我们引入了定量语义差异的新指标，揭示了模型生成的推理之间的显著差异和悖论行为。

Conclusion: 我们的实验强调了不同大型语言模型（LLMs）在效用、可解释性和可靠性方面的差异。

Abstract: Detecting hateful content is a challenging and important problem. Automated
tools, like machine-learning models, can help, but they require continuous
training to adapt to the ever-changing landscape of social media. In this work,
we evaluate eight open-source LLMs' capability to detect antisemitic content,
specifically leveraging in-context definition as a policy guideline. We explore
various prompting techniques and design a new CoT-like prompt, Guided-CoT.
Guided-CoT handles the in-context policy well, increasing performance across
all evaluated models, regardless of decoding configuration, model sizes, or
reasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5.
Additionally, we examine LLM errors and introduce metrics to quantify semantic
divergence in model-generated rationales, revealing notable differences and
paradoxical behaviors among LLMs. Our experiments highlight the differences
observed across LLMs' utility, explainability, and reliability.

</details>


### [132] [Exploiting Tree Structure for Credit Assignment in RL Training of LLMs](https://arxiv.org/abs/2509.18314)
*Hieu Tran,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: 本论文提出了一种新的无评论员算法TEMPO，通过树结构提供准确的token级信用分配，解决传统方法的不足，效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中稀疏延迟奖励导致的token级别信用分配问题，特别是在数学和医学问答任务中，决策token对结果的影响较大。

Method: 提出的TEMPO算法基于Prefix-to-Tree(P2T)方法，不使用评论员，利用树结构提供准确的token级别奖励信息。

Result: TEMPO在Qwen3-1.7B/4B型号上，在各种有分布和无分布基准（如MATH, MedQA, GSM-HARD等）上表现优于PPO和GRPO，且验证准确率更高。

Conclusion: TEMPO在各种基准测试中超越了PPO和GRPO，且验证准确率更高。

Abstract: Reinforcement learning improves LLM reasoning, yet sparse delayed reward over
long sequences makes token-level credit assignment the key bottleneck. We study
the verifiable-reward setting, where the final answer is checkable and multiple
responses can be drawn per prompt. Reasoning tasks in math and medical QA align
with this setup, where only a few decision tokens significantly impact the
outcome. PPO offers token-level advantages with a learned value model, but it
is complex to train both the actor and critic models simultaneously, and it is
not easily generalizable, as the token-level values from the critic model can
make training prone to overfitting. GRPO is critic-free and supports verifiable
rewards, but spreads a single sequence-level return across tokens and ignores
branching. We introduce \textbf{Prefix-to-Tree (P2T)}, a simple procedure that
converts a group of responses into a prefix tree and computes
\emph{nonparametric} prefix values \(V(s)\) by aggregating descendant outcomes.
Built on P2T, we propose \textbf{TEMPO} (\emph{\textbf{T}ree-\textbf{E}stimated
\textbf{M}ean Prefix Value for \textbf{P}olicy \textbf{O}ptimization}), a
critic-free algorithm that augments the group-relative outcome signal of GRPO
with \emph{branch-gated} temporal-difference corrections derived from the tree.
At non-branch tokens, the temporal-difference (TD) term is zero, so TEMPO
reduces to GRPO; at branching tokens, it supplies precise token-level credit
without a learned value network or extra judges/teachers. On Qwen3-1.7B/4B,
TEMPO outperforms PPO and GRPO on in-distribution (MATH, MedQA) and
out-of-distribution (GSM-HARD, AMC23, MedMCQA, MMLU-Medical) benchmarks, and
reaches higher validation accuracy with roughly the same wall-clock time.

</details>


### [133] [Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning](https://arxiv.org/abs/2509.18316)
*Saksham Khatwani,He Cheng,Majid Afshar,Dmitriy Dligach,Yanjun Gao*

Main category: cs.CL

TL;DR: 本研究探讨了将大语言模型作为知识图谱推理的奖励模型，评估了路径判断能力及其在下游诊断任务中的应用，发现具有潜力但在迁移性方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在诊断推理方面展现出潜力，但往往缺乏可靠的知识支撑推理。知识图谱如统一医学语言系统（UMLS）能提供结构化生物医学知识，从而支持可信的推理。

Method: 将大语言模型作为知识图谱推理路径的奖励模型，学习判断候选路径是否能为特定病人输入提供正确的诊断。

Result: 实验结果显示，特定的奖励优化和蒸馏能导致较强的路径判断性能，但在向下游任务的迁移能力较弱。

Conclusion: 本研究首次系统评估了通过奖励模型形式的推理在临床知识图谱上的应用，揭示了结构化、基于奖励的监督对医疗保健中生成式人工智能系统的诊断推理的影响。

Abstract: Large language models (LLMs) show promise for diagnostic reasoning but often
lack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as
the Unified Medical Language System (UMLS), offer structured biomedical
knowledge that can support trustworthy reasoning. Prior approaches typically
integrate KGs via retrieval augmented generation or fine tuning, inserting KG
content into prompts rather than enabling structured reasoning. We explore an
alternative paradigm: treating the LLM as a reward model of KG reasoning paths,
where the model learns to judge whether a candidate path leads to correct
diagnosis for a given patient input. This approach is inspired by recent work
that leverages reward training to enhance model reasoning abilities, and
grounded in computational theory, which suggests that verifying a solution is
often easier than generating one from scratch. It also parallels physicians'
diagnostic assessment, where they judge which sequences of findings and
intermediate conditions most plausibly support a diagnosis. We first
systematically evaluate five task formulation for knowledge path judging and
eight training paradigm. Second, we test whether the path judging abilities
generalize to downstream diagnostic tasks, including diagnosis summarization
and medical question answering. Experiments with three open source
instruct-tuned LLMs reveal both promise and brittleness: while specific reward
optimization and distillation lead to strong path-judging performance, the
transferability to downstream tasks remain weak. Our finding provides the first
systematic assessment of "reward model style" reasoning over clinical KGs,
offering insights into how structured, reward-based supervision influences
diagnostic reasoning in GenAI systems for healthcare.

</details>


### [134] [LOTUSDIS: A Thai far-field meeting corpus for robust conversational ASR](https://arxiv.org/abs/2509.18722)
*Pattara Tipaksorn,Sumonmas Thatphithakkul,Vataya Chunwijitra,Kwanchiva Thangthai*

Main category: cs.CL

TL;DR: 本文介绍了LOTUSDIS，一个旨在提升泰语远场会话ASR的公开语料库，结果显示微调模型在鲁棒性上有显著提高，强调了多样化训练数据的重要性。


<details>
  <summary>Details</summary>
Motivation: 为了解决泰语远场ASR中的鲁棒性问题，创建一个真实的对话语料库以进行研究。

Method: 通过收集由九个独立设备在多种距离下记录的自发对话，构建了LOTUSDIS数据集，并评估了Whisper模型的零样本和微调情况。

Result: 微调后的泰语Whisper模型显著提高了鲁棒性，整体错误率从64.3降至38.3，远场错误率从81.6降至49.5，尤其在最远麦克风上有显著提升。

Conclusion: LOTUSDIS语料库对于提高远场会话ASR的鲁棒性至关重要，特别是在训练数据多样性方面。

Abstract: We present LOTUSDIS, a publicly available Thai meeting corpus designed to
advance far-field conversational ASR. The dataset comprises 114 hours of
spontaneous, unscripted dialogue collected in 15-20 minute sessions with three
participants, where overlapping speech is frequent and natural. Speech was
recorded simultaneously by nine independent single-channel devices spanning six
microphone types at distances from 0.12 m to 10 m, preserving the authentic
effects of reverberation, noise, and device coloration without relying on
microphone arrays. We provide standard train, dev, test splits and release a
reproducible baseline system. We benchmarked several Whisper variants under
zero-shot and fine-tuned conditions. Off-the-shelf models showed strong
degradation with distance, confirming a mismatch between pre-training data and
Thai far-field speech. Fine-tuning on LOTUSDIS dramatically improved
robustness: a Thai Whisper baseline reduced overall WER from 64.3 to 38.3 and
far-field WER from 81.6 to 49.5, with especially large gains on the most
distant microphones. These results underscore the importance of
distance-diverse training data for robust ASR. The corpus is available under
CC-BY-SA 4.0. We also release training and evaluation scripts as a baseline
system to promote reproducible research in this field.

</details>


### [135] [Speculate Deep and Accurate: Lossless and Training-Free Acceleration for Offloaded LLMs via Substitute Speculative Decoding](https://arxiv.org/abs/2509.18344)
*Pei-Shuo Wang,Jian-Jia Chen,Chun-Che Yang,Chi-Chih Chang,Ning-Chi Huang,Mohamed S. Abdelfattah,Kai-Chiang Wu*

Main category: cs.CL

TL;DR: 针对大型语言模型在有限内存下的推理速度问题，提出无损无训练的 SubSpec 方法，显著加速参数卸载，在多个基准上实现高达 12.5 倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的巨大模型尺寸对内存有限的消费级 GPU 的部署构成挑战，因此需要有效的加速方法以解决参数卸载引起的推理速度问题。

Method: SubSpec 是一种无损且无训练的插件方法，它通过生成低比特量化替代层和共享 GPU 层及 KV-Cache 来实现。

Result: SubSpec 在 Qwen2.5 7B 上实现了 9.1 倍的速度提升，在 Qwen2.5 32B 上的速度提升达到了 12.5 倍。

Conclusion: SubSpec 通过构建一个高对齐度的草稿模型及共享 GPU 层来加速参数卸载，显著提高推理速度。

Abstract: The immense model sizes of large language models (LLMs) challenge deployment
on memory-limited consumer GPUs. Although model compression and parameter
offloading are common strategies to address memory limitations, compression can
degrade quality, and offloading maintains quality but suffers from slow
inference. Speculative decoding presents a promising avenue to accelerate
parameter offloading, utilizing a fast draft model to propose multiple draft
tokens, which are then verified by the target LLM in parallel with a single
forward pass. This method reduces the time-consuming data transfers in forward
passes that involve offloaded weight transfers. Existing methods often rely on
pretrained weights of the same family, but require additional training to align
with custom-trained models. Moreover, approaches that involve draft model
training usually yield only modest speedups. This limitation arises from
insufficient alignment with the target model, preventing higher token
acceptance lengths. To address these challenges and achieve greater speedups,
we propose SubSpec, a plug-and-play method to accelerate parameter offloading
that is lossless and training-free. SubSpec constructs a highly aligned draft
model by generating low-bit quantized substitute layers from offloaded target
LLM portions. Additionally, our method shares the remaining GPU-resident layers
and the KV-Cache, further reducing memory overhead and enhance alignment.
SubSpec achieves a high average acceptance length, delivering 9.1x speedup for
Qwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for
Qwen2.5 32B on popular generation benchmarks (24GB VRAM limit).

</details>


### [136] [SloPalSpeech: A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data](https://arxiv.org/abs/2509.19270)
*Erik Božík,Marek Šuppa*

Main category: cs.CL

TL;DR: SloPalSpeech是一个新颖的斯洛伐克语ASR数据集，含2806小时的语音，经过良好处理后用于提升多个Whisper模型的识别性能，显著降低了错误率。


<details>
  <summary>Details</summary>
Motivation: 旨在解决斯洛伐克等低资源语言在自动语音识别上由于训练数据稀缺而面临的挑战。

Method: 构建了一个大型斯洛伐克语ASR数据集，并开发了处理管道，将长录音切分为适合模型训练的30秒音频-文本对。

Result: 使用SloPalSpeech数据集细调多个Whisper模型，特别是Whisper-small模型的错误率降低了70	he。

Conclusion: 本研究成功开发了SloPalSpeech数据集，并利用该数据集对多种OpenAI Whisper模型进行了微调，显著提高了斯洛伐克语的自动语音识别性能。

Abstract: Automatic Speech Recognition (ASR) for low-resource languages like Slovak is
hindered by the scarcity of training data. To address this, we introduce
SloPalSpeech, a new, large-scale Slovak ASR dataset containing 2,806 hours of
speech from parliamentary proceedings. We developed a robust processing
pipeline to align and segment long-form recordings into clean, 30-second
audio-transcript pairs suitable for model training. We use this dataset to
fine-tune several OpenAI Whisper models (small, medium, large-v3, and
large-v3-turbo), achieving significant Word Error Rate (WER) reductions on
standard Slovak benchmarks like Common Voice and FLEURS. For instance, the
fine-tuned Whisper-small model's WER dropped by up to 70\%, approaching the
baseline performance of the much larger Whisper-large-v3 model. To foster
future research in low-resource speech recognition, we publicly release the
complete SloPalSpeech dataset, the fully segmented transcripts (60 million
words), and all our fine-tuned models.

</details>


### [137] [Speech Vecalign: an Embedding-based Method for Aligning Parallel Speech Documents](https://arxiv.org/abs/2509.18360)
*Chutong Meng,Philipp Koehn*

Main category: cs.CL

TL;DR: Speech Vecalign是一种新方法，用于对齐语音文档，效果优于传统方法，且在英语和德语翻译模型中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有对齐方法在处理无标签语音文档时的局限性，提升语音到语音的对齐质量，减少噪声。

Method: 提出了一种平行语音文档对齐的方法Speech Vecalign，利用语音段嵌入进行单调对齐，不依赖文本转录。

Result: 在对3000小时无标签的英语-德语语音文档进行对齐后，产生了约1000小时的高质量对齐，并在翻译模型中表现出比Global Mining方法更好的翻译性能。

Conclusion: Speech Vecalign在对话音档的对齐方面表现优于现有方法，并且在英语和德语的翻译模型中也取得了更好的结果。

Abstract: We present Speech Vecalign, a parallel speech document alignment method that
monotonically aligns speech segment embeddings and does not depend on text
transcriptions. Compared to the baseline method Global Mining, a variant of
speech mining, Speech Vecalign produces longer speech-to-speech alignments. It
also demonstrates greater robustness than Local Mining, another speech mining
variant, as it produces less noise. We applied Speech Vecalign to 3,000 hours
of unlabeled parallel English-German (En-De) speech documents from VoxPopuli,
yielding about 1,000 hours of high-quality alignments. We then trained En-De
speech-to-speech translation models on the aligned data. Speech Vecalign
improves the En-to-De and De-to-En performance over Global Mining by 0.37 and
0.18 ASR-BLEU, respectively. Moreover, our models match or outperform
SpeechMatrix model performance, despite using 8 times fewer raw speech
documents.

</details>


### [138] [Interactive Real-Time Speaker Diarization Correction with Human Feedback](https://arxiv.org/abs/2509.18377)
*Xinlu He,Yiwen Guan,Badrivishal Paurana,Zilin Dai,Jacob Whitehill*

Main category: cs.CL

TL;DR: 本研究提出了一种LLM辅助的说话者 diarization 校正系统，通过实时用户反馈显著提高了说话者识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的自动语音处理系统通常缺乏用户反馈，而用户反馈有望提高准确率。

Method: 提出了一种结合大规模语言模型（LLM）的人机互动说话者 diarization 校正系统，包括实时反馈机制和多种改进技术。

Result: 通过LLM驱动的仿真实验，我们的系统在AMI测试集上将误识别率（DER）降低了9.92%，说话者混淆错误降低了44.23%。

Conclusion: 我们的方法显著提高了说话者区分的准确性，并有效减少了说话者混淆错误。

Abstract: Most automatic speech processing systems operate in "open loop" mode without
user feedback about who said what; yet, human-in-the-loop workflows can
potentially enable higher accuracy. We propose an LLM-assisted speaker
diarization correction system that lets users fix speaker attribution errors in
real time. The pipeline performs streaming ASR and diarization, uses an LLM to
deliver concise summaries to the users, and accepts brief verbal feedback that
is immediately incorporated without disrupting interactions. Moreover, we
develop techniques to make the workflow more effective: First, a
split-when-merged (SWM) technique detects and splits multi-speaker segments
that the ASR erroneously attributes to just a single speaker. Second, online
speaker enrollments are collected based on users' diarization corrections, thus
helping to prevent speaker diarization errors from occurring in the future.
LLM-driven simulations on the AMI test set indicate that our system
substantially reduces DER by 9.92% and speaker confusion error by 44.23%. We
further analyze correction efficacy under different settings, including summary
vs full transcript display, the number of online enrollments limitation, and
correction frequency.

</details>


### [139] [NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided Social Norm Modeling and Violation Recovery](https://arxiv.org/abs/2509.18395)
*Minki Hong,Jangho Choi,Jihie Kim*

Main category: cs.CL

TL;DR: NormGenesis是一个旨在提高对话系统社会规范意识的多文化框架，包含新的对话类型V2R和一个注释丰富的数据集，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了提高对话系统在沟通中遵循社会规范的能力，允许生成在语义上连贯且社会上可接受的回应。

Method: 通过提出新的对话类型Violation-to-Resolution (V2R)，以及早期对话合成过程中的示例基础迭代优化，来生成和注释符合社会规范的多文化对话。

Result: 使用NormGenesis构建了一个包含10,800个多轮对话的数据集，并在规范遵循、说话意图和情感反应的逐轮注释上取得显著提升，评估显示在对话自然性和推广性能上超越了现有数据集。

Conclusion: NormGenesis为跨文化对话生成提供了一种新的基准和可扩展的方法，特别是在语言和文化多样性的背景下提高社会规范意识。

Abstract: Social norms govern culturally appropriate behavior in communication,
enabling dialogue systems to produce responses that are not only coherent but
also socially acceptable. We present NormGenesis, a multicultural framework for
generating and annotating socially grounded dialogues across English, Chinese,
and Korean. To model the dynamics of social interaction beyond static norm
classification, we propose a novel dialogue type, Violation-to-Resolution
(V2R), which models the progression of conversations following norm violations
through recognition and socially appropriate repair. To improve pragmatic
consistency in underrepresented languages, we implement an exemplar-based
iterative refinement early in the dialogue synthesis process. This design
introduces alignment with linguistic, emotional, and sociocultural expectations
before full dialogue generation begins. Using this framework, we construct a
dataset of 10,800 multi-turn dialogues annotated at the turn level for norm
adherence, speaker intent, and emotional response. Human and LLM-based
evaluations demonstrate that NormGenesis significantly outperforms existing
datasets in refinement quality, dialogue naturalness, and generalization
performance. We show that models trained on our V2R-augmented data exhibit
improved pragmatic competence in ethically sensitive contexts. Our work
establishes a new benchmark for culturally adaptive dialogue modeling and
provides a scalable methodology for norm-aware generation across linguistically
and culturally diverse languages.

</details>


### [140] [Evaluating the Creativity of LLMs in Persian Literary Text Generation](https://arxiv.org/abs/2509.18401)
*Armin Tourajmehr,Mohammad Reza Modarres,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 本研究评估大型语言模型生成波斯文学文本的能力，采用创造力评估标准，结果显示模型具有创造力，但也存在改进空间。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在非英语文学传统中的创造力表现，并建立标准化的评估方法。

Method: 通过构建用户生成的波斯文学数据集，采用Torrance创造力测试的四个维度评估模型输出，并使用大型语言模型进行自动评分。

Result: 评估显示出大型语言模型在波斯文学文本生成中具有创造力，但同时也存在明显的局限性。

Conclusion: 大型语言模型在波斯文学文本生成方面显示出强项与局限性，需进一步改进。

Abstract: Large language models (LLMs) have demonstrated notable creative abilities in
generating literary texts, including poetry and short stories. However, prior
research has primarily centered on English, with limited exploration of
non-English literary traditions and without standardized methods for assessing
creativity. In this paper, we evaluate the capacity of LLMs to generate Persian
literary text enriched with culturally relevant expressions. We build a dataset
of user-generated Persian literary spanning 20 diverse topics and assess model
outputs along four creativity dimensions-originality, fluency, flexibility, and
elaboration-by adapting the Torrance Tests of Creative Thinking. To reduce
evaluation costs, we adopt an LLM as a judge for automated scoring and validate
its reliability against human judgments using intraclass correlation
coefficients, observing strong agreement. In addition, we analyze the models'
ability to understand and employ four core literary devices: simile, metaphor,
hyperbole, and antithesis. Our results highlight both the strengths and
limitations of LLMs in Persian literary text generation, underscoring the need
for further refinement.

</details>


### [141] [Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations](https://arxiv.org/abs/2509.18439)
*Oscar J. Ponce-Ponte,David Toro-Tobon,Luis F. Figueroa,Michael Gionfriddo,Megan Branda,Victor M. Montori,Saturnino Luz,Juan P. Brito*

Main category: cs.CL

TL;DR: 本研究开发了一种通过深度学习和BERT模型自动化测量共享决策的方法，有助于大规模评估患者-医生对话中的决策过程。


<details>
  <summary>Details</summary>
Motivation: 急需一种方法来自动化、大规模地衡量共享决策，以实现以患者为中心的护理。

Method: 使用语言建模和对话一致性（CA）评分的方法，通过训练深度学习模型和微调BERT模型，分析157个视频录制的患者-医生对话。

Result: 研究结果表明，使用深度学习和微调BERT模型的方法可以有效计算CA评分，并与共享决策结果（DCS和OPTION12）相关联。

Conclusion: 本研究提出了一种自动化、可扩展的方法，通过可解释的对话一致性评分来衡量患者与医生之间的共享决策，具有在大规模评估共享决策策略的潜力。

Abstract: Shared decision-making (SDM) is necessary to achieve patient-centred care.
Currently no methodology exists to automatically measure SDM at scale. This
study aimed to develop an automated approach to measure SDM by using language
modelling and the conversational alignment (CA) score. A total of 157
video-recorded patient-doctor conversations from a randomized multi-centre
trial evaluating SDM decision aids for anticoagulation in atrial fibrillations
were transcribed and segmented into 42,559 sentences. Context-response pairs
and negative sampling were employed to train deep learning (DL) models and
fine-tuned BERT models via the next sentence prediction (NSP) task. Each
top-performing model was used to calculate four types of CA scores. A
random-effects analysis by clinician, adjusting for age, sex, race, and trial
arm, assessed the association between CA scores and SDM outcomes: the
Decisional Conflict Scale (DCS) and the Observing Patient Involvement in
Decision-Making 12 (OPTION12) scores. p-values were corrected for multiple
comparisons with the Benjamini-Hochberg method. Among 157 patients (34% female,
mean age 70 SD 10.8), clinicians on average spoke more words than patients
(1911 vs 773). The DL model without the stylebook strategy achieved a recall@1
of 0.227, while the fine-tuned BERTbase (110M) achieved the highest recall@1
with 0.640. The AbsMax (18.36 SE7.74 p=0.025) and Max CA (21.02 SE7.63 p=0.012)
scores generated with the DL without stylebook were associated with OPTION12.
The Max CA score generated with the fine-tuned BERTbase (110M) was associated
with the DCS score (-27.61 SE12.63 p=0.037). BERT model sizes did not have an
impact the association between CA scores and SDM. This study introduces an
automated, scalable methodology to measure SDM in patient-doctor conversations
through explainable CA scores, with potential to evaluate SDM strategies at
scale.

</details>


### [142] [CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable Length, Intrinsic Difficulty, and Distractor Density](https://arxiv.org/abs/2509.18458)
*Daniel Kaiser,Arnoldo Frigessi,Ali Ramezani-Kebrya,Benjamin Ricaud*

Main category: cs.CL

TL;DR: CogniLoad 是一个基于认知负担理论的新基准，系统分析大型语言模型的推理能力，发现任务长度是主要限制，提供了一种可复制和可扩展的工具。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型基准测试往往忽视了任务复杂性、干扰干扰和任务长度等关键因素，迫切需要一种新的方法来进行更精确的失败分析。

Method: CogniLoad 通过自然语言逻辑难题生成，调整内在难度、干扰信号比率和任务长度等参数，深入探讨认知负荷理论的核心维度。

Result: 通过对22种最先进的推理大型语言模型的评估，CogniLoad 揭示了显著的性能敏感性，任务长度被确认为主要限制，并发现了对内在复杂性和干扰比例的不同容忍度以及U型响应。

Conclusion: CogniLoad 是一个新颖的合成基准，能够系统地分析大型语言模型的推理能力，帮助识别其在任务复杂性、干扰因素及任务长度上的表现差异。

Abstract: Current benchmarks for long-context reasoning in Large Language Models (LLMs)
often blur critical factors like intrinsic task complexity, distractor
interference, and task length. To enable more precise failure analysis, we
introduce CogniLoad, a novel synthetic benchmark grounded in Cognitive Load
Theory (CLT). CogniLoad generates natural-language logic puzzles with
independently tunable parameters that reflect CLT's core dimensions: intrinsic
difficulty ($d$) controls intrinsic load; distractor-to-signal ratio ($\rho$)
regulates extraneous load; and task length ($N$) serves as an operational proxy
for conditions demanding germane load. Evaluating 22 SotA reasoning LLMs,
CogniLoad reveals distinct performance sensitivities, identifying task length
as a dominant constraint and uncovering varied tolerances to intrinsic
complexity and U-shaped responses to distractor ratios. By offering systematic,
factorial control over these cognitive load dimensions, CogniLoad provides a
reproducible, scalable, and diagnostically rich tool for dissecting LLM
reasoning limitations and guiding future model development.

</details>


### [143] [LAWCAT: Efficient Distillation from Quadratic to Linear Attention with Convolution across Tokens for Long Context Modeling](https://arxiv.org/abs/2509.18467)
*Zeyu Liu,Souvik Kundu,Lianghao Jiang,Anni Li,Srikanth Ronanki,Sravan Bodapati,Gourav Datta,Peter A. Beerel*

Main category: cs.CL

TL;DR: LAWCAT是一个新颖的线性化框架，通过转移预训练变压器的能力，解决长上下文线性模型的训练及性能问题。


<details>
  <summary>Details</summary>
Motivation: 解决变压器架构在序列长度方面的二次计算复杂度带来的瓶颈，尤其是在延迟敏感的长上下文应用中，同时高效训练线性复杂度替代品。

Method: LAWCAT结合了因果Conv1D层和规范化门控线性注意力，以提高局部依赖建模和在不同上下文长度下的泛化能力。

Result: LAWCAT在高达22K tokens的上下文长度中实现超过90%的关键检索准确率，并在多个基准任务上展示竞争力，且所需的预训练令牌数量不到0.1%。

Conclusion: LAWCAT为高性能长上下文线性模型提供了一条高效的路径，适合边缘部署，减少对大量长序列训练数据和计算资源的依赖。

Abstract: Although transformer architectures have achieved state-of-the-art performance
across diverse domains, their quadratic computational complexity with respect
to sequence length remains a significant bottleneck, particularly for
latency-sensitive long-context applications. While recent linear-complexity
alternatives are increasingly powerful, effectively training them from scratch
is still resource-intensive. To overcome these limitations, we propose LAWCAT
(Linear Attention with Convolution Across Time), a novel linearization
framework designed to efficiently transfer the capabilities of pre-trained
transformers into a performant linear attention architecture. LAWCAT integrates
causal Conv1D layers to enhance local dependency modeling and employs
normalized gated linear attention to improve generalization across varying
context lengths. Our comprehensive evaluations demonstrate that, distilling
Mistral-7B with only 1K-length sequences yields over 90\% passkey retrieval
accuracy up to 22K tokens, significantly extending its effective context
window. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance
on S-NIAH 1\&2\&3 tasks (1K-8K context length) and BABILong benchmark
(QA2\&QA3, 0K-16K context length), requiring less than 0.1\% pre-training
tokens compared with pre-training models. Furthermore, LAWCAT exhibits faster
prefill speeds than FlashAttention-2 for sequences exceeding 8K tokens. LAWCAT
thus provides an efficient pathway to high-performance, long-context linear
models suitable for edge deployment, reducing reliance on extensive
long-sequence training data and computational resources.

</details>


### [144] [Actions Speak Louder than Prompts: A Large-Scale Study of LLMs for Graph Inference](https://arxiv.org/abs/2509.18487)
*Ben Finkelshtein,Silviu Cucerzan,Sujay Kumar Jauhar,Ryen White*

Main category: cs.CL

TL;DR: 本文评估了LLM在图数据处理中的多种交互策略，发现代码生成是最佳方法，提供了未来设计的指导原则。


<details>
  <summary>Details</summary>
Motivation: 尽管对LLM的兴趣激增，仍缺乏对其在图数据互动中的能力的原则性理解。

Method: 进行大规模、受控的评估，系统地分析了LLM在文本驱动的图机器学习应用中的表现，涵盖多个关键变量的维度。

Result: 通过分析，发现代码生成在处理长文本和高度连接的图时表现最佳，而在异质图上的交互策略保持有效。

Conclusion: 当前LLM与图数据的交互模式具有良好的适应性和多样性，尤其是代码生成对输入类型的灵活利用显著提升了性能。

Abstract: Large language models (LLMs) are increasingly used for text-rich graph
machine learning tasks such as node classification in high-impact domains like
fraud detection and recommendation systems. Yet, despite a surge of interest,
the field lacks a principled understanding of the capabilities of LLMs in their
interaction with graph data. In this work, we conduct a large-scale, controlled
evaluation across several key axes of variability to systematically assess the
strengths and weaknesses of LLM-based graph reasoning methods in text-based
applications. The axes include the LLM-graph interaction mode, comparing
prompting, tool-use, and code generation; dataset domains, spanning citation,
web-link, e-commerce, and social networks; structural regimes contrasting
homophilic and heterophilic graphs; feature characteristics involving both
short- and long-text node attributes; and model configurations with varying LLM
sizes and reasoning capabilities. We further analyze dependencies by
methodically truncating features, deleting edges, and removing labels to
quantify reliance on input types. Our findings provide practical and actionable
guidance. (1) LLMs as code generators achieve the strongest overall performance
on graph data, with especially large gains on long-text or high-degree graphs
where prompting quickly exceeds the token budget. (2) All interaction
strategies remain effective on heterophilic graphs, challenging the assumption
that LLM-based methods collapse under low homophily. (3) Code generation is
able to flexibly adapt its reliance between structure, features, or labels to
leverage the most informative input type. Together, these findings provide a
comprehensive view of the strengths and limitations of current LLM-graph
interaction modes and highlight key design principles for future approaches.

</details>


### [145] [A Rhythm-Aware Phrase Insertion for Classical Arabic Poetry Composition](https://arxiv.org/abs/2509.18514)
*Mohamad Elzohbi,Richard Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种利用ByT5模型插入阿拉伯诗歌短语以符合特定韵律的方法，结合条件去噪目标和课程学习策略，实验结果表明模型表现良好。


<details>
  <summary>Details</summary>
Motivation: 旨在为阿拉伯诗歌插入短语，以符合特定的韵律。

Method: 使用ByT5模型，结合规则基础的音素到节拍转换，以及条件去噪目标进行微调。

Result: 实验结果表明，模型在韵律对齐与语义保持方面表现优秀。

Conclusion: 该模型在保持语义一致性的同时实现了高韵律对齐，可以在创作阿拉伯古典诗歌的过程中发挥积极作用。

Abstract: This paper presents a methodology for inserting phrases in Arabic poems to
conform to a specific rhythm using ByT5, a byte-level multilingual
transformer-based model. Our work discusses a rule-based grapheme-to-beat
transformation tailored for extracting the rhythm from fully diacritized Arabic
script. Our approach employs a conditional denoising objective to fine-tune
ByT5, where the model reconstructs masked words to match a target rhythm. We
adopt a curriculum learning strategy, pre-training on a general Arabic dataset
before fine-tuning on poetic dataset, and explore cross-lingual transfer from
English to Arabic. Experimental results demonstrate that our models achieve
high rhythmic alignment while maintaining semantic coherence. The proposed
model has the potential to be used in co-creative applications in the process
of composing classical Arabic poems.

</details>


### [146] [Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector](https://arxiv.org/abs/2509.18535)
*Mo Mu,Dianqiao Lei,Chang Li*

Main category: cs.CL

TL;DR: 本研究提出了一种新任务和轻量框架，用于检测AI生成文本，包括原始及其修改版本，且在多个数据集上展示了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT的广泛应用，检测AI生成文本的需求日益迫切，现有方法无法有效应对文本的修改和变化。

Method: 提出了一种基于文本内部结构的轻量级框架，使用预训练语言模型的句子嵌入，结合注意力机制和对比学习，利用因果图和反事实方法来隔离结构特征。

Result: 在两个精心策划的数据集上进行的实验证明了我们的方法的有效性。

Conclusion: 我们的框架有效地解决了当前文本检测的局限性，并在多个数据集上验证了其有效性。

Abstract: The widespread adoption of ChatGPT has raised concerns about its misuse,
highlighting the need for robust detection of AI-generated text. Current
word-level detectors are vulnerable to paraphrasing or simple prompts (PSP),
suffer from biases induced by ChatGPT's word-level patterns (CWP) and training
data content, degrade on modified text, and often require large models or
online LLM interaction. To tackle these issues, we introduce a novel task to
detect both original and PSP-modified AI-generated texts, and propose a
lightweight framework that classifies texts based on their internal structure,
which remains invariant under word-level changes. Our approach encodes sentence
embeddings from pre-trained language models and models their relationships via
attention. We employ contrastive learning to mitigate embedding biases from
autoregressive generation and incorporate a causal graph with counterfactual
methods to isolate structural features from topic-related biases. Experiments
on two curated datasets, including abstract comparisons and revised life FAQs,
validate the effectiveness of our method.

</details>


### [147] [CCQA: Generating Question from Solution Can Improve Inference-Time Reasoning in SLMs](https://arxiv.org/abs/2509.18536)
*Jin Young Kim,Ji Won Yoon*

Main category: cs.CL

TL;DR: 提出了一种新的循环一致性问答方法(CCQA)，在小型语言模型上实现了有效推理，超越了现有最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 研究表明，传统方法在小型语言模型(SLMs)中的效果有限，因此需要开发新的推理方法以提升性能。

Method: CCQA(循环一致性问答)方法通过从每个推理路径和答案生成问题，再通过计算其与原始问题的相似性来评估并选择最佳答案。

Result: 实验结果表明，CCQA在八种模型上均表现优于现有的最先进方法，验证了其有效性。

Conclusion: CCQA方法在数学和常识推理基准上持续超越现有最先进的方法，并为小型语言模型提供了新的高效推理基准。

Abstract: Recently, inference-time reasoning strategies have further improved the
accuracy of large language models (LLMs), but their effectiveness on smaller
models remains unclear. Based on the observation that conventional approaches
often fail to improve performance in this context, we propose
\textbf{C}ycle-\textbf{C}onsistency in \textbf{Q}uestion \textbf{A}nswering
(CCQA), a novel reasoning method that can be effectively applied to SLMs.
Inspired by cycle consistency, CCQA generates a question from each reasoning
path and answer, evaluates each by its similarity to the original question, and
then selects the candidate solution with the highest similarity score as the
final response. Since conventional SLMs struggle to generate accurate questions
from their own reasoning paths and answers, we employ a lightweight Flan-T5
model specialized for question generation to support this process efficiently.
From the experimental results, it is verified that CCQA consistently
outperforms existing state-of-the-art (SOTA) methods across eight models on
mathematical and commonsense reasoning benchmarks. Furthermore, our method
establishes a new practical baseline for efficient reasoning in SLMs. Source
code can be found at https://github.com/scai-research/ccqa_official.

</details>


### [148] [Prior-based Noisy Text Data Filtering: Fast and Strong Alternative For Perplexity](https://arxiv.org/abs/2509.18577)
*Yeongbin Seo,Gayoung Kim,Jaehyung Kim,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 本研究提出了一种优先基于数据过滤的方法，显著提高数据选择效率和准确性，且在多语言和符号语言方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 考虑到当前基于困惑度的过滤方法在处理噪声和分布外样本时的高时间成本和不可靠性，迫切需要寻找一个高效且有效的数据过滤方法。

Method: 采用优先基于数据过滤的方法，通过语料级词项频率统计估计词项优先级，并根据均值和标准差对文档进行过滤，无需模型推理。

Result: 优先基于过滤的方式在20个下游基准测试中平均表现最佳，相比于基于困惑度的过滤，时间成本减低超过1000倍。

Conclusion: 优先基于数据过滤的方法在处理多语言语料和符号语言的适应性方面表现出色，且在20个下游基准测试中性能优异。

Abstract: As large language models (LLMs) are pretrained on massive web corpora,
careful selection of data becomes essential to ensure effective and efficient
learning. While perplexity (PPL)-based filtering has shown strong performance,
it suffers from drawbacks: substantial time costs and inherent unreliability of
the model when handling noisy or out-of-distribution samples. In this work, we
propose a simple yet powerful alternative: a prior-based data filtering method
that estimates token priors using corpus-level term frequency statistics,
inspired by linguistic insights on word roles and lexical density. Our approach
filters documents based on the mean and standard deviation of token priors,
serving as a fast proxy to PPL while requiring no model inference. Despite its
simplicity, the prior-based filter achieves the highest average performance
across 20 downstream benchmarks, while reducing time cost by over 1000x
compared to PPL-based filtering. We further demonstrate its applicability to
symbolic languages such as code and math, and its dynamic adaptability to
multilingual corpora without supervision

</details>


### [149] [TsqLoRA: Towards Sensitivity and Quality Low-Rank Adaptation for Efficient Fine-Tuning](https://arxiv.org/abs/2509.18585)
*Yu Chen,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: TsqLoRA是一种新颖的微调方法，通过数据质量选择和敏感性低秩适应，提高了效率并优化了多种自然语言处理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的环境中，传统的完全微调方法计算成本高且占用内存大，而现有的参数高效微调方法未能充分考虑模型层的敏感性和训练数据的重要性。

Method: 提出了一种基于数据质量选择和敏感性意识的低秩适应的微调方法，包括一个质量感知的采样机制和一个动态秩分配模块。

Result: 实验结果表明，TsqLoRA显著提高了微调效率，并在多种NLP任务上保持或提高了性能。

Conclusion: TsqLoRA在提高微调效率的同时，保持或改善了多种自然语言处理任务的性能。

Abstract: Fine-tuning large pre-trained models for downstream tasks has become a
fundamental approach in natural language processing. Fully fine-tuning all
model parameters is computationally expensive and memory-intensive, especially
in resource-constrained environments. Existing parameter-efficient fine-tuning
methods reduce the number of trainable parameters but typically overlook the
varying sensitivity of different model layers and the importance of training
data. In this work, we propose TsqLoRA, a novel method that integrates
data-quality-driven selection with sensitivity-aware low-rank adaptation,
consisted of two main components: a quality-aware sampling mechanism for
selecting the most informative training data, and a dynamic rank allocation
module that adjusts the rank of each layer based on its sensitivity to
parameter updates. The experimental results demonstrate that TsqLoRA improves
fine-tuning efficiency while maintaining or even improving performance on a
variety of NLP tasks. Our code will be available at
https://github.com/Benjamin-Ricky/TsqLoRA.

</details>


### [150] [UniECG: Understanding and Generating ECG in One Unified Model](https://arxiv.org/abs/2509.18588)
*Jiarui Jin,Haoyu Wang,Xiang Lan,Jun Li,Gaofeng Cheng,Hongyan Li,Shenda Hong*

Main category: cs.CL

TL;DR: UniECG是第一个专注于ECG的统一模型，能够执行ECG解读与生成，通过两阶段训练方法提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型在理解ECG信号和准确提供医疗诊断方面存在不足，难以正确生成ECG信号，因此需要一个新模型来解决这些问题。

Method: 采用解耦的两阶段训练方法，首先学习基于证据的解读技能（ECG转文本），然后通过潜在空间对齐注入ECG生成能力（文本转ECG）。

Result: UniECG能够根据用户输入自主选择解读或生成ECG，显著扩展目前ECG模型的能力边界。

Conclusion: UniECG是一个创新的统一模型，能够同时进行基于证据的ECG解读和文本条件的ECG生成，克服了当前模型在ECG信号理解和生成方面的局限性。

Abstract: Recent unified models such as GPT-5 have achieved encouraging progress on
vision-language tasks. However, these unified models typically fail to
correctly understand ECG signals and provide accurate medical diagnoses, nor
can they correctly generate ECG signals. To address these limitations, we
propose UniECG, the first unified model for ECG capable of concurrently
performing evidence-based ECG interpretation and text-conditioned ECG
generation tasks. Through a decoupled two-stage training approach, the model
first learns evidence-based interpretation skills (ECG-to-Text), and then
injects ECG generation capabilities (Text-to-ECG) via latent space alignment.
UniECG can autonomously choose to interpret or generate an ECG based on user
input, significantly extending the capability boundaries of current ECG models.
Our code and checkpoints will be made publicly available at
https://github.com/PKUDigitalHealth/UniECG upon acceptance.

</details>


### [151] [A Good Plan is Hard to Find: Aligning Models with Preferences is Misaligned with What Helps Users](https://arxiv.org/abs/2509.18632)
*Nishant Balepur,Matthew Shu,Yoo Yeon Sung,Seraphina Goldfarb-Tarrant,Shi Feng,Fumeng Yang,Rachel Rudinger,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 研究表明，LLM的有效性与用户偏好存在脱节，因此需要基于真实用户交互进行有效的对齐。


<details>
  <summary>Details</summary>
Motivation: 探索LLM生成的计划与用户实际帮助之间的差距，重新评估现有的对齐方法。

Method: 通过Planorama界面收集126名用户对300个多步骤问题的LLM计划执行结果，并分析4388次执行和5584次偏好比较。

Result: 发现用户/模型偏好与计划的有效性不一致，表明常见的对齐反馈可能会与有用性产生错位。

Conclusion: 对LLM的帮助需要基于真实用户交互的反馈，而不仅仅是用户偏好的表面特征。

Abstract: To assist users in complex tasks, LLMs generate plans: step-by-step
instructions towards a goal. While alignment methods aim to ensure LLM plans
are helpful, they train (RLHF) or evaluate (ChatbotArena) on what users prefer,
assuming this reflects what helps them. We test this with Planorama: an
interface where 126 users answer 300 multi-step questions with LLM plans. We
get 4388 plan executions and 5584 comparisons to measure plan helpfulness (QA
success) and user preferences on plans, and recreate the setup in agents and
reward models to see if they simulate or prefer what helps users. We expose: 1)
user/model preferences and agent success do not accurately predict which plans
help users, so common alignment feedback can misalign with helpfulness; 2) this
gap is not due to user-specific preferences, as users are similarly successful
when using plans they prefer/disprefer; 3) surface-level cues like brevity and
question similarity strongly link to preferences, but such biases fail to
predict helpfulness. In all, we argue aligning helpful LLMs needs feedback from
real user interactions, not just preferences of what looks helpful, so we
discuss the plan NLP researchers can execute to solve this problem.

</details>


### [152] [Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering](https://arxiv.org/abs/2509.18655)
*Lingwen Deng,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: CAPE-KG是一个新的框架，通过关注一致性提高了知识图在多跳问答中的知识编辑，改善了PPKE性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于知识图的PPKE方法存在一致性缺失，从而导致知识污染和不稳定更新，这影响了模型在多跳推理中的可靠性。

Method: 提出了一种新颖的一致性意识框架CAPE-KG，用于在多跳问答中进行参数保护的知识编辑。

Result: 在MQuAKE基准测试上进行的广泛实验表明，CAPE-KG在PPKE性能上取得了准确性的提升，验证了对一致性的关注对PPKE的重要性。

Conclusion: CAPE-KG通过确保知识图的构建、更新和检索与多跳问答任务的要求一致，提升了PPKE在多跳推理中的可靠性和准确性。

Abstract: Parameter-Preserving Knowledge Editing (PPKE) enables updating models with
new or corrected information without retraining or parameter adjustment. Recent
PPKE approaches based on knowledge graphs (KG) to extend knowledge editing (KE)
capabilities to multi-hop question answering (MHQA). However, these methods
often lack consistency, leading to knowledge contamination, unstable updates,
and retrieval behaviors that fail to reflect the intended edits. Such
inconsistencies undermine the reliability of PPKE in multi- hop reasoning. We
present CAPE-KG, Consistency-Aware Parameter-Preserving Editing with Knowledge
Graphs, a novel consistency-aware framework for PPKE on MHQA. CAPE-KG ensures
KG construction, update, and retrieval are always aligned with the requirements
of the MHQA task, maintaining coherent reasoning over both unedited and edited
knowledge. Extensive experiments on the MQuAKE benchmark show accuracy
improvements in PPKE performance for MHQA, demonstrating the effectiveness of
addressing consistency in PPKE.

</details>


### [153] [Analyzing Uncertainty of LLM-as-a-Judge: Interval Evaluations with Conformal Prediction](https://arxiv.org/abs/2509.18658)
*Huanxin Sheng,Xinyi Liu,Hangfeng He,Jieyu Zhao,Jian Kang*

Main category: cs.CL

TL;DR: 本研究提出了一个框架来分析大型语言模型评分的不确定性，以提升其评估的可靠性和有效性。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在自然语言生成评估中的不确定性，以此提升其在实际应用中的可靠性。

Method: 通过顺应预测构建连续预测区间，设计了用于离散评分任务的序贯边界调整，并提出了一种基于中点的评分方法。

Result: 通过广泛的实验证明，顺应预测能够提供有效的预测区间，并确保覆盖率，同时探索中点评分和重新提示对判断的作用。

Conclusion: 该研究提出了一种新的框架，通过顺应预测提供了LLM评分的不确定性分析，确保了预测区间的有效性和应用的可靠性。

Abstract: LLM-as-a-judge has become a promising paradigm for using large language
models (LLMs) to evaluate natural language generation (NLG), but the
uncertainty of its evaluation remains underexplored. This lack of reliability
may limit its deployment in many applications. This work presents the first
framework to analyze the uncertainty by offering a prediction interval of
LLM-based scoring via conformal prediction. Conformal prediction constructs
continuous prediction intervals from a single evaluation run, and we design an
ordinal boundary adjustment for discrete rating tasks. We also suggest a
midpoint-based score within the interval as a low-bias alternative to raw model
score and weighted average. We perform extensive experiments and analysis,
which show that conformal prediction can provide valid prediction interval with
coverage guarantees. We also explore the usefulness of interval midpoint and
judge reprompting for better judgment.

</details>


### [154] [MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service](https://arxiv.org/abs/2509.18713)
*Yizhe Huang,Yang Liu,Ruiyu Zhao,Xiaolong Zhong,Xingming Yue,Ling Jiang*

Main category: cs.CL

TL;DR: 通过引入MemOrb，本文提出了一种增强记忆机制，显著提高了LLM代理在客户服务中的成功率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型代理在动态环境中不可靠的问题，特别是会话遗忘、重复错误和缺乏持续自我改进的机制。

Method: 提出了一种轻量级的、即插即用的语言增强记忆层（MemOrb），通过将多轮交互提炼为紧凑的策略反思，并存储在共享内存库中进行决策指导。

Result: MemOrb付出了高达63个百分点的多轮成功率提升，并在多次试验中表现出更一致的性能。

Conclusion: MemOrb显著提高了多轮成功率和稳定性，证明了结构化反思在增强固定LLM代理在客户服务场景中的长期可靠性方面的有效性。

Abstract: Large Language Model-based agents(LLM-based agents) are increasingly deployed
in customer service, yet they often forget across sessions, repeat errors, and
lack mechanisms for continual self-improvement. This makes them unreliable in
dynamic settings where stability and consistency are critical. To better
evaluate these properties, we emphasize two indicators: task success rate as a
measure of overall effectiveness, and consistency metrics such as Pass$^k$ to
capture reliability across multiple trials. To address the limitations of
existing approaches, we propose MemOrb, a lightweight and plug-and-play verbal
reinforcement memory layer that distills multi-turn interactions into compact
strategy reflections. These reflections are stored in a shared memory bank and
retrieved to guide decision-making, without requiring any fine-tuning.
Experiments show that MemOrb significantly improves both success rate and
stability, achieving up to a 63 percentage-point gain in multi-turn success
rate and delivering more consistent performance across repeated trials. Our
results demonstrate that structured reflection is a powerful mechanism for
enhancing long-term reliability of frozen LLM agents in customer service
scenarios.

</details>


### [155] [Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models](https://arxiv.org/abs/2509.18742)
*Yunan Wang,Jianxin Li,Ziwei Zhang*

Main category: cs.CL

TL;DR: DyGRASP是一种新方法，通过结合LLMs和时间图神经网络，有效处理动态文本属性图的语义，显著提升了节点检索效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注静态文本属性图，缺乏对动态文本属性图中近期和全局语义的考虑，且在处理大量动态文本时存在效率问题。

Method: 提出一种动态全局-近期自适应语义处理的方法，结合了LLMs和时间图神经网络，采用隐式推理方法和滑动窗口机制有效捕获近期语义，利用定制提示和RNN链结构推理长期语义，并通过更新和合并层整合近期和全局语义。

Result: DyGRASP在DyTAG基准上测试，目标节点检索任务的Hit@10提升了最多34%。

Conclusion: DyGRASP在动态文本属性图中表现出优越性，显著提升了目标节点检索任务的效果，并展现出良好的泛化能力。

Abstract: Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph
interactions and associated text attributes, are prevalent in real-world
applications. Existing methods, such as Graph Neural Networks (GNNs) and Large
Language Models (LLMs), mostly focus on static TAGs. Extending these existing
methods to DyTAGs is challenging as they largely neglect the recent-global
temporal semantics: the recent semantic dependencies among interaction texts
and the global semantic evolution of nodes over time. Furthermore, applying
LLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To
tackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic
Processing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to
efficiently and effectively reason on DyTAGs. Specifically, we first design a
node-centric implicit reasoning method together with a sliding window mechanism
to efficiently capture recent temporal semantics. In addition, to capture
global semantic dynamics of nodes, we leverage explicit reasoning with tailored
prompts and an RNN-like chain structure to infer long-term semantics. Lastly,
we intricately integrate the recent and global temporal semantics as well as
the dynamic graph structural information using updating and merging layers.
Extensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority,
achieving up to 34% improvement in Hit@10 for destination node retrieval task.
Besides, DyGRASP exhibits strong generalization across different temporal GNNs
and LLMs.

</details>


### [156] [False Friends Are Not Foes: Investigating Vocabulary Overlap in Multilingual Language Models](https://arxiv.org/abs/2509.18750)
*Julie Kallini,Dan Jurafsky,Christopher Potts,Martijn Bartelds*

Main category: cs.CL

TL;DR: 本研究探讨了子词分词器中跨语言词汇重叠的影响，发现重叠可增强跨语言转移，尤其在共享词汇语义相似度高的情况下。


<details>
  <summary>Details</summary>
Motivation: 探索多语言语料库上训练的子词分词器中词汇重叠对跨语言转移的影响。

Method: 通过控制实验，训练双语自回归模型，并在不同的词汇重叠设置下进行评估。

Result: 含有词汇重叠的模型在多语言任务上的表现优于无词汇重叠的模型，且随着重叠程度增加，转移性能逐渐提升。

Conclusion: 词汇重叠有助于提升多语言模型的性能，尤其是当共享词汇具有较高的语义相似度时。

Abstract: Subword tokenizers trained on multilingual corpora naturally produce
overlapping tokens across languages. Does token overlap facilitate
cross-lingual transfer or instead introduce interference between languages?
Prior work offers mixed evidence, partly due to varied setups and confounders,
such as token frequency or subword segmentation granularity. To address this
question, we devise a controlled experiment where we train bilingual
autoregressive models on multiple language pairs under systematically varied
vocabulary overlap settings. Crucially, we explore a new dimension to
understanding how overlap affects transfer: the semantic similarity of tokens
shared across languages. We first analyze our models' hidden representations
and find that overlap of any kind creates embedding spaces that capture
cross-lingual semantic relationships, while this effect is much weaker in
models with disjoint vocabularies. On XNLI and XQuAD, we find that models with
overlap outperform models with disjoint vocabularies, and that transfer
performance generally improves as overlap increases. Overall, our findings
highlight the advantages of token overlap in multilingual models and show that
substantial shared vocabulary remains a beneficial design choice for
multilingual tokenizers.

</details>


### [157] [When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models](https://arxiv.org/abs/2509.18762)
*Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen*

Main category: cs.CL

TL;DR: 本研究探讨了长上下文数据在短上下文任务中的影响，发现长上下文SFT有助于短上下文性能，提出混合训练作为缓解知识偏好偏差的解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着现实应用对于更长上下文窗口的需求增加，继续预训练和在长上下文数据上进行监督微调（SFT）成为了常见的方法。

Method: 系统性地调查SFT数据长度对短上下文任务的影响，分析多头注意力（MHA）和前馈网络（FFN）的两个关键组件。

Result: 长上下文SFT提高了短上下文性能，揭示了知识偏好偏差：长上下文SFT促进上下文知识，而短上下文SFT偏向参数知识。

Conclusion: 混合训练可以缓解知识偏好偏差，并为LLM微调提供可解释的指导。

Abstract: Large language models (LLMs) have achieved impressive performance across
natural language processing (NLP) tasks. As real-world applications
increasingly demand longer context windows, continued pretraining and
supervised fine-tuning (SFT) on long-context data has become a common approach.
While the effects of data length in continued pretraining have been extensively
studied, their implications for SFT remain unclear. In this work, we
systematically investigate how SFT data length influences LLM behavior on
short-context tasks. Counterintuitively, we find that long-context SFT improves
short-context performance, contrary to the commonly observed degradation from
long-context pretraining. To uncover the underlying mechanisms of this
phenomenon, we first decouple and analyze two key components, Multi-Head
Attention (MHA) and Feed-Forward Network (FFN), and show that both
independently benefit from long-context SFT. We further study their interaction
and reveal a knowledge preference bias: long-context SFT promotes contextual
knowledge, while short-context SFT favors parametric knowledge, making
exclusive reliance on long-context SFT suboptimal. Finally, we demonstrate that
hybrid training mitigates this bias, offering explainable guidance for
fine-tuning LLMs.

</details>


### [158] [Financial Risk Relation Identification through Dual-view Adaptation](https://arxiv.org/abs/2509.18775)
*Wei-Ning Chiu,Yu-Hsiang Wang,Andy Hsiao,Yu-Shiang Huang,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: 提出了一种基于自然语言处理的系统方法，从Form 10-K文件中提取企业间风险关系，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 识别企业间风险关系对投资组合管理和投资策略至关重要，但传统方法主观且难以扩展。

Method: 通过使用Form 10-K文件，利用自然语言处理技术提取企业间风险关系，并进行无监督微调。

Result: 该方法显示出较强的性能，能够系统地识别和量化企业间的风险关系。

Conclusion: 该方法在多种评估设置下优于强基线，具有良好的应用潜力。

Abstract: A multitude of interconnected risk events -- ranging from regulatory changes
to geopolitical tensions -- can trigger ripple effects across firms.
Identifying inter-firm risk relations is thus crucial for applications like
portfolio management and investment strategy. Traditionally, such assessments
rely on expert judgment and manual analysis, which are, however, subjective,
labor-intensive, and difficult to scale. To address this, we propose a
systematic method for extracting inter-firm risk relations using Form 10-K
filings -- authoritative, standardized financial documents -- as our data
source. Leveraging recent advances in natural language processing, our approach
captures implicit and abstract risk connections through unsupervised
fine-tuning based on chronological and lexical patterns in the filings. This
enables the development of a domain-specific financial encoder with a deeper
contextual understanding and introduces a quantitative risk relation score for
transparency, interpretable analysis. Extensive experiments demonstrate that
our method outperforms strong baselines across multiple evaluation settings.

</details>


### [159] [AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field](https://arxiv.org/abs/2509.18776)
*Chen Liang,Zhaoqi Huang,Haofen Wang,Fu Chai,Chunying Yu,Huanhuan Wei,Zhengjie Liu,Yanpeng Li,Hongjun Wang,Ruifeng Luo,Xianzhong Zhao*

Main category: cs.CL

TL;DR: 本研究建立了一个综合基准AECBench，评估当前大型语言模型在建筑、工程和建设领域的能力和局限性，揭示了其在安全关键领域应用中存在的重要性能缺陷。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在建筑、工程和建设领域应用的稳健性和可靠性，以应对该领域的特殊性和安全性挑战。

Method: 建立了AECBench基准，通过23个具有代表性的任务评估当前大型语言模型在AEC领域的表现，采用了LLM作为评判者的方法。

Result: 对九个大型语言模型进行评估，发现它们在知识记忆和理解层面的基础任务表现良好，但在复杂推理、计算及领域特定文档生成方面表现显著不足。

Conclusion: 本研究为未来在安全关键工程实践中稳健而可靠地整合大型语言模型奠定了基础。

Abstract: Large language models (LLMs), as a novel information technology, are seeing
increasing adoption in the Architecture, Engineering, and Construction (AEC)
field. They have shown their potential to streamline processes throughout the
building lifecycle. However, the robustness and reliability of LLMs in such a
specialized and safety-critical domain remain to be evaluated. To address this
challenge, this paper establishes AECBench, a comprehensive benchmark designed
to quantify the strengths and limitations of current LLMs in the AEC domain.
The benchmark defines 23 representative tasks within a five-level
cognition-oriented evaluation framework encompassing Knowledge Memorization,
Understanding, Reasoning, Calculation, and Application. These tasks were
derived from authentic AEC practice, with scope ranging from codes retrieval to
specialized documents generation. Subsequently, a 4,800-question dataset
encompassing diverse formats, including open-ended questions, was crafted
primarily by engineers and validated through a two-round expert review.
Furthermore, an LLM-as-a-Judge approach was introduced to provide a scalable
and consistent methodology for evaluating complex, long-form responses
leveraging expert-derived rubrics. Through the evaluation of nine LLMs, a clear
performance decline across five cognitive levels was revealed. Despite
demonstrating proficiency in foundational tasks at the Knowledge Memorization
and Understanding levels, the models showed significant performance deficits,
particularly in interpreting knowledge from tables in building codes, executing
complex reasoning and calculation, and generating domain-specific documents.
Consequently, this study lays the groundwork for future research and
development aimed at the robust and reliable integration of LLMs into
safety-critical engineering practices.

</details>


### [160] [Beyond the Leaderboard: Understanding Performance Disparities in Large Language Models via Model Diffing](https://arxiv.org/abs/2509.18792)
*Sabri Boughorbel,Fahim Dalvi,Nadir Durrani,Majd Hawasly*

Main category: cs.CL

TL;DR: 本研究通过模型差异分析深入探讨了Gemma-2-9b-it与SimPO增强变体之间的能力差异，揭示了安全性和多语言能力等方面的显著提升。


<details>
  <summary>Details</summary>
Motivation: 随着微调成为提升大语言模型的主要手段，理解这一过程中的变化变得愈发重要，传统基准测试无法充分解释模型性能差异。

Method: 使用模型差异分析（model diffing）和交叉编码器（crosscoders）识别和分类模型之间的潜在表示差异。

Result: SimPO增强变体在安全机制、跨语言能力和指令遵循方面显著提升，同时降低了模型自我引用和幻觉管理的强调。

Conclusion: 模型差异分析能够提供更具体的洞察，以便更好地比较大语言模型的性能和改进方向。

Abstract: As fine-tuning becomes the dominant paradigm for improving large language
models (LLMs), understanding what changes during this process is increasingly
important. Traditional benchmarking often fails to explain why one model
outperforms another. In this work, we use model diffing, a mechanistic
interpretability approach, to analyze the specific capability differences
between Gemma-2-9b-it and a SimPO-enhanced variant. Using crosscoders, we
identify and categorize latent representations that differentiate the two
models. We find that SimPO acquired latent concepts predominantly enhance
safety mechanisms (+32.8%), multilingual capabilities (+43.8%), and
instruction-following (+151.7%), while its additional training also reduces
emphasis on model self-reference (-44.1%) and hallucination management
(-68.5%). Our analysis shows that model diffing can yield fine-grained insights
beyond leaderboard metrics, attributing performance gaps to concrete
mechanistic capabilities. This approach offers a transparent and targeted
framework for comparing LLMs.

</details>


### [161] [MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction](https://arxiv.org/abs/2509.18813)
*Liting Zhang,Shiwan Zhao,Aobo Kong,Qicheng Li*

Main category: cs.CL

TL;DR: MAPEX是一个多智能体框架，用于提高关键短语提取的性能，特别是在处理不同长度文档的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有无监督的基于提示的大型语言模型方法在关键短语提取任务上的效果受到限制，不能充分利用LLM的推理和生成能力。

Method: 提出了一种多智能体协作的框架，并使用双路径策略分别处理短文本和长文本。

Result: 在六个基准数据集上的广泛实验表明，MAPEX在F1@5指标上平均超过了最先进的无监督方法2.44%和标准LLM基线4.01%。

Conclusion: MAPEX框架通过引入多智能体合作的方式，显著提高了关键短语提取的性能，特别是在不同长度文档的处理上。

Abstract: Keyphrase extraction is a fundamental task in natural language processing.
However, existing unsupervised prompt-based methods for Large Language Models
(LLMs) often rely on single-stage inference pipelines with uniform prompting,
regardless of document length or LLM backbone. Such one-size-fits-all designs
hinder the full exploitation of LLMs' reasoning and generation capabilities,
especially given the complexity of keyphrase extraction across diverse
scenarios. To address these challenges, we propose MAPEX, the first framework
that introduces multi-agent collaboration into keyphrase extraction. MAPEX
coordinates LLM-based agents through modules for expert recruitment, candidate
extraction, topic guidance, knowledge augmentation, and post-processing. A
dual-path strategy dynamically adapts to document length: knowledge-driven
extraction for short texts and topic-guided extraction for long texts.
Extensive experiments on six benchmark datasets across three different LLMs
demonstrate its strong generalization and universality, outperforming the
state-of-the-art unsupervised method by 2.44\% and standard LLM baselines by
4.01\% in F1@5 on average. Code is available at
https://github.com/NKU-LITI/MAPEX.

</details>


### [162] [Are Smaller Open-Weight LLMs Closing the Gap to Proprietary Models for Biomedical Question Answering?](https://arxiv.org/abs/2509.18843)
*Damian Stachura,Joanna Konieczna,Artur Nowak*

Main category: cs.CL

TL;DR: 本研究比较了开放权重与专有LLM在生物医学问答中的表现，结果表明开放权重模型在某些情况下表现更好，尤其是在采用集成策略时。


<details>
  <summary>Details</summary>
Motivation: 探索小型开放权重LLM是否能有效替代大型闭源模型，特别是在生物医学问答领域。

Method: 通过比较多个开放权重模型与顶级系统，使用检索相关片段、上下文学习和结构化输出等技术，进行生物医学问答任务。

Result: 开放权重的LLM与专有模型 comparable，某些情况下甚至表现更佳。

Conclusion: 开放权重的LLM在某些情况下超过了闭源模型，特别是使用集成策略时。

Abstract: Open-weight versions of large language models (LLMs) are rapidly advancing,
with state-of-the-art models like DeepSeek-V3 now performing comparably to
proprietary LLMs. This progression raises the question of whether small
open-weight LLMs are capable of effectively replacing larger closed-source
models. We are particularly interested in the context of biomedical
question-answering, a domain we explored by participating in Task 13B Phase B
of the BioASQ challenge. In this work, we compare several open-weight models
against top-performing systems such as GPT-4o, GPT-4.1, Claude 3.5 Sonnet, and
Claude 3.7 Sonnet. To enhance question answering capabilities, we use various
techniques including retrieving the most relevant snippets based on embedding
distance, in-context learning, and structured outputs. For certain submissions,
we utilize ensemble approaches to leverage the diverse outputs generated by
different models for exact-answer questions. Our results demonstrate that
open-weight LLMs are comparable to proprietary ones. In some instances,
open-weight LLMs even surpassed their closed counterparts, particularly when
ensembling strategies were applied. All code is publicly available at
https://github.com/evidenceprime/BioASQ-13b.

</details>


### [163] [Multi-Hierarchical Feature Detection for Large Language Model Generated Text](https://arxiv.org/abs/2509.18862)
*Luyan Zhang,Xinyu Xie*

Main category: cs.CL

TL;DR: 尽管多特征集成理论上有益，但实验结果显示其在实际应用中提供的改进微乎其微，且计算成本高，现代语言模型足以有效捕捉检测信号。


<details>
  <summary>Details</summary>
Motivation: 研究多特征方法是否能显著改善AI文本检测的效果，超越单一神经模型的表现。

Method: 实施MHFD（多层次特征检测），结合DeBERTa基础的语义分析、句法解析和统计概率特征，通过自适应融合。

Result: MHFD方法在领域内检测中实现89.7%的准确率，在跨领域检测中稳定维持84.2%的性能，较现有方法有0.4-2.6%的适度提升。

Conclusion: 现代神经语言模型已有效捕捉大部分相关的检测信号，使用多特征集成方法并未获得显著性能提升。

Abstract: With the rapid advancement of large language model technology, there is
growing interest in whether multi-feature approaches can significantly improve
AI text detection beyond what single neural models achieve. While intuition
suggests that combining semantic, syntactic, and statistical features should
provide complementary signals, this assumption has not been rigorously tested
with modern LLM-generated text. This paper provides a systematic empirical
investigation of multi-hierarchical feature integration for AI text detection,
specifically testing whether the computational overhead of combining multiple
feature types is justified by performance gains. We implement MHFD
(Multi-Hierarchical Feature Detection), integrating DeBERTa-based semantic
analysis, syntactic parsing, and statistical probability features through
adaptive fusion. Our investigation reveals important negative results: despite
theoretical expectations, multi-feature integration provides minimal benefits
(0.4-0.5% improvement) while incurring substantial computational costs (4.2x
overhead), suggesting that modern neural language models may already capture
most relevant detection signals efficiently. Experimental results on multiple
benchmark datasets demonstrate that the MHFD method achieves 89.7% accuracy in
in-domain detection and maintains 84.2% stable performance in cross-domain
detection, showing modest improvements of 0.4-2.6% over existing methods.

</details>


### [164] [Diversity Boosts AI-Generated Text Detection](https://arxiv.org/abs/2509.18880)
*Advik Raj Basani,Pin-Yu Chen*

Main category: cs.CL

TL;DR: DivEye是一种新型文本检测框架，通过基于惊讶度的特征提高了对AI生成文本的检测准确性，并提供可解释的分析，同时在多个任务和基准中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在多个领域的应用增加，检测AI生成文本的必要性日益增加，尤其是在教育、商业合规、新闻和社交媒体中，确保信息的真实性至关重要。

Method: 提出了一种基于惊讶度特征的检测框架，通过捕捉文本中不可预测性的波动来区分人类创作和AI生成的文本。

Result: DivEye在多个基准测试中相比已有的零样本检测器的表现提升了最高33.2%，并且在针对不同领域和模型的泛化能力及抵御同义改写和对抗攻击方面表现出色。

Conclusion: DivEye是一种新颖的文本检测框架，它不仅提高了检测的准确性，还提供了可解释的洞见，揭示了节奏性不可预测性在LLM检测中作为强大信号的重要性。

Abstract: Detecting AI-generated text is an increasing necessity to combat misuse of
LLMs in education, business compliance, journalism, and social media, where
synthetic fluency can mask misinformation or deception. While prior detectors
often rely on token-level likelihoods or opaque black-box classifiers, these
approaches struggle against high-quality generations and offer little
interpretability. In this work, we propose DivEye, a novel detection framework
that captures how unpredictability fluctuates across a text using
surprisal-based features. Motivated by the observation that human-authored text
exhibits richer variability in lexical and structural unpredictability than LLM
outputs, DivEye captures this signal through a set of interpretable statistical
features. Our method outperforms existing zero-shot detectors by up to 33.2%
and achieves competitive performance with fine-tuned baselines across multiple
benchmarks. DivEye is robust to paraphrasing and adversarial attacks,
generalizes well across domains and models, and improves the performance of
existing detectors by up to 18.7% when used as an auxiliary signal. Beyond
detection, DivEye provides interpretable insights into why a text is flagged,
pointing to rhythmic unpredictability as a powerful and underexplored signal
for LLM detection.

</details>


### [165] [Extractive Fact Decomposition for Interpretable Natural Language Inference in one Forward Pass](https://arxiv.org/abs/2509.18901)
*Nicholas Popovič,Michael Färber*

Main category: cs.CL

TL;DR: JEDI是一种基于编码器的架构，通过合成推理在不依赖生成模型的情况下，实现原子事实分解和可解释推理，展现了良好的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有依赖资源密集型生成大语言模型的原子事实分解问题，提升自然语言推理（NLI）及相关任务的可解释性与鲁棒性。

Method: 提出了一种编码器架构JEDI，能够联合执行提取式原子事实分解和可解释推理，在推理过程中不依赖生成模型。

Result: 实验结果显示，JEDI在分布内外的准确性上具有竞争力，并在对抗环境中显著提高鲁棒性，优于仅依赖提取式推理监督的模型。

Conclusion: JEDI能够在保持竞争力的准确性同时，显著提高模型在未知分布和对抗环境中的鲁棒性，证明了解释性和鲁棒性泛化可以通过编码器架构和合成推理实现。

Abstract: Recent works in Natural Language Inference (NLI) and related tasks, such as
automated fact-checking, employ atomic fact decomposition to enhance
interpretability and robustness. For this, existing methods rely on
resource-intensive generative large language models (LLMs) to perform
decomposition. We propose JEDI, an encoder-only architecture that jointly
performs extractive atomic fact decomposition and interpretable inference
without requiring generative models during inference. To facilitate training,
we produce a large corpus of synthetic rationales covering multiple NLI
benchmarks. Experimental results demonstrate that JEDI achieves competitive
accuracy in distribution and significantly improves robustness out of
distribution and in adversarial settings over models based solely on extractive
rationale supervision. Our findings show that interpretability and robust
generalization in NLI can be realized using encoder-only architectures and
synthetic rationales. Code and data available at https://jedi.nicpopovic.com

</details>


### [166] [DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment](https://arxiv.org/abs/2509.18987)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本文提出了一种通过动态时间规整（DTW）对齐语音与文本嵌入的方法，克服了现有E2E-ST中模态差异的问题，特别是在低资源环境下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的E2E-ST方法需要对齐工具，但并非所有语言都有此工具，因此需要解决语音与文本模态之间的差异。

Method: 通过动态时间规整（DTW）对语音和文本嵌入进行对齐；使用该方法在训练过程中优化对齐。

Result: 我们的实验表明，该方法在5个6个语言方向的低资源设置中实现了更准确的对齐，且与以往方法相比，E2E-ST结果相当。此外，速度显著提高。

Conclusion: 我们的方法在低资源环境中表现优于以往的研究，并在速度和准确性上都有显著提升。

Abstract: End-to-End Speech Translation (E2E-ST) is the task of translating source
speech directly into target text bypassing the intermediate transcription step.
The representation discrepancy between the speech and text modalities has
motivated research on what is known as bridging the modality gap.
State-of-the-art methods addressed this by aligning speech and text
representations on the word or token level. Unfortunately, this requires an
alignment tool that is not available for all languages. Although this issue has
been addressed by aligning speech and text embeddings using nearest-neighbor
similarity search, it does not lead to accurate alignments. In this work, we
adapt Dynamic Time Warping (DTW) for aligning speech and text embeddings during
training. Our experiments demonstrate the effectiveness of our method in
bridging the modality gap in E2E-ST. Compared to previous work, our method
produces more accurate alignments and achieves comparable E2E-ST results while
being significantly faster. Furthermore, our method outperforms previous work
in low resource settings on 5 out of 6 language directions.

</details>


### [167] [Investigating Test-Time Scaling with Reranking for Machine Translation](https://arxiv.org/abs/2509.19020)
*Shaomu Tan,Ryosuke Mitani,Ritvik Choudhary,Toshiyuki Sekiya*

Main category: cs.CL

TL;DR: 研究表明，测试时间缩放(TTS)能够有效提高高资源语言的机器翻译质量，小模型可以在增加计算预算的情况下实现更好性能。


<details>
  <summary>Details</summary>
Motivation: 随着模型参数的扩展带来了巨大的计算成本，探索更高效的推理方法成为必要。TTS作为一种替代方案，有望在推理阶段优化机器翻译系统的性能。

Method: 进行了基于WMT24基准的系统性实验，采用了一个简单但实用的最佳N框架，涵盖多个语言对、模型大小及TTS计算预算。

Result: 在高资源语言中，TTS普遍提升了翻译质量；利用大N的较小模型在计算成本上具备优势；而在固定计算预算下，较大模型通常更有效，但在低资源语言时TTS效果可能下降。

Conclusion: 在机器翻译任务中，测试时间缩放(TTS)方法能够提升翻译质量，尤其是对于高资源语言，且适当地调整计算预算可以使得小模型在翻译质量上接近或超越大模型。

Abstract: Scaling model parameters has become the de facto strategy for improving NLP
systems, but it comes with substantial computational costs. Test-Time Scaling
(TTS) offers an alternative by allocating more computation at inference:
generating multiple candidates and selecting the best. While effective in tasks
such as mathematical reasoning, TTS has not been systematically explored for
machine translation (MT). In this paper, we present the first systematic study
of TTS for MT, investigating a simple but practical best-of-N framework on
WMT24 benchmarks. Our experiments cover six high-resource and one low-resource
language pairs, five model sizes (3B-72B), and various TTS compute budget (N up
to 1024). Our results show that a) For high-resource languages, TTS generally
improves translation quality according to multiple neural MT evaluation
metrics, and our human evaluation confirms these gains; b) Augmenting smaller
models with large $N$ can match or surpass larger models at $N{=}1$ with more
compute cost; c) Under fixed compute budgets, larger models are typically more
efficient, and TTS can degrade quality due to metric blind spots in
low-resource cases.

</details>


### [168] [Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus](https://arxiv.org/abs/2509.19033)
*Chiara Alzetta,Serena Auriemma,Alessandro Bondielli,Luca Dini,Chiara Fazzone,Alessio Miaschi,Martina Miliani,Marta Sartor*

Main category: cs.CL

TL;DR: 本研究分析了意大利计算语言学和自然语言处理领域的研究趋势，通过CLiC-it会议的论文编制语料库，揭示了研究领域的重要发展和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着大规模语言模型的出现，意大利的计算语言学和自然语言处理研究领域面临新的目标和优先事项。

Method: 通过分析CLiC-it会议的论文贡献，编制CLiC-it语料库，涵盖10届会议的元数据和论文内容。

Result: 我们为意大利和国际研究界提供了关于新兴趋势和关键发展的综合分析，支持未来的研究方向。

Conclusion: 本研究为意大利计算语言学和自然语言处理领域提供了有价值的见解，揭示了研究趋势和关键发展。

Abstract: Over the past decade, Computational Linguistics (CL) and Natural Language
Processing (NLP) have evolved rapidly, especially with the advent of
Transformer-based Large Language Models (LLMs). This shift has transformed
research goals and priorities, from Lexical and Semantic Resources to Language
Modelling and Multimodality. In this study, we track the research trends of the
Italian CL and NLP community through an analysis of the contributions to
CLiC-it, arguably the leading Italian conference in the field. We compile the
proceedings from the first 10 editions of the CLiC-it conference (from 2014 to
2024) into the CLiC-it Corpus, providing a comprehensive analysis of both its
metadata, including author provenance, gender, affiliations, and more, as well
as the content of the papers themselves, which address various topics. Our goal
is to provide the Italian and international research communities with valuable
insights into emerging trends and key developments over time, supporting
informed decisions and future directions in the field.

</details>


### [169] [Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering](https://arxiv.org/abs/2509.19094)
*Alireza Salemi,Cheng Li,Mingyang Zhang,Qiaozhu Mei,Zhuowan Li,Spurthi Amba Hombaiah,Weize Kong,Tao Chen,Hamed Zamani,Michael Bendersky*

Main category: cs.CL

TL;DR: 提出个性化问答方法PoT，解决用户偏好推断及上下文恰当性问题，实验表明在准确性和用户满意度上显著优于基础方法。


<details>
  <summary>Details</summary>
Motivation: 个性化问答系统能够根据用户需求改善问答准确性和满意度，但面临如何从复杂背景中推断偏好及生成合适回应的挑战。

Method: PoT 作为一种推理阶段的方法，适用于任何大型语言模型，通过迭代决策过程动态选择认知操作，实现多样性应答。

Result: 在LaMP-QA基准测试中，PoT 方法表现优异，相对提升达13.1%，且人类评估支持结果。

Conclusion: Pathways of Thoughts (PoT) 方法在个性化问答系统中表现突出，提升了回答的准确性和用户满意度。

Abstract: Personalization is essential for adapting question answering (QA) systems to
user-specific information needs, thereby improving both accuracy and user
satisfaction. However, personalized QA remains relatively underexplored due to
challenges such as inferring preferences from long, noisy, and implicit
contexts, and generating responses that are simultaneously correct,
contextually appropriate, and aligned with user expectations and background
knowledge. To address these challenges, we propose Pathways of Thoughts (PoT),
an inference-stage method that applies to any large language model (LLM)
without requiring task-specific fine-tuning. The approach models the reasoning
of an LLM as an iterative decision process, where the model dynamically selects
among cognitive operations such as reasoning, revision, personalization, and
clarification. This enables exploration of multiple reasoning trajectories,
producing diverse candidate responses that capture different perspectives. PoT
then aggregates and reweights these candidates according to inferred user
preferences, yielding a final personalized response that benefits from the
complementary strengths of diverse reasoning paths. Experiments on the LaMP-QA
benchmark for personalized QA show that PoT consistently outperforms
competitive baselines, achieving up to a 13.1% relative improvement. Human
evaluation corroborates these results, with annotators preferring outputs from
PoT in 66% of cases and reporting ties in only 15% of cases.

</details>


### [170] [Are most sentences unique? An empirical examination of Chomskyan claims](https://arxiv.org/abs/2509.19108)
*Hiram Ring*

Main category: cs.CL

TL;DR: 此论文实证研究了语言表达的唯一性，通过分析不同体裁的语料库，发现重复句子在语料库中并非微不足道，尽管唯一句子通常占多数。


<details>
  <summary>Details</summary>
Motivation: 通过大型语料库的可用性，实证研究语言学中的重复性主张，以验证大多数语言表达是否确实是独一无二的。

Method: 使用NLTK Python库解析不同体裁的语料库，提供每种中的精确字符串匹配计数。

Result: 研究结果表明，尽管完全唯一的句子通常占主导地位，但其受体裁高度限制，重复句子在任何语料库中占有重要部分。

Conclusion: 虽然完全唯一的句子通常是语料库中的大多数，但这受限于体裁，重复句子在任何个别语料库中并非微不足道。

Abstract: A repeated claim in linguistics is that the majority of linguistic utterances
are unique. For example, Pinker (1994: 10), summarizing an argument by Noam
Chomsky, states that "virtually every sentence that a person utters or
understands is a brand-new combination of words, appearing for the first time
in the history of the universe." With the increased availability of large
corpora, this is a claim that can be empirically investigated. The current
paper addresses the question by using the NLTK Python library to parse corpora
of different genres, providing counts of exact string matches in each. Results
show that while completely unique sentences are often the majority of corpora,
this is highly constrained by genre, and that duplicate sentences are not an
insignificant part of any individual corpus.

</details>


### [171] [Human-Annotated NER Dataset for the Kyrgyz Language](https://arxiv.org/abs/2509.19109)
*Timur Turatali,Anton Alekseev,Gulira Jumalieva,Gulnara Kabaeva,Sergey Nikolenko*

Main category: cs.CL

TL;DR: 本文介绍了吉尔吉斯语的首个命名实体识别数据集KyrgyzNER，并评估了多种模型的表现，结果显示多语言预训练模型在资源有限的语言处理上表现出潜力。


<details>
  <summary>Details</summary>
Motivation: 创建并分享第一个专为吉尔吉斯语手动注释的命名实体识别数据集，以帮助提高该语言的自然语言处理能力。

Method: 对多种命名实体识别模型进行评估，包括基于条件随机场的传统序列标注方法和在我们的数据集上微调的最新多语言变压器模型。

Result: 多种模型在处理稀有实体类别时都遇到困难，但多语言RoBERTa模型表现最佳，取得了良好的精确率和召回率平衡。

Conclusion: 多语种预训练模型在处理资源有限的语言时具有潜力，未来的研究可通过更细致的注释方案以获得更深入的见解。

Abstract: We introduce KyrgyzNER, the first manually annotated named entity recognition
dataset for the Kyrgyz language. Comprising 1,499 news articles from the 24.KG
news portal, the dataset contains 10,900 sentences and 39,075 entity mentions
across 27 named entity classes. We show our annotation scheme, discuss the
challenges encountered in the annotation process, and present the descriptive
statistics. We also evaluate several named entity recognition models, including
traditional sequence labeling approaches based on conditional random fields and
state-of-the-art multilingual transformer-based models fine-tuned on our
dataset. While all models show difficulties with rare entity categories, models
such as the multilingual RoBERTa variant pretrained on a large corpus across
many languages achieve a promising balance between precision and recall. These
findings emphasize both the challenges and opportunities of using multilingual
pretrained models for processing languages with limited resources. Although the
multilingual RoBERTa model performed best, other multilingual models yielded
comparable results. This suggests that future work exploring more granular
annotation schemes may offer deeper insights for Kyrgyz language processing
pipelines evaluation.

</details>


### [172] [Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering](https://arxiv.org/abs/2509.19125)
*Kun Zhu,Lizi Liao,Yuxuan Gu,Lei Huang,Xiaocheng Feng,Bing Qin*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的上下文感知层次分类生成框架，有效组织和综合科学文献，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 科学文献的快速增长需要高效的方法来组织和综合研究成果。

Method: 我们提出了一种新颖的上下文感知层次分类生成框架，集成了LLM引导的多方面编码和动态聚类。

Result: 实验结果表明，我们的方法在分类的一致性、细粒度和可解释性方面显著超越了先前的方法。

Conclusion: 我们的方法在分类的一致性、细粒度和可解释性方面显著优于以前的方法，达到最先进的性能。

Abstract: The rapid growth of scientific literature demands efficient methods to
organize and synthesize research findings. Existing taxonomy construction
methods, leveraging unsupervised clustering or direct prompting of large
language models (LLMs), often lack coherence and granularity. We propose a
novel context-aware hierarchical taxonomy generation framework that integrates
LLM-guided multi-aspect encoding with dynamic clustering. Our method leverages
LLMs to identify key aspects of each paper (e.g., methodology, dataset,
evaluation) and generates aspect-specific paper summaries, which are then
encoded and clustered along each aspect to form a coherent hierarchy. In
addition, we introduce a new evaluation benchmark of 156 expert-crafted
taxonomies encompassing 11.6k papers, providing the first naturally annotated
dataset for this task. Experimental results demonstrate that our method
significantly outperforms prior approaches, achieving state-of-the-art
performance in taxonomy coherence, granularity, and interpretability.

</details>


### [173] [Anecdoctoring: Automated Red-Teaming Across Language and Place](https://arxiv.org/abs/2509.19143)
*Alejandro Cuevas,Saloni Dash,Bharat Kumar Nayak,Dan Vann,Madeleine I. G. Daepp*

Main category: cs.CL

TL;DR: 本研究提出了一种新的红队方法'anecdoctoring'，可以自动生成跨语言和文化的对抗性提示，以应对生成AI滥用中的虚假信息风险。


<details>
  <summary>Details</summary>
Motivation: 全球范围内的生成AI的普遍采用需要进行红队评估，而现有的红队数据集通常以美国和英语为中心。

Method: 我们提出了一种名为'anecdoctoring'的新型红队方法，自动生成跨语言和文化的对抗性提示。

Result: 我们的方法比少量提示推理的攻击成功率更高，并提供了可解释性收益。

Conclusion: 结果强调了需要全球范围内的虚假信息缓解措施，这些措施应扎根于现实世界的对抗性滥用中。

Abstract: Disinformation is among the top risks of generative artificial intelligence
(AI) misuse. Global adoption of generative AI necessitates red-teaming
evaluations (i.e., systematic adversarial probing) that are robust across
diverse languages and cultures, but red-teaming datasets are commonly US- and
English-centric. To address this gap, we propose "anecdoctoring", a novel
red-teaming approach that automatically generates adversarial prompts across
languages and cultures. We collect misinformation claims from fact-checking
websites in three languages (English, Spanish, and Hindi) and two geographies
(US and India). We then cluster individual claims into broader narratives and
characterize the resulting clusters with knowledge graphs, with which we
augment an attacker LLM. Our method produces higher attack success rates and
offers interpretability benefits relative to few-shot prompting. Results
underscore the need for disinformation mitigations that scale globally and are
grounded in real-world adversarial misuse.

</details>


### [174] [Measuring AI "Slop" in Text](https://arxiv.org/abs/2509.19163)
*Chantal Shaib,Tuhin Chakrabarty,Diego Garcia-Olano,Byron C. Wallace*

Main category: cs.CL

TL;DR: 本研究旨在定义和测量低质量AI文本（“slop”），开发了分类法和评估维度，发现文本质量与连贯性、相关性等因素相关。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成文本的普及，对低质量AI生成文本（即“slop”）的理解和测量变得越来越重要。

Method: 通过与自然语言处理、写作和哲学领域的专家进行访谈，开发了一种“slop”的分类法，并提出了一组可解释的维度用于文本评估。

Result: 通过跨度级别的注释，我们发现二元“slop”判断具有一定的主观性，但这些判断与潜在维度（如连贯性和相关性）相关联。

Conclusion: 我们的框架能够用于评估AI生成文本，揭示影响质量判断的语言和风格因素。

Abstract: AI "slop" is an increasingly popular term used to describe low-quality
AI-generated text, but there is currently no agreed upon definition of this
term nor a means to measure its occurrence. In this work, we develop a taxonomy
of "slop" through interviews with experts in NLP, writing, and philosophy, and
propose a set of interpretable dimensions for its assessment in text. Through
span-level annotation, we find that binary "slop" judgments are (somewhat)
subjective, but such determinations nonetheless correlate with latent
dimensions such as coherence and relevance. Our framework can be used to
evaluate AI-generated text in both detection and binary preference tasks,
potentially offering new insights into the linguistic and stylistic factors
that contribute to quality judgments.

</details>


### [175] [Soft Tokens, Hard Truths](https://arxiv.org/abs/2509.19170)
*Natasha Butt,Ariel Kwiatkowski,Ismail Labiad,Julia Kempe,Yann Ollivier*

Main category: cs.CL

TL;DR: 此研究提出了一种通过强化学习学习连续链式思维的方法，克服了传统方法在训练中的难题，提升了模型的推理能力和多样性。


<details>
  <summary>Details</summary>
Motivation: 连续代币的使用可以通过模拟多条推理路径的叠加来提升 LLM 的推理能力，而现有方法受限于训练困难。

Method: 引入了一种可扩展的方法通过强化学习直接学习连续链式思维，不需要从参考离散链式思维中提取。

Result: 在数学推理基准测试中，使用连续 CoTs 的训练在准确度方面与离散 CoTs 相当，并在更高的目标上超越。

Conclusion: 通过强化学习（RL）学习连续链式思维（CoT）显著提升了模型的推理能力，并在保持基础模型预测的同时，提高了推理多样性。

Abstract: The use of continuous instead of discrete tokens during the Chain-of-Thought
(CoT) phase of reasoning LLMs has garnered attention recently, based on the
intuition that a continuous mixture of discrete tokens could simulate a
superposition of several reasoning paths simultaneously. Theoretical results
have formally proven that continuous tokens have much greater expressivity and
can solve specific problems more efficiently. However, practical use of
continuous tokens has been limited by strong training difficulties: previous
works either just use continuous tokens at inference time on a pre-trained
discrete-token model, or must distill the continuous CoT from ground-truth
discrete CoTs and face computational costs that limit the CoT to very few
tokens.
  This is the first work introducing a scalable method to learn continuous CoTs
via reinforcement learning (RL), without distilling from reference discrete
CoTs. We use "soft" tokens: mixtures of tokens together with noise on the input
embedding to provide RL exploration. Computational overhead is minimal,
enabling us to learn continuous CoTs with hundreds of tokens. On math reasoning
benchmarks with Llama and Qwen models up to 8B, training with continuous CoTs
match discrete-token CoTs for pass@1 and surpass them for pass@32, showing
greater CoT diversity. In systematic comparisons, the best-performing scenario
is to train with continuous CoT tokens then use discrete tokens for inference,
meaning the "soft" models can be deployed in a standard way. Finally, we show
continuous CoT RL training better preserves the predictions of the base model
on out-of-domain tasks, thus providing a softer touch to the base model.

</details>


### [176] [Online Process Reward Leanring for Agentic Reinforcement Learning](https://arxiv.org/abs/2509.19199)
*Xiaoqian Liu,Ke Wang,Yuchuan Wu,Fei Huang,Yongbin Li,Junge Zhang,Jianbin Jiao*

Main category: cs.CL

TL;DR: 本文提出了在线过程奖励学习（OPRL），用于改进强化学习中的信用分配，表现优越且具有实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 面对稀疏且难以验证的奖励，在交互环境中进行长期决策的代理学习具有挑战性，因此需要改进的信用分配策略。

Method: 通过隐性过程奖励模型与代理策略交替优化，应用基于轨迹的目标实现信用分配。

Result: 在WebShop、VisualSokoban和SOTOPIA等基准测试上，OPRL在性能上超越了前沿的LLM和强RL基线，并实现了最新的研究进展。

Conclusion: OPRL在多个领域表现优越，展现了更高的样本效率和更低的训练方差，具备实际应用潜力。

Abstract: Large language models (LLMs) are increasingly trained with reinforcement
learning (RL) as autonomous agents that reason and act over long horizons in
interactive environments.
  However, sparse and sometimes unverifiable rewards make temporal credit
assignment extremely challenging.
  Recent work attempts to integrate process supervision into agent learning but
suffers from biased annotation, reward hacking, high-variance from overly
fine-grained signals or failtures when state overlap is rare.
  We therefore introduce Online Process Reward Learning (OPRL), a general
credit-assignment strategy for agentic RL that integrates seamlessly with
standard on-policy algorithms without relying on additional rollouts or
explicit step labels.
  In OPRL, we optimize an implicit process reward model (PRM) alternately with
the agent's policy to transform trajectory preferences into implicit step
rewards through a trajectory-based DPO objective.
  These step rewards are then used to compute step-level advantages, which are
combined with episode-level advantages from outcome rewards for policy update,
creating a self-reinforcing loop.
  Theoretical findings guarantee that the learned step rewards are consistent
with trajectory preferences and act as potential-based shaping rewards,
providing bounded gradients to stabilize training.
  Empirically, we evaluate OPRL on three distinct agent benmarks, including
WebShop and VisualSokoban, as well as open-ended social interactions with
unverfiable rewards in SOTOPIA.
  Crucially, OPRL shows superior performance over frontier LLMs and strong RL
baselines across domains, achieving state-of-the-art results with higher
sample-efficiency and lower variance during training.
  Further analysis also demonstrates the efficient exploration by OPRL using
fewer actions, underscoring its potential for agentic learning in real-world
scenarios.

</details>


### [177] [Steering Multimodal Large Language Models Decoding for Context-Aware Safety](https://arxiv.org/abs/2509.19212)
*Zheyuan Liu,Zhangchen Xu,Guangyao Dou,Xiangchi Yuan,Zhaoxuan Tan,Radha Poovendran,Meng Jiang*

Main category: cs.CL

TL;DR: 提出Safety-aware Contrastive Decoding（SafeCoDe），解决多模态大语言模型在安全决策中的灵敏度问题，提高拒绝行为的上下文敏感性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在安全决策中存在的过敏和不足灵敏的问题。

Method: 通过对比解码机制和全局感知的令牌调节策略，动态调整令牌生成。

Result: 在各种多模态大语言模型架构和安全基准测试中，SafeCoDe在敏感拒绝行为上取得了一致的改善。

Conclusion: SafeCoDe提高了多模态大语言模型的上下文敏感拒绝行为，同时保持模型的有用性。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly deployed in
real-world applications, yet their ability to make context-aware safety
decisions remains limited. Existing methods often fail to balance
oversensitivity (unjustified refusals of benign queries) and undersensitivity
(missed detection of visually grounded risks), leaving a persistent gap in
safety alignment. To address this issue, we introduce Safety-aware Contrastive
Decoding (SafeCoDe), a lightweight and model-agnostic decoding framework that
dynamically adjusts token generation based on multimodal context. SafeCoDe
operates in two stages: (1) a contrastive decoding mechanism that highlights
tokens sensitive to visual context by contrasting real and Gaussian-noised
images, and (2) a global-aware token modulation strategy that integrates
scene-level reasoning with token-level adjustment to adapt refusals according
to the predicted safety verdict. Extensive experiments across diverse MLLM
architectures and safety benchmarks, covering undersensitivity,
oversensitivity, and general safety evaluations, show that SafeCoDe
consistently improves context-sensitive refusal behaviors while preserving
model helpfulness.

</details>


### [178] [Systematic Comparative Analysis of Large Pretrained Language Models on Contextualized Medication Event Extraction](https://arxiv.org/abs/2509.19224)
*Tariq Abdul-Quddoos,Xishuang Dong,Lijun Qian*

Main category: cs.CL

TL;DR: 该研究比较了多种预训练的注意力模型在电子健康记录信息提取任务中的效果，发现临床数据预训练模型在检测药物事件时更有效，但Bert Base在事件上下文分类中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 为提高从电子健康记录中提取患者用药事件的上下文信息的效果，比较不同的预训练注意力模型。

Method: 对多种预训练的注意力模型进行比较分析，应用于电子健康记录（EHR）信息提取任务，并进行了细致的性能分析。

Result: 通过对各个模型在CMED数据集上的药物提取、医疗事件检测和多维药物事件上下文分类任务的表现进行对比，得出临床模型更有效，但Bert Base在事件上下文分类中表现突出。

Conclusion: 预训练的临床数据模型在检测药物和药物事件方面更有效，但在分类与药物相关的事件上下文时，Bert Base表现最佳。

Abstract: Attention-based models have become the leading approach in modeling medical
language for Natural Language Processing (NLP) in clinical notes. These models
outperform traditional techniques by effectively capturing contextual rep-
resentations of language. In this research a comparative analysis is done
amongst pre- trained attention based models namely Bert Base, BioBert, two
variations of Bio+Clinical Bert, RoBerta, and Clinical Long- former on task
related to Electronic Health Record (EHR) information extraction. The tasks
from Track 1 of Harvard Medical School's 2022 National Clinical NLP Challenges
(n2c2) are considered for this comparison, with the Contextualized Medication
Event Dataset (CMED) given for these task. CMED is a dataset of unstructured
EHRs and annotated notes that contain task relevant information about the EHRs.
The goal of the challenge is to develop effective solutions for extracting
contextual information related to patient medication events from EHRs using
data driven methods. Each pre-trained model is fine-tuned and applied on CMED
to perform medication extraction, medical event detection, and
multi-dimensional medication event context classification. Pro- cessing methods
are also detailed for breaking down EHRs for compatibility with the applied
models. Performance analysis has been carried out using a script based on
constructing medical terms from the evaluation portion of CMED with metrics
including recall, precision, and F1-Score. The results demonstrate that models
pre-trained on clinical data are more effective in detecting medication and
medication events, but Bert Base, pre- trained on general domain data showed to
be the most effective for classifying the context of events related to
medications.

</details>


### [179] [CompLLM: Compression for Long Context Q&A](https://arxiv.org/abs/2509.19228)
*Gabriele Berton,Jayakrishnan Unnikrishnan,Son Tran,Mubarak Shah*

Main category: cs.CL

TL;DR: CompLLM是一种新颖的上下文压缩技术，通过独立处理上下文片段，实现了高效、可扩展和可复用的特性，显著提高了大型语言模型的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理长上下文时面临的计算挑战，推动了对有效上下文压缩技术的需求。

Method: CompLLM通过将长上下文分段进行独立压缩，与传统方法相比，具有线性压缩复杂度，能在不同查询间复用计算。

Result: CompLLM在高上下文长度下提高了Time To First Token (TTFT)速度，并减少了KV缓存大小，同时其性能可与未压缩上下文媲美，甚至在很长序列中超过未压缩上下文。

Conclusion: CompLLM是一种有效且实用的软压缩技术，能够显著提高大型语言模型在处理长上下文时的效率，并在保持良好性能的同时，减少计算资源需求。

Abstract: Large Language Models (LLMs) face significant computational challenges when
processing long contexts due to the quadratic complexity of self-attention.
While soft context compression methods, which map input text to smaller latent
representations, have shown promise, their real-world adoption is limited.
Existing techniques typically compress the context as a single unit, which
leads to quadratic compression complexity and an inability to reuse
computations across queries with overlapping contexts. In this work, we
introduce CompLLM, a soft compression technique designed for practical
deployment. Instead of processing the context holistically, CompLLM divides it
into segments and compresses each one independently. This simple design choice
yields three critical properties: efficiency, as the compression step scales
linearly with the context length; scalability, enabling models trained on short
sequences (e.g., 1k tokens) to generalize to contexts of 100k tokens; and
reusability, allowing compressed segments to be cached and reused across
different queries. Our experiments show that with a 2x compression rate, at
high context lengths CompLLM speeds up Time To First Token (TTFT) by up to 4x
and reduces the KV cache size by 50%. Furthermore, CompLLM achieves performance
comparable to that obtained with the uncompressed context, and even surpasses
it on very long sequences, demonstrating its effectiveness and practical
utility.

</details>


### [180] [Reinforcement Learning on Pre-Training Data](https://arxiv.org/abs/2509.19249)
*Siheng Li,Kejiao Li,Zenan Xu,Guanhua Huang,Evander Yang,Kun Li,Haoyuan Wu,Jiajia Wu,Zihao Zheng,Chenchen Zhang,Kun Shi,Kyrierl Deng,Qi Yi,Ruibin Xiong,Tingqiang Xu,Yuhao Jiang,Jianfeng Yan,Yuyuan Zeng,Guanghui Xu,Jinbao Xue,Zhijiang Xu,Zheng Fang,Shuai Li,Qibin Liu,Xiaoxue Li,Zhuoyu Li,Yangyu Tao,Fei Gao,Cheng Jiang,Bo Chao Wang,Kai Liu,Jianchen Zhu,Wai Lam,Wayyt Wang,Bo Zhou,Di Wang*

Main category: cs.CL

TL;DR: RLPT是一种新的训练范式，通过无需人类标注直接从预训练数据中获得奖励信号，显著提升了大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决计算资源与高质量文本数据之间的增长差距限制了当前大语言模型的扩展方法。

Method: 采用加强学习（RL）对预训练数据进行自主探索，通过下一个片段推理目标，奖励策略准确预测后续文本片段。

Result: RLPT在多个基准测试上展示了显著的性能提升，尤其在Qwen3-4B-Base模型中在MMLU等任务上获得了绝对提高，以及良好的扩展行为，显示出潜在的继续提升空间。

Conclusion: RLPT为大语言模型的优化提供了一种新的训练时间扩展范式，通过从预训练数据中直接获取奖励信号，促进了更丰富的学习轨迹和更强的推理能力。

Abstract: The growing disparity between the exponential scaling of computational
resources and the finite growth of high-quality text data now constrains
conventional scaling approaches for large language models (LLMs). To address
this challenge, we introduce Reinforcement Learning on Pre-Training data
(RLPT), a new training-time scaling paradigm for optimizing LLMs. In contrast
to prior approaches that scale training primarily through supervised learning,
RLPT enables the policy to autonomously explore meaningful trajectories to
learn from pre-training data and improve its capability through reinforcement
learning (RL). While existing RL strategies such as reinforcement learning from
human feedback (RLHF) and reinforcement learning with verifiable rewards (RLVR)
rely on human annotation for reward construction, RLPT eliminates this
dependency by deriving reward signals directly from pre-training data.
Specifically, it adopts a next-segment reasoning objective, rewarding the
policy for accurately predicting subsequent text segments conditioned on the
preceding context. This formulation allows RL to be scaled on pre-training
data, encouraging the exploration of richer trajectories across broader
contexts and thereby fostering more generalizable reasoning skills. Extensive
experiments on both general-domain and mathematical reasoning benchmarks across
multiple models validate the effectiveness of RLPT. For example, when applied
to Qwen3-4B-Base, RLPT yields absolute improvements of $3.0$, $5.1$, $8.1$,
$6.0$, $6.6$, and $5.3$ on MMLU, MMLU-Pro, GPQA-Diamond, KOR-Bench, AIME24, and
AIME25, respectively. The results further demonstrate favorable scaling
behavior, suggesting strong potential for continued gains with more compute. In
addition, RLPT provides a solid foundation, extending the reasoning boundaries
of LLMs and enhancing RLVR performance.

</details>


### [181] [Extracting Conceptual Spaces from LLMs Using Prototype Embeddings](https://arxiv.org/abs/2509.19269)
*Nitesh Kumar,Usashi Chatterjee,Steven Schockaert*

Main category: cs.CL

TL;DR: 本文提出了一种新的策略，通过微调大语言模型来提取概念空间，并且验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然已有方法从大语言模型中提取嵌入，但提取概念空间仍然缺乏有效方法。

Method: 通过对大语言模型进行微调，使其原型嵌入与对应的概念空间维度对齐，从而编码特征。

Result: 实证分析表明，该策略在提取相关概念空间中特征嵌入的有效性很高。

Conclusion: 该方法在提取概念空间方面表现出色，为解释性AI的发展提供了新的思路。

Abstract: Conceptual spaces represent entities and concepts using cognitively
meaningful dimensions, typically referring to perceptual features. Such
representations are widely used in cognitive science and have the potential to
serve as a cornerstone for explainable AI. Unfortunately, they have proven
notoriously difficult to learn, although recent LLMs appear to capture the
required perceptual features to a remarkable extent. Nonetheless, practical
methods for extracting the corresponding conceptual spaces are currently still
lacking. While various methods exist for extracting embeddings from LLMs,
extracting conceptual spaces also requires us to encode the underlying
features. In this paper, we propose a strategy in which features (e.g.
sweetness) are encoded by embedding the description of a corresponding
prototype (e.g. a very sweet food). To improve this strategy, we fine-tune the
LLM to align the prototype embeddings with the corresponding conceptual space
dimensions. Our empirical analysis finds this approach to be highly effective.

</details>


### [182] [WolBanking77: Wolof Banking Speech Intent Classification Dataset](https://arxiv.org/abs/2509.19271)
*Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione*

Main category: cs.CL

TL;DR: 本研究创建并发布了Wolof意图分类数据集WolBanking77，以支持低资源语言的意图分类研究，实验显示出良好的性能。


<details>
  <summary>Details</summary>
Motivation: 针对低资源语言和高文盲率地区的研究缺口，尤其是在塞内加尔的沃洛夫语言环境中。

Method: 利用传统文本和语音意图分类模型进行实验，包括基准F1分数和字错误率度量。

Result: WolBanking77数据集包含9791个银行领域文本句子和超过4小时的语音句子，实验结果表现出良好的基准性能。

Conclusion: 该研究提出了Wolof意图分类数据集WolBanking77，并在其上进行了有效的实验，显示出良好的效果。

Abstract: Intent classification models have made a lot of progress in recent years.
However, previous studies primarily focus on high-resource languages datasets,
which results in a gap for low-resource languages and for regions with a high
rate of illiterate people where languages are more spoken than read or written.
This is the case in Senegal, for example, where Wolof is spoken by around 90\%
of the population, with an illiteracy rate of 42\% for the country. Wolof is
actually spoken by more than 10 million people in West African region. To
tackle such limitations, we release a Wolof Intent Classification Dataset
(WolBanking77), for academic research in intent classification. WolBanking77
currently contains 9,791 text sentences in the banking domain and more than 4
hours of spoken sentences. Experiments on various baselines are conducted in
this work, including text and voice state-of-the-art models. The results are
very promising on this current dataset. This paper also provides detailed
analyses of the contents of the data. We report baseline f1-score and word
error rate metrics respectively on NLP and ASR models trained on WolBanking77
dataset and also comparisons between models. We plan to share and conduct
dataset maintenance, updates and to release open-source code.

</details>


### [183] [DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture](https://arxiv.org/abs/2509.19274)
*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Nemil Shah,Abhilekh Borah,Vanshika Shah,Nishant Mishra,Sriparna Saha*

Main category: cs.CL

TL;DR: DRISHTIKON是一个专注于印度文化的多模态多语言基准，评估AI系统的文化理解，揭示了现有模型的局限性，推动包容性AI的发展。


<details>
  <summary>Details</summary>
Motivation: 为了填补现有基准在文化领域评估方面的空白，特别是针对印度丰富多样的文化和语言背景，促进包容性AI研究。

Method: 通过构建一个包括64,000个对齐的文本-图像对的多模态和多语言数据集，对多种视觉-语言模型进行了评估，覆盖印度的所有州和联邦领地，涉及15种语言。

Result: 目前模型在处理以文化为基础的多模态输入方面存在显著的局限性，特别是在低资源语言和非主流传统的表现。

Conclusion: DRISHTIKON为评估生成AI系统的文化理解提供了一个全面的基准，强调了当前模型在低资源语言和少数传统方面的局限性，推动文化意识和多模态语言技术的发展。

Abstract: We introduce DRISHTIKON, a first-of-its-kind multimodal and multilingual
benchmark centered exclusively on Indian culture, designed to evaluate the
cultural understanding of generative AI systems. Unlike existing benchmarks
with a generic or global scope, DRISHTIKON offers deep, fine-grained coverage
across India's diverse regions, spanning 15 languages, covering all states and
union territories, and incorporating over 64,000 aligned text-image pairs. The
dataset captures rich cultural themes including festivals, attire, cuisines,
art forms, and historical heritage amongst many more. We evaluate a wide range
of vision-language models (VLMs), including open-source small and large models,
proprietary systems, reasoning-specialized VLMs, and Indic-focused models,
across zero-shot and chain-of-thought settings. Our results expose key
limitations in current models' ability to reason over culturally grounded,
multimodal inputs, particularly for low-resource languages and less-documented
traditions. DRISHTIKON fills a vital gap in inclusive AI research, offering a
robust testbed to advance culturally aware, multimodally competent language
technologies.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [184] [XMUspeech Systems for the ASVspoof 5 Challenge](https://arxiv.org/abs/2509.18102)
*Wangjie Li,Xingjia Xie,Yishuang Li,Wenhao Guan,Kaidi Wang,Pengyu Ren,Lin Li,Qingyang Hong*

Main category: cs.SD

TL;DR: 本文提出了XMUspeech系统用于ASVspoof 5挑战，探索了多种模型及特征融合方法，显著提高了深伪检测性能。


<details>
  <summary>Details</summary>
Motivation: 音频持续时间的显著增加促使我们研究输入音频长度的调整如何显著提高系统性能。

Method: 我们训练了自监督模型作为特征提取器，并应用自适应多尺度特征融合（AMFF）方法来集成多个Transformer层的特征与手工特征，以增强检测能力。

Result: 我们探索了多种输入特征和损失函数对AASIST、HM-Conformer、Hubert和Wav2vec2的性能影响，并进行了大量实验，以便更好地与反欺骗任务对齐。

Conclusion: 我们的融合系统在闭合条件下获得了0.4783的最小DCF和20.45%的EER，在开放条件下则获得了0.2245的最小DCF和9.36%的EER。

Abstract: In this paper, we present our submitted XMUspeech systems to the speech
deepfake detection track of the ASVspoof 5 Challenge. Compared to previous
challenges, the audio duration in ASVspoof 5 database has significantly
increased. And we observed that merely adjusting the input audio length can
substantially improve system performance. To capture artifacts at multiple
levels, we explored the performance of AASIST, HM-Conformer, Hubert, and
Wav2vec2 with various input features and loss functions. Specifically, in order
to obtain artifact-related information, we trained self-supervised models on
the dataset containing spoofing utterances as the feature extractors. And we
applied an adaptive multi-scale feature fusion (AMFF) method to integrate
features from multiple Transformer layers with the hand-crafted feature to
enhance the detection capability. In addition, we conducted extensive
experiments on one-class loss functions and provided optimized configurations
to better align with the anti-spoofing task. Our fusion system achieved a
minDCF of 0.4783 and an EER of 20.45% in the closed condition, and a minDCF of
0.2245 and an EER of 9.36% in the open condition.

</details>


### [185] [MNV-17: A High-Quality Performative Mandarin Dataset for Nonverbal Vocalization Recognition in Speech](https://arxiv.org/abs/2509.18196)
*Jialong Mai,Jinxin Ji,Xiaofen Xing,Chen Yang,Weidong Chen,Jingyuan Xing,Xiangmin Xu*

Main category: cs.SD

TL;DR: MNV-17是一个新的普通话数据集，专注于非言语发声，解决了ASR系统识别非言语内容的不足，为研究提供了丰富的资源。


<details>
  <summary>Details</summary>
Motivation: 现有ASR系统在处理非言语发声（如叹息、笑声和咳嗽）方面表现不足，因此需要建立高质量的标注数据集以解决这一问题。

Method: 基于MNV-17数据集评估四种主流ASR架构在语义转录和NV分类上的综合表现。

Result: MNV-17是一个7.55小时的普通话表演性语音数据集，包含17种非言语发声类别，确保了高保真度和清晰度的NV实例。

Conclusion: MNV-17数据集的引入为表情化ASR的研究提供了高质量的资源，促进了非言语发声的分类与识别。

Abstract: Mainstream Automatic Speech Recognition (ASR) systems excel at transcribing
lexical content, but largely fail to recognize nonverbal vocalizations (NVs)
embedded in speech, such as sighs, laughs, and coughs. This capability is
important for a comprehensive understanding of human communication, as NVs
convey crucial emotional and intentional cues. Progress in NV-aware ASR has
been hindered by the lack of high-quality, well-annotated datasets. To address
this gap, we introduce MNV-17, a 7.55-hour performative Mandarin speech
dataset. Unlike most existing corpora that rely on model-based detection,
MNV-17's performative nature ensures high-fidelity, clearly articulated NV
instances. To the best of our knowledge, MNV-17 provides the most extensive set
of nonverbal vocalization categories, comprising 17 distinct and well-balanced
classes of common NVs. We benchmarked MNV-17 on four mainstream ASR
architectures, evaluating their joint performance on semantic transcription and
NV classification. The dataset and the pretrained model checkpoints will be
made publicly available to facilitate future research in expressive ASR.

</details>


### [186] [StereoFoley: Object-Aware Stereo Audio Generation from Video](https://arxiv.org/abs/2509.18272)
*Tornike Karchkhadze,Kuan-Lin Chen,Mojtaba,Heydari,Robert Henzel,Alessandro Toso,Mehrez Souden,Joshua Atkins*

Main category: cs.SD

TL;DR: 本文提出StereoFoley，一个视频到音频生成框架，克服了现有模型的局限，实现在48kHz下生成语义一致、时间同步和空间准确的立体声音频，设置了新基准。


<details>
  <summary>Details</summary>
Motivation: 现有的视频到音频生成模型主要限于单声道或缺乏对象感知的立体声成像，受限于缺乏专业混合的空间准确视频到音频数据集。

Method: 开发并训练了一个基础模型，生成立体声音频，同时引入合成数据生成管道，通过视频分析、物体跟踪和音频合成实现空间准确的对象感知声音。

Result: 基础模型在语义准确性和同步性方面达到了最先进水平；通过引入合成数据生成管道，模型在合成数据集上进行微调后，得到了清晰的对象音频对应关系，并通过人类听觉研究验证了其感知的强相关性。

Conclusion: 本研究建立了第一个立体声对象感知视频到音频生成的端到端框架，填补了这一领域的关键空白，并设定了新的基准。

Abstract: We present StereoFoley, a video-to-audio generation framework that produces
semantically aligned, temporally synchronized, and spatially accurate stereo
sound at 48 kHz. While recent generative video-to-audio models achieve strong
semantic and temporal fidelity, they largely remain limited to mono or fail to
deliver object-aware stereo imaging, constrained by the lack of professionally
mixed, spatially accurate video-to-audio datasets. First, we develop and train
a base model that generates stereo audio from video, achieving state-of-the-art
in both semantic accuracy and synchronization. Next, to overcome dataset
limitations, we introduce a synthetic data generation pipeline that combines
video analysis, object tracking, and audio synthesis with dynamic panning and
distance-based loudness controls, enabling spatially accurate object-aware
sound. Finally, we fine-tune the base model on this synthetic dataset, yielding
clear object-audio correspondence. Since no established metrics exist, we
introduce stereo object-awareness measures and validate it through a human
listening study, showing strong correlation with perception. This work
establishes the first end-to-end framework for stereo object-aware
video-to-audio generation, addressing a critical gap and setting a new
benchmark in the field.

</details>


### [187] [A Dimensional Approach to Canine Bark Analysis for Assistance Dog Seizure Signaling](https://arxiv.org/abs/2509.18375)
*Hailin Song,Shelley Brady,Tomás Ward,Alan F. Smeaton*

Main category: cs.SD

TL;DR: 这项研究提出了一种新的方法，通过调整的Siamese网络在情感空间中分析犬类吠叫，解决了样本数据稀缺的问题，并取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 由于样本数据稀少且犬只之间存在差异，传统的犬类 vocalisations 分类方法受到严重限制。因此，我们将此问题重新框定为在二维情感空间中的连续回归任务。

Method: 我们的模型使用调整后的Siamese网络，通过对输入样本对的序数和数值距离进行训练，而不是简单的二元相似性。

Result: 与回归基线相比，我们的模型在具有挑战性的情感维度上减少了多达50%的返回百分比，且在真实世界数据集上的定性验证确认了所学习的空间在语义上的合理性。

Conclusion: 我们的模型在分析犬类吠叫方面具有创新性，为在数据有限情况下的响应提供了有效方法。

Abstract: Standard classification of canine vocalisations is severely limited for
assistance dogs, where sample data is sparse and variable across dogs and where
capture of the full range of bark types is ethically constrained. We reframe
this problem as a continuous regression task within a two-dimensional
arousal-valence space. Central to our approach is an adjusted Siamese Network
trained not on binary similarity, but on the ordinal and numeric distance
between input sample pairs. Trained on a public dataset, our model reduces
Turn-around Percentage by up to 50% on the challenging valence dimension
compared to a regression baseline. Qualitative validation on a real-world
dataset confirms the learned space is semantically meaningful, establishing a
proof-of-concept for analysing canine barking under severe data limitations.

</details>


### [188] [Identifying birdsong syllables without labelled data](https://arxiv.org/abs/2509.18412)
*Mélisande Teng,Julien Boussard,David Rolnick,Hugo Larochelle*

Main category: cs.SD

TL;DR: 本研究开发了一种完全无监督的方法来分解鸟鸣录音为音节序列，并在实验中取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 识别鸟鸣中的音节序列对于鸟类个体识别和动物交流理解至关重要，但现有机器学习方法依赖于有标签的数据。

Method: 我们首先检测音节事件，然后对其进行聚类以提取模板，最后通过匹配追求方法将录音分解为音节序列。

Result: 在对孟加拉雀歌的实验中，该无监督方法与人类标签相比表现出高性能，并能够区分不同物种个体。

Conclusion: 该研究提出的无监督算法在自动注解方面表现出色，能够有效区分不同鸟类的个体。

Abstract: Identifying sequences of syllables within birdsongs is key to tackling a wide
array of challenges, including bird individual identification and better
understanding of animal communication and sensory-motor learning. Recently,
machine learning approaches have demonstrated great potential to alleviate the
need for experts to label long audio recordings by hand. However, they still
typically rely on the availability of labelled data for model training,
restricting applicability to a few species and datasets. In this work, we build
the first fully unsupervised algorithm to decompose birdsong recordings into
sequences of syllables. We first detect syllable events, then cluster them to
extract templates --syllable representations-- before performing matching
pursuit to decompose the recording as a sequence of syllables. We evaluate our
automatic annotations against human labels on a dataset of Bengalese finch
songs and find that our unsupervised method achieves high performance. We also
demonstrate that our approach can distinguish individual birds within a species
through their unique vocal signatures, for both Bengalese finches and another
species, the great tit.

</details>


### [189] [Scattering Transformer: A Training-Free Transformer Architecture for Heart Murmur Detection](https://arxiv.org/abs/2509.18424)
*Rami Zewail*

Main category: cs.SD

TL;DR: 本研究提出了一种新型的Scattering Transformer，用于心脏杂音检测，表现出优越的性能，适用于资源受限的环境。


<details>
  <summary>Details</summary>
Motivation: 应对心音解读中缺乏熟练临床医生的需求，并探索自动心脏听诊的深度学习方法。

Method: 提出了一种名为Scattering Transformer的训练-free变换器架构，利用小波散射网络引入上下文依赖性，无需反向传播。

Result: Scattering Transformer在CirCor DigiScope数据集上取得了0.786的加权准确率和0.697的非加权平均召回率，表现与现有最先进方法具有高度竞争力。

Conclusion: Scattering Transformer是一种可行且有前景的轻量级心脏杂音检测替代方案，适用于资源受限的环境。

Abstract: In an attempt to address the need for skilled clinicians in heart sound
interpretation, recent research efforts on automating cardiac auscultation have
explored deep learning approaches. The majority of these approaches have been
based on supervised learning that is always challenged in occasions where
training data is limited. More recently, there has been a growing interest in
potentials of pre-trained self-supervised audio foundation models for
biomedical end tasks. Despite exhibiting promising results, these foundational
models are typically computationally intensive. Within the context of automatic
cardiac auscultation, this study explores a lightweight alternative to these
general-purpose audio foundation models by introducing the Scattering
Transformer, a novel, training-free transformer architecture for heart murmur
detection. The proposed method leverages standard wavelet scattering networks
by introducing contextual dependencies in a transformer-like architecture
without any backpropagation. We evaluate our approach on the public CirCor
DigiScope dataset, directly comparing it against leading general-purpose
foundational models. The Scattering Transformer achieves a Weighted
Accuracy(WAR) of 0.786 and an Unweighted Average Recall(UAR) of 0.697,
demonstrating performance highly competitive with contemporary state of the art
methods. This study establishes the Scattering Transformer as a viable and
promising alternative in resource-constrained setups.

</details>


### [190] [Explore the Reinforcement Learning for the LLM based ASR and TTS system](https://arxiv.org/abs/2509.18569)
*Changfeng Gao,Yabin Li,Keyu An,Zhifu Gao,Zhihao Du,Han Zhao,Xiangang Li*

Main category: cs.SD

TL;DR: 提出了一种轻量级强化学习框架，显著提高了自动语音识别和文本到语音转换的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习在文本任务中表现出色，但在ASR和TTS中的应用仍未得到充分探索，主要由于音频模型训练的复杂性。

Method: 设计了一种轻量级的强化学习框架，基于GRPO和DiffRO评估ASR和TTS任务的效果。

Result: 在ASR任务中，实验不同的基于规则的奖励函数，探讨RL数据构建对性能的影响；在TTS任务中比较GRPO与DiffRO，并结合二者以提升性能。

Conclusion: 强化学习显著提高了ASR和TTS系统的性能，即使在训练数据有限和优化步骤较少的情况下。

Abstract: In recent years, large language models (LLMs) have played an important role
in automatic speech recognition (ASR) and text-to-speech (TTS) systems. While
reinforcement learning (RL) has significantly enhanced LLM performance in
text-based tasks, its application to ASR and TTS remains underexplored due to
the complexity of training audio-based models. In this study, we propose a
lightweight RL framework tailored for audio-based LLMs that can process audio
inputs and generate audio outputs. Based on this framework, we evaluate the
effectiveness of reinforcement learning on both ASR and TTS tasks. For the ASR
task, we experiment with different rule-based reward functions within the Group
Relative Policy Optimization (GRPO) framework and investigate the impact of RL
data construction. For the TTS task, we compare GRPO with Differentiable Reward
Optimization (DiffRO) and further combine the two approaches to achieve
improved performance. Our experiments demonstrate that RL can significantly
enhance the performance of both ASR and TTS systems, even with limited training
data and a small number of optimization steps.

</details>


### [191] [Scalable Evaluation for Audio Identification via Synthetic Latent Fingerprint Generation](https://arxiv.org/abs/2509.18620)
*Aditya Bhattacharjee,Marco Pasini,Emmanouil Benetos*

Main category: cs.SD

TL;DR: 由于大型音乐数据库的缺乏，我们提出了一种通过合成指纹模拟音频指纹检索的无音频方法，展示了其在系统可扩展性评估中的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于大型公共音乐数据库的稀缺，音频指纹评估在实际规模上的应用受到限制，因此我们提出了一种无音频的方法，合成用于模拟检索性能的指纹。

Method: 使用经过培训的神经音频指纹提取系统提取的嵌入来训练修正流模型，合成出近似真实指纹分布的合成指纹。

Result: 合成指纹的保真度通过与真实数据的分布比较进行评估，合成干扰物显著增强了多种音频指纹框架的检索性能，并能够很好地替代真实干扰物。

Conclusion: 我们的方法有效地生成了逼真的合成指纹，能够在没有额外音频的情况下模拟检索性能，为大规模系统的可扩展性提供了实际指标。

Abstract: The evaluation of audio fingerprinting at a realistic scale is limited by the
scarcity of large public music databases. We present an audio-free approach
that synthesises latent fingerprints which approximate the distribution of real
fingerprints. Our method trains a Rectified Flow model on embeddings extracted
by pre-trained neural audio fingerprinting systems. The synthetic fingerprints
generated using our system act as realistic distractors and enable the
simulation of retrieval performance at a large scale without requiring
additional audio. We assess the fidelity of synthetic fingerprints by comparing
the distributions to real data. We further benchmark the retrieval performances
across multiple state-of-the-art audio fingerprinting frameworks by augmenting
real reference databases with synthetic distractors, and show that the scaling
trends obtained with synthetic distractors closely track those obtained with
real distractors. Finally, we scale the synthetic distractor database to model
retrieval performance for very large databases, providing a practical metric of
system scalability that does not depend on access to audio corpora.

</details>


### [192] [An overview of neural architectures for self-supervised audio representation learning from masked spectrograms](https://arxiv.org/abs/2509.18691)
*Sarthak Yadav,Sergios Theodoridis,Zheng-Hua Tan*

Main category: cs.SD

TL;DR: 本文综述了掩蔽谱图建模、Mamba和xLSTM的关系，并在音频分类任务中进行了比较，以帮助选取合适的模型。


<details>
  <summary>Details</summary>
Motivation: 随着自监督学习的兴起，特别是掩蔽谱图建模方法，研究者们对Transformer架构的局限性产生了兴趣，这促使了对循环序列建模方法的关注。

Method: 通过对比三种自监督学习模型（Transformers、Mamba和xLSTM）在十个不同的下游音频分类任务中的表现来进行研究。

Result: 通过对三种模型的比较，研究为读者提供了在选择适合的音频表示模型时的参考，解决了现有文献中对这两个领域交集的不足之处。

Conclusion: 本文全面概述了掩蔽谱图建模与选择性结构状态空间模型（Mamba）和扩展长短期记忆（xLSTM）之间的交集，并在统一的框架中对三者进行了比较。

Abstract: In recent years, self-supervised learning has amassed significant interest
for training deep neural representations without labeled data. One such
self-supervised learning approach is masked spectrogram modeling, where the
objective is to learn semantically rich contextual representations by
predicting removed or hidden portions of the input audio spectrogram. With the
Transformer neural architecture at its core, masked spectrogram modeling has
emerged as the prominent approach for learning general purpose audio
representations, a.k.a. audio foundation models. Meanwhile, addressing the
issues of the Transformer architecture, in particular the underlying Scaled
Dot-product Attention operation, which scales quadratically with input sequence
length, has led to renewed interest in recurrent sequence modeling approaches.
Among them, Selective structured state space models (such as Mamba) and
extended Long Short-Term Memory (xLSTM) are the two most promising approaches
which have experienced widespread adoption. While the body of work on these two
topics continues to grow, there is currently a lack of an adequate overview
encompassing the intersection of these topics. In this paper, we present a
comprehensive overview of the aforementioned research domains, covering masked
spectrogram modeling and the previously mentioned neural sequence modeling
architectures, Mamba and xLSTM. Further, we compare Transformers, Mamba and
xLSTM based masked spectrogram models in a unified, reproducible framework on
ten diverse downstream audio classification tasks, which will help interested
readers to make informed decisions regarding suitability of the evaluated
approaches to adjacent applications.

</details>


### [193] [Enhancing Automatic Chord Recognition through LLM Chain-of-Thought Reasoning](https://arxiv.org/abs/2509.18700)
*Chih-Cheng Chang,Bo-Yu Chen,Lu-Rong Chen,Li Su*

Main category: cs.SD

TL;DR: 本论文研究了大型语言模型在音乐信息检索中的应用，提出了一种新方法以提升和弦识别性能，实验结果表明准确率有所提高。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型如何作为集成桥梁，连接和整合多个音乐信息检索工具的信息，以提高自动和弦识别的性能。

Method: 提出了一种新颖的方法，通过将基于文本的大型语言模型视为智能协调者，处理和整合来自多种最新音乐信息检索工具的输出。

Result: 在三个数据集上的实验评估表明，多项评估指标上均有一致的改进，MIREX指标的整体准确率提高了1-2.77%。

Conclusion: 大型语言模型可以有效地作为音乐信息检索流程中的集成桥梁，为音乐信息检索任务的多工具协调开辟新的方向。

Abstract: Music Information Retrieval (MIR) encompasses a broad range of computational
techniques for analyzing and understanding musical content, with recent deep
learning advances driving substantial improvements. Building upon these
advances, this paper explores how large language models (LLMs) can serve as an
integrative bridge to connect and integrate information from multiple MIR
tools, with a focus on enhancing automatic chord recognition performance. We
present a novel approach that positions text-based LLMs as intelligent
coordinators that process and integrate outputs from diverse state-of-the-art
MIR tools-including music source separation, key detection, chord recognition,
and beat tracking. Our method converts audio-derived musical information into
textual representations, enabling LLMs to perform reasoning and correction
specifically for chord recognition tasks. We design a 5-stage chain-of-thought
framework that allows GPT-4o to systematically analyze, compare, and refine
chord recognition results by leveraging music-theoretical knowledge to
integrate information across different MIR components. Experimental evaluation
on three datasets demonstrates consistent improvements across multiple
evaluation metrics, with overall accuracy gains of 1-2.77% on the MIREX metric.
Our findings demonstrate that LLMs can effectively function as integrative
bridges in MIR pipelines, opening new directions for multi-tool coordination in
music information retrieval tasks.

</details>


### [194] [MECap-R1: Emotion-aware Policy with Reinforcement Learning for Multimodal Emotion Captioning](https://arxiv.org/abs/2509.18729)
*Haoqin Sun,Chenyang Lyu,Xiangyu Kong,Shiwan Zhao,Jiaming Zhou,Hui Wang,Aobo Kong,Jinghua Zhao,Longyue Wang,Weihua Luo,Kaifu Zhang,Yong Qin*

Main category: cs.SD

TL;DR: MECap-R1 是一种基于强化学习的多模态情感字幕生成方法，显著提高了情感描述的准确性和多样性。


<details>
  <summary>Details</summary>
Motivation: 传统的离散分类方法无法充分表示人类语音中的情感，因此使用自然语言描述语音情感是一个创新的途径。

Method: 采用带有情感奖励的组相对策略优化（Emo-GRPO）的情感感知策略，结合强化学习进行多模态情感字幕生成。

Result: 在 EmotionTalk 数据集上的实验结果显示，MECap-R1 能较好地生成情感描述，并在准确性和多样性上取得显著提升。

Conclusion: MECap-R1 在情感描述生成中表现优异，准确性和多样性均有显著提升。

Abstract: Speech Emotion Captioning (SEC) has emerged as a notable research direction.
The inherent complexity of emotional content in human speech makes it
challenging for traditional discrete classification methods to provide an
adequate representation. Consequently, utilizing natural language to describe
speech emotions presents a novel avenue for more effectively capturing and
expressing affect. In this paper, we propose MECap-R1, a pioneering
emotion-aware policy with reinforcement learning for multimodal emotion
captioning. By employing Group Relative Policy Optimization with emotion-aware
reward (Emo-GRPO), the framework precisely captures the emotion and semantic
features, thereby addressing the shortcomings of rigid rules in handling the
dynamic and flexible nature of captions. Experimental results on the
EmotionTalk dataset demonstrate that MECap-R1 performs well in generating
emotion descriptions and achieves substantial gains in both accuracy and
diversity.

</details>


### [195] [Pay More Attention To Audio: Mitigating Imbalance of Cross-Modal Attention in Large Audio Language Models](https://arxiv.org/abs/2509.18816)
*Junyu Wang,Ziyang Ma,Zhengding Luo,Tianrui Wang,Meng Ge,Xiaobao Wang,Longbiao Wang*

Main category: cs.SD

TL;DR: MATA是一种新方法，通过动态调整音频标记的注意力，提高多模态模型在音频推理任务中的表现，实验结果表明其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的LALMs在多模态融合层中倾向于优先考虑文本信息，导致音频信息的利用不足，从而影响音频推理任务的性能。

Method: MATA是一种训练自由的方法，通过动态干预自注意力机制，促使LALMs在自注意力机制中更关注音频标记。

Result: 在MMAU和MMAR基准测试中，MATA展现出一致的性能提升，使开源模型首次超越了专有模型Gemini 2.0 Flash。

Conclusion: 本研究提出的MATA方法有效缓解了LALMs中的音频-文本注意力失衡问题，提高了模型在音频推理任务中的表现。

Abstract: Large Audio-Language Models (LALMs) often suffer from audio-textual attention
imbalance, prioritizing text over acoustic information, particularly in the
multi-modal fusion layers of the Transformer architecture. This bias hinders
their ability to fully utilize acoustic cues, causing suboptimal performance on
audio reasoning tasks. To mitigate this, we propose \textbf{MATA}, a novel
training-free method that dynamically pushes LALMs to pay \textbf{M}ore
\textbf{A}ttention \textbf{T}o \textbf{A}udio tokens within the self-attention
mechanism. Specifically, MATA intervenes post raw attention scoring, targeting
only the last token in intermediate layers without introducing additional
parameters or computational overhead. Experiments on the MMAU and MMAR
benchmarks confirm MATA's effectiveness, with consistent performance gains.
Notably, on MMAR, MATA enables an open-source model to surpass the proprietary
Gemini 2.0 Flash for the first time. Our work provides an efficient solution to
mitigate attention bias and opens a new research direction for enhancing the
audio-processing capabilities of multi-modal models.

</details>


### [196] [Finding My Voice: Generative Reconstruction of Disordered Speech for Automated Clinical Evaluation](https://arxiv.org/abs/2509.19231)
*Karen Rosero,Eunjung Yeo,David R. Mortensen,Cortney Van't Slot,Rami R. Hallac,Carlos Busso*

Main category: cs.SD

TL;DR: ChiReSSD是一个针对儿童发音障碍的语音重建框架，能提高发音准确性并保留身份，且对成人口吃言语具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 针对有语言障碍的儿童，开发一种能够改善其发音的重建框架，提升其语言交流效果。

Method: 提出了一种基于风格的文本到语音（TTS）重建框架，专注于儿童的声音身份及其发音特征。

Result: 在STAR数据集上，ChiReSSD在词汇准确性和说话者身份保留方面表现显著提升；在TORGO数据集上，对成年人口吃语言也能有效重建。

Conclusion: ChiReSSD能够有效地保持儿童说话者的身份，同时改善发音不准确的问题，并在处理成人口吃演讲时也表现良好。

Abstract: We present ChiReSSD, a speech reconstruction framework that preserves
children speaker's identity while suppressing mispronunciations. Unlike prior
approaches trained on healthy adult speech, ChiReSSD adapts to the voices of
children with speech sound disorders (SSD), with particular emphasis on pitch
and prosody. We evaluate our method on the STAR dataset and report substantial
improvements in lexical accuracy and speaker identity preservation.
Furthermore, we automatically predict the phonetic content in the original and
reconstructed pairs, where the proportion of corrected consonants is comparable
to the percentage of correct consonants (PCC), a clinical speech assessment
metric. Our experiments show Pearson correlation of 0.63 between automatic and
human expert annotations, highlighting the potential to reduce the manual
transcription burden. In addition, experiments on the TORGO dataset demonstrate
effective generalization for reconstructing adult dysarthric speech. Our
results indicate that disentangled, style-based TTS reconstruction can provide
identity-preserving speech across diverse clinical populations.

</details>

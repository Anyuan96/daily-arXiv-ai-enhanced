{"id": "2510.08849", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.08849", "abs": "https://arxiv.org/abs/2510.08849", "authors": ["Hongrui Wu", "Zhicheng Gao", "Jin Cao", "Kelu Yao", "Wen Shen", "Zhihua Wei"], "title": "FOLK: Fast Open-Vocabulary 3D Instance Segmentation via Label-guided Knowledge Distillation", "comment": null, "summary": "Open-vocabulary 3D instance segmentation seeks to segment and classify\ninstances beyond the annotated label space. Existing methods typically map 3D\ninstances to 2D RGB-D images, and then employ vision-language models (VLMs) for\nclassification. However, such a mapping strategy usually introduces noise from\n2D occlusions and incurs substantial computational and memory costs during\ninference, slowing down the inference speed. To address the above problems, we\npropose a Fast Open-vocabulary 3D instance segmentation method via Label-guided\nKnowledge distillation (FOLK). Our core idea is to design a teacher model that\nextracts high-quality instance embeddings and distills its open-vocabulary\nknowledge into a 3D student model. In this way, during inference, the distilled\n3D model can directly classify instances from the 3D point cloud, avoiding\nnoise caused by occlusions and significantly accelerating the inference\nprocess. Specifically, we first design a teacher model to generate a 2D CLIP\nembedding for each 3D instance, incorporating both visibility and viewpoint\ndiversity, which serves as the learning target for distillation. We then\ndevelop a 3D student model that directly produces a 3D embedding for each 3D\ninstance. During training, we propose a label-guided distillation algorithm to\ndistill open-vocabulary knowledge from label-consistent 2D embeddings into the\nstudent model. FOLK conducted experiments on the ScanNet200 and Replica\ndatasets, achieving state-of-the-art performance on the ScanNet200 dataset with\nan AP50 score of 35.7, while running approximately 6.0x to 152.2x faster than\nprevious methods. All codes will be released after the paper is accepted.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFOLK\u7684\u5feb\u901f\u5f00\u653e\u8bcd\u6c473D\u5b9e\u4f8b\u5206\u5272\u65b9\u6cd5\uff0c\u901a\u8fc7\u6807\u7b7e\u5f15\u5bfc\u7684\u77e5\u8bc6\u84b8\u998f\uff0c\u5b9e\u73b0\u9ad8\u6548\u51c6\u786e\u76843D\u5b9e\u4f8b\u5206\u7c7b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c063D\u5b9e\u4f8b\u6620\u5c04\u52302D\u56fe\u50cf\u8fdb\u884c\u5206\u7c7b\uff0c\u5b58\u5728\u906e\u6321\u566a\u58f0\u548c\u9ad8\u8ba1\u7b97\u5f00\u9500\uff0c\u63a8\u7406\u901f\u5ea6\u6162\uff0c\u9650\u5236\u4e86\u5f00\u653e\u8bcd\u6c473D\u5b9e\u4f8b\u5206\u5272\u7684\u6548\u7387\u4e0e\u5b9e\u7528\u6027\u3002", "method": "\u8bbe\u8ba1\u4e00\u4e2a\u6559\u5e08\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u76842D CLIP\u5b9e\u4f8b\u5d4c\u5165\uff08\u8003\u8651\u53ef\u89c6\u6027\u548c\u89c6\u89d2\u591a\u6837\u6027\uff09\uff0c\u5e76\u901a\u8fc7\u6807\u7b7e\u5f15\u5bfc\u7684\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\uff0c\u5c06\u5f00\u653e\u8bcd\u6c47\u77e5\u8bc6\u8fc1\u79fb\u5230\u76f4\u63a5\u5904\u74063D\u70b9\u4e91\u76843D\u5b66\u751f\u6a21\u578b\u3002", "result": "\u5728ScanNet200\u548cReplica\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\uff0cFOLK\u5728ScanNet200\u4e0a\u8fbe\u523035.7\u7684AP50\u5206\u6570\uff0c\u4e3a\u5f53\u524d\u6700\u4f18\uff0c\u4e14\u63a8\u7406\u901f\u5ea6\u6bd4\u73b0\u6709\u65b9\u6cd5\u5feb6.0\u81f3152.2\u500d\u3002", "conclusion": "FOLK\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u907f\u514d\u4e862D\u6620\u5c04\u5e26\u6765\u7684\u566a\u58f0\u548c\u8ba1\u7b97\u8d1f\u62c5\uff0c\u5b9e\u73b0\u4e86\u5feb\u901f\u3001\u51c6\u786e\u7684\u5f00\u653e\u8bcd\u6c473D\u5b9e\u4f8b\u5206\u5272\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\u3002"}}

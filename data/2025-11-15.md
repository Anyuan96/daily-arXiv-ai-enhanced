<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 4]
- [cs.CL](#cs.CL) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals](https://arxiv.org/abs/2511.10615)
*Shruti Singh Baghel,Yash Pratap Singh Rathore,Sushovan Jena,Anurag Pradhan,Amit Shukla,Arnav Bhavsar,Pawan Goyal*

Main category: cs.CV

TL;DR: 工作评估了500M和2.2B参数的SmolVLM2变体在户外（AVCaps）和室内（Charades）数据集上的表现，针对BLV用户的可访问性描述质量。引入了两个新颖的评估框架：多上下文BLV框架和导航辅助框架，并系统评估了四种提示策略以及在智能手机上的部署性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在生成视频描述方面表现出色，但高内存、计算和部署需求限制了实际应用，特别是对于依赖详细、上下文感知描述的盲人和低视力用户。研究模型大小对可访问性描述质量的影响。

Method: 评估SmolVLM2的500M和2.2B参数变体在AVCaps和Charades数据集上的表现。引入多上下文BLV框架（评估空间定向、社交互动、动作事件和环境上下文）和导航辅助框架（关注移动关键信息）。系统评估四种提示策略，并在智能手机上部署模型，评估FP32和INT8精度变体的性能。

Result: 通过两个专门设计的评估框架，系统评估了不同模型大小和提示策略对BLV用户可访问性描述质量的影响，并测试了在资源受限移动设备上的实际性能。

Conclusion: 该研究为BLV用户的可访问性描述提供了专门的评估方法，并验证了较小模型在移动设备上的可行性，为实际应用提供了重要参考。

Abstract: Large Vision-Language Models (VLMs) excel at understanding and generating video descriptions but their high memory, computation, and deployment demands hinder practical use particularly for blind and low-vision (BLV) users who depend on detailed, context-aware descriptions. To study the effect of model size on accessibility-focused description quality, we evaluate SmolVLM2 variants with 500M and 2.2B parameters across two diverse datasets: AVCaps (outdoor), and Charades (indoor). In this work, we introduce two novel evaluation frameworks specifically designed for BLV accessibility assessment: the Multi-Context BLV Framework evaluating spatial orientation, social interaction, action events, and ambience contexts; and the Navigational Assistance Framework focusing on mobility-critical information. Additionally, we conduct a systematic evaluation of four different prompt design strategies and deploy both models on a smartphone, evaluating FP32 and INT8 precision variants to assess real-world performance constraints on resource-limited mobile devices.

</details>


### [2] [One Small Step in Latent, One Giant Leap for Pixels: Fast Latent Upscale Adapter for Your Diffusion Models](https://arxiv.org/abs/2511.10629)
*Aleksandr Razin,Danil Kazantsev,Ilya Makarov*

Main category: cs.CV

TL;DR: LUA：一种在潜在空间中执行超分辨率的轻量级模块，可在不修改基础模型的情况下实现高效的高分辨率图像合成。


<details>
  <summary>Details</summary>
Motivation: 扩散模型难以扩展到训练分辨率之外，直接高分辨率采样成本高，而传统的图像超分辨率方法存在伪影和额外延迟。

Method: 使用Swin风格的共享主干网络和特定尺度的像素重排头，在VAE解码前对潜在代码进行超分辨率处理。

Result: LUA在保持可比感知质量的同时，将解码和上采样时间降低近3倍（1024px生成仅增加0.42秒）。

Conclusion: LUA提供了一种实用高效的方法，在现代扩散管道中实现可扩展的高保真图像合成。

Abstract: Diffusion models struggle to scale beyond their training resolutions, as direct high-resolution sampling is slow and costly, while post-hoc image super-resolution (ISR) introduces artifacts and additional latency by operating after decoding. We present the Latent Upscaler Adapter (LUA), a lightweight module that performs super-resolution directly on the generator's latent code before the final VAE decoding step. LUA integrates as a drop-in component, requiring no modifications to the base model or additional diffusion stages, and enables high-resolution synthesis through a single feed-forward pass in latent space. A shared Swin-style backbone with scale-specific pixel-shuffle heads supports 2x and 4x factors and remains compatible with image-space SR baselines, achieving comparable perceptual quality with nearly 3x lower decoding and upscaling time (adding only +0.42 s for 1024 px generation from 512 px, compared to 1.87 s for pixel-space SR using the same SwinIR architecture). Furthermore, LUA shows strong generalization across the latent spaces of different VAEs, making it easy to deploy without retraining from scratch for each new decoder. Extensive experiments demonstrate that LUA closely matches the fidelity of native high-resolution generation while offering a practical and efficient path to scalable, high-fidelity image synthesis in modern diffusion pipelines.

</details>


### [3] [Depth Anything 3: Recovering the Visual Space from Any Views](https://arxiv.org/abs/2511.10647)
*Haotong Lin,Sili Chen,Junhao Liew,Donny Y. Chen,Zhenyu Li,Guang Shi,Jiashi Feng,Bingyi Kang*

Main category: cs.CV

TL;DR: Depth Anything 3 (DA3) 是一个新的视觉几何模型，能从未知数量的视觉输入（无论是否有已知相机姿态）中预测空间一致的几何信息，实现了简化的模型设计并达到与DA2相当的精度。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在开发一个更简洁但性能强大的视觉几何模型，减少对复杂架构和多任务学习的依赖，同时提升在各种视觉几何任务上的表现。

Method: DA3使用单一的普通transformer（例如vanilla DINO编码器）作为骨干网络，采用师生训练范式，并引入单一深度射线预测目标来避免复杂的多任务学习。

Result: DA3在新的视觉几何基准测试中在所有任务上都创下了新的最先进水平，相机姿态精度平均比之前的SOTA VGGT高出44.3%，几何精度高出25.1%，并且在单目深度估计方面也超过了DA2。

Conclusion: Depth Anything 3证明了单一通用transformer架构在视觉几何任务中的有效性，通过简化的设计实现了卓越的性能，为视觉几何建模提供了新的方向。

Abstract: We present Depth Anything 3 (DA3), a model that predicts spatially consistent geometry from an arbitrary number of visual inputs, with or without known camera poses. In pursuit of minimal modeling, DA3 yields two key insights: a single plain transformer (e.g., vanilla DINO encoder) is sufficient as a backbone without architectural specialization, and a singular depth-ray prediction target obviates the need for complex multi-task learning. Through our teacher-student training paradigm, the model achieves a level of detail and generalization on par with Depth Anything 2 (DA2). We establish a new visual geometry benchmark covering camera pose estimation, any-view geometry and visual rendering. On this benchmark, DA3 sets a new state-of-the-art across all tasks, surpassing prior SOTA VGGT by an average of 44.3% in camera pose accuracy and 25.1% in geometric accuracy. Moreover, it outperforms DA2 in monocular depth estimation. All models are trained exclusively on public academic datasets.

</details>


### [4] [Enhancing the Outcome Reward-based RL Training of MLLMs with Self-Consistency Sampling](https://arxiv.org/abs/2511.10648)
*Jiahao Wang,Weiye Xu,Aijun Yang,Wengang Zhou,Lewei Lu,Houqiang Li,Xiaohua Wang,Jinguo Zhu*

Main category: cs.CV

TL;DR: 提出自我一致性采样（SCS）方法，通过视觉扰动和轨迹重采样解决多模态大模型在强化学习中奖励不忠实推理轨迹的问题，显著提升多个基准性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态推理中强化学习的一个关键缺陷：错误推理链却侥幸猜对答案的轨迹与真正正确推理获得相同奖励，这会影响模型训练效果。

Method: SCS方法对每个问题（i）引入小的视觉扰动，（ii）重复截断和重采样初始轨迹，通过轨迹间一致性评分在策略更新时降低不可靠轨迹的权重。

Result: 在Qwen2.5-VL-7B等模型上，SCS方法将RLOO、GRPO等算法的准确率最高提升7.7个百分点，在多个基准上表现优异且计算开销很小。

Conclusion: SCS为多模态大模型的结局奖励强化学习提供了一个简单通用的解决方案，能有效提升推理可靠性。

Abstract: Outcome-reward reinforcement learning (RL) is a common and increasingly significant way to refine the step-by-step reasoning of multimodal large language models (MLLMs). In the multiple-choice setting - a dominant format for multimodal reasoning benchmarks - the paradigm faces a significant yet often overlooked obstacle: unfaithful trajectories that guess the correct option after a faulty chain of thought receive the same reward as genuine reasoning, which is a flaw that cannot be ignored. We propose Self-Consistency Sampling (SCS) to correct this issue. For each question, SCS (i) introduces small visual perturbations and (ii) performs repeated truncation and resampling of an initial trajectory; agreement among the resulting trajectories yields a differentiable consistency score that down-weights unreliable traces during policy updates. Based on Qwen2.5-VL-7B-Instruct, plugging SCS into RLOO, GRPO, and REINFORCE++ series improves accuracy by up to 7.7 percentage points on six multimodal benchmarks with negligible extra computation. SCS also yields notable gains on both Qwen2.5-VL-3B-Instruct and InternVL3-8B, offering a simple, general remedy for outcome-reward RL in MLLMs.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [5] [Know Your Limits: Entropy Estimation Modeling for Compression and Generalization](https://arxiv.org/abs/2511.10618)
*Benjamin L. Badger,Matthew Neligeorge*

Main category: cs.CL

TL;DR: 该论文探讨了语言模型预测精度的理论极限，提出了一种能够更高效估计语言熵的编码器增强因果解码器架构，并通过实验证明接近但不超过估计熵值的模型具有更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于因果语言模型的语言压缩算法在准确估计语言熵方面存在计算不可行的问题，需要找到更高效的方法来接近语言的信息熵极限。

Method: 引入编码器增强的因果解码器模型架构，这种架构具有更好的训练效率特性，能够在普通硬件上实现比因果Transformer更高的压缩效果，并提供基于token的熵估计方法。

Result: 实验表明，训练到接近但不超过估计token熵的因果模型比不考虑熵的模型表现出更好的泛化能力。

Conclusion: 模型训练时应该考虑接近语言熵的极限值，这不仅能提高压缩效率，还能增强模型的泛化性能。

Abstract: Language prediction is constrained by informational entropy intrinsic to language, such that there exists a limit to how accurate any language model can become and equivalently a lower bound to language compression. The most efficient language compression algorithms today are causal (next token prediction) large language models, but the use of these models to form accurate estimates of language entropy is currently computationally infeasible. We introduce encoder-augmented causal decoder model architectures that exhibit superior training efficiency characteristics and achieve higher compression than causal transformers even when trained on modest hardware. We demonstrate how entropy estimates can be obtained on a per-token basis, and show that the generalization of models trained to approach the entropy of their training data necessarily exceeds the generalization of models trained to minimize loss beyond this value. We show empirically that causal models trained to approach but not exceed estimated per-token entropies exhibit greater generalization than models trained without taking entropy into account.

</details>


### [6] [SSR: Socratic Self-Refine for Large Language Model Reasoning](https://arxiv.org/abs/2511.10621)
*Haizhou Shi,Ye Liu,Bo Pang,Zeyu Leo Liu,Hao Wang,Silvio Savarese,Caiming Xiong,Yingbo Zhou,Semih Yavuz*

Main category: cs.CL

TL;DR: SSR是一个用于细粒度评估和改进LLM推理的框架，通过分解为可验证的子问题对实现步骤级置信度估计，在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有测试框架依赖粗粒度的自我验证和自我修正，限制了在复杂任务上的效果，需要更精细的评估和修正方法。

Method: SSR将模型响应分解为可验证的（子问题，子答案）对，通过控制性重解和自我一致性检查进行步骤级置信度估计，精确定位不可靠步骤并迭代优化。

Result: 在五个推理基准和三个LLM上的实验结果表明，SSR持续优于最先进的迭代自优化基线方法。

Conclusion: SSR不仅带来性能提升，还为评估和理解LLM内部推理过程提供了原则性的黑盒方法。

Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning abilities, yet existing test-time frameworks often rely on coarse self-verification and self-correction, limiting their effectiveness on complex tasks. In this paper, we propose Socratic Self-Refine (SSR), a novel framework for fine-grained evaluation and precise refinement of LLM reasoning. Our proposed SSR decomposes model responses into verifiable (sub-question, sub-answer) pairs, enabling step-level confidence estimation through controlled re-solving and self-consistency checks. By pinpointing unreliable steps and iteratively refining them, SSR produces more accurate and interpretable reasoning chains. Empirical results across five reasoning benchmarks and three LLMs show that SSR consistently outperforms state-of-the-art iterative self-refinement baselines. Beyond performance gains, SSR provides a principled black-box approach for evaluating and understanding the internal reasoning processes of LLMs. Code is available at https://github.com/SalesforceAIResearch/socratic-self-refine-reasoning.

</details>


### [7] [Instella: Fully Open Language Models with Stellar Performance](https://arxiv.org/abs/2511.10628)
*Jiang Liu,Jialian Wu,Xiaodong Yu,Yusheng Su,Prakamya Mishra,Gowtham Ramesh,Sudhanshu Ranjan,Chaitanya Manem,Ximeng Sun,Ze Wang,Pratik Prabhanjan Brahma,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: Instella是一个完全开放的30亿参数语言模型家族，使用AMD MI300X GPU和公开数据进行训练，在完全开放模型中达到SOTA性能，并可扩展到128K上下文长度和数学推理任务。


<details>
  <summary>Details</summary>
Motivation: 解决高性能语言模型多为封闭或部分开放的问题，提供透明且可复现的完全开源替代方案。

Method: 分三阶段开发：大规模预训练、通用指令微调、人类偏好对齐；并开发了支持长上下文和数学推理的专用变体。

Result: 虽然预训练token数较少，但在完全开放模型中达到最先进水平，且与同规模领先开源权重模型竞争。

Conclusion: Instella为社区提供了透明、高性能且多功能的替代方案，推动了开放和可复现的语言建模研究。

Abstract: Large language models (LLMs) have demonstrated remarkable performance across a wide range of tasks, yet the majority of high-performing models remain closed-source or partially open, limiting transparency and reproducibility. In this work, we introduce Instella, a family of fully open three billion parameter language models trained entirely on openly available data and codebase. Powered by AMD Instinct MI300X GPUs, Instella is developed through large-scale pre-training, general-purpose instruction tuning, and alignment with human preferences. Despite using substantially fewer pre-training tokens than many contemporaries, Instella achieves state-of-the-art results among fully open models and is competitive with leading open-weight models of comparable size. We further release two specialized variants: Instella-Long, capable of handling context lengths up to 128K tokens, and Instella-Math, a reasoning-focused model enhanced through supervised fine-tuning and reinforcement learning on mathematical tasks. Together, these contributions establish Instella as a transparent, performant, and versatile alternative for the community, advancing the goal of open and reproducible language modeling research.

</details>


### [8] [Black-Box On-Policy Distillation of Large Language Models](https://arxiv.org/abs/2511.10643)
*Tianzhu Ye,Li Dong,Zewen Chi,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.CL

TL;DR: GAD是一种使用生成对抗网络进行黑盒知识蒸馏的方法，通过将学生模型作为生成器、训练判别器区分师生模型响应，实现了在策略蒸馏，性能优于序列级知识蒸馏。


<details>
  <summary>Details</summary>
Motivation: 解决黑盒蒸馏中无法访问教师模型内部参数或logits的问题，实现在策略且高效的知识迁移。

Method: 将学生LLM作为生成器，训练判别器区分师生响应，形成极小极大博弈，判别器作为在策略奖励模型随学生共同进化。

Result: GAD一致超越序列级知识蒸馏，Qwen2.5-14B-Instruct学生模型在LMSYS-Chat评估中达到与GPT-5-Chat教师相当的水平。

Conclusion: GAD是黑盒LLM蒸馏的有效新范式，具有稳定、自适应的反馈机制。

Abstract: Black-box distillation creates student large language models (LLMs) by learning from a proprietary teacher model's text outputs alone, without access to its internal logits or parameters. In this work, we introduce Generative Adversarial Distillation (GAD), which enables on-policy and black-box distillation. GAD frames the student LLM as a generator and trains a discriminator to distinguish its responses from the teacher LLM's, creating a minimax game. The discriminator acts as an on-policy reward model that co-evolves with the student, providing stable, adaptive feedback. Experimental results show that GAD consistently surpasses the commonly used sequence-level knowledge distillation. In particular, Qwen2.5-14B-Instruct (student) trained with GAD becomes comparable to its teacher, GPT-5-Chat, on the LMSYS-Chat automatic evaluation. The results establish GAD as a promising and effective paradigm for black-box LLM distillation.

</details>


### [9] [ParoQuant: Pairwise Rotation Quantization for Efficient Reasoning LLM Inference](https://arxiv.org/abs/2511.10645)
*Yesheng Liang,Haisheng Chen,Song Han,Zhijian Liu*

Main category: cs.CL

TL;DR: 提出ParoQuant方法-利用成对旋转量化和通道缩放技术解决LLM量化中的异常值问题，在推理任务上比AWQ平均提升2.4%准确率，仅增加不到10%开销


<details>
  <summary>Details</summary>
Motivation: 现有PTQ方法无法有效抑制权重和激活中的异常值，导致量化误差累积，特别是在需要长链推理的LLM中准确率下降严重

Method: 结合硬件高效的独立Givens旋转和通道级缩放，通过成对旋转均衡通道间幅度，缩小量化组内动态范围，并协同设计推理内核充分利用GPU并行性

Result: 在推理任务上相比AWQ平均提升2.4%准确率，运行时开销控制在10%以内

Conclusion: ParoQuant为实现更高效准确的推理LLM部署提供了可行路径，平衡了量化精度和推理效率

Abstract: Weight-only post-training quantization (PTQ) compresses the weights of Large Language Models (LLMs) into low-precision representations to reduce memory footprint and accelerate inference. However, the presence of outliers in weights and activations often leads to large quantization errors and severe accuracy degradation, especially in recent reasoning LLMs where errors accumulate across long chains of thought. Existing PTQ methods either fail to sufficiently suppress outliers or introduce significant overhead during inference. In this paper, we propose Pairwise Rotation Quantization (ParoQuant), a weight-only PTQ method that combines hardware-efficient and optimizable independent Givens rotations with channel-wise scaling to even out the magnitude across channels and narrow the dynamic range within each quantization group. We further co-design the inference kernel to fully exploit GPU parallelism and keep the rotations and scaling lightweight at runtime. ParoQuant achieves an average 2.4% accuracy improvement over AWQ on reasoning tasks with less than 10% overhead. This paves the way for more efficient and accurate deployment of reasoning LLMs.

</details>

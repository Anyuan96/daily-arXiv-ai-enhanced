<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 100]
- [cs.CL](#cs.CL) [Total: 124]
- [cs.SD](#cs.SD) [Total: 6]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [MultiFoodhat: A potential new paradigm for intelligent food quality inspection](https://arxiv.org/abs/2510.13889)
*Yue Hu,Guohang Zhuang*

Main category: cs.CV

TL;DR: 提出MultiFoodChat，一种基于对话驱动的多智能体推理框架，用于零样本食品识别，无需额外训练或标注，实现高精度和可解释的食品图像分类。


<details>
  <summary>Details</summary>
Motivation: 现有监督模型依赖大量标注数据，难以泛化到未见食品类别，且标注成本高，限制了在食品质量检测和饮食评估中的应用。

Method: 结合视觉-语言模型（VLM）和大语言模型（LLM），通过多轮视觉-文本对话实现多智能体协同推理；引入对象感知令牌（OPT）提取细粒度视觉特征，交互式推理代理（IRA）动态解读上下文以优化预测。

Result: 在多个公开食品数据集上实验表明，MultiFoodChat在零样本和少样本设置下均优于现有无监督和少样本方法，具有更高的识别精度和可解释性。

Conclusion: MultiFoodChat为食品图像识别提供了一种无需训练、灵活且类人的新范式，有望推动智能食品质量检测与分析的发展。

Abstract: Food image classification plays a vital role in intelligent food quality
inspection, dietary assessment, and automated monitoring. However, most
existing supervised models rely heavily on large labeled datasets and exhibit
limited generalization to unseen food categories. To overcome these challenges,
this study introduces MultiFoodChat, a dialogue-driven multi-agent reasoning
framework for zero-shot food recognition. The framework integrates
vision-language models (VLMs) and large language models (LLMs) to enable
collaborative reasoning through multi-round visual-textual dialogues. An Object
Perception Token (OPT) captures fine-grained visual attributes, while an
Interactive Reasoning Agent (IRA) dynamically interprets contextual cues to
refine predictions. This multi-agent design allows flexible and human-like
understanding of complex food scenes without additional training or manual
annotations. Experiments on multiple public food datasets demonstrate that
MultiFoodChat achieves superior recognition accuracy and interpretability
compared with existing unsupervised and few-shot methods, highlighting its
potential as a new paradigm for intelligent food quality inspection and
analysis.

</details>


### [2] [Post-surgical Endometriosis Segmentation in Laparoscopic Videos](https://arxiv.org/abs/2510.13899)
*Andreas Leibetseder,Klaus Schoeffmann,Jörg Keckstein,Simon Keckstein*

Main category: cs.CV

TL;DR: 该系统旨在通过训练模型分割内膜异位症的一种常见视觉表现——深色内膜植入物，辅助妇科医生识别和分析腹腔镜手术视频中的病灶区域。


<details>
  <summary>Details</summary>
Motivation: 由于内膜异位症在体内不同位置呈现多种视觉形态，导致其识别困难且易出错，尤其是在非专科医生中。因此需要一种辅助工具来提高诊断准确性。

Method: 开发了一个基于训练模型的系统，用于分析腹腔镜手术视频，对检测到的深色内膜植入区域进行多色覆盖标注，并生成检测摘要以改善视频浏览体验。

Result: 系统能够有效分割深色内膜植入物，在手术视频中进行可视化标注，并提供检测摘要以支持医生快速浏览和判断。

Conclusion: 该系统为妇科医生提供了实用的辅助工具，有助于提高内膜异位症的识别效率和准确性，特别是针对特定类型的病变。

Abstract: Endometriosis is a common women's condition exhibiting a manifold visual
appearance in various body-internal locations. Having such properties makes its
identification very difficult and error-prone, at least for laymen and
non-specialized medical practitioners. In an attempt to provide assistance to
gynecologic physicians treating endometriosis, this demo paper describes a
system that is trained to segment one frequently occurring visual appearance of
endometriosis, namely dark endometrial implants. The system is capable of
analyzing laparoscopic surgery videos, annotating identified implant regions
with multi-colored overlays and displaying a detection summary for improved
video browsing.

</details>


### [3] [Efficient Few-Shot Learning in Remote Sensing: Fusing Vision and Vision-Language Models](https://arxiv.org/abs/2510.13993)
*Jia Yun Chua,Argyrios Zolotas,Miguel Arana-Catania*

Main category: cs.CV

TL;DR: 本文提出将YOLO等传统视觉模型与LLaVA、ChatGPT、Gemini等视觉语言模型（VLM）结合，提升遥感图像中飞机检测与场景理解的准确性与上下文感知能力，尤其在标注数据少和图像质量差的情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 遥感数据量大增，但传统视觉模型依赖大量标注数据且上下文理解能力有限；视觉语言模型（VLM）在遥感中的应用尚不充分，亟需探索其潜力以提升分析效果。

Method: 将YOLO目标检测模型与LLaVA、ChatGPT、Gemini等VLM结合，利用VLM的语义理解能力增强视觉输出的上下文解释，在标注和未标注数据以及降质图像上进行评估。

Result: 在飞机检测与计数任务中，各模型平均MAE降低48.46%，CLIPScore提升6.17%，在挑战性条件下仍保持良好性能。

Conclusion: 结合传统视觉模型与VLM的方法显著提升了遥感图像分析的精度与理解能力，尤其适用于少样本和图像质量不佳的场景，为遥感智能解译提供了新路径。

Abstract: Remote sensing has become a vital tool across sectors such as urban planning,
environmental monitoring, and disaster response. While the volume of data
generated has increased significantly, traditional vision models are often
constrained by the requirement for extensive domain-specific labelled data and
their limited ability to understand the context within complex environments.
Vision Language Models offer a complementary approach by integrating visual and
textual data; however, their application to remote sensing remains
underexplored, particularly given their generalist nature. This work
investigates the combination of vision models and VLMs to enhance image
analysis in remote sensing, with a focus on aircraft detection and scene
understanding. The integration of YOLO with VLMs such as LLaVA, ChatGPT, and
Gemini aims to achieve more accurate and contextually aware image
interpretation. Performance is evaluated on both labelled and unlabelled remote
sensing data, as well as degraded image scenarios which are crucial for remote
sensing. The findings show an average MAE improvement of 48.46% across models
in the accuracy of aircraft detection and counting, especially in challenging
conditions, in both raw and degraded scenarios. A 6.17% improvement in
CLIPScore for comprehensive understanding of remote sensing images is obtained.
The proposed approach combining traditional vision models and VLMs paves the
way for more advanced and efficient remote sensing image analysis, especially
in few-shot learning scenarios.

</details>


### [4] [Finding Holes: Pathologist Level Performance Using AI for Cribriform Morphology Detection in Prostate Cancer](https://arxiv.org/abs/2510.13995)
*Kelvin Szolnoky,Anders Blilie,Nita Mulliqi,Toyonori Tsuzuki,Hemamali Samaratunga,Matteo Titus,Xiaoyi Ji,Sol Erika Boman,Einar Gudlaugsson,Svein Reidar Kjosavik,José Asenjo,Marcello Gambacorta,Paolo Libretti,Marcin Braun,Radisław Kordek,Roman Łowicki,Brett Delahunt,Kenneth A. Iczkowski,Theo van der Kwast,Geert J. L. H. van Leenders,Katia R. M. Leite,Chin-Chen Pan,Emiel Adrianus Maria Janssen,Martin Eklund,Lars Egevad,Kimmo Kartasalo*

Main category: cs.CV

TL;DR: 该研究开发并验证了一种基于AI的深度学习模型，用于准确检测前列腺癌中的筛状结构，表现出与病理学家相当甚至更优的性能，有助于提高诊断一致性和临床决策。


<details>
  <summary>Details</summary>
Motivation: 筛状结构是前列腺癌中预后不良的重要组织学特征，但目前报告率低且病理学家间一致性差，亟需提高检测的准确性和标准化。

Method: 采用EfficientNetV2-S编码器结合多实例学习，基于三个队列的640例前列腺穿刺活检全切片图像进行端到端训练，并在内部和外部独立队列中验证；同时与九位专家病理学家进行对比评估。

Result: 模型在内部验证中表现优异（AUC: 0.97，kappa: 0.81），外部验证中仍保持稳健（AUC: 0.90，kappa: 0.55）；在88例切片的对比中，模型平均一致性（kappa: 0.66）高于所有九位病理学家（kappa: 0.35–0.62）。

Conclusion: 该AI模型在检测前列腺癌筛状结构方面达到或超过病理学家水平，有望提升诊断可靠性、标准化报告流程，并优化患者治疗决策。

Abstract: Background: Cribriform morphology in prostate cancer is a histological
feature that indicates poor prognosis and contraindicates active surveillance.
However, it remains underreported and subject to significant interobserver
variability amongst pathologists. We aimed to develop and validate an AI-based
system to improve cribriform pattern detection.
  Methods: We created a deep learning model using an EfficientNetV2-S encoder
with multiple instance learning for end-to-end whole-slide classification. The
model was trained on 640 digitised prostate core needle biopsies from 430
patients, collected across three cohorts. It was validated internally (261
slides from 171 patients) and externally (266 slides, 104 patients from three
independent cohorts). Internal validation cohorts included laboratories or
scanners from the development set, while external cohorts used completely
independent instruments and laboratories. Annotations were provided by three
expert uropathologists with known high concordance. Additionally, we conducted
an inter-rater analysis and compared the model's performance against nine
expert uropathologists on 88 slides from the internal validation cohort.
  Results: The model showed strong internal validation performance (AUC: 0.97,
95% CI: 0.95-0.99; Cohen's kappa: 0.81, 95% CI: 0.72-0.89) and robust external
validation (AUC: 0.90, 95% CI: 0.86-0.93; Cohen's kappa: 0.55, 95% CI:
0.45-0.64). In our inter-rater analysis, the model achieved the highest average
agreement (Cohen's kappa: 0.66, 95% CI: 0.57-0.74), outperforming all nine
pathologists whose Cohen's kappas ranged from 0.35 to 0.62.
  Conclusion: Our AI model demonstrates pathologist-level performance for
cribriform morphology detection in prostate cancer. This approach could enhance
diagnostic reliability, standardise reporting, and improve treatment decisions
for prostate cancer patients.

</details>


### [5] [NAPPure: Adversarial Purification for Robust Image Classification under Non-Additive Perturbations](https://arxiv.org/abs/2510.14025)
*Junjie Nan,Jianing Li,Wei Chen,Mingkun Zhang,Xueqi Cheng*

Main category: cs.CV

TL;DR: 本文提出了一种名为NAPPure的扩展对抗净化框架，能够有效应对非加性对抗扰动（如模糊、遮挡和失真），通过解耦干净图像和扰动参数来提升图像分类模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗净化方法主要针对加性扰动设计，对现实中常见的非加性扰动（如模糊、遮挡、失真）效果有限，因此需要更通用的净化框架。

Method: 建立对抗图像的生成过程，并通过最大似然估计解耦出潜在的干净图像和扰动参数，从而实现对非加性扰动的处理。

Result: 在GTSRB和CIFAR-10数据集上的实验表明，NAPPure显著提升了图像分类模型在非加性扰动下的鲁棒性。

Conclusion: NAPPure是一种有效的扩展对抗净化方法，能够广泛应对多种非加性对抗扰动，增强了模型的实际应用安全性。

Abstract: Adversarial purification has achieved great success in combating adversarial
image perturbations, which are usually assumed to be additive. However,
non-additive adversarial perturbations such as blur, occlusion, and distortion
are also common in the real world. Under such perturbations, existing
adversarial purification methods are much less effective since they are
designed to fit the additive nature. In this paper, we propose an extended
adversarial purification framework named NAPPure, which can further handle
non-additive perturbations. Specifically, we first establish the generation
process of an adversarial image, and then disentangle the underlying clean
image and perturbation parameters through likelihood maximization. Experiments
on GTSRB and CIFAR-10 datasets show that NAPPure significantly boosts the
robustness of image classification models against non-additive perturbations.

</details>


### [6] [Vgent: Graph-based Retrieval-Reasoning-Augmented Generation For Long Video Understanding](https://arxiv.org/abs/2510.14032)
*Xiaoqian Shen,Wenxuan Zhang,Jun Chen,Mohamed Elhoseiny*

Main category: cs.CV

TL;DR: 提出Vgent框架，通过图结构和中间推理步骤提升长视频理解的准确性和上下文感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有大型视频语言模型在处理超出上下文窗口的密集视频标记和保持长期序列信息方面存在困难，而检索增强生成方法应用于长视频时存在时序依赖破坏和无关信息干扰等问题。

Method: 提出基于图的检索-推理-生成增强框架Vgent：1）将视频表示为保留语义关系的结构化图以提高检索效果；2）引入中间推理步骤，通过结构化验证减少检索噪声并促进跨片段相关信息的显式聚合。

Result: 在三个长视频理解基准上，相比基础模型在MLVU上性能提升3.0%～5.4%，优于现有最先进的视频RAG方法达8.6%。

Conclusion: Vgent框架有效提升了大型视频语言模型在长视频理解任务中的性能，具备更强的推理能力和上下文整合能力。

Abstract: Understanding and reasoning over long videos pose significant challenges for
large video language models (LVLMs) due to the difficulty in processing
intensive video tokens beyond context window and retaining long-term sequential
information. Retrieval-Augmented Generation (RAG) has demonstrated
effectiveness in processing long context for Large Language Models (LLMs);
however, applying RAG to long video faces challenges such as disrupted temporal
dependencies and inclusion of irrelevant information that can hinder accurate
reasoning. To address these limitations, we propose Vgent, a novel graph-based
retrieval-reasoning-augmented generation framework to enhance LVLMs for long
video understanding. Our approach introduces two key innovations: (i) It
represents videos by structured graphs with semantic relationships across video
clips preserved to improve retrieval effectiveness. (ii) It introduces an
intermediate reasoning step to mitigate the reasoning limitation of LVLMs,
which leverages structured verification to reduce retrieval noise and
facilitate the explicit aggregation of relevant information across clips,
resulting in more accurate and context-aware responses. We comprehensively
evaluate our framework with various open-source LVLMs on three long-video
understanding benchmarks. Our approach yielded an overall performance
improvement of $3.0\%\sim 5.4\%$ over base models on MLVU, and outperformed
state-of-the-art video RAG methods by $8.6\%$. Our code is publicly available
at https://xiaoqian-shen.github.io/Vgent.

</details>


### [7] [Synchronization of Multiple Videos](https://arxiv.org/abs/2510.14051)
*Avihai Naaman,Ron Shapira Weber,Oren Freifeld*

Main category: cs.CV

TL;DR: 提出了一种基于原型的时序对齐框架TPL，用于解决多场景或生成式AI视频间的复杂同步问题，通过构建共享的一维表示实现高效准确的视频同步。


<details>
  <summary>Details</summary>
Motivation: 传统多摄像头视频同步相对简单，但跨场景或生成式AI视频因内容和时间非线性差异难以对齐，现有方法效率低且鲁棒性差，需更通用高效的解决方案。

Method: 提出Temporal Prototype Learning（TPL），利用预训练模型提取的高维嵌入构建共享的紧凑一维原型序列，作为关键动作阶段的锚点，避免耗时的成对匹配，实现多视频的统一时间对齐。

Result: 实验表明TPL在多个数据集上提升了同步精度、效率和鲁棒性，尤其在细粒度帧检索和阶段分类任务中表现优越，并首次成功应用于多个生成式AI视频的同步问题。

Conclusion: TPL为跨场景及生成式AI视频同步提供了有效解决方案，具有良好的通用性和扩展性，推动了多视频分析与应用的发展。

Abstract: Synchronizing videos captured simultaneously from multiple cameras in the
same scene is often easy and typically requires only simple time shifts.
However, synchronizing videos from different scenes or, more recently,
generative AI videos, poses a far more complex challenge due to diverse
subjects, backgrounds, and nonlinear temporal misalignment. We propose Temporal
Prototype Learning (TPL), a prototype-based framework that constructs a shared,
compact 1D representation from high-dimensional embeddings extracted by any of
various pretrained models. TPL robustly aligns videos by learning a unified
prototype sequence that anchors key action phases, thereby avoiding exhaustive
pairwise matching. Our experiments show that TPL improves synchronization
accuracy, efficiency, and robustness across diverse datasets, including
fine-grained frame retrieval and phase classification tasks. Importantly, TPL
is the first approach to mitigate synchronization issues in multiple generative
AI videos depicting the same action. Our code and a new multiple video
synchronization dataset are available at https://bgu-cs-vil.github.io/TPL/

</details>


### [8] [Capture, Canonicalize, Splat: Zero-Shot 3D Gaussian Avatars from Unstructured Phone Images](https://arxiv.org/abs/2510.14081)
*Emanuel Garbin,Guy Adam,Oded Krams,Zohar Barzelay,Eran Guendelman,Michael Schwarz,Moran Vatelmacher,Yigal Shenkman,Eli Peker,Itai Druker,Uri Patish,Yoav Blum,Max Bluvstein,Junxuan Li,Rawal Khirodkar,Shunsuke Saito*

Main category: cs.CV

TL;DR: 提出了一种零样本生成高保真、身份保持的3D头像新方法，通过多视角非结构化手机图像实现逼真重建。


<details>
  <summary>Details</summary>
Motivation: 现有单视角方法存在几何不一致和身份失真问题，合成数据训练的模型缺乏高频细节，难以实现真实感和身份保持。

Method: 提出“Capture, Canonicalize, Splat”流程：首先用生成式规范化模块将多视角非结构图像转换为标准一致表示，再使用基于Transformer的模型，在基于真实人物穹顶采集构建的大规模高保真高斯溅射头像数据集上训练。

Result: 能够从非结构化手机照片生成静态四分之三身3D头像，具有高度真实感和强身份保持能力。

Conclusion: 该方法在零样本设定下有效克服了现有技术的局限，显著提升了3D头像生成的细节表现和身份一致性。

Abstract: We present a novel, zero-shot pipeline for creating hyperrealistic,
identity-preserving 3D avatars from a few unstructured phone images. Existing
methods face several challenges: single-view approaches suffer from geometric
inconsistencies and hallucinations, degrading identity preservation, while
models trained on synthetic data fail to capture high-frequency details like
skin wrinkles and fine hair, limiting realism. Our method introduces two key
contributions: (1) a generative canonicalization module that processes multiple
unstructured views into a standardized, consistent representation, and (2) a
transformer-based model trained on a new, large-scale dataset of high-fidelity
Gaussian splatting avatars derived from dome captures of real people. This
"Capture, Canonicalize, Splat" pipeline produces static quarter-body avatars
with compelling realism and robust identity preservation from unstructured
photos.

</details>


### [9] [cubic: CUDA-accelerated 3D Bioimage Computing](https://arxiv.org/abs/2510.14143)
*Alexandr A. Kalinin,Anne E. Carpenter,Shantanu Singh,Matthew J. O'Meara*

Main category: cs.CV

TL;DR: 本文介绍了一个名为cubic的开源Python库，通过集成CuPy和RAPIDS cuCIM，为生物图像分析提供GPU加速，提升2D/3D图像处理的效率与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有生物图像分析工具在可扩展性、GPU支持、3D处理能力和与其他科学计算工作流的互操作性方面存在局限，难以应对现代显微镜产生的大规模数据。

Method: cubic扩展了SciPy和scikit-image的API，使其兼容GPU加速；其设备无关的API能根据数据位置自动调度CPU或GPU执行运算。

Result: 在基准测试和实际去卷积与分割流程复现中，cubic实现了显著的速度提升，同时保持算法准确性。

Conclusion: cubic为可扩展、可重现的生物图像分析提供了坚实基础，良好集成于Python科学计算生态，支持交互式探索与高通量自动化分析。

Abstract: Quantitative analysis of multidimensional biological images is useful for
understanding complex cellular phenotypes and accelerating advances in
biomedical research. As modern microscopy generates ever-larger 2D and 3D
datasets, existing computational approaches are increasingly limited by their
scalability, efficiency, and integration with modern scientific computing
workflows. Existing bioimage analysis tools often lack application programmable
interfaces (APIs), do not support graphics processing unit (GPU) acceleration,
lack broad 3D image processing capabilities, and/or have poor interoperability
for compute-heavy workflows. Here, we introduce cubic, an open-source Python
library that addresses these challenges by augmenting widely used SciPy and
scikit-image APIs with GPU-accelerated alternatives from CuPy and RAPIDS cuCIM.
cubic's API is device-agnostic and dispatches operations to GPU when data
reside on the device and otherwise executes on CPU, seamlessly accelerating a
broad range of image processing routines. This approach enables GPU
acceleration of existing bioimage analysis workflows, from preprocessing to
segmentation and feature extraction for 2D and 3D data. We evaluate cubic both
by benchmarking individual operations and by reproducing existing deconvolution
and segmentation pipelines, achieving substantial speedups while maintaining
algorithmic fidelity. These advances establish a robust foundation for
scalable, reproducible bioimage analysis that integrates with the broader
Python scientific computing ecosystem, including other GPU-accelerated methods,
enabling both interactive exploration and automated high-throughput analysis
workflows. cubic is openly available at
https://github$.$com/alxndrkalinin/cubic

</details>


### [10] [Virtually Being: Customizing Camera-Controllable Video Diffusion Models with Multi-View Performance Captures](https://arxiv.org/abs/2510.14179)
*Yuancheng Xu,Wenqi Xian,Li Ma,Julien Philip,Ahmet Levent Taşel,Yiwei Zhao,Ryan Burgert,Mingming He,Oliver Hermann,Oliver Pilarski,Rahul Garg,Paul Debevec,Ning Yu*

Main category: cs.CV

TL;DR: 提出了一种通过新定制数据管道实现多视角角色一致性与3D相机控制的视频扩散模型框架，利用4D高斯点阵重渲染和光照变化数据进行训练，支持多主体生成、场景定制及运动与空间布局控制，显著提升了虚拟制作中的视频生成质量与可控性。


<details>
  <summary>Details</summary>
Motivation: 在虚拟制作中，实现角色在多视角下的一致性以及精确的相机与光照控制是一个关键挑战。现有视频生成模型在这些方面表现不足，因此需要一个能够集成高保真角色一致性与灵活控制能力的框架。

Method: 构建了一个新的定制数据管道，使用4D高斯点阵（4DGS）对体捕捉表演进行重渲染，结合多种相机轨迹和通过视频重光照模型生成的光照变化数据。在此基础上微调先进的开源视频扩散模型，并支持联合训练和噪声融合两种多主体生成方法。

Result: 实验表明，该方法在视频质量、个性化准确性、相机控制和光照适应性方面均优于现有方法，支持多主体生成、场景定制以及对运动和空间布局的控制。

Conclusion: 所提框架有效推动了视频生成技术在虚拟制作中的应用，实现了高一致性、高可控性和高适应性的视频合成，具备广泛的应用潜力。

Abstract: We introduce a framework that enables both multi-view character consistency
and 3D camera control in video diffusion models through a novel customization
data pipeline. We train the character consistency component with recorded
volumetric capture performances re-rendered with diverse camera trajectories
via 4D Gaussian Splatting (4DGS), lighting variability obtained with a video
relighting model. We fine-tune state-of-the-art open-source video diffusion
models on this data to provide strong multi-view identity preservation, precise
camera control, and lighting adaptability. Our framework also supports core
capabilities for virtual production, including multi-subject generation using
two approaches: joint training and noise blending, the latter enabling
efficient composition of independently customized models at inference time; it
also achieves scene and real-life video customization as well as control over
motion and spatial layout during customization. Extensive experiments show
improved video quality, higher personalization accuracy, and enhanced camera
control and lighting adaptability, advancing the integration of video
generation into virtual production. Our project page is available at:
https://eyeline-labs.github.io/Virtually-Being.

</details>


### [11] [Joint Modeling of Big Five and HEXACO for Multimodal Apparent Personality-trait Recognition](https://arxiv.org/abs/2510.14203)
*Ryo Masumura,Shota Orihashi,Mana Ihori,Tomohiro Tanaka,Naoki Makishima,Taiga Yamane,Naotaka Kawata,Satoshi Suzuki,Taichi Katayama*

Main category: cs.CV

TL;DR: 提出一种联合建模Big Five和HEXACO的方法，用于从多模态人类行为中自动识别表观人格特质，实验表明该方法能有效识别两种人格模型。


<details>
  <summary>Details</summary>
Motivation: 以往研究多关注Big Five模型进行多模态人格识别，但缺乏对HEXACO模型（特别是其Honesty-Humility维度）的关注，且两者在机器学习建模下的关系尚不清楚。本文旨在通过联合建模提升对多模态行为的理解。

Method: 提出一种联合优化方法，同时识别Big Five和HEXACO人格特质，利用自我介绍视频数据集进行多模态行为分析。

Result: 在自我介绍视频数据集上的实验表明，该方法能有效识别Big Five和HEXACO人格特质，且联合建模优于单一模型。

Conclusion: 联合建模Big Five与HEXACO有助于提升多模态人格识别效果，并揭示两种人格模型间的潜在关系。

Abstract: This paper proposes a joint modeling method of the Big Five, which has long
been studied, and HEXACO, which has recently attracted attention in psychology,
for automatically recognizing apparent personality traits from multimodal human
behavior. Most previous studies have used the Big Five for multimodal apparent
personality-trait recognition. However, no study has focused on apparent HEXACO
which can evaluate an Honesty-Humility trait related to displaced aggression
and vengefulness, social-dominance orientation, etc. In addition, the
relationships between the Big Five and HEXACO when modeled by machine learning
have not been clarified. We expect awareness of multimodal human behavior to
improve by considering these relationships. The key advance of our proposed
method is to optimize jointly recognizing the Big Five and HEXACO. Experiments
using a self-introduction video dataset demonstrate that the proposed method
can effectively recognize the Big Five and HEXACO.

</details>


### [12] [LOTA: Bit-Planes Guided AI-Generated Image Detection](https://arxiv.org/abs/2510.14230)
*Hongsong Wang,Renxi Cheng,Yang Zhang,Chaolei Han,Jie Gui*

Main category: cs.CV

TL;DR: 提出一种基于比特平面的噪声提取方法，用于高效检测AI生成图像，速度快且准确率高。


<details>
  <summary>Details</summary>
Motivation: 现有基于重建误差的AI生成图像检测方法计算成本高，且难以捕捉图像中的内在噪声特征。

Method: 利用比特平面图像处理技术提取噪声特征，结合多种归一化策略；设计最大梯度块选择机制增强噪声信号，并提出轻量级分类头（噪声分类器与噪声引导分类器）。

Result: 在GenImage基准上平均准确率达98.9%，跨生成器泛化性能优异：GAN到Diffusion超98.2%，Diffusion到GAN超99.2%；提取误差仅需毫秒级，比现有方法快近百倍。

Conclusion: 该方法在检测AI生成图像方面高效、准确，具有良好的实用性和推广价值。

Abstract: The rapid advancement of GAN and Diffusion models makes it more difficult to
distinguish AI-generated images from real ones. Recent studies often use
image-based reconstruction errors as an important feature for determining
whether an image is AI-generated. However, these approaches typically incur
high computational costs and also fail to capture intrinsic noisy features
present in the raw images. To solve these problems, we innovatively refine
error extraction by using bit-plane-based image processing, as lower bit planes
indeed represent noise patterns in images. We introduce an effective bit-planes
guided noisy image generation and exploit various image normalization
strategies, including scaling and thresholding. Then, to amplify the noise
signal for easier AI-generated image detection, we design a maximum gradient
patch selection that applies multi-directional gradients to compute the noise
score and selects the region with the highest score. Finally, we propose a
lightweight and effective classification head and explore two different
structures: noise-based classifier and noise-guided classifier. Extensive
experiments on the GenImage benchmark demonstrate the outstanding performance
of our method, which achieves an average accuracy of \textbf{98.9\%}
(\textbf{11.9}\%~$\uparrow$) and shows excellent cross-generator generalization
capability. Particularly, our method achieves an accuracy of over 98.2\% from
GAN to Diffusion and over 99.2\% from Diffusion to GAN. Moreover, it performs
error extraction at the millisecond level, nearly a hundred times faster than
existing methods. The code is at https://github.com/hongsong-wang/LOTA.

</details>


### [13] [PIA: Deepfake Detection Using Phoneme-Temporal and Identity-Dynamic Analysis](https://arxiv.org/abs/2510.14241)
*Soumyya Kanti Datta,Tanvi Ranga,Chengzhe Sun,Siwei Lyu*

Main category: cs.CV

TL;DR: 提出一种新的多模态音视频框架PIA，通过结合语音、面部动态和身份特征来检测由先进生成模型产生的深伪视频中的细微时间不一致。


<details>
  <summary>Details</summary>
Motivation: 传统检测方法难以应对由GAN、扩散模型等先进生成模型制造的高质量深伪视频，因其主要依赖手工设计的对齐阈值或单模态策略，无法有效捕捉时间上的细微异常。

Method: 提出Phoneme-Temporal and Identity-Dynamic Analysis (PIA)框架，融合音素序列、唇部几何数据和高级面部身份嵌入，进行多模态分析以捕捉跨模态的不一致性。

Result: 该方法在检测现代深伪视频方面表现优越，能有效识别传统方法忽略的细微时间差异，显著提升检测性能。

Conclusion: PIA框架通过整合语言、动态面部运动和身份线索，为应对复杂深伪视频提供了更鲁棒和有效的解决方案。

Abstract: The rise of manipulated media has made deepfakes a particularly insidious
threat, involving various generative manipulations such as lip-sync
modifications, face-swaps, and avatar-driven facial synthesis. Conventional
detection methods, which predominantly depend on manually designed
phoneme-viseme alignment thresholds, fundamental frame-level consistency
checks, or a unimodal detection strategy, inadequately identify modern-day
deepfakes generated by advanced generative models such as GANs, diffusion
models, and neural rendering techniques. These advanced techniques generate
nearly perfect individual frames yet inadvertently create minor temporal
discrepancies frequently overlooked by traditional detectors. We present a
novel multimodal audio-visual framework, Phoneme-Temporal and Identity-Dynamic
Analysis(PIA), incorporating language, dynamic face motion, and facial
identification cues to address these limitations. We utilize phoneme sequences,
lip geometry data, and advanced facial identity embeddings. This integrated
method significantly improves the detection of subtle deepfake alterations by
identifying inconsistencies across multiple complementary modalities. Code is
available at https://github.com/skrantidatta/PIA

</details>


### [14] [Event Interval Modulation: A Novel Scheme for Event-based Optical Camera Communication](https://arxiv.org/abs/2510.14245)
*Miu Sumino,Mayu Ishii,Shun Kaizu,Daisuke Hisano,Yu Nakayama*

Main category: cs.CV

TL;DR: 提出了一种针对基于事件的光学相机通信（OCC）系统的新型调制方案——事件间隔调制（EIM），实现了在10米距离28 kbps和50米距离8.4 kbps的数据传输速率，创下了事件型OCC系统的新纪录。


<details>
  <summary>Details</summary>
Motivation: 传统基于帧的OCC系统存在低比特率和高处理负载的问题，现有基于事件传感器（EVS）的OCC系统尚未充分利用EVS的异步、高速、高动态范围特性，缺乏专门设计的调制方案。

Method: 提出事件间隔调制（EIM）方案，利用事件之间的时间间隔携带信息，以提升传输速率；建立EIM的理论模型，并对EVS参数进行调优以适应EIM；实验确定最大可用调制阶数，并开展室内传输验证。

Result: 在10米距离实现28 kbps、50米距离实现8.4 kbps的成功传输，显著优于现有事件型OCC系统，创下新纪录。

Conclusion: EIM方案有效利用了事件传感器的特性，显著提升了事件型OCC系统的传输速率，为未来高速低延迟可见光通信提供了可行的技术路径。

Abstract: Optical camera communication (OCC) represents a promising visible light
communication technology. Nonetheless, typical OCC systems utilizing
frame-based cameras are encumbered by limitations, including low bit rate and
high processing load. To address these issues, OCC system utilizing an
event-based vision sensor (EVS) as receivers have been proposed. The EVS
enables high-speed, low-latency, and robust communication due to its
asynchronous operation and high dynamic range. In existing event-based OCC
systems, conventional modulation schemes such as on-off keying (OOK) and pulse
position modulation have been applied, however, to the best of our knowledge,
no modulation method has been proposed that fully exploits the unique
characteristics of the EVS. This paper proposes a novel modulation scheme,
called the event interval modulation (EIM) scheme, specifically designed for
event-based OCC. EIM enables improvement in transmission speed by modulating
information using the intervals between events. This paper proposes a
theoretical model of EIM and conducts a proof-of-concept experiment. First, the
parameters of the EVS are tuned and customized to optimize the frequency
response specifically for EIM. Then, the maximum modulation order usable in EIM
is determined experimentally. We conduct transmission experiments based on the
obtained parameters. Finally, we report successful transmission at 28 kbps over
10 meters and 8.4 kbps over 50 meters in an indoor environment. This sets a new
benchmark for bit rate in event-based OCC systems.

</details>


### [15] [MACE: Mixture-of-Experts Accelerated Coordinate Encoding for Large-Scale Scene Localization and Rendering](https://arxiv.org/abs/2510.14251)
*Mingkai Liu,Dikai Fan,Haohua Que,Haojia Gao,Xiao Liu,Shuxue Peng,Meixia Lin,Shengyu Gu,Ruicong Ye,Wanli Qiu,Handong Yao,Ruopeng Zhang,Xianliang Huang*

Main category: cs.CV

TL;DR: 提出了一种基于混合专家的加速坐标编码方法MACE，用于大规模场景中的高效定位与高质量渲染，显著降低成本并保持高精度。


<details>
  <summary>Details</summary>
Motivation: 现有场景坐标回归方法在扩展到大规模场景时受限于单个网络的容量，且计算成本高，难以实现高效定位与渲染。

Method: 受MOE在大模型中表现的启发，引入门控网络隐式分类并选择子网络，每次推理仅激活一个子网络，并提出无需辅助损失的负载均衡策略（ALF-LB）以提升定位精度。

Result: 在Cambridge测试集上的实验表明，该方法仅需10分钟训练即可实现高质量渲染，且定位精度更高、计算成本显著降低。

Conclusion: MACE为大规模场景的定位与渲染提供了一个高效、精确且低成本的解决方案。

Abstract: Efficient localization and high-quality rendering in large-scale scenes
remain a significant challenge due to the computational cost involved. While
Scene Coordinate Regression (SCR) methods perform well in small-scale
localization, they are limited by the capacity of a single network when
extended to large-scale scenes. To address these challenges, we propose the
Mixed Expert-based Accelerated Coordinate Encoding method (MACE), which enables
efficient localization and high-quality rendering in large-scale scenes.
Inspired by the remarkable capabilities of MOE in large model domains, we
introduce a gating network to implicitly classify and select sub-networks,
ensuring that only a single sub-network is activated during each inference.
Furtheremore, we present Auxiliary-Loss-Free Load Balancing(ALF-LB) strategy to
enhance the localization accuracy on large-scale scene. Our framework provides
a significant reduction in costs while maintaining higher precision, offering
an efficient solution for large-scale scene applications. Additional
experiments on the Cambridge test set demonstrate that our method achieves
high-quality rendering results with merely 10 minutes of training.

</details>


### [16] [Identity-Preserving Image-to-Video Generation via Reward-Guided Optimization](https://arxiv.org/abs/2510.14255)
*Liao Shen,Wentao Jiang,Yiran Zhu,Tiezheng Ge,Zhiguo Cao,Bo Zheng*

Main category: cs.CV

TL;DR: 提出了一种基于强化学习的身份保持奖励引导优化（IPRO）框架，通过面部身份评分器直接优化扩散模型，有效提升图像到视频生成中的人脸身份一致性，尤其在人脸占比小、表情动作变化大的情况下表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有图像到视频生成模型在生成过程中难以保持输入人脸与生成视频之间的身份一致性，尤其在面部区域较小或动作表情剧烈变化时问题突出，而人对身份变化敏感，因此亟需解决该问题。

Method: 提出IPRO框架，采用强化学习方法，引入面部身份评分子作为奖励信号，通过反向传播最后几步采样链的奖励信号提供更丰富的梯度反馈；设计新型面部评分机制，利用真实视频中的多角度人脸特征增强泛化能力，并加入KL散度正则化稳定训练过程。

Result: 在Wan 2.2 I2V模型和自研I2V模型上进行广泛实验，结果表明IPRO显著提升了生成视频的身份一致性，同时保持视频质量与时序连贯性，尤其在小人脸和大动作场景下优势明显。

Conclusion: IPRO提供了一种无需修改模型结构的高效微调方法，通过奖励引导优化显著增强了图像到视频生成中的人脸身份保持能力，为人类中心视频生成提供了有效解决方案。

Abstract: Recent advances in image-to-video (I2V) generation have achieved remarkable
progress in synthesizing high-quality, temporally coherent videos from static
images. Among all the applications of I2V, human-centric video generation
includes a large portion. However, existing I2V models encounter difficulties
in maintaining identity consistency between the input human image and the
generated video, especially when the person in the video exhibits significant
expression changes and movements. This issue becomes critical when the human
face occupies merely a small fraction of the image. Since humans are highly
sensitive to identity variations, this poses a critical yet under-explored
challenge in I2V generation. In this paper, we propose Identity-Preserving
Reward-guided Optimization (IPRO), a novel video diffusion framework based on
reinforcement learning to enhance identity preservation. Instead of introducing
auxiliary modules or altering model architectures, our approach introduces a
direct and effective tuning algorithm that optimizes diffusion models using a
face identity scorer. To improve performance and accelerate convergence, our
method backpropagates the reward signal through the last steps of the sampling
chain, enabling richer gradient feedback. We also propose a novel facial
scoring mechanism that treats faces in ground-truth videos as facial feature
pools, providing multi-angle facial information to enhance generalization. A
KL-divergence regularization is further incorporated to stabilize training and
prevent overfitting to the reward signal. Extensive experiments on Wan 2.2 I2V
model and our in-house I2V model demonstrate the effectiveness of our method.
Our project and code are available at
\href{https://ipro-alimama.github.io/}{https://ipro-alimama.github.io/}.

</details>


### [17] [Identity-GRPO: Optimizing Multi-Human Identity-preserving Video Generation via Reinforcement Learning](https://arxiv.org/abs/2510.14256)
*Xiangyu Meng,Zixian Zhang,Zhenghao Zhang,Junchao Liao,Long Qin,Weizhi Wang*

Main category: cs.CV

TL;DR: 提出了Identity-GRPO，一种基于人类反馈的优化方法，显著提升了多人体视频生成中的身份一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多人体动态交互场景中难以保持一致的身份特征，限制了个性化视频生成的质量。

Method: 构建了一个大规模偏好数据集训练视频奖励模型，并设计了一种适用于多人体一致性的GRPO变体，用于优化VACE和Phantom等生成模型。

Result: 实验表明，Identity-GRPO在人类一致性指标上比基线方法最高提升18.9%，且通过消融研究验证了标注质量和设计选择的影响。

Conclusion: Identity-GRPO有效提升了多人体身份保持的视频生成质量，为强化学习与个性化视频生成的结合提供了可行路径。

Abstract: While advanced methods like VACE and Phantom have advanced video generation
for specific subjects in diverse scenarios, they struggle with multi-human
identity preservation in dynamic interactions, where consistent identities
across multiple characters are critical. To address this, we propose
Identity-GRPO, a human feedback-driven optimization pipeline for refining
multi-human identity-preserving video generation. First, we construct a video
reward model trained on a large-scale preference dataset containing
human-annotated and synthetic distortion data, with pairwise annotations
focused on maintaining human consistency throughout the video. We then employ a
GRPO variant tailored for multi-human consistency, which greatly enhances both
VACE and Phantom. Through extensive ablation studies, we evaluate the impact of
annotation quality and design choices on policy optimization. Experiments show
that Identity-GRPO achieves up to 18.9% improvement in human consistency
metrics over baseline methods, offering actionable insights for aligning
reinforcement learning with personalized video generation.

</details>


### [18] [MatchAttention: Matching the Relative Positions for High-Resolution Cross-View Matching](https://arxiv.org/abs/2510.14260)
*Tingman Yan,Tao Liu,Xilian Yang,Qunfei Zhao,Zeyang Xia*

Main category: cs.CV

TL;DR: 本文提出了一种名为MatchAttention的新型注意力机制，通过动态匹配相对位置实现高效高分辨率跨视图匹配，并结合MatchDecoder和抗遮挡设计，在多个基准上实现了最先进的性能，同时具备实时性和低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的跨视图匹配方法受限于交叉注意力的二次复杂度和缺乏显式的匹配约束，难以高效处理高分辨率图像，尤其在存在遮挡时性能下降明显，因此需要一种更高效且鲁棒的机制。

Method: 提出MatchAttention机制，利用BilinearSoftmax实现连续可导的滑窗注意力采样，并通过残差连接在层间迭代更新相对位置；设计基于此的MatchDecoder，并引入门控交叉MatchAttention和一致性约束损失以应对遮挡问题。

Result: 在Middlebury基准上平均误差排名第一，KITTI分辨率推理仅需29ms；MatchStereo-T可在0.1秒内处理4K图像并仅使用3GB GPU内存，同时在KITTI、ETH3D和Spring等数据集上达到SOTA性能。

Conclusion: MatchAttention通过显式建模相对位置显著提升了跨视图匹配的效率与精度，结合轻量化解码器和遮挡处理机制，实现了高分辨率下的实时、高精度匹配，具有广泛应用前景。

Abstract: Cross-view matching is fundamentally achieved through cross-attention
mechanisms. However, matching of high-resolution images remains challenging due
to the quadratic complexity and lack of explicit matching constraints in the
existing cross-attention. This paper proposes an attention mechanism,
MatchAttention, that dynamically matches relative positions. The relative
position determines the attention sampling center of the key-value pairs given
a query. Continuous and differentiable sliding-window attention sampling is
achieved by the proposed BilinearSoftmax. The relative positions are
iteratively updated through residual connections across layers by embedding
them into the feature channels. Since the relative position is exactly the
learning target for cross-view matching, an efficient hierarchical cross-view
decoder, MatchDecoder, is designed with MatchAttention as its core component.
To handle cross-view occlusions, gated cross-MatchAttention and a
consistency-constrained loss are proposed. These two components collectively
mitigate the impact of occlusions in both forward and backward passes, allowing
the model to focus more on learning matching relationships. When applied to
stereo matching, MatchStereo-B ranked 1st in average error on the public
Middlebury benchmark and requires only 29ms for KITTI-resolution inference.
MatchStereo-T can process 4K UHD images in 0.1 seconds using only 3GB of GPU
memory. The proposed models also achieve state-of-the-art performance on KITTI
2012, KITTI 2015, ETH3D, and Spring flow datasets. The combination of high
accuracy and low computational complexity makes real-time, high-resolution, and
high-accuracy cross-view matching possible. Code is available at
https://github.com/TingmanYan/MatchAttention.

</details>


### [19] [Experimental Demonstration of Event-based Optical Camera Communication in Long-Range Outdoor Environment](https://arxiv.org/abs/2510.14266)
*Miu Sumino,Mayu Ishii,Shun Kaizu,Daisuke Hisano,Yu Nakayama*

Main category: cs.CV

TL;DR: 提出了一种基于事件的视觉传感器的光学相机通信系统鲁棒解调方案，结合OOK与切换解调及数字锁相环，在户外实验中实现了在200米-60kbps和400米-30kbps条件下误码率低于10^-3的性能突破。


<details>
  <summary>Details</summary>
Motivation: 提高光学相机通信系统在复杂户外环境下的解调可靠性与通信距离，克服传统方法在低信噪比和动态光照条件下的性能瓶颈。

Method: 采用事件型视觉传感器，结合开关键控（OOK）与切换解调技术，并引入数字相位锁定环（DPLL）实现时钟同步与信号稳定恢复。

Result: 在200米距离下实现60kbps、400米下30kbps的传输速率，并在户外实验中首次实现误码率低于10^-3的稳定通信。

Conclusion: 所提方案显著提升了光学相机通信系统的可靠性与传输距离，适用于复杂动态环境下的高速稳健通信。

Abstract: We propose a robust demodulation scheme for optical camera communication
systems using an event-based vision sensor, combining OOK with toggle
demodulation and a digital phase-locked loop. This is the first report to
achieve a $\mathrm{BER} < 10^{-3}$ at 200m-60kbps and 400m-30kbps in outdoor
experiments.

</details>


### [20] [GauSSmart: Enhanced 3D Reconstruction through 2D Foundation Models and Geometric Filtering](https://arxiv.org/abs/2510.14270)
*Alexander Valverde,Brian Xu,Yuyin Zhou,Meng Xu,Hongyun Wang*

Main category: cs.CV

TL;DR: 提出GauSSmart，一种结合2D基础模型与3D高斯点阵重构的混合方法，通过引入2D语义特征监督和滤波技术，提升稀疏区域的重建质量与细节保持。


<details>
  <summary>Details</summary>
Motivation: 高斯点阵在大规模场景重建中表现良好，但在稀疏视角下难以捕捉细节和保持真实感，主要受限于稀疏的3D训练数据；因此需引入更强的2D先验来增强重建效果。

Method: 提出GauSSmart，融合2D基础模型（如DINO）的语义特征监督和凸滤波技术，利用2D分割先验和高维特征嵌入引导高斯点的致密化与优化，从而提升3D重建质量。

Result: 在三个数据集上验证，GauSSmart在大多数场景中优于现有的高斯点阵方法，尤其在稀疏区域覆盖和细节保留方面表现更优。

Conclusion: 2D-3D混合方法具有显著潜力，合理结合2D基础模型与3D重建流程可克服单一方法的局限性，提升场景重建的整体性能。

Abstract: Scene reconstruction has emerged as a central challenge in computer vision,
with approaches such as Neural Radiance Fields (NeRF) and Gaussian Splatting
achieving remarkable progress. While Gaussian Splatting demonstrates strong
performance on large-scale datasets, it often struggles to capture fine details
or maintain realism in regions with sparse coverage, largely due to the
inherent limitations of sparse 3D training data.
  In this work, we propose GauSSmart, a hybrid method that effectively bridges
2D foundational models and 3D Gaussian Splatting reconstruction. Our approach
integrates established 2D computer vision techniques, including convex
filtering and semantic feature supervision from foundational models such as
DINO, to enhance Gaussian-based scene reconstruction. By leveraging 2D
segmentation priors and high-dimensional feature embeddings, our method guides
the densification and refinement of Gaussian splats, improving coverage in
underrepresented areas and preserving intricate structural details.
  We validate our approach across three datasets, where GauSSmart consistently
outperforms existing Gaussian Splatting in the majority of evaluated scenes.
Our results demonstrate the significant potential of hybrid 2D-3D approaches,
highlighting how the thoughtful combination of 2D foundational models with 3D
reconstruction pipelines can overcome the limitations inherent in either
approach alone.

</details>


### [21] [CLEAR: Causal Learning Framework For Robust Histopathology Tumor Detection Under Out-Of-Distribution Shifts](https://arxiv.org/abs/2510.14273)
*Kieu-Anh Truong Thi,Huy-Hieu Pham,Duc-Trong Le*

Main category: cs.CV

TL;DR: 提出了一种基于因果推断的新框架，利用语义特征并减轻混杂因素影响，通过前门原则设计转换策略，在CAMELYON17和私有数据集上实现了最高7%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决组织病理学中由于采集过程或数据源差异导致的域移问题，现有方法多关注统计相关性而忽视因果关系。

Method: 基于因果推断设计框架，采用前门原则，显式引入中介变量和观测组织切片来建模因果路径，缓解混杂因素影响。

Result: 在CAMELYON17和一个私有组织病理学数据集上验证，跨未见域均取得一致性能提升，最高提升达7%。

Conclusion: 因果推断是应对组织病理学图像分析中域移问题的有效工具。

Abstract: Domain shift in histopathology, often caused by differences in acquisition
processes or data sources, poses a major challenge to the generalization
ability of deep learning models. Existing methods primarily rely on modeling
statistical correlations by aligning feature distributions or introducing
statistical variation, yet they often overlook causal relationships. In this
work, we propose a novel causal-inference-based framework that leverages
semantic features while mitigating the impact of confounders. Our method
implements the front-door principle by designing transformation strategies that
explicitly incorporate mediators and observed tissue slides. We validate our
method on the CAMELYON17 dataset and a private histopathology dataset,
demonstrating consistent performance gains across unseen domains. As a result,
our approach achieved up to a 7% improvement in both the CAMELYON17 dataset and
the private histopathology dataset, outperforming existing baselines. These
results highlight the potential of causal inference as a powerful tool for
addressing domain shift in histopathology image analysis.

</details>


### [22] [Watermarking for Factuality: Guiding Vision-Language Models Toward Truth via Tri-layer Contrastive Decoding](https://arxiv.org/abs/2510.14304)
*Kyungryul Back,Seongbeom Park,Milim Kim,Mincheol Kwon,SangHyeok Lee,Hyunyoung Lee,Junhee Cho,Seunghyun Park,Jinkyu Kim*

Main category: cs.CV

TL;DR: 提出一种无需训练的三层对比解码方法，通过水印问题选择关键层，有效减少大视觉语言模型的幻觉并提升视觉 grounded 的响应能力。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型（LVLMs）在多模态任务中表现优异，但易产生幻觉，依赖单一模态或记忆训练数据，缺乏真实视觉 grounding。

Method: 提出训练免费的三层对比解码结合水印机制：选择成熟层、业余层和通过水印问题评估的 pivot 层，利用三层对比生成更 grounded 的输出。

Result: 在 POPE、MME 和 AMBER 等基准上达到减少幻觉的最先进水平，生成更具视觉依据的响应。

Conclusion: 该方法无需训练即可有效缓解 LVLMs 的幻觉问题，增强了多模态输出的可靠性与视觉对齐能力。

Abstract: Large Vision-Language Models (LVLMs) have recently shown promising results on
various multimodal tasks, even achieving human-comparable performance in
certain cases. Nevertheless, LVLMs remain prone to hallucinations -- they often
rely heavily on a single modality or memorize training data without properly
grounding their outputs. To address this, we propose a training-free, tri-layer
contrastive decoding with watermarking, which proceeds in three steps: (1)
select a mature layer and an amateur layer among the decoding layers, (2)
identify a pivot layer using a watermark-related question to assess whether the
layer is visually well-grounded, and (3) apply tri-layer contrastive decoding
to generate the final output. Experiments on public benchmarks such as POPE,
MME and AMBER demonstrate that our method achieves state-of-the-art performance
in reducing hallucinations in LVLMs and generates more visually grounded
responses.

</details>


### [23] [A Multi-domain Image Translative Diffusion StyleGAN for Iris Presentation Attack Detection](https://arxiv.org/abs/2510.14314)
*Shivangi Yadav,Arun Ross*

Main category: cs.CV

TL;DR: 提出了一种新的多域图像生成框架MID-StyleGAN，用于生成逼真的虹膜呈现攻击和真实眼睛的合成图像，有效缓解了虹膜活体检测中数据稀缺的问题，并显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 由于构建和采集虹膜呈现攻击（PA）样本困难，现有虹膜活体检测技术缺乏足够的训练和评估数据，限制了其发展。因此需要一种能生成高质量、多样化合成数据的方法来解决数据稀缺问题。

Method: 提出MID-StyleGAN，结合扩散模型与生成对抗网络（GAN）的优势，采用多域架构实现真实眼、打印眼和 Cosmetic contact lens 等不同域之间的图像转换，并设计自适应损失函数以保持眼部数据的域一致性。

Result: 实验证明MID-StyleGAN在生成高质量合成眼部图像方面优于现有方法；在LivDet2020数据集上，使用生成数据后活体检测的1%误报率下的真检率从93.41%提升至98.72%。

Conclusion: MID-StyleGAN能有效生成多样且逼真的多域眼部图像，为虹膜活体检测提供了可扩展的数据增强方案，显著提升检测系统性能。

Abstract: An iris biometric system can be compromised by presentation attacks (PAs)
where artifacts such as artificial eyes, printed eye images, or cosmetic
contact lenses are presented to the system. To counteract this, several
presentation attack detection (PAD) methods have been developed. However, there
is a scarcity of datasets for training and evaluating iris PAD techniques due
to the implicit difficulties in constructing and imaging PAs. To address this,
we introduce the Multi-domain Image Translative Diffusion StyleGAN
(MID-StyleGAN), a new framework for generating synthetic ocular images that
captures the PA and bonafide characteristics in multiple domains such as
bonafide, printed eyes and cosmetic contact lens. MID-StyleGAN combines the
strengths of diffusion models and generative adversarial networks (GANs) to
produce realistic and diverse synthetic data. Our approach utilizes a
multi-domain architecture that enables the translation between bonafide ocular
images and different PA domains. The model employs an adaptive loss function
tailored for ocular data to maintain domain consistency. Extensive experiments
demonstrate that MID-StyleGAN outperforms existing methods in generating
high-quality synthetic ocular images. The generated data was used to
significantly enhance the performance of PAD systems, providing a scalable
solution to the data scarcity problem in iris and ocular biometrics. For
example, on the LivDet2020 dataset, the true detect rate at 1% false detect
rate improved from 93.41% to 98.72%, showcasing the impact of the proposed
method.

</details>


### [24] [Vision-Centric Activation and Coordination for Multimodal Large Language Models](https://arxiv.org/abs/2510.14349)
*Yunnan Wang,Fan Lu,Kecheng Zheng,Ziyuan Huang,Ziqiang Li,Wenjun Zeng,Xin Jin*

Main category: cs.CV

TL;DR: 提出VaCo方法，通过多视觉基础模型的视觉中心激活与协调，提升多模态大语言模型的视觉理解能力。


<details>
  <summary>Details</summary>
Motivation: 主流多模态大语言模型仅依赖文本token的下一词预测，忽略了对分析能力至关重要的视觉中心信息。

Method: 引入视觉判别对齐机制，结合可学习的模块化任务查询（MTQs）和视觉对齐层（VALs），在多种视觉基础模型监督下激活特定视觉信号，并通过令牌网关掩码（TGM）协调不同模型间的表征冲突。

Result: 在多个基准上显著提升了不同多模态大语言模型的性能，验证了方法在视觉理解上的优势。

Conclusion: VaCo能有效统一文本与视觉输出的优化，增强多模态大语言模型的视觉分析能力。

Abstract: Multimodal large language models (MLLMs) integrate image features from visual
encoders with LLMs, demonstrating advanced comprehension capabilities. However,
mainstream MLLMs are solely supervised by the next-token prediction of textual
tokens, neglecting critical vision-centric information essential for analytical
abilities. To track this dilemma, we introduce VaCo, which optimizes MLLM
representations through Vision-Centric activation and Coordination from
multiple vision foundation models (VFMs). VaCo introduces visual discriminative
alignment to integrate task-aware perceptual features extracted from VFMs,
thereby unifying the optimization of both textual and visual outputs in MLLMs.
Specifically, we incorporate the learnable Modular Task Queries (MTQs) and
Visual Alignment Layers (VALs) into MLLMs, activating specific visual signals
under the supervision of diverse VFMs. To coordinate representation conflicts
across VFMs, the crafted Token Gateway Mask (TGM) restricts the information
flow among multiple groups of MTQs. Extensive experiments demonstrate that VaCo
significantly improves the performance of different MLLMs on various
benchmarks, showcasing its superior capabilities in visual comprehension.

</details>


### [25] [Leveraging Cycle-Consistent Anchor Points for Self-Supervised RGB-D Registration](https://arxiv.org/abs/2510.14354)
*Siddharth Tourani,Jayaram Reddy,Sarvesh Thakur,K Madhava Krishna,Muhammad Haris Khan,N Dinesh Reddy*

Main category: cs.CV

TL;DR: 本文提出一种利用无标签RGB-D数据进行场景几何推理的新方法，通过循环一致的关键点和新型姿态模块提升点云配准精度。


<details>
  <summary>Details</summary>
Motivation: 随着消费级深度相机的普及，大量无标签RGB-D数据可用，如何有效利用这些数据进行场景几何理解成为一个关键问题。现有方法多依赖几何和特征相似性，缺乏对空间一致性的充分建模。

Method: 提出使用循环一致的关键点作为显著点来强制匹配过程中的空间一致性约束；设计一个新的姿态模块，结合GRU循环单元与变换同步机制，融合历史和多视角信息以优化位姿估计。

Result: 在ScanNet和3DMatch数据集上超越了以往的自监督配准方法，并优于一些早期的监督方法；所提组件集成到现有方法中也显著提升了性能。

Conclusion: 该方法有效利用无标签RGB-D数据，通过关键点循环一致性和多视角信息融合显著提升了自监督点云配准的性能。

Abstract: With the rise in consumer depth cameras, a wealth of unlabeled RGB-D data has
become available. This prompts the question of how to utilize this data for
geometric reasoning of scenes. While many RGB-D registration meth- ods rely on
geometric and feature-based similarity, we take a different approach. We use
cycle-consistent keypoints as salient points to enforce spatial coherence
constraints during matching, improving correspondence accuracy. Additionally,
we introduce a novel pose block that combines a GRU recurrent unit with
transformation synchronization, blending historical and multi-view data. Our
approach surpasses previous self- supervised registration methods on ScanNet
and 3DMatch, even outperforming some older supervised methods. We also
integrate our components into existing methods, showing their effectiveness.

</details>


### [26] [Spatial Preference Rewarding for MLLMs Spatial Understanding](https://arxiv.org/abs/2510.14374)
*Han Qiu,Peng Gao,Lewei Lu,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: 提出了一种名为SPR（Spatial Preference Rewarding）的新方法，通过直接优化多模态大模型对细粒度空间理解的偏好，提升其在精确物体定位和区域描述生成方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在细粒度空间感知能力上仍不足，且缺乏对其实际响应的直接监督，导致无法满足用户对精细空间理解的需求。

Method: SPR方法引入语义和定位评分机制，评估MLLM生成描述的质量，并通过随机选取图像区域与模型描述进行配对，利用最优与最差描述进行直接偏好优化，强化细粒度视觉对齐。

Result: 在标准的指代和定位基准测试上，SPR显著提升了MLLM的空间理解能力，且训练开销极小。

Conclusion: SPR通过引入细粒度响应奖励机制，有效增强了MLLM在空间感知任务中的表现，为未来多模态模型的空间理解提供了新方向。

Abstract: Multimodal large language models~(MLLMs) have demonstrated promising spatial
understanding capabilities, such as referencing and grounding object
descriptions. Despite their successes, MLLMs still fall short in fine-grained
spatial perception abilities, such as generating detailed region descriptions
or accurately localizing objects. Additionally, they often fail to respond to
the user's requirements for desired fine-grained spatial understanding. This
issue might arise because existing approaches primarily focus on tuning MLLMs
to model pre-annotated instruction data to inject spatial knowledge, without
direct supervision of MLLMs' actual responses. We address this issue by SPR, a
Spatial Preference Rewarding~(SPR) approach that enhances MLLMs' spatial
capabilities by rewarding MLLMs' detailed responses with precise object
localization over vague or inaccurate responses. With randomly selected image
regions and region descriptions from MLLMs, SPR introduces semantic and
localization scores to comprehensively evaluate the text quality and
localization quality in MLLM-generated descriptions. We also refine the MLLM
descriptions with better localization accuracy and pair the best-scored
refinement with the initial descriptions of the lowest score for direct
preference optimization, thereby enhancing fine-grained alignment with visual
input. Extensive experiments over standard referring and grounding benchmarks
show that SPR improves MLLM spatial understanding capabilities effectively with
minimal overhead in training. Data and code will be released at
https://github.com/hanqiu-hq/SPR

</details>


### [27] [DOS: Directional Object Separation in Text Embeddings for Multi-Object Image Generation](https://arxiv.org/abs/2510.14376)
*Dongnam Byun,Jungwon Park,Jumgmin Ko,Changin Choi,Wonjong Rhee*

Main category: cs.CV

TL;DR: 提出了DOS（Directional Object Separation）方法，通过调整CLIP文本嵌入来提升多物体文本到图像生成的成功率，减少对象忽略和混合问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型在处理包含多个物体的提示时容易出现对象忽略或混合问题，特别是在形状、纹理相似或背景偏差明显等场景下表现不佳。

Method: 基于对CLIP嵌入的两个关键观察，提出DOS方法，修改三种类型的CLIP文本嵌入，以增强对象间的区分性，从而改善多物体生成效果。

Result: 实验表明，DOS在多个基准上显著提升了多物体图像生成的成功率，减少了对象混合现象，在人类评估中比四种对比方法获得更多支持（提升26.24%-43.04%）。

Conclusion: DOS是一种实用且有效的方法，能够显著改善复杂多物体场景下的文本到图像生成性能。

Abstract: Recent progress in text-to-image (T2I) generative models has led to
significant improvements in generating high-quality images aligned with text
prompts. However, these models still struggle with prompts involving multiple
objects, often resulting in object neglect or object mixing. Through extensive
studies, we identify four problematic scenarios, Similar Shapes, Similar
Textures, Dissimilar Background Biases, and Many Objects, where inter-object
relationships frequently lead to such failures. Motivated by two key
observations about CLIP embeddings, we propose DOS (Directional Object
Separation), a method that modifies three types of CLIP text embeddings before
passing them into text-to-image models. Experimental results show that DOS
consistently improves the success rate of multi-object image generation and
reduces object mixing. In human evaluations, DOS significantly outperforms four
competing methods, receiving 26.24%-43.04% more votes across four benchmarks.
These results highlight DOS as a practical and effective solution for improving
multi-object image generation.

</details>


### [28] [DRBD-Mamba for Robust and Efficient Brain Tumor Segmentation with Analytical Insights](https://arxiv.org/abs/2510.14383)
*Danish Ali,Ajmal Mian,Naveed Akhtar,Ghulam Mubashar Hassan*

Main category: cs.CV

TL;DR: 提出了一种高效的3D脑肿瘤分割模型DRBD-Mamba，通过双分辨率双向Mamba结构、空间填充曲线映射和门控融合机制，在降低计算开销的同时提升了多尺度长程依赖建模能力与鲁棒性，并在BraTS2023上实现了性能和效率的显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有Mamba模型在脑肿瘤分割中因多轴序列计算导致计算开销大，且在不同数据划分下的鲁棒性缺乏验证，缺乏可靠评估。

Method: 提出DRBD-Mamba：利用空间填充曲线进行3D到1D的特征映射以保持空间局部性，减少多轴扫描；设计门控融合模块整合前向与反向上下文；引入量化块增强鲁棒性；构建五个系统性BraTS2023数据划分用于全面评估。

Result: 在常用20%测试集上，全肿瘤Dice提升0.10%，肿瘤核心提升1.75%，增强肿瘤提升0.93%；在新提出的五折划分上，平均Dice在肿瘤核心提升0.86%，增强肿瘤提升1.45%，同时效率提升15倍。

Conclusion: DRBD-Mamba在保持高分割精度的同时大幅降低计算成本，具有更强的鲁棒性和实际应用潜力，为3D医学图像分割中的高效Mamba架构设计提供了新思路。

Abstract: Accurate brain tumor segmentation is significant for clinical diagnosis and
treatment. It is challenging due to the heterogeneity of tumor subregions.
Mamba-based State Space Models have demonstrated promising performance.
However, they incur significant computational overhead due to sequential
feature computation across multiple spatial axes. Moreover, their robustness
across diverse BraTS data partitions remains largely unexplored, leaving a
critical gap in reliable evaluation. To address these limitations, we propose
dual-resolution bi-directional Mamba (DRBD-Mamba), an efficient 3D segmentation
model that captures multi-scale long-range dependencies with minimal
computational overhead. We leverage a space-filling curve to preserve spatial
locality during 3D-to-1D feature mapping, thereby reducing reliance on
computationally expensive multi-axial feature scans. To enrich feature
representation, we propose a gated fusion module that adaptively integrates
forward and reverse contexts, along with a quantization block that discretizes
features to improve robustness. In addition, we propose five systematic folds
on BraTS2023 for rigorous evaluation of segmentation techniques under diverse
conditions and present detailed analysis of common failure scenarios. On the
20\% test set used by recent methods, our model achieves Dice improvements of
0.10\% for whole tumor, 1.75\% for tumor core, and 0.93\% for enhancing tumor.
Evaluations on the proposed systematic five folds demonstrate that our model
maintains competitive whole tumor accuracy while achieving clear average Dice
gains of 0.86\% for tumor core and 1.45\% for enhancing tumor over existing
state-of-the-art. Furthermore, our model attains 15 times improvement in
efficiency while maintaining high segmentation accuracy, highlighting its
robustness and computational advantage over existing approaches.

</details>


### [29] [BoardVision: Deployment-ready and Robust Motherboard Defect Detection with YOLO+Faster-RCNN Ensemble](https://arxiv.org/abs/2510.14389)
*Brandon Hill,Kma Solaiman*

Main category: cs.CV

TL;DR: 本文提出BoardVision框架，用于检测主板组装缺陷，结合YOLOv7和Faster R-CNN并通过CTV Voter轻量级集成方法平衡精度与召回率，提升检测稳定性，并发布了一个可部署的GUI工具以促进实际应用。


<details>
  <summary>Details</summary>
Motivation: 现有关于PCB检测的研究多集中于裸板或线路级缺陷，而对整块主板的组装级缺陷检测研究不足，且实际制造中缺乏兼顾精度、召回率与鲁棒性的解决方案。

Method: 提出BoardVision框架，基于YOLOv7和Faster R-CNN两种检测器，在MiracleFactory数据集上进行系统评估，并设计了基于置信度与时间投票的轻量级集成方法CTV Voter以融合两者优势。

Result: 实现了在组装级缺陷检测中精度与召回率的更好平衡，CTV Voter优于单一模型；在真实扰动（如亮度、锐度、旋转变化）下表现出更强的鲁棒性。

Conclusion: 通过系统性比较与集成策略，结合可部署GUI工具，展示了计算机视觉在主板组装质检中从基准研究到实际应用落地的可行性。

Abstract: Motherboard defect detection is critical for ensuring reliability in
high-volume electronics manufacturing. While prior research in PCB inspection
has largely targeted bare-board or trace-level defects, assembly-level
inspection of full motherboards inspection remains underexplored. In this work,
we present BoardVision, a reproducible framework for detecting assembly-level
defects such as missing screws, loose fan wiring, and surface scratches. We
benchmark two representative detectors - YOLOv7 and Faster R-CNN, under
controlled conditions on the MiracleFactory motherboard dataset, providing the
first systematic comparison in this domain. To mitigate the limitations of
single models, where YOLO excels in precision but underperforms in recall and
Faster R-CNN shows the reverse, we propose a lightweight ensemble,
Confidence-Temporal Voting (CTV Voter), that balances precision and recall
through interpretable rules. We further evaluate robustness under realistic
perturbations including sharpness, brightness, and orientation changes,
highlighting stability challenges often overlooked in motherboard defect
detection. Finally, we release a deployable GUI-driven inspection tool that
bridges research evaluation with operator usability. Together, these
contributions demonstrate how computer vision techniques can transition from
benchmark results to practical quality assurance for assembly-level motherboard
manufacturing.

</details>


### [30] [DCMIL: A Progressive Representation Learning Model of Whole Slide Images for Cancer Prognosis Analysis](https://arxiv.org/abs/2510.14403)
*Chao Tu,Kun Huang,Jie Zhang,Qianjin Feng,Yu Zhang,Zhenyuan Ning*

Main category: cs.CV

TL;DR: 提出了一种名为DCMIL的渐进式表示学习模型，无需密集标注即可高效处理全切片图像（WSI）并提升癌症预后预测性能。


<details>
  <summary>Details</summary>
Motivation: 计算病理学面临高分辨率图像带来的计算瓶颈以及密集手工标注稀缺的问题，且现有方法常忽略多倍率WSI中的细粒度信息和肿瘤微环境差异。

Method: 提出双课程对比多实例学习（DCMIL）模型，采用由易到难的渐进学习策略，通过对比学习直接从WSI中提取特征并进行预后预测，无需密集标注。

Result: 在12种癌症类型、近6000名患者和上千万图块上验证，DCMIL优于现有的WSI预后模型，能识别预后关键区域、估计实例不确定性、捕捉正常与肿瘤组织的形态差异。

Conclusion: DCMIL是一种高效、鲁棒的WSI分析方法，克服了标注稀缺和计算复杂性的挑战，具有生成新生物学洞见的潜力。

Abstract: The burgeoning discipline of computational pathology shows promise in
harnessing whole slide images (WSIs) to quantify morphological heterogeneity
and develop objective prognostic modes for human cancers. However, progress is
impeded by the computational bottleneck of gigapixel-size inputs and the
scarcity of dense manual annotations. Current methods often overlook
fine-grained information across multi-magnification WSIs and variations in
tumor microenvironments. Here, we propose an easy-to-hard progressive
representation learning model, termed dual-curriculum contrastive
multi-instance learning (DCMIL), to efficiently process WSIs for cancer
prognosis. The model does not rely on dense annotations and enables the direct
transformation of gigapixel-size WSIs into outcome predictions. Extensive
experiments on twelve cancer types (5,954 patients, 12.54 million tiles)
demonstrate that DCMIL outperforms standard WSI-based prognostic models.
Additionally, DCMIL identifies fine-grained prognosis-salient regions, provides
robust instance uncertainty estimation, and captures morphological differences
between normal and tumor tissues, with the potential to generate new biological
insights. All codes have been made publicly accessible at
https://github.com/tuuuc/DCMIL.

</details>


### [31] [Real-Time Neural Video Compression with Unified Intra and Inter Coding](https://arxiv.org/abs/2510.14431)
*Hui Xiang,Yifan Bian,Li Li,Jingran Wu,Xianguo Zhang,Dong Liu*

Main category: cs.CV

TL;DR: 提出了一种统一的神经视频压缩框架，结合帧内和帧间编码，自适应地处理遮挡和新内容，抑制误差传播，同时提升压缩效率和帧间稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有神经视频压缩方法在处理遮挡、新内容和帧间误差传播方面存在不足，需引入类似传统编码的帧内编码机制以提升鲁棒性和效率。

Method: 设计了一个统一的神经网络模型，可在同一框架下自适应地执行帧内和帧间编码，并提出双帧同时压缩结构，前后向挖掘帧间冗余。

Result: 相比DCVC-RT平均降低10.7% BD-rate，帧级码率和质量更稳定，且保持实时编解码能力。

Conclusion: 所提方法有效解决了NVC中的关键问题，在压缩效率和稳定性上显著优于现有方案，具有实际应用潜力。

Abstract: Neural video compression (NVC) technologies have advanced rapidly in recent
years, yielding state-of-the-art schemes such as DCVC-RT that offer superior
compression efficiency to H.266/VVC and real-time encoding/decoding
capabilities. Nonetheless, existing NVC schemes have several limitations,
including inefficiency in dealing with disocclusion and new content, interframe
error propagation and accumulation, among others. To eliminate these
limitations, we borrow the idea from classic video coding schemes, which allow
intra coding within inter-coded frames. With the intra coding tool enabled,
disocclusion and new content are properly handled, and interframe error
propagation is naturally intercepted without the need for manual refresh
mechanisms. We present an NVC framework with unified intra and inter coding,
where every frame is processed by a single model that is trained to perform
intra/inter coding adaptively. Moreover, we propose a simultaneous two-frame
compression design to exploit interframe redundancy not only forwardly but also
backwardly. Experimental results show that our scheme outperforms DCVC-RT by an
average of 10.7\% BD-rate reduction, delivers more stable bitrate and quality
per frame, and retains real-time encoding/decoding performances. Code and
models will be released.

</details>


### [32] [Structured Universal Adversarial Attacks on Object Detection for Video Sequences](https://arxiv.org/abs/2510.14460)
*Sven Jacob,Weijia Shao,Gjergji Kasneci*

Main category: cs.CV

TL;DR: 提出一种针对视频目标检测的最小失真通用对抗攻击方法，利用核范数正则化在背景区域生成结构化扰动，通过自适应乐观指数梯度法实现高效优化，攻击效果更优且隐蔽性强。


<details>
  <summary>Details</summary>
Motivation: 视频目标检测在安全关键应用中至关重要，但深度学习模型易受通用对抗扰动攻击，现有方法在扰动结构和优化效率方面存在不足，需设计更有效且隐蔽的攻击方法以评估模型鲁棒性。

Method: 提出采用核范数正则化的最小失真通用对抗攻击方法，通过约束扰动的低秩结构使其集中在背景区域；使用自适应、乐观指数梯度法进行优化，提升收敛速度与可扩展性。

Result: 所提方法在攻击效果上优于低秩投影梯度下降和基于Frank-Wolfe的攻击方法，同时保持更高的隐蔽性（低失真），验证了其在视频目标检测模型上的有效性与高效性。

Conclusion: 核范数正则化结合自适应优化策略可有效生成结构化且隐蔽的通用对抗扰动，为视频目标检测模型的对抗鲁棒性评估提供了新思路。

Abstract: Video-based object detection plays a vital role in safety-critical
applications. While deep learning-based object detectors have achieved
impressive performance, they remain vulnerable to adversarial attacks,
particularly those involving universal perturbations. In this work, we propose
a minimally distorted universal adversarial attack tailored for video object
detection, which leverages nuclear norm regularization to promote structured
perturbations concentrated in the background. To optimize this formulation
efficiently, we employ an adaptive, optimistic exponentiated gradient method
that enhances both scalability and convergence. Our results demonstrate that
the proposed attack outperforms both low-rank projected gradient descent and
Frank-Wolfe based attacks in effectiveness while maintaining high stealthiness.
All code and data are publicly available at
https://github.com/jsve96/AO-Exp-Attack.

</details>


### [33] [Unsupervised Deep Generative Models for Anomaly Detection in Neuroimaging: A Systematic Scoping Review](https://arxiv.org/abs/2510.14462)
*Youwan Mahé,Elise Bannier,Stéphanie Leplaideur,Elisa Fromont,Francesca Galassi*

Main category: cs.CV

TL;DR: 本综述总结了2018-2025年间49项关于无监督深度生成模型在神经影像异常检测中的应用研究，表明这些模型在无需标注数据的情况下能有效识别脑部异常，尤其适用于罕见病和复杂病变。


<details>
  <summary>Details</summary>
Motivation: 由于监督学习依赖大量精细标注数据且仅限于已知病变，而现实中异常数据稀缺且多样，因此需要一种仅基于健康数据训练即可检测未知异常的无监督方法。

Method: 采用PRISMA指南进行范围综述，系统梳理基于自动编码器、变分自编码器、生成对抗网络和去噪扩散模型的无监督生成模型在脑MRI和CT中的应用。

Result: 生成模型在检测大病灶方面表现良好，并在识别细微异常上取得进展；模型可生成可解释的伪健康重建图像，有助于异常定位与解释。

Conclusion: 无监督生成模型为神经影像异常检测提供了有前景的解决方案，未来应关注解剖结构感知建模、基础模型构建、合适的评估指标及临床验证以推动实际应用。

Abstract: Unsupervised deep generative models are emerging as a promising alternative
to supervised methods for detecting and segmenting anomalies in brain imaging.
Unlike fully supervised approaches, which require large voxel-level annotated
datasets and are limited to well-characterised pathologies, these models can be
trained exclusively on healthy data and identify anomalies as deviations from
learned normative brain structures. This PRISMA-guided scoping review
synthesises recent work on unsupervised deep generative models for anomaly
detection in neuroimaging, including autoencoders, variational autoencoders,
generative adversarial networks, and denoising diffusion models. A total of 49
studies published between 2018 - 2025 were identified, covering applications to
brain MRI and, less frequently, CT across diverse pathologies such as tumours,
stroke, multiple sclerosis, and small vessel disease. Reported performance
metrics are compared alongside architectural design choices. Across the
included studies, generative models achieved encouraging performance for large
focal lesions and demonstrated progress in addressing more subtle
abnormalities. A key strength of generative models is their ability to produce
interpretable pseudo-healthy (also referred to as counterfactual)
reconstructions, which is particularly valuable when annotated data are scarce,
as in rare or heterogeneous diseases. Looking ahead, these models offer a
compelling direction for anomaly detection, enabling semi-supervised learning,
supporting the discovery of novel imaging biomarkers, and facilitating within-
and cross-disease deviation mapping in unified end-to-end frameworks. To
realise clinical impact, future work should prioritise anatomy-aware modelling,
development of foundation models, task-appropriate evaluation metrics, and
rigorous clinical validation.

</details>


### [34] [Pruning Overparameterized Multi-Task Networks for Degraded Web Image Restoration](https://arxiv.org/abs/2510.14463)
*Thomas Katraouras,Dimitrios Rafailidis*

Main category: cs.CV

TL;DR: 提出了一种名为MIR-L的多任务图像恢复模型压缩方法，通过迭代剪枝策略在仅保留10%参数的情况下保持甚至超越原有模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多任务图像恢复模型参数量大、计算效率低，难以部署在资源受限的场景中，因此需要一种高效压缩模型的方法。

Method: 采用迭代剪枝策略，在每轮中移除低幅值权重，并将剩余权重重置为初始值，以发现过参数化模型中的高稀疏子网络（即“ winning tickets”）。

Result: 在去雨、去雾和去噪任务上的实验表明，MIR-L仅保留10%可训练参数时仍能保持高性能，达到或超过现有最先进模型的表现。

Conclusion: MIR-L能有效压缩多任务图像恢复模型，在显著降低参数量的同时维持优异性能，具有良好的应用前景。

Abstract: Image quality is a critical factor in delivering visually appealing content
on web platforms. However, images often suffer from degradation due to lossy
operations applied by online social networks (OSNs), negatively affecting user
experience. Image restoration is the process of recovering a clean high-quality
image from a given degraded input. Recently, multi-task (all-in-one) image
restoration models have gained significant attention, due to their ability to
simultaneously handle different types of image degradations. However, these
models often come with an excessively high number of trainable parameters,
making them computationally inefficient. In this paper, we propose a strategy
for compressing multi-task image restoration models. We aim to discover highly
sparse subnetworks within overparameterized deep models that can match or even
surpass the performance of their dense counterparts. The proposed model, namely
MIR-L, utilizes an iterative pruning strategy that removes low-magnitude
weights across multiple rounds, while resetting the remaining weights to their
original initialization. This iterative process is important for the multi-task
image restoration model's optimization, effectively uncovering "winning
tickets" that maintain or exceed state-of-the-art performance at high sparsity
levels. Experimental evaluation on benchmark datasets for the deraining,
dehazing, and denoising tasks shows that MIR-L retains only 10% of the
trainable parameters while maintaining high image restoration performance. Our
code, datasets and pre-trained models are made publicly available at
https://github.com/Thomkat/MIR-L.

</details>


### [35] [Grazing Detection using Deep Learning and Sentinel-2 Time Series Data](https://arxiv.org/abs/2510.14493)
*Aleksis Pirinen,Delia Fano Yela,Smita Chakraborty,Erik Källman*

Main category: cs.CV

TL;DR: 利用Sentinel-2卫星数据和CNN-LSTM模型，该研究实现了对季节性放牧活动的高效检测，准确识别放牧与非放牧地块，显著提升土地使用合规性检查的效率。


<details>
  <summary>Details</summary>
Motivation: 放牧行为对农业生产和生物多样性有重要影响，但目前缺乏可扩展的监测手段，亟需一种高效、低成本的方法来识别放牧区域，以支持生态保护和合规监督。

Method: 基于Sentinel-2 L2A多时相影像数据，提取4月至10月的地表反射率特征，使用CNN-LSTM模型集成方法对多边形农田边界进行二分类预测（放牧/未放牧）。

Result: 模型在五次验证中平均F1得分为77%，对放牧草地的召回率达到90%；在实际检查资源有限（每年仅能检查4%场地）的情况下，采用模型预测的非放牧地块优先检查，可使确认的非放牧站点数量提高17.2倍。

Conclusion: 研究表明，利用免费、粗分辨率的卫星数据结合深度学习模型，可有效指导生态保护相关的土地利用合规性检查，具有良好的可扩展性和实际应用价值。

Abstract: Grazing shapes both agricultural production and biodiversity, yet scalable
monitoring of where grazing occurs remains limited. We study seasonal grazing
detection from Sentinel-2 L2A time series: for each polygon-defined field
boundary, April-October imagery is used for binary prediction (grazed / not
grazed). We train an ensemble of CNN-LSTM models on multi-temporal reflectance
features, and achieve an average F1 score of 77 percent across five validation
splits, with 90 percent recall on grazed pastures. Operationally, if inspectors
can visit at most 4 percent of sites annually, prioritising fields predicted by
our model as non-grazed yields 17.2 times more confirmed non-grazing sites than
random inspection. These results indicate that coarse-resolution, freely
available satellite data can reliably steer inspection resources for
conservation-aligned land-use compliance. Code and models have been made
publicly available.

</details>


### [36] [Vision Mamba for Permeability Prediction of Porous Media](https://arxiv.org/abs/2510.14516)
*Ali Kashefi,Tapan Mukerji*

Main category: cs.CV

TL;DR: 本文首次提出使用Vision Mamba作为主干网络来预测三维多孔介质的渗透率，相比ViT和CNN在计算效率、内存占用和参数量上更具优势。


<details>
  <summary>Details</summary>
Motivation: 由于ViT在处理高分辨率图像时计算复杂度高，CNN参数量大，而Vision Mamba具有线性缩放特性和更少的参数，因此探索其在科学计算领域如渗透率预测中的应用潜力。

Method: 采用Vision Mamba作为主干网络构建模型，并与ViT和CNN在多个渗透率预测指标上进行比较，同时进行消融实验分析各组件对性能的影响。

Result: 实验表明，Vision Mamba在保持高预测精度的同时，显著减少了计算资源和内存消耗，优于ViT和CNN模型。

Conclusion: Vision Mamba在三维多孔介质渗透率预测中展现出优越性能，具备推广至大型视觉模型替代ViT的潜力，且代码已公开以支持可复现性研究。

Abstract: Vision Mamba has recently received attention as an alternative to Vision
Transformers (ViTs) for image classification. The network size of Vision Mamba
scales linearly with input image resolution, whereas ViTs scale quadratically,
a feature that improves computational and memory efficiency. Moreover, Vision
Mamba requires a significantly smaller number of trainable parameters than
traditional convolutional neural networks (CNNs), and thus, they can be more
memory efficient. Because of these features, we introduce, for the first time,
a neural network that uses Vision Mamba as its backbone for predicting the
permeability of three-dimensional porous media. We compare the performance of
Vision Mamba with ViT and CNN models across multiple aspects of permeability
prediction and perform an ablation study to assess the effects of its
components on accuracy. We demonstrate in practice the aforementioned
advantages of Vision Mamba over ViTs and CNNs in the permeability prediction of
three-dimensional porous media. We make the source code publicly available to
facilitate reproducibility and to enable other researchers to build on and
extend this work. We believe the proposed framework has the potential to be
integrated into large vision models in which Vision Mamba is used instead of
ViTs.

</details>


### [37] [Real-Time Surgical Instrument Defect Detection via Non-Destructive Testing](https://arxiv.org/abs/2510.14525)
*Qurrat Ul Ain,Atif Aftab Ahmed Jilani,Zunaira Shafqat,Nigar Azhar Butt*

Main category: cs.CV

TL;DR: SurgScan是一个基于YOLOv8的AI缺陷检测框架，利用高分辨率图像数据集实现对手术器械缺陷的高精度、实时分类，准确率达99.3%，具备工业可扩展性。


<details>
  <summary>Details</summary>
Motivation: 手动质检易出错且不一致，存在安全隐患，亟需自动化、高精度的缺陷检测方案以提升手术器械制造的质量控制水平。

Method: 提出SurgScan框架，采用YOLOv8模型，在包含102,876张图像、涵盖11类器械和5类缺陷的数据集上进行训练，并引入对比度增强预处理提升检测效果。

Result: SurgScan达到99.3%的最高准确率，单图推理时间仅4.2-5.8毫秒，显著优于现有CNN模型，且经过统计验证，对比度增强能有效提升检测性能。

Conclusion: SurgScan为手术器械质量控制提供了可扩展、低成本的AI解决方案，减少人工依赖，符合ISO 13485和FDA标准，推动医疗制造中缺陷检测的自动化发展。

Abstract: Defective surgical instruments pose serious risks to sterility, mechanical
integrity, and patient safety, increasing the likelihood of surgical
complications. However, quality control in surgical instrument manufacturing
often relies on manual inspection, which is prone to human error and
inconsistency. This study introduces SurgScan, an AI-powered defect detection
framework for surgical instruments. Using YOLOv8, SurgScan classifies defects
in real-time, ensuring high accuracy and industrial scalability. The model is
trained on a high-resolution dataset of 102,876 images, covering 11 instrument
types and five major defect categories. Extensive evaluation against
state-of-the-art CNN architectures confirms that SurgScan achieves the highest
accuracy (99.3%) with real-time inference speeds of 4.2-5.8 ms per image,
making it suitable for industrial deployment. Statistical analysis demonstrates
that contrast-enhanced preprocessing significantly improves defect detection,
addressing key limitations in visual inspection. SurgScan provides a scalable,
cost-effective AI solution for automated quality control, reducing reliance on
manual inspection while ensuring compliance with ISO 13485 and FDA standards,
paving the way for enhanced defect detection in medical manufacturing.

</details>


### [38] [Noise Projection: Closing the Prompt-Agnostic Gap Behind Text-to-Image Misalignment in Diffusion Models](https://arxiv.org/abs/2510.14526)
*Yunze Tong,Didi Zhu,Zijing Hu,Jinluan Yang,Ziyu Zhao*

Main category: cs.CV

TL;DR: 提出一种文本条件噪声投影方法，通过在生成前对初始噪声进行文本引导的优化，提升Stable Diffusion中图像与文本的对齐性，无需修改模型且推理高效。


<details>
  <summary>Details</summary>
Motivation: 在文本到图像生成中，不同初始噪声会导致去噪路径差异，部分生成图像与文本提示不匹配。这是由于训练时噪声隐含在文本相关的潜在空间子集中，而推理时使用的是无条件高斯噪声，存在训练-推理不一致问题。

Method: 提出噪声投影器，利用提示词嵌入对初始噪声进行文本条件化优化。通过采样噪声生成图像，使用视觉-语言模型提供token级反馈，蒸馏为奖励模型，并采用拟直接偏好优化方法训练噪声投影器。

Result: 该方法在无需参考图像或人工先验的情况下，显著提升文本-图像对齐度，推理成本低，仅需单次前向传播即可完成优化，优于多采样选择策略。

Conclusion: 通过引入文本条件噪声投影，有效缓解了Stable Diffusion中的训练-推理噪声分布不一致问题，提升了生成质量与语义一致性，且具有良好的通用性和效率。

Abstract: In text-to-image generation, different initial noises induce distinct
denoising paths with a pretrained Stable Diffusion (SD) model. While this
pattern could output diverse images, some of them may fail to align well with
the prompt. Existing methods alleviate this issue either by altering the
denoising dynamics or by drawing multiple noises and conducting post-selection.
In this paper, we attribute the misalignment to a training-inference mismatch:
during training, prompt-conditioned noises lie in a prompt-specific subset of
the latent space, whereas at inference the noise is drawn from a
prompt-agnostic Gaussian prior. To close this gap, we propose a noise projector
that applies text-conditioned refinement to the initial noise before denoising.
Conditioned on the prompt embedding, it maps the noise to a prompt-aware
counterpart that better matches the distribution observed during SD training,
without modifying the SD model. Our framework consists of these steps: we first
sample some noises and obtain token-level feedback for their corresponding
images from a vision-language model (VLM), then distill these signals into a
reward model, and finally optimize the noise projector via a quasi-direct
preference optimization. Our design has two benefits: (i) it requires no
reference images or handcrafted priors, and (ii) it incurs small inference
cost, replacing multi-sample selection with a single forward pass. Extensive
experiments further show that our prompt-aware noise projection improves
text-image alignment across diverse prompts.

</details>


### [39] [PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model](https://arxiv.org/abs/2510.14528)
*Cheng Cui,Ting Sun,Suyin Liang,Tingquan Gao,Zelun Zhang,Jiaxuan Liu,Xueqing Wang,Changda Zhou,Hongen Liu,Manhui Lin,Yue Zhang,Yubo Zhang,Handong Zheng,Jing Zhang,Jun Zhang,Yi Liu,Dianhai Yu,Yanjun Ma*

Main category: cs.CV

TL;DR: PaddleOCR-VL是一种先进的、资源高效的文档解析模型，核心为PaddleOCR-VL-0.9B，结合动态分辨率视觉编码器与ERNIE-4.5-0.3B语言模型，支持109种语言，擅长识别文本、表格、公式和图表等复杂元素，性能达到SOTA且推理速度快，适合实际部署。


<details>
  <summary>Details</summary>
Motivation: 为解决现有文档解析模型在多语言支持、复杂元素识别和资源消耗方面的不足，提出一种高效且强大的视觉-语言模型。

Method: 构建PaddleOCR-VL-0.9B，采用NaViT风格的动态分辨率视觉编码器与ERNIE-4.5-0.3B语言模型融合，实现精准的元素识别，并优化模型资源消耗。

Result: 在公开和内部基准测试中，PaddleOCR-VL在页面级文档解析和元素级识别任务上均达到SOTA性能，显著优于现有方案，推理速度快，具备与顶级VLM竞争的能力。

Conclusion: PaddleOCR-VL兼具高性能与低资源消耗，适用于真实场景中的高效文档解析，具有广泛的应用前景。

Abstract: In this report, we propose PaddleOCR-VL, a SOTA and resource-efficient model
tailored for document parsing. Its core component is PaddleOCR-VL-0.9B, a
compact yet powerful vision-language model (VLM) that integrates a NaViT-style
dynamic resolution visual encoder with the ERNIE-4.5-0.3B language model to
enable accurate element recognition. This innovative model efficiently supports
109 languages and excels in recognizing complex elements (e.g., text, tables,
formulas, and charts), while maintaining minimal resource consumption. Through
comprehensive evaluations on widely used public benchmarks and in-house
benchmarks, PaddleOCR-VL achieves SOTA performance in both page-level document
parsing and element-level recognition. It significantly outperforms existing
solutions, exhibits strong competitiveness against top-tier VLMs, and delivers
fast inference speeds. These strengths make it highly suitable for practical
deployment in real-world scenarios.

</details>


### [40] [Towards Generalist Intelligence in Dentistry: Vision Foundation Models for Oral and Maxillofacial Radiology](https://arxiv.org/abs/2510.14532)
*Xinrui Huang,Fan Xiao,Dongming He,Anqi Gao,Dandan Li,Xiaofan Zhang,Shaoting Zhang,Xudong Wang*

Main category: cs.CV

TL;DR: DentVFM是首个专为牙科设计的视觉基础模型家族，通过自监督学习在大规模多模态牙科影像数据集DentVista上训练，具备跨任务、跨模态的强泛化能力，显著优于现有方法，并推动牙科AI向高效、可扩展的新范式发展。


<details>
  <summary>Details</summary>
Motivation: 牙科影像解读受限于专业人才短缺，现有AI系统因单模态、任务特定及依赖大量标注数据而难以泛化。因此需要一个通用、高效且可扩展的基础模型来提升牙科智能诊断能力。

Method: 提出DentVFM，基于Vision Transformer架构的2D和3D视觉基础模型，采用自监督学习在含约160万张多模态影像的大型数据集DentVista上训练；同时构建DentBench benchmark，涵盖八个牙科亚专科以评估模型性能。

Result: DentVFM在多种牙科任务中表现出卓越的泛化能力，显著优于监督、自监督和弱监督基线方法，在疾病诊断、治疗分析、生物标志物识别、解剖标志检测与分割等任务中均取得领先性能，并实现跨模态诊断，某些场景下表现超越资深牙医。

Conclusion: DentVFM建立了牙科AI的新范式，具备良好的可扩展性、适应性和标签效率，有望缓解全球口腔医疗资源短缺问题，推动智能化牙科诊疗的发展。

Abstract: Oral and maxillofacial radiology plays a vital role in dental healthcare, but
radiographic image interpretation is limited by a shortage of trained
professionals. While AI approaches have shown promise, existing dental AI
systems are restricted by their single-modality focus, task-specific design,
and reliance on costly labeled data, hindering their generalization across
diverse clinical scenarios. To address these challenges, we introduce DentVFM,
the first family of vision foundation models (VFMs) designed for dentistry.
DentVFM generates task-agnostic visual representations for a wide range of
dental applications and uses self-supervised learning on DentVista, a large
curated dental imaging dataset with approximately 1.6 million multi-modal
radiographic images from various medical centers. DentVFM includes 2D and 3D
variants based on the Vision Transformer (ViT) architecture. To address gaps in
dental intelligence assessment and benchmarks, we introduce DentBench, a
comprehensive benchmark covering eight dental subspecialties, more diseases,
imaging modalities, and a wide geographical distribution. DentVFM shows
impressive generalist intelligence, demonstrating robust generalization to
diverse dental tasks, such as disease diagnosis, treatment analysis, biomarker
identification, and anatomical landmark detection and segmentation.
Experimental results indicate DentVFM significantly outperforms supervised,
self-supervised, and weakly supervised baselines, offering superior
generalization, label efficiency, and scalability. Additionally, DentVFM
enables cross-modality diagnostics, providing more reliable results than
experienced dentists in situations where conventional imaging is unavailable.
DentVFM sets a new paradigm for dental AI, offering a scalable, adaptable, and
label-efficient model to improve intelligent dental healthcare and address
critical gaps in global oral healthcare.

</details>


### [41] [Acquisition of interpretable domain information during brain MR image harmonization for content-based image retrieval](https://arxiv.org/abs/2510.14535)
*Keima Abe,Hayato Muraki,Shuhei Tomoshige,Kenichi Oishi,Hitoshi Iyatomi*

Main category: cs.CV

TL;DR: 提出了一种新的可解释性医学图像域适应框架PL-SE-ADA，有效实现脑MR图像的域均衡与疾病相关信息保留。


<details>
  <summary>Details</summary>
Motivation: 医学图像在不同成像设备和协议间存在域偏移，影响机器学习性能，现有域适应方法缺乏可解释性，限制了其在临床中的应用。

Method: 设计了包含两个编码器（f_E和f_SE）、解码器（f_D）和域预测器（g_D）的框架，通过对抗训练和分别重建域不变（z_u）和域特定（z_d）特征实现可解释的表示学习。

Result: 在图像重建、疾病分类和域识别任务上性能优于或等同于现有方法，并能可视化域不变和域特定的脑部特征。

Conclusion: PL-SE-ADA在实现有效域均衡的同时，提供了高可解释性，有助于推动可信任的医学图像分析模型的发展。

Abstract: Medical images like MR scans often show domain shifts across imaging sites
due to scanner and protocol differences, which degrade machine learning
performance in tasks such as disease classification. Domain harmonization is
thus a critical research focus. Recent approaches encode brain images
$\boldsymbol{x}$ into a low-dimensional latent space $\boldsymbol{z}$, then
disentangle it into $\boldsymbol{z_u}$ (domain-invariant) and
$\boldsymbol{z_d}$ (domain-specific), achieving strong results. However, these
methods often lack interpretability$-$an essential requirement in medical
applications$-$leaving practical issues unresolved. We propose
Pseudo-Linear-Style Encoder Adversarial Domain Adaptation (PL-SE-ADA), a
general framework for domain harmonization and interpretable representation
learning that preserves disease-relevant information in brain MR images.
PL-SE-ADA includes two encoders $f_E$ and $f_{SE}$ to extract
$\boldsymbol{z_u}$ and $\boldsymbol{z_d}$, a decoder to reconstruct the image
$f_D$, and a domain predictor $g_D$. Beyond adversarial training between the
encoder and domain predictor, the model learns to reconstruct the input image
$\boldsymbol{x}$ by summing reconstructions from $\boldsymbol{z_u}$ and
$\boldsymbol{z_d}$, ensuring both harmonization and informativeness. Compared
to prior methods, PL-SE-ADA achieves equal or better performance in image
reconstruction, disease classification, and domain recognition. It also enables
visualization of both domain-independent brain features and domain-specific
components, offering high interpretability across the entire framework.

</details>


### [42] [Exploring Image Representation with Decoupled Classical Visual Descriptors](https://arxiv.org/abs/2510.14536)
*Chenyuan Qu,Hao Chen,Jianbo Jiao*

Main category: cs.CV

TL;DR: VisualSplit 是一种将图像分解为经典视觉描述符的新框架，在保持可解释性的同时，通过重建驱动的预训练学习每个描述符的本质，有效支持图像生成与编辑等高级视觉任务。


<details>
  <summary>Details</summary>
Motivation: 现代深度学习模型虽然性能强大，但其内部表示缺乏可解释性；而经典视觉描述符（如边缘、颜色、强度分布）具有直观可理解性。本文旨在弥合这一差距，探索是否可将经典视觉线索融入现代学习中以提升表示的透明性与可控性。

Method: 提出 VisualSplit 框架，显式地将图像分解为解耦的经典视觉描述符（如边缘、颜色、纹理等），并将每个描述符作为独立且互补的视觉知识组件。通过基于重建的预训练策略，模型学习每个描述符的本质特征，同时保持其语义可解释性。

Result: VisualSplit 在图像生成和编辑等高级视觉任务中展现出有效的属性控制能力，验证了其在保持表示可解释性的同时提升模型功能性的潜力。此外，该方法超越了传统的分类与分割任务，展示了广泛的应用前景。

Conclusion: 将经典视觉描述符显式引入现代学习框架是可行且有效的，VisualSplit 提供了一种兼具可解释性与表达能力的新视觉学习范式，为未来可理解的视觉表示学习提供了新方向。

Abstract: Exploring and understanding efficient image representations is a
long-standing challenge in computer vision. While deep learning has achieved
remarkable progress across image understanding tasks, its internal
representations are often opaque, making it difficult to interpret how visual
information is processed. In contrast, classical visual descriptors (e.g. edge,
colour, and intensity distribution) have long been fundamental to image
analysis and remain intuitively understandable to humans. Motivated by this
gap, we ask a central question: Can modern learning benefit from these
classical cues? In this paper, we answer it with VisualSplit, a framework that
explicitly decomposes images into decoupled classical descriptors, treating
each as an independent but complementary component of visual knowledge. Through
a reconstruction-driven pre-training scheme, VisualSplit learns to capture the
essence of each visual descriptor while preserving their interpretability. By
explicitly decomposing visual attributes, our method inherently facilitates
effective attribute control in various advanced visual tasks, including image
generation and editing, extending beyond conventional classification and
segmentation, suggesting the effectiveness of this new learning approach for
visual understanding. Project page: https://chenyuanqu.com/VisualSplit/.

</details>


### [43] [Exploring Cross-Modal Flows for Few-Shot Learning](https://arxiv.org/abs/2510.14543)
*Ziqi Jiang,Yanghao Wang,Long Chen*

Main category: cs.CV

TL;DR: 本文提出了首个模型无关的多步对齐方法Flow Matching Alignment (FMA)，通过学习跨模态速度场实现更精确、鲁棒的特征对齐，显著提升复杂数据集下的跨模态性能。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调（PEFT）方法仅进行单步调整，难以有效解耦高度纠缠的跨模态特征，尤其在复杂数据集上表现不足。

Method: 提出FMA方法，包括固定耦合策略确保类别对应、噪声增强策略缓解数据稀缺、设计早停求解器提升效率与精度，通过多步调整学习跨模态速度场。

Result: FMA在多个基准和主干模型上均取得显著性能提升，尤其在挑战性数据集上表现突出，优于现有的单步PEFT方法。

Conclusion: FMA为跨模态对齐提供了新的多步调整视角，具备良好的通用性和鲁棒性，是解决复杂场景下特征对齐问题的有效方案。

Abstract: Aligning features from different modalities, is one of the most fundamental
challenges for cross-modal tasks. Although pre-trained vision-language models
can achieve a general alignment between image and text, they often require
parameter-efficient fine-tuning (PEFT) for further adjustment. Today's PEFT
methods (e.g., prompt tuning, LoRA-based, or adapter-based) always selectively
fine-tune a subset of parameters, which can slightly adjust either visual or
textual features, and avoid overfitting. In this paper, we are the first to
highlight that all existing PEFT methods perform one-step adjustment. It is
insufficient for complex (or difficult) datasets, where features of different
modalities are highly entangled. To this end, we propose the first
model-agnostic multi-step adjustment approach by learning a cross-modal
velocity field: Flow Matching Alignment (FMA). Specifically, to ensure the
correspondence between categories during training, we first utilize a fixed
coupling strategy. Then, we propose a noise augmentation strategy to alleviate
the data scarcity issue. Finally, we design an early-stopping solver, which
terminates the transformation process earlier, improving both efficiency and
accuracy. Compared with one-step PEFT methods, FMA has the multi-step
rectification ability to achieve more precise and robust alignment. Extensive
results have demonstrated that FMA can consistently yield significant
performance gains across various benchmarks and backbones, particularly on
challenging datasets.

</details>


### [44] [Consistent text-to-image generation via scene de-contextualization](https://arxiv.org/abs/2510.14553)
*Song Tang,Peihao Gong,Kunyu Li,Kai Guo,Boyu Wang,Mao Ye,Jianwei Zhang,Xiatian Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的提示嵌入编辑方法Scene De-Contextualization（SDeC），用于缓解文本到图像生成中的身份漂移问题，通过消除场景上下文化影响来实现跨场景的身份一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在一致的文本到图像生成中常因身份（ID）漂移而失败，且大多依赖于预先知道所有目标场景的不现实假设；本文旨在解决这一局限性并揭示场景上下文化是ID漂移的关键来源。

Method: 提出SDeC方法，通过奇异值分解（SVD）方向稳定性量化并自适应重加权ID提示嵌入中的特征值，抑制潜在的场景-ID相关性，实现对T2I模型内置场景上下文化的反向过程，且无需访问所有目标场景。

Result: 实验证明SDeC显著提升了身份保持能力，同时维持了生成图像的场景多样性，且适用于单场景提示，具有高效性和通用性。

Conclusion: SDeC为文本到图像生成中的身份一致性问题提供了灵活、无需训练的解决方案，尤其适用于无法预先获知所有场景的实际应用场景。

Abstract: Consistent text-to-image (T2I) generation seeks to produce
identity-preserving images of the same subject across diverse scenes, yet it
often fails due to a phenomenon called identity (ID) shift. Previous methods
have tackled this issue, but typically rely on the unrealistic assumption of
knowing all target scenes in advance. This paper reveals that a key source of
ID shift is the native correlation between subject and scene context, called
scene contextualization, which arises naturally as T2I models fit the training
distribution of vast natural images. We formally prove the near-universality of
this scene-ID correlation and derive theoretical bounds on its strength. On
this basis, we propose a novel, efficient, training-free prompt embedding
editing approach, called Scene De-Contextualization (SDeC), that imposes an
inversion process of T2I's built-in scene contextualization. Specifically, it
identifies and suppresses the latent scene-ID correlation within the ID
prompt's embedding by quantifying the SVD directional stability to adaptively
re-weight the corresponding eigenvalues. Critically, SDeC allows for per-scene
use (one scene per prompt) without requiring prior access to all target scenes.
This makes it a highly flexible and general solution well-suited to real-world
applications where such prior knowledge is often unavailable or varies over
time. Experiments demonstrate that SDeC significantly enhances identity
preservation while maintaining scene diversity.

</details>


### [45] [Eyes Wide Open: Ego Proactive Video-LLM for Streaming Video](https://arxiv.org/abs/2510.14560)
*Yulin Zhang,Cheng Shi,Yang Wang,Sibei Yang*

Main category: cs.CV

TL;DR: 本文提出了一种能够在第一视角视频流中主动理解、预测并适时响应动态问题的AI系统，引入了ESTP-Bench评测基准和ESTP-F1指标，并通过一套包含数据引擎、多阶段训练和动态压缩技术的 pipeline 实现了在同步感知与推理下的高效主动响应。


<details>
  <summary>Details</summary>
Motivation: 当前大多数AI系统依赖被动观察，难以在动态人类环境中主动理解与响应。本文旨在构建能在恰当时机主动回答多样化问题的智能助手，提升AI在真实场景中的实用性与交互能力。

Method: 提出ESTP-Bench基准和ESTP-F1评估指标，设计包含数据引擎、多阶段训练策略和主动动态压缩技术的综合技术 pipeline，以实现同步感知、推理与及时响应。

Result: 所提模型在ESTP-Bench上显著优于多个基线方法，在线上线下多种基准测试中均表现出优越的主动响应能力、同步效率和整体性能。

Conclusion: 本文推动了面向主动交互的AI系统发展，验证了在第一视角流中实现主动性、及时性和同步性的可行性，为未来智能代理在真实环境中的应用提供了有效框架。

Abstract: Envision an AI capable of functioning in human-like settings, moving beyond
mere observation to actively understand, anticipate, and proactively respond to
unfolding events. Towards this vision, we focus on the innovative task where,
given ego-streaming video input, an assistant proactively answers diverse,
evolving questions at the opportune moment, while maintaining synchronized
perception and reasoning. This task embodies three key properties: (1)
Proactive Coherence, (2) Just-in-Time Responsiveness, and (3) Synchronized
Efficiency. To evaluate and address these properties, we first introduce
ESTP-Bench (Ego Streaming Proactive Benchmark) alongside the ESTP-F1 metric-a
novel framework designed for their rigorous assessment. Secondly, we propose a
comprehensive technical pipeline to enable models to tackle this challenging
task. This pipeline comprises: (1) a data engine, (2) a multi-stage training
strategy, and (3) a proactive dynamic compression technique. Our proposed model
effectively addresses these critical properties while outperforming multiple
baselines across diverse online and offline benchmarks. Project
Page:https://zhangyl4.github.io/publications/eyes-wide-open/

</details>


### [46] [BalanceGS: Algorithm-System Co-design for Efficient 3D Gaussian Splatting Training on GPU](https://arxiv.org/abs/2510.14564)
*Junyi Wu,Jiaming Xu,Jinhao Li,Yongkang Zhou,Jiayi Pan,Xingyang Li,Guohao Dai*

Main category: cs.CV

TL;DR: 提出BalanceGS，一种算法-系统协同设计的3D高斯溅射训练优化方法，通过密度控制、自适应采样与内存访问优化，实现比传统3DGS快1.44倍的训练速度。


<details>
  <summary>Details</summary>
Motivation: 传统3D高斯溅射（3DGS）训练存在高斯密度分配不均、计算负载不平衡和内存访问碎片化三大效率瓶颈，限制了训练效率。

Method: 1）算法层面：提出启发式工作负载感知的高斯密度控制，自动平衡点分布；2）系统层面：提出基于相似性的高斯采样与合并，实现动态负载分配；3）映射层面：设计基于重排序的内存访问策略，优化RGB存储与批量加载。

Result: 在NVIDIA A100 GPU上相比3DGS实现了1.44倍的训练加速，且重建质量几乎无损。

Conclusion: BalanceGS通过算法与系统的协同优化，显著提升了3DGS的训练效率，为高斯溅射技术的实际应用提供了更高效的解决方案。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a promising 3D reconstruction
technique. The traditional 3DGS training pipeline follows three sequential
steps: Gaussian densification, Gaussian projection, and color splatting.
Despite its promising reconstruction quality, this conventional approach
suffers from three critical inefficiencies: (1) Skewed density allocation
during Gaussian densification, (2) Imbalanced computation workload during
Gaussian projection and (3) Fragmented memory access during color splatting.
  To tackle the above challenges, we introduce BalanceGS, the algorithm-system
co-design for efficient training in 3DGS. (1) At the algorithm level, we
propose heuristic workload-sensitive Gaussian density control to automatically
balance point distributions - removing 80% redundant Gaussians in dense regions
while filling gaps in sparse areas. (2) At the system level, we propose
Similarity-based Gaussian sampling and merging, which replaces the static
one-to-one thread-pixel mapping with adaptive workload distribution - threads
now dynamically process variable numbers of Gaussians based on local cluster
density. (3) At the mapping level, we propose reordering-based memory access
mapping strategy that restructures RGB storage and enables batch loading in
shared memory.
  Extensive experiments demonstrate that compared with 3DGS, our approach
achieves a 1.44$\times$ training speedup on a NVIDIA A100 GPU with negligible
quality degradation.

</details>


### [47] [CALM-Net: Curvature-Aware LiDAR Point Cloud-based Multi-Branch Neural Network for Vehicle Re-Identification](https://arxiv.org/abs/2510.14576)
*Dongwook Lee,Sol Han,Jinwhan Kim*

Main category: cs.CV

TL;DR: CALM-Net是一种基于LiDAR点云的多分支神经网络，通过引入曲率信息和多分支结构提升车辆重识别性能，在nuScenes数据集上比最强基线提高约1.97%的平均识别精度。


<details>
  <summary>Details</summary>
Motivation: 从三维点云中学习具有判别性和互补性的特征以区分不同车辆，解决现有方法在几何细节利用上的不足。

Method: 提出CALM-Net，采用多分支架构，结合边缘卷积、点注意力和曲率嵌入模块，分别捕获局部几何结构、重要特征权重和表面曲率变化。

Result: 在nuScenes数据集上，CALM-Net的平均重识别精度比最强基线提升约1.97个百分点，验证了曲率信息和多分支设计的有效性。

Conclusion: 引入曲率信息可增强点云特征表示，多分支结构有助于学习更丰富、更具判别性的特征，显著提升LiDAR点云车辆重识别性能。

Abstract: This paper presents CALM-Net, a curvature-aware LiDAR point cloud-based
multi-branch neural network for vehicle re-identification. The proposed model
addresses the challenge of learning discriminative and complementary features
from three-dimensional point clouds to distinguish between vehicles. CALM-Net
employs a multi-branch architecture that integrates edge convolution, point
attention, and a curvature embedding that characterizes local surface variation
in point clouds. By combining these mechanisms, the model learns richer
geometric and contextual features that are well suited for the
re-identification task. Experimental evaluation on the large-scale nuScenes
dataset demonstrates that CALM-Net achieves a mean re-identification accuracy
improvement of approximately 1.97\% points compared with the strongest baseline
in our study. The results confirms the effectiveness of incorporating curvature
information into deep learning architectures and highlight the benefit of
multi-branch feature learning for LiDAR point cloud-based vehicle
re-identification.

</details>


### [48] [Talking Points: Describing and Localizing Pixels](https://arxiv.org/abs/2510.14583)
*Matan Rusanovsky,Shimon Malnick,Shai Avidan*

Main category: cs.CV

TL;DR: 提出一种用于像素级关键点定位的新框架，包含关键点描述生成和精确坐标回归两个组件，通过合成数据集LlamaPointInPart进行训练，并采用新评估协议验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型大多局限于对象或区域级别的定位，缺乏通过自然语言实现像素级关键点理解的能力，本文旨在填补这一空白。

Method: 提出由Point Descriptor和Point Localizer组成的双向框架：前者生成关键点的上下文描述，后者从描述中回归精确坐标；利用多个视觉-语言模型合成20K+图像-关键点-描述三元组构成LlamaPointInPart数据集；采用GRPO优化Point Descriptor，以冻结的Point Localizer作为奖励模型提升定位准确性。

Result: 在LlamaPointInPart上的实验表明，该方法在定位精度上显著优于基线模型；新评估协议通过预测点与真实点的距离来衡量性能，避免直接比较文本描述。

Conclusion: 该框架实现了自然语言与像素级关键点的对齐，支持跨类别泛化，为关键点引导的图像理解与语言引导的精确定位提供了新方向。

Abstract: Vision-language models have achieved remarkable success in cross-modal
understanding. Yet, these models remain limited to object-level or region-level
grounding, lacking the capability for pixel-precise keypoint comprehension
through natural language. We introduce a novel framework for pixel level
grounding. The framework consists of two complementary components: a Point
Descriptor that generates rich, contextual descriptions of individual
keypoints, and a Point Localizer that regresses precise pixel coordinates from
these descriptions. Unlike prior work that relies on templated prompts or
keypoint names, our approach produces free-form, coarse-to-fine descriptions
that situate keypoints within their visual context. Since there is no available
dataset to train such a system, we introduce LlamaPointInPart, a carefully
curated dataset of 20K+ image-keypoint-description triplets synthesized from
multiple vision-language models, capturing multi-scale information from
scene-level context to visual features around the keypoint. For cross-category
generalization, we optimize the Point Descriptor on AP-10K via GRPO, using the
frozen Point Localizer as a reward model to produce descriptions that maximize
localization accuracy. To evaluate our results we establish a new evaluation
protocol. Instead of comparing the text description produced by our method to
the ground truth, we use the localizer to determine how close is the predicted
point generated to the ground truth point. Experiments demonstrate superior
performance compared to baseline models on LlamaPointInPart.The bidirectional
nature of our framework should enable future applications in both
keypoint-guided image understanding and language-guided precise localization.
Our code and dataset are publicly available at
https://github.com/matanr/Talking_Points.

</details>


### [49] [STANCE: Motion Coherent Video Generation Via Sparse-to-Dense Anchored Encoding](https://arxiv.org/abs/2510.14588)
*Zhifei Chen,Tianshuo Xu,Leyi Wu,Luozhou Wang,Dongyu Yan,Zihan You,Wenting Luo,Guo Zhang,Yingcong Chen*

Main category: cs.CV

TL;DR: STANCE 是一种新的图像到视频生成框架，通过引入实例线索和 Dense RoPE 技术，有效提升了视频生成中的物体运动连贯性和时序一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的视频生成方法在保持物体运动和交互的连贯性方面存在困难，主要受限于人类提供的运动提示在编码后有效信息丢失，以及外观和运动优化耦合导致的时间不一致问题。

Method: STANCE 框架包含两个关键组件：1）实例线索，将稀疏的手工提示转换为密集的 2.5D 运动场，结合实例流和单目深度信息；2）Dense RoPE，使用空间可寻址的旋转嵌入标记关键运动令牌，保持其在令牌空间中的显著性。同时采用 RGB 与辅助图（如分割或深度）联合预测策略。

Result: STANCE 在保持结构稳定性的同时提升了视频的时间连贯性，无需逐帧轨迹脚本即可生成高质量、运动一致的视频序列。

Conclusion: STANCE 通过解耦结构与外观建模，解决了视频生成中运动提示弱化和优化冲突的问题，为图像到视频生成提供了更鲁棒且用户友好的解决方案。

Abstract: Video generation has recently made striking visual progress, but maintaining
coherent object motion and interactions remains difficult. We trace two
practical bottlenecks: (i) human-provided motion hints (e.g., small 2D maps)
often collapse to too few effective tokens after encoding, weakening guidance;
and (ii) optimizing for appearance and motion in a single head can favor
texture over temporal consistency. We present STANCE, an image-to-video
framework that addresses both issues with two simple components. First, we
introduce Instance Cues -- a pixel-aligned control signal that turns sparse,
user-editable hints into a dense 2.5D (camera-relative) motion field by
averaging per-instance flow and augmenting with monocular depth over the
instance mask. This reduces depth ambiguity compared to 2D arrow inputs while
remaining easy to use. Second, we preserve the salience of these cues in token
space with Dense RoPE, which tags a small set of motion tokens (anchored on the
first frame) with spatial-addressable rotary embeddings. Paired with joint RGB
\(+\) auxiliary-map prediction (segmentation or depth), our model anchors
structure while RGB handles appearance, stabilizing optimization and improving
temporal coherence without requiring per-frame trajectory scripts.

</details>


### [50] [Hierarchical Re-Classification: Combining Animal Classification Models with Vision Transformers](https://arxiv.org/abs/2510.14594)
*Hugo Markoff,Jevgenijs Galaktionovs*

Main category: cs.CV

TL;DR: 提出了一种结合SpeciesNet、CLIP嵌入和度量学习的分层重分类系统，可在数千种动物分类中将高层级分类标签精细化到物种级别，在LILA BC数据集上实现了64.9%的物种级识别率和96.5%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有动物分类模型（如SpeciesNet）虽覆盖广泛物种，但常采用保守策略，将许多动物标记在较高分类层级而非具体物种，限制了实际应用的精度，需提升物种级识别能力。

Method: 构建一个五阶段分层重分类流程：高置信度接受、鸟类覆盖、聚类中心构建、三元组损失度量学习和自适应余弦距离评分，融合SpeciesNet的EfficientNetV2-M预测结果与CLIP嵌入进行精细化分类。

Result: 在LILA BC沙漠狮保护数据集（4,018张图像，15,031个检测）上，从‘空白’或‘动物’标签中恢复761个鸟类检测，并对456个原标注为动物、哺乳动物或空白的检测进行重分类，准确率达96.5%，其中64.9%成功识别到物种级别。

Conclusion: 该方法能有效提升现有分类模型的物种级识别能力，尤其适用于标注粗粒度的实际场景，为野生动物监测提供了更精确的自动分类解决方案。

Abstract: State-of-the-art animal classification models like SpeciesNet provide
predictions across thousands of species but use conservative rollup strategies,
resulting in many animals labeled at high taxonomic levels rather than species.
We present a hierarchical re-classification system for the Animal Detect
platform that combines SpeciesNet EfficientNetV2-M predictions with CLIP
embeddings and metric learning to refine high-level taxonomic labels toward
species-level identification. Our five-stage pipeline (high-confidence
acceptance, bird override, centroid building, triplet-loss metric learning, and
adaptive cosine-distance scoring) is evaluated on a segment of the LILA BC
Desert Lion Conservation dataset (4,018 images, 15,031 detections). After
recovering 761 bird detections from "blank" and "animal" labels, we re-classify
456 detections labeled animal, mammal, or blank with 96.5% accuracy, achieving
species-level identification for 64.9 percent

</details>


### [51] [Zero-Shot Wildlife Sorting Using Vision Transformers: Evaluating Clustering and Continuous Similarity Ordering](https://arxiv.org/abs/2510.14596)
*Hugo Markoff,Jevgenijs Galaktionovs*

Main category: cs.CV

TL;DR: 本文评估了在动物检测平台中使用自监督视觉Transformer进行零样本野生动物图像组织的方法，通过无监督聚类和降维技术实现了高准确率的图像分类，并部署了连续相似性排序以加速手动标注。


<details>
  <summary>Details</summary>
Motivation: 由于许多野生动物数据集包含现有分类器无法识别的新物种，需要有效的零样本方法来组织和分析这些未标记的图像数据。

Method: 比较了三种架构（CLIP、DINOv2、MegaDescriptor）结合PCA和UMAP降维技术的无监督聚类方法（DBSCAN、GMM），并利用t-SNE投影实现连续一维相似性排序。

Result: 在五物种测试集上，DINOv2结合UMAP和GMM达到88.6%的准确率（macro-F1 = 0.874），一维排序对哺乳动物和鸟类的连贯性为88.2%，对鱼类为95.2%。

Conclusion: 研究结果支持将连续相似性排序应用于生产环境，显著提升了探索性分析和生物多样性监测中的人工标注效率。

Abstract: Camera traps generate millions of wildlife images, yet many datasets contain
species that are absent from existing classifiers. This work evaluates
zero-shot approaches for organizing unlabeled wildlife imagery using
self-supervised vision transformers, developed and tested within the Animal
Detect platform for camera trap analysis. We compare unsupervised clustering
methods (DBSCAN, GMM) across three architectures (CLIP, DINOv2, MegaDescriptor)
combined with dimensionality reduction techniques (PCA, UMAP), and we
demonstrate continuous 1D similarity ordering via t-SNE projection. On a
5-species test set with ground truth labels used only for evaluation, DINOv2
with UMAP and GMM achieves 88.6 percent accuracy (macro-F1 = 0.874), while 1D
sorting reaches 88.2 percent coherence for mammals and birds and 95.2 percent
for fish across 1,500 images. Based on these findings, we deployed continuous
similarity ordering in production, enabling rapid exploratory analysis and
accelerating manual annotation workflows for biodiversity monitoring.

</details>


### [52] [Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering](https://arxiv.org/abs/2510.14605)
*Yuyang Hong,Jiaqi Gu,Qi Yang,Lubin Fan,Yue Wu,Ying Wang,Kun Ding,Shiming Xiang,Jieping Ye*

Main category: cs.CV

TL;DR: 提出了一种名为Wiki-PRF的三阶段方法，通过增强多模态查询质量和检索结果相关性，在知识库视觉问答任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成方法在多模态查询质量和检索结果相关性方面存在不足，难以有效结合视觉理解和外部知识检索。

Method: 提出Wiki-PRF，包含处理、检索和过滤三个阶段：处理阶段动态调用视觉工具提取精确的多模态信息；检索阶段融合视觉与文本特征进行多模态知识检索；过滤阶段对结果进行相关性筛选与聚焦；并通过强化学习以答案准确性和格式一致性为奖励信号训练模型。

Result: 在E-VQA和InfoSeek两个基准数据集上显著提升了回答质量，分别取得36.0和42.8的性能提升，达到当前最优水平。

Conclusion: Wiki-PRF通过协同的三阶段架构和强化学习训练，有效提升了KB-VQA中多模态检索的准确性和相关性，增强了模型的推理与信息筛选能力。

Abstract: Knowledge-based visual question answering (KB-VQA) requires visual language
models (VLMs) to integrate visual understanding with external knowledge
retrieval. Although retrieval-augmented generation (RAG) achieves significant
advances in this task by combining knowledge-base querying, it still struggles
with the quality of multimodal queries and the relevance of retrieved results.
To overcome these challenges, we propose a novel three-stage method, termed
Wiki-PRF, including Processing, Retrieval and Filtering stages. The processing
stage dynamically invokes visual tools to extract precise multimodal
information for retrieval. The retrieval stage integrates visual and text
features to achieve multimodal knowledge retrieval. The filtering stage
performs relevance filtering and concentration on retrieval results. To this
end, we introduce a visual language model trained with answer accuracy and
format consistency as reward signals via a reinforcement learning manner. This
enhances the model's reasoning, tool invocation for accurate queries, and
filtering of irrelevant content. Experiments on benchmark datasets (E-VQA and
InfoSeek) show significant improvements~(36.0 and 42.8) in answer quality,
achieving state-of-the-art performance. Code is available at
https://github.com/cqu-student/Wiki-PRF

</details>


### [53] [Shot2Tactic-Caption: Multi-Scale Captioning of Badminton Videos for Tactical Understanding](https://arxiv.org/abs/2510.14617)
*Ning Ding,Keisuke Fujii,Toru Tamaki*

Main category: cs.CV

TL;DR: 本文提出了Shot2Tactic-Caption框架和首个羽毛球战术描述数据集，用于生成击球级和战术级的多尺度视频描述，并引入了基于提示的机制以更好捕捉动态战术执行过程。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时描述羽毛球中个体动作与动态战术执行过程，缺乏标注数据集支持多层级战术语义建模。

Method: 提出双分支框架，结合视觉编码器、时空Transformer编码器和解码器，生成击球和战术级描述；引入战术单元检测器识别战术类型与状态，并通过击球级提示引导机制将战术信息注入解码器。

Result: 在自建数据集上实验表明该框架能有效生成准确的击球和战术描述，消融实验显示ResNet50为基础的时空编码器最优，提示机制提升描述一致性与准确性。

Conclusion: Shot2Tactic-Caption能够有效实现羽毛球视频中多尺度战术语义描述，尤其擅长捕捉战术执行中的中断与恢复过程，推动体育视频理解的发展。

Abstract: Tactical understanding in badminton involves interpreting not only individual
actions but also how tactics are dynamically executed over time. In this paper,
we propose \textbf{Shot2Tactic-Caption}, a novel framework for semantic and
temporal multi-scale video captioning in badminton, capable of generating
shot-level captions that describe individual actions and tactic-level captions
that capture how these actions unfold over time within a tactical execution. We
also introduce the Shot2Tactic-Caption Dataset, the first badminton captioning
dataset containing 5,494 shot captions and 544 tactic captions.
Shot2Tactic-Caption adopts a dual-branch design, with both branches including a
visual encoder, a spatio-temporal Transformer encoder, and a Transformer-based
decoder to generate shot and tactic captions. To support tactic captioning, we
additionally introduce a Tactic Unit Detector that identifies valid tactic
units, tactic types, and tactic states (e.g., Interrupt, Resume). For tactic
captioning, we further incorporate a shot-wise prompt-guided mechanism, where
the predicted tactic type and state are embedded as prompts and injected into
the decoder via cross-attention. The shot-wise prompt-guided mechanism enables
our system not only to describe successfully executed tactics but also to
capture tactical executions that are temporarily interrupted and later resumed.
Experimental results demonstrate the effectiveness of our framework in
generating both shot and tactic captions. Ablation studies show that the
ResNet50-based spatio-temporal encoder outperforms other variants, and that
shot-wise prompt structuring leads to more coherent and accurate tactic
captioning.

</details>


### [54] [Efficient Video Sampling: Pruning Temporally Redundant Tokens for Faster VLM Inference](https://arxiv.org/abs/2510.14624)
*Natan Bagrov,Eugene Khvedchenia,Borys Tymchenko,Shay Aharon,Lior Kadoch,Tomer Keren,Ofri Masad,Yonatan Geifman,Ran Zilberstein,Tuomas Rintamaki,Matthieu Le,Andrew Tao*

Main category: cs.CV

TL;DR: 提出了一种名为EVS的高效视频采样方法，通过识别并剪枝连续帧中不变的时空区域来减少视频中的冗余token，显著提升推理效率，同时保持语义完整性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型在处理长视频时受限于密集帧序列带来的二次计算成本和token预算限制，导致上下文受限和延迟问题，亟需一种高效且无需重训练的方法来提升可扩展性。

Method: 提出EVS（Efficient Video Sampling），在推理时识别视频中时间上静态的图像块（即在连续帧中未变化的区域）并剪枝，保留位置信息，无需修改模型结构或重新训练，可作为即插即用组件。结合随机剪枝率的上训练阶段，增强模型对不同压缩程度的鲁棒性。

Result: EVS显著降低了token数量，在保持语义保真度的同时将大语言模型的首次生成时间（TTFT）最多减少4倍，且精度损失极小。在多种设置下均提升了效率与准确性的权衡表现。

Conclusion: EVS为视频语言理解提供了一种高效、灵活且无需重训练的token压缩方案，有效解决了长视频处理中的上下文限制与延迟问题，推动了可扩展的视频理解技术发展。

Abstract: Vision-language models (VLMs) have recently expanded from static image
understanding to video reasoning, but their scalability is fundamentally
limited by the quadratic cost of processing dense frame sequences. Long videos
often exceed the token budget of modern language models, leading to severe
context limitations and latency issues. We introduce Efficient Video Sampling
(EVS), a simple, plug-and-play method for reducing token redundancy in videos
by identifying and pruning temporally static patches -- spatial regions that
remain unchanged across consecutive frames. EVS preserves positional identity,
requires no architectural changes or retraining. We show that EVS substantially
reduces token count while maintaining semantic fidelity, enabling faster
inference and longer input sequences. Applied at inference time, EVS reduces
large language model (LLM) time-to-first-token (TTFT) by up to 4x with minimal
accuracy loss. When combined with an uptraining phase using stochastic pruning
rates, EVS yields models that are robust to varying compression levels and
retain full performance under aggressive pruning. Extensive experiments
demonstrate that EVS consistently improves efficiency-accuracy trade-offs,
unlocking scalable video-language understanding without sacrificing quality.

</details>


### [55] [Adapting Self-Supervised Representations as a Latent Space for Efficient Generation](https://arxiv.org/abs/2510.14630)
*Ming Gui,Johannes Schusterbauer,Timy Phan,Felix Krause,Josh Susskind,Miguel Angel Bautista,Björn Ommer*

Main category: cs.CV

TL;DR: RepTok 是一种生成建模框架，通过自监督视觉 Transformer 将图像表示为单个连续的潜在令牌，实现高效且高质量的图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型通常依赖复杂的二维潜在空间，存在空间冗余和高训练成本。本文旨在探索基于自监督学习（SSL）表征的更紧凑、高效的潜在空间用于生成建模。

Method: 在预训练的自监督学习编码器基础上，仅微调语义令牌嵌入，并将其与使用流匹配目标联合训练的生成解码器结合；引入余弦相似性损失以保持原始 SSL 空间的几何结构，确保潜在空间平滑。

Result: RepTok 在类别条件 ImageNet 生成任务上取得有竞争力的结果，并可自然扩展到文本到图像生成，在极低训练预算下于 MS-COCO 实现优秀的零样本生成性能。

Conclusion: 微调后的 SSL 表征可作为紧凑且有效的潜在空间，RepTok 的单令牌设计显著降低训练成本并消除空间冗余，展示了高效生成建模的新方向。

Abstract: We introduce Representation Tokenizer (RepTok), a generative modeling
framework that represents an image using a single continuous latent token
obtained from self-supervised vision transformers. Building on a pre-trained
SSL encoder, we fine-tune only the semantic token embedding and pair it with a
generative decoder trained jointly using a standard flow matching objective.
This adaptation enriches the token with low-level, reconstruction-relevant
details, enabling faithful image reconstruction. To preserve the favorable
geometry of the original SSL space, we add a cosine-similarity loss that
regularizes the adapted token, ensuring the latent space remains smooth and
suitable for generation. Our single-token formulation resolves spatial
redundancies of 2D latent spaces and significantly reduces training costs.
Despite its simplicity and efficiency, RepTok achieves competitive results on
class-conditional ImageNet generation and naturally extends to text-to-image
synthesis, reaching competitive zero-shot performance on MS-COCO under
extremely limited training budgets. Our findings highlight the potential of
fine-tuned SSL representations as compact and effective latent spaces for
efficient generative modeling.

</details>


### [56] [SteeringTTA: Guiding Diffusion Trajectories for Robust Test-Time-Adaptation](https://arxiv.org/abs/2510.14634)
*Jihyun Yu,Yoojin Oh,Wonho Bae,Mingyu Kim,Junhyug Noh*

Main category: cs.CV

TL;DR: SteeringTTA是一种无需模型更新或源数据的推理阶段框架，通过Feynman-Kac引导扩散输入适应，利用伪标签奖励优化分类在分布偏移下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的测试时适应方法依赖梯度引导，限制了对不同失真类型的探索与泛化能力，因此需要一种更灵活且有效的输入适应机制。

Method: 提出SteeringTTA框架，采用Feynman-Kac机制引导扩散过程，维护多个粒子轨迹，结合累积Top-K概率与熵调度策略，在推理阶段通过伪标签奖励来指导输入适应。

Result: 在ImageNet-C上，SteeringTTA持续优于基线方法，显著提升分类模型在各种腐蚀情形下的鲁棒性，且无需模型更新或源数据。

Conclusion: SteeringTTA通过引入轨迹引导与奖励机制，在不更新模型的情况下有效提升了扩散模型在分布偏移下的适应能力，展现出良好的泛化与探索平衡。

Abstract: Test-time adaptation (TTA) aims to correct performance degradation of deep
models under distribution shifts by updating models or inputs using unlabeled
test data. Input-only diffusion-based TTA methods improve robustness for
classification to corruptions but rely on gradient guidance, limiting
exploration and generalization across distortion types. We propose SteeringTTA,
an inference-only framework that adapts Feynman-Kac steering to guide
diffusion-based input adaptation for classification with rewards driven by
pseudo-label. SteeringTTA maintains multiple particle trajectories, steered by
a combination of cumulative top-K probabilities and an entropy schedule, to
balance exploration and confidence. On ImageNet-C, SteeringTTA consistently
outperforms the baseline without any model updates or source data.

</details>


### [57] [In-Context Learning with Unpaired Clips for Instruction-based Video Editing](https://arxiv.org/abs/2510.14648)
*Xinyao Liao,Xianfang Zeng,Ziye Song,Zhoujie Fu,Gang Yu,Guosheng Lin*

Main category: cs.CV

TL;DR: 提出一种低成本预训练策略，利用非配对视频片段进行上下文学习，实现基于指令的视频编辑，显著提升指令对齐和编辑质量。


<details>
  <summary>Details</summary>
Motivation: 由于构建大规模配对视频编辑数据集的成本和复杂性极高，指令型视频编辑发展受限，因此需要一种低成本、高效的预训练方法。

Method: 基于基础视频生成模型，利用约100万未配对真实视频片段进行预训练以学习基本编辑概念，再在少于15万精选配对数据上微调以扩展任务并提升质量。

Result: 在指令对齐和视觉保真度方面优于现有方法，指令遵循能力提升12%，编辑质量提升15%。

Conclusion: 该预训练策略能有效赋予模型通用视频编辑能力，且仅需少量高质量配对数据即可高效优化，推动了指令型视频编辑的发展。

Abstract: Despite the rapid progress of instruction-based image editing, its extension
to video remains underexplored, primarily due to the prohibitive cost and
complexity of constructing large-scale paired video editing datasets. To
address this challenge, we introduce a low-cost pretraining strategy for
instruction-based video editing that leverages in-context learning from
unpaired video clips. We show that pretraining a foundation video generation
model with this strategy endows it with general editing capabilities, such as
adding, replacing, or deleting operations, according to input editing
instructions. The pretrained model can then be efficiently refined with a small
amount of high-quality paired editing data. Built upon HunyuanVideoT2V, our
framework first pretrains on approximately 1M real video clips to learn basic
editing concepts, and subsequently fine-tunes on fewer than 150k curated
editing pairs to extend more editing tasks and improve the editing quality.
Comparative experiments show that our method surpasses existing
instruction-based video editing approaches in both instruction alignment and
visual fidelity, achieving a 12\% improvement in editing instruction following
and a 15\% improvement in editing quality.

</details>


### [58] [Decorrelation Speeds Up Vision Transformers](https://arxiv.org/abs/2510.14657)
*Kieran Carrigg,Rob van Gastel,Melda Yeghaian,Sander Dalm,Faysal Boughorbel,Marcel van Gerven*

Main category: cs.CV

TL;DR: 将去相关反向传播（DBP）引入MAE预训练，可在加速收敛的同时减少能耗并提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: MAE在视觉Transformer预训练中表现优异，但计算成本高，难以应用于资源受限的工业场景，因此需要一种高效且稳定的加速方法。

Method: 在MAE的编码器中选择性地引入Decorrelated Backpropagation（DBP），以逐层减少输入相关性，加速训练收敛，同时保持训练稳定性。

Result: 在ImageNet-1K预训练+ADE20K微调任务中，DBP-MAE将达到基线性能的训练时间减少21.1%，碳排放降低21.4%，分割mIoU提升1.1点；在工业私有数据上也取得类似增益。

Conclusion: DBP能有效减少大规模ViT预训练的时间和能耗，同时提升下游任务性能，具备实际应用价值。

Abstract: Masked Autoencoder (MAE) pre-training of vision transformers (ViTs) yields
strong performance in low-label regimes but comes with substantial
computational costs, making it impractical in time- and resource-constrained
industrial settings. We address this by integrating Decorrelated
Backpropagation (DBP) into MAE pre-training, an optimization method that
iteratively reduces input correlations at each layer to accelerate convergence.
Applied selectively to the encoder, DBP achieves faster pre-training without
loss of stability. On ImageNet-1K pre-training with ADE20K fine-tuning, DBP-MAE
reduces wall-clock time to baseline performance by 21.1%, lowers carbon
emissions by 21.4% and improves segmentation mIoU by 1.1 points. We observe
similar gains when pre-training and fine-tuning on proprietary industrial data,
confirming the method's applicability in real-world scenarios. These results
demonstrate that DBP can reduce training time and energy use while improving
downstream performance for large-scale ViT pre-training.

</details>


### [59] [EuroMineNet: A Multitemporal Sentinel-2 Benchmark for Spatiotemporal Mining Footprint Analysis in the European Union (2015-2024)](https://arxiv.org/abs/2510.14661)
*Weikang Yu,Vincent Nwazelibe,Xianping Ma,Xiaokang Zhang,Richard Gloaguen,Xiao Xiang Zhu,Pedram Ghamisi*

Main category: cs.CV

TL;DR: EuroMineNet是首个基于哨兵-2多光谱影像的欧盟范围内长期、多时相的采矿 footprint 监测基准数据集，支持可持续土地利用管理与环境治理。


<details>
  <summary>Details</summary>
Motivation: 现有采矿活动监测数据在时间深度和地理范围上存在局限，难以支持长期、一致的环境影响评估，亟需一个全面、权威的多时相数据集来推动GeoAI在可持续资源管理中的应用。

Method: 构建覆盖欧盟133个矿区、2015–2024年每年的遥感影像数据集，提供专家验证标注，定义两个任务：多时相采矿区制图与跨时相变化检测，并提出CA-TIoU评估指标。

Result: 基准测试20种前沿深度学习模型表明，GeoAI能有效识别长期环境变化，但在捕捉关键短期动态方面仍具挑战。

Conclusion: EuroMineNet推动了时间一致且可解释的采矿监测，有助于可持续土地管理与环境韧性建设，促进GeoAI服务于社会与环境福祉，且遵循FAIR与开放科学原则公开数据与代码。

Abstract: Mining activities are essential for industrial and economic development, but
remain a leading source of environmental degradation, contributing to
deforestation, soil erosion, and water contamination. Sustainable resource
management and environmental governance require consistent, long-term
monitoring of mining-induced land surface changes, yet existing datasets are
often limited in temporal depth or geographic scope. To address this gap, we
present EuroMineNet, the first comprehensive multitemporal benchmark for mining
footprint mapping and monitoring based on Sentinel-2 multispectral imagery.
Spanning 133 mining sites across the European Union, EuroMineNet provides
annual observations and expert-verified annotations from 2015 to 2024, enabling
GeoAI-based models to analyze environmental dynamics at a continental scale. It
supports two sustainability-driven tasks: (1) multitemporal mining footprint
mapping for consistent annual land-use delineation, evaluated with a novel
Change-Aware Temporal IoU (CA-TIoU) metric, and (2) cross-temporal change
detection to capture both gradual and abrupt surface transformations.
Benchmarking 20 state-of-the-art deep learning models reveals that while GeoAI
methods effectively identify long-term environmental changes, challenges remain
in detecting short-term dynamics critical for timely mitigation. By advancing
temporally consistent and explainable mining monitoring, EuroMineNet
contributes to sustainable land-use management, environmental resilience, and
the broader goal of applying GeoAI for social and environmental good. We
release the codes and datasets by aligning with FAIR and the open science
paradigm at https://github.com/EricYu97/EuroMineNet.

</details>


### [60] [WeCKD: Weakly-supervised Chained Distillation Network for Efficient Multimodal Medical Imaging](https://arxiv.org/abs/2510.14668)
*Md. Abdur Rahman,Mohaimenul Azam Khan Raiaan,Sami Azam,Asif Karim,Jemima Beissbarth,Amanda Leach*

Main category: cs.CV

TL;DR: 提出首个弱监督链式知识蒸馏网络WeCKD，通过模型链逐级传递并优化知识，在低数据场景下显著提升性能，超越传统监督方法。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏依赖强教师模型或大量标注数据，在数据受限的实际场景中效果有限，亟需减少数据依赖并提升知识传递效率。

Method: 构建一个链式结构的弱监督知识蒸馏框架（WeCKD），每个模型在仅使用部分数据的情况下从前一个模型学习并优化知识后传递给下一个模型。

Result: 在四个耳镜图像数据集上表现媲美甚至超越现有监督方法，在其他两种医学图像模态上也展现良好泛化性，相较单一骨干模型最高累计提升23%准确率。

Conclusion: WeCKD有效缓解了传统知识蒸馏对强教师和大数据的依赖，为低资源医学图像分析提供了高效、可推广的新范式。

Abstract: Knowledge distillation (KD) has traditionally relied on a static
teacher-student framework, where a large, well-trained teacher transfers
knowledge to a single student model. However, these approaches often suffer
from knowledge degradation, inefficient supervision, and reliance on either a
very strong teacher model or large labeled datasets, which limits their
effectiveness in real-world, limited-data scenarios. To address these, we
present the first-ever Weakly-supervised Chain-based KD network (WeCKD) that
redefines knowledge transfer through a structured sequence of interconnected
models. Unlike conventional KD, it forms a progressive distillation chain,
where each model not only learns from its predecessor but also refines the
knowledge before passing it forward. This structured knowledge transfer further
enhances feature learning, reduces data dependency, and mitigates the
limitations of one-step KD. Each model in the distillation chain is trained on
only a fraction of the dataset and demonstrates that effective learning can be
achieved with minimal supervision. Extensive evaluations across four otoscopic
imaging datasets demonstrate that it not only matches but in many cases
surpasses the performance of existing supervised methods. Experimental results
on two other datasets further underscore its generalization across diverse
medical imaging modalities, including microscopic and magnetic resonance
imaging. Furthermore, our evaluations resulted in cumulative accuracy gains of
up to +23% over a single backbone trained on the same limited data, which
highlights its potential for real-world adoption.

</details>


### [61] [VTimeCoT: Thinking by Drawing for Video Temporal Grounding and Reasoning](https://arxiv.org/abs/2510.14672)
*Jinglei Zhang,Yuanfan Guo,Rolandos Alexandros Potamias,Jiankang Deng,Hang Xu,Chao Ma*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的框架VTimeCoT，通过引入进度条视觉工具和时空链式推理，显著提升了多模态大模型在视频时序定位与推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态大语言模型的视频问答系统在视频时序定位和推理方面表现不足，限制了真实场景下的视频理解应用。受人类使用播放进度条理解视频的启发，本文旨在提升模型的时间感知与推理能力。

Method: 提出了VTimeCoT框架，包含两个视觉工具：即插即用的进度条集成工具和高效高亮工具，并引入了融合视频与文本跨模态推理的视觉时序链式思维（visuotemporal CoT）过程。

Result: 在Qwen2VL-7B和GPT4o基线上，VTimeCoT显著提升了视频时序定位和推理问答任务的性能，且推理过程具有组成性和可解释性。

Conclusion: VTimeCoT通过引入类人交互机制和跨模态推理流程，为多模态视频理解提供了一种高效、可解释且无需训练的新范式。

Abstract: In recent years, video question answering based on multimodal large language
models (MLLM) has garnered considerable attention, due to the benefits from the
substantial advancements in LLMs. However, these models have a notable
deficiency in the domains of video temporal grounding and reasoning, posing
challenges to the development of effective real-world video understanding
systems. Inspired by how humans use video players to interact with the progress
bar for video comprehension, we introduce VTimeCoT, a simple yet effective
training-free framework, designed for high-performance video grounding and
reasoning. The proposed framework incorporates two novel visual tools of the
progress bar: a plug-and-play progress bar integration tool and a
high-efficiency highlighting tool. In addition, to address the limitations of
conventional text-based chain-of-thought (CoT) approaches, we introduce a
visuotemporal CoT process that integrates cross-modality reasoning across both
video and text. Our approach demonstrates significant performance improvements
on both Qwen2VL-7B and GPT4o baselines in tasks of video temporal grounding and
reasoning-based question answering. Finally, we showcase that the proposed
framework achieves a compositional and interpretable reasoning process. Project
page: https://vtimecot.github.io

</details>


### [62] [Leveraging Learned Image Prior for 3D Gaussian Compression](https://arxiv.org/abs/2510.14705)
*Seungjoo Shin,Jaesik Park,Sunghyun Cho*

Main category: cs.CV

TL;DR: 提出了一种基于学习图像先验的3D高斯点阵压缩增强框架，通过在图像空间恢复压缩损失，显著提升率失真性能和渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯点阵压缩方法缺乏学习先验，限制了率失真权衡的进一步优化，难以在极低存储下保持高质量渲染。

Method: 构建一个恢复网络，在图像空间建模压缩引入的伪影；利用粗略渲染残差作为侧信息，并结合原始图像监督来优化压缩后的高斯参数。

Result: 在多个基准上显著优于当前最先进的3DGS压缩方法，实现更优的率失真性能，在更少存储下获得更高渲染质量。

Conclusion: 该框架可兼容现有压缩方法，有效利用学习先验提升压缩性能，为3DGS的高效存储与传输提供了新思路。

Abstract: Compression techniques for 3D Gaussian Splatting (3DGS) have recently
achieved considerable success in minimizing storage overhead for 3D Gaussians
while preserving high rendering quality. Despite the impressive storage
reduction, the lack of learned priors restricts further advances in the
rate-distortion trade-off for 3DGS compression tasks. To address this, we
introduce a novel 3DGS compression framework that leverages the powerful
representational capacity of learned image priors to recover
compression-induced quality degradation. Built upon initially compressed
Gaussians, our restoration network effectively models the compression artifacts
in the image space between degraded and original Gaussians. To enhance the
rate-distortion performance, we provide coarse rendering residuals into the
restoration network as side information. By leveraging the supervision of
restored images, the compressed Gaussians are refined, resulting in a highly
compact representation with enhanced rendering performance. Our framework is
designed to be compatible with existing Gaussian compression methods, making it
broadly applicable across different baselines. Extensive experiments validate
the effectiveness of our framework, demonstrating superior rate-distortion
performance and outperforming the rendering quality of state-of-the-art 3DGS
compression methods while requiring substantially less storage.

</details>


### [63] [Where are the Whales: A Human-in-the-loop Detection Method for Identifying Whales in High-resolution Satellite Imagery](https://arxiv.org/abs/2510.14709)
*Caleb Robinson,Kimberly T. Goetz,Christin B. Khan,Meredith Sackett,Kathleen Leonard,Rahul Dodhia,Juan M. Lavista Ferres*

Main category: cs.CV

TL;DR: 提出了一种基于统计异常检测的半自动化方法，在高分辨率卫星图像中高效发现潜在鲸鱼位置，显著减少需人工检查的区域，无需依赖标注训练数据，提升了大规模鲸群监测的可行性。


<details>
  <summary>Details</summary>
Motivation: 传统鲸类种群监测方法成本高、难以扩展，现有基于卫星图像的自动化检测因缺乏标注数据、图像质量差异和计算成本高等问题难以实现规模化应用。

Method: 采用统计异常检测方法识别图像中的空间离群点（即‘有趣点’），结合网页标注界面，辅助专家快速标注这些候选区域，构建半自动化检测流程。

Result: 在三个已知鲸鱼标注的基准场景中，召回率达到90.3%至96.4%，需专家检查的区域最多减少99.8%，从超过1000平方公里减少到不足2平方公里。

Conclusion: 该方法不依赖标注训练数据，可扩展性强，为未来基于卫星影像的机器辅助海洋哺乳动物监测提供了可复用的开源解决方案。

Abstract: Effective monitoring of whale populations is critical for conservation, but
traditional survey methods are expensive and difficult to scale. While prior
work has shown that whales can be identified in very high-resolution (VHR)
satellite imagery, large-scale automated detection remains challenging due to a
lack of annotated imagery, variability in image quality and environmental
conditions, and the cost of building robust machine learning pipelines over
massive remote sensing archives. We present a semi-automated approach for
surfacing possible whale detections in VHR imagery using a statistical anomaly
detection method that flags spatial outliers, i.e. "interesting points". We
pair this detector with a web-based labeling interface designed to enable
experts to quickly annotate the interesting points. We evaluate our system on
three benchmark scenes with known whale annotations and achieve recalls of
90.3% to 96.4%, while reducing the area requiring expert inspection by up to
99.8% -- from over 1,000 sq km to less than 2 sq km in some cases. Our method
does not rely on labeled training data and offers a scalable first step toward
future machine-assisted marine mammal monitoring from space. We have open
sourced this pipeline at https://github.com/microsoft/whales.

</details>


### [64] [Camera Movement Classification in Historical Footage: A Comparative Study of Deep Video Models](https://arxiv.org/abs/2510.14713)
*Tingyu Lin,Armin Dadras,Florian Kleber,Robert Sablatnig*

Main category: cs.CV

TL;DR: 首次系统评估深度视频相机运动分类模型在历史档案影片上的表现，发现现有模型在低质量视频上的适应性挑战与潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管近期相机运动分类方法在现代数据集上表现良好，但其在历史影像上的泛化能力尚未被探索。

Method: 总结代表性方法与数据集，采用五种标准视频分类模型在包含专家标注的二战影像的HISTORIAN数据集上进行评估。

Result: 表现最佳的Video Swin Transformer模型达到80.25%的准确率，尽管训练数据有限但仍表现出强收敛性。

Conclusion: 研究突显了将现有模型应用于低质量视频的挑战与潜力，推动未来结合多模态输入与时间架构的研究。

Abstract: Camera movement conveys spatial and narrative information essential for
understanding video content. While recent camera movement classification (CMC)
methods perform well on modern datasets, their generalization to historical
footage remains unexplored. This paper presents the first systematic evaluation
of deep video CMC models on archival film material. We summarize representative
methods and datasets, highlighting differences in model design and label
definitions. Five standard video classification models are assessed on the
HISTORIAN dataset, which includes expert-annotated World War II footage. The
best-performing model, Video Swin Transformer, achieves 80.25% accuracy,
showing strong convergence despite limited training data. Our findings
highlight the challenges and potential of adapting existing models to
low-quality video and motivate future work combining diverse input modalities
and temporal architectures.

</details>


### [65] [Cross-Layer Feature Self-Attention Module for Multi-Scale Object Detection](https://arxiv.org/abs/2510.14726)
*Dingzhou Xie,Rushi Lan,Cheng Pang,Enhao Ning,Jiahao Zeng,Wei Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种新的跨层特征自注意力模块（CFSAM），通过建模多尺度特征图中的局部和全局依赖关系，显著提升了目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有注意力机制多局限于单层或双层特征优化，忽略了多尺度特征间的深层依赖关系，难以有效处理尺度变化大的物体检测问题。

Method: 提出CFSAM模块，包含卷积局部特征提取器、基于Transformer的全局建模单元和特征融合机制，集成到SSD300框架中，实现跨层特征交互建模。

Result: 在PASCAL VOC数据集上达到78.6% mAP（基线75.5%），在COCO上达到52.1% mAP（基线43.1%），且训练收敛更快，计算开销低。

Conclusion: 显式建模跨层注意力对提升多尺度目标检测性能至关重要，CFSAM有效整合多尺度上下文信息，优于现有注意力模块。

Abstract: Recent object detection methods have made remarkable progress by leveraging
attention mechanisms to improve feature discriminability. However, most
existing approaches are confined to refining single-layer or fusing dual-layer
features, overlooking the rich inter-layer dependencies across multi-scale
representations. This limits their ability to capture comprehensive contextual
information essential for detecting objects with large scale variations. In
this paper, we propose a novel Cross-Layer Feature Self-Attention Module
(CFSAM), which holistically models both local and global dependencies within
multi-scale feature maps. CFSAM consists of three key components: a
convolutional local feature extractor, a Transformer-based global modeling unit
that efficiently captures cross-layer interactions, and a feature fusion
mechanism to restore and enhance the original representations. When integrated
into the SSD300 framework, CFSAM significantly boosts detection performance,
achieving 78.6% mAP on PASCAL VOC (vs. 75.5% baseline) and 52.1% mAP on COCO
(vs. 43.1% baseline), outperforming existing attention modules. Moreover, the
module accelerates convergence during training without introducing substantial
computational overhead. Our work highlights the importance of explicit
cross-layer attention modeling in advancing multi-scale object detection.

</details>


### [66] [Free-Grained Hierarchical Recognition](https://arxiv.org/abs/2510.14737)
*Seulki Park,Zilin Wang,Stella X. Yu*

Main category: cs.CV

TL;DR: 提出了一种新的方法Free-grain learning，用于处理分级图像分类中混合粒度标签的现实挑战，并构建了ImageNet-F基准进行评估。


<details>
  <summary>Details</summary>
Motivation: 现有的分层图像分类方法通常假设有完整的细粒度标注，但在现实中监督信号的粒度是不一致且变化的，因此需要更贴近实际的方法。

Method: 提出了Free-grain learning框架，支持实例间的异构监督；利用视觉-语言模型生成伪属性以增强语义指导，并结合半监督学习提升视觉指导。同时构建了ImageNet-F基准，模拟真实的混合粒度标注。

Result: 所提方法在ImageNet-F基准上显著优于现有基线，在混合监督条件下实现了更好的分层分类性能。

Conclusion: 该研究推进了在现实约束下的分层图像分类，为处理不规则标注粒度提供了有效解决方案。

Abstract: Hierarchical image classification predicts labels across a semantic taxonomy,
but existing methods typically assume complete, fine-grained annotations, an
assumption rarely met in practice. Real-world supervision varies in
granularity, influenced by image quality, annotator expertise, and task
demands; a distant bird may be labeled Bird, while a close-up reveals Bald
eagle. We introduce ImageNet-F, a large-scale benchmark curated from ImageNet
and structured into cognitively inspired basic, subordinate, and fine-grained
levels. Using CLIP as a proxy for semantic ambiguity, we simulate realistic,
mixed-granularity labels reflecting human annotation behavior. We propose
free-grain learning, with heterogeneous supervision across instances. We
develop methods that enhance semantic guidance via pseudo-attributes from
vision-language models and visual guidance via semi-supervised learning. These,
along with strong baselines, substantially improve performance under mixed
supervision. Together, our benchmark and methods advance hierarchical
classification under real-world constraints.

</details>


### [67] [DEXTER: Diffusion-Guided EXplanations with TExtual Reasoning for Vision Models](https://arxiv.org/abs/2510.14741)
*Simone Carnemolla,Matteo Pennisi,Sarinda Samarasinghe,Giovanni Bellitto,Simone Palazzo,Daniela Giordano,Mubarak Shah,Concetto Spampinato*

Main category: cs.CV

TL;DR: DEXTER 是一种无需训练数据的框架，利用扩散模型和大语言模型生成视觉分类器的全局文本解释，能有效揭示模型决策机制和类别级偏差。


<details>
  <summary>Details</summary>
Motivation: 为了提升机器学习模型的透明性和可信度，需要在无训练数据和真实标签的情况下对视觉分类器进行解释。

Method: DEXTER 通过优化文本提示生成类别条件图像以激活目标分类器，并利用合成样本通过大语言模型生成描述分类决策模式和偏差的自然语言报告。

Result: 在 ImageNet、Waterbirds、CelebA 和 FairFaces 上的实验表明，DEXTER 在全局模型解释和类别级偏差报告方面优于现有方法，用户研究也验证了其输出的准确性和可解释性。

Conclusion: DEXTER 能有效实现数据无关的视觉模型解释，支持激活最大化、切片发现与去偏、偏差解释等任务，具有良好的灵活性和应用前景。

Abstract: Understanding and explaining the behavior of machine learning models is
essential for building transparent and trustworthy AI systems. We introduce
DEXTER, a data-free framework that employs diffusion models and large language
models to generate global, textual explanations of visual classifiers. DEXTER
operates by optimizing text prompts to synthesize class-conditional images that
strongly activate a target classifier. These synthetic samples are then used to
elicit detailed natural language reports that describe class-specific decision
patterns and biases. Unlike prior work, DEXTER enables natural language
explanation about a classifier's decision process without access to training
data or ground-truth labels. We demonstrate DEXTER's flexibility across three
tasks-activation maximization, slice discovery and debiasing, and bias
explanation-each illustrating its ability to uncover the internal mechanisms of
visual classifiers. Quantitative and qualitative evaluations, including a user
study, show that DEXTER produces accurate, interpretable outputs. Experiments
on ImageNet, Waterbirds, CelebA, and FairFaces confirm that DEXTER outperforms
existing approaches in global model explanation and class-level bias reporting.
Code is available at https://github.com/perceivelab/dexter.

</details>


### [68] [LightQANet: Quantized and Adaptive Feature Learning for Low-Light Image Enhancement](https://arxiv.org/abs/2510.14753)
*Xu Wu,Zhihui Lai,Xianxu Hou,Jie Zhou,Ya-nan Zhang,Linlin Shen*

Main category: cs.CV

TL;DR: 本文提出LightQANet，通过量化和自适应特征学习提升低光照图像的增强效果，有效改善纹理恢复、色彩一致性和伪影问题。


<details>
  <summary>Details</summary>
Motivation: 现有低光照图像增强方法因退化的像素信息难以提取可靠特征，导致纹理恢复差、颜色不一致和伪影，本文旨在提升特征表示的一致性和鲁棒性。

Method: 提出LightQANet框架，包含Light Quantization Module（LQM）用于显式量化光照相关因子，学习光照不变特征；以及Light-Aware Prompt Module（LAPM）通过可学习提示编码光照先验，动态引导特征学习。

Result: 在多个低光数据集上实验表明，该方法在定性和定量指标上均达到最先进的性能，尤其在复杂多变光照条件下表现优异。

Conclusion: LightQANet通过静态量化与动态适应的结合，实现了跨不同光照条件下的高质量、一致性图像增强，显著优于现有方法。

Abstract: Low-light image enhancement (LLIE) aims to improve illumination while
preserving high-quality color and texture. However, existing methods often fail
to extract reliable feature representations due to severely degraded
pixel-level information under low-light conditions, resulting in poor texture
restoration, color inconsistency, and artifact. To address these challenges, we
propose LightQANet, a novel framework that introduces quantized and adaptive
feature learning for low-light enhancement, aiming to achieve consistent and
robust image quality across diverse lighting conditions. From the static
modeling perspective, we design a Light Quantization Module (LQM) to explicitly
extract and quantify illumination-related factors from image features. By
enforcing structured light factor learning, LQM enhances the extraction of
light-invariant representations and mitigates feature inconsistency across
varying illumination levels. From the dynamic adaptation perspective, we
introduce a Light-Aware Prompt Module (LAPM), which encodes illumination priors
into learnable prompts to dynamically guide the feature learning process. LAPM
enables the model to flexibly adapt to complex and continuously changing
lighting conditions, further improving image enhancement. Extensive experiments
on multiple low-light datasets demonstrate that our method achieves
state-of-the-art performance, delivering superior qualitative and quantitative
results across various challenging lighting scenarios.

</details>


### [69] [Inpainting the Red Planet: Diffusion Models for the Reconstruction of Martian Environments in Virtual Reality](https://arxiv.org/abs/2510.14765)
*Giuseppe Lorenzo Catalano,Agata Marta Soccini*

Main category: cs.CV

TL;DR: 提出了一种基于无条件扩散模型的方法来重建火星表面，利用NASA的HiRISE数据集进行训练，并在空洞填充任务中显著优于传统插值方法。


<details>
  <summary>Details</summary>
Motivation: 火星地形数据常存在缺失值，传统插值方法难以保持几何一致性，且无法应用地球上的条件深度学习方法，因此需要一种适用于火星的高效无监督重建方法。

Method: 采用无条件扩散模型，使用12000张来自NASA HiRISE调查的火星高程图进行训练，并通过非均匀重缩放策略保留多尺度地形特征，输入统一调整为128x128分辨率。

Result: 在1000个样本的测试集上，该方法相较于反距离权重、克里金和Navier-Stokes等方法，在重建精度上RMSE提升4-15%，在感知相似性LPIPS上提升29-81%。

Conclusion: 所提出的无条件扩散模型在火星地形空洞填充任务中表现出色，能够生成几何更一致且视觉更真实的地形重建结果，具有应用于行星表面模拟与任务规划的潜力。

Abstract: Space exploration increasingly relies on Virtual Reality for several tasks,
such as mission planning, multidisciplinary scientific analysis, and astronaut
training. A key factor for the reliability of the simulations is having
accurate 3D representations of planetary terrains. Extraterrestrial heightmaps
derived from satellite imagery often contain missing values due to acquisition
and transmission constraints. Mars is among the most studied planets beyond
Earth, and its extensive terrain datasets make the Martian surface
reconstruction a valuable task, although many areas remain unmapped. Deep
learning algorithms can support void-filling tasks; however, whereas Earth's
comprehensive datasets enables the use of conditional methods, such approaches
cannot be applied to Mars. Current approaches rely on simpler interpolation
techniques which, however, often fail to preserve geometric coherence. In this
work, we propose a method for reconstructing the surface of Mars based on an
unconditional diffusion model. Training was conducted on an augmented dataset
of 12000 Martian heightmaps derived from NASA's HiRISE survey. A
non-homogeneous rescaling strategy captures terrain features across multiple
scales before resizing to a fixed 128x128 model resolution. We compared our
method against established void-filling and inpainting techniques, including
Inverse Distance Weighting, kriging, and Navier-Stokes algorithm, on an
evaluation set of 1000 samples. Results show that our approach consistently
outperforms these methods in terms of reconstruction accuracy (4-15% on RMSE)
and perceptual similarity (29-81% on LPIPS) with the original data.

</details>


### [70] [MoCom: Motion-based Inter-MAV Visual Communication Using Event Vision and Spiking Neural Networks](https://arxiv.org/abs/2510.14770)
*Zhang Nengbo,Hann Woei Ho,Ye Zhou*

Main category: cs.CV

TL;DR: 提出一种受蜜蜂摇摆舞启发的视觉通信框架，利用运动信号和事件相机实现微小无人机群在受限环境中的低功耗可靠通信。


<details>
  <summary>Details</summary>
Motivation: 传统无线电通信在频谱拥塞、干扰和高功耗环境下难以支持微型无人机群的可靠通信，需寻找更高效、节能的替代方案。

Method: 设计基于四种飞行模式（上下、左右、左上右、左下右）的视觉码本，通过事件相机捕获飞行动作，结合事件帧分割模型与轻量级脉冲神经网络（SNN）进行动作识别，并集成解码算法解析运动序列。

Result: 实验结果表明该框架能准确解码飞行信号，具备低功耗优势，适合资源受限环境下的无人机群通信。

Conclusion: 该视觉通信框架为微型无人机群在复杂电磁环境下的高效、节能通信提供了可行方案，具有实际应用潜力。

Abstract: Reliable communication in Micro Air Vehicle (MAV) swarms is challenging in
environments, where conventional radio-based methods suffer from spectrum
congestion, jamming, and high power consumption. Inspired by the waggle dance
of honeybees, which efficiently communicate the location of food sources
without sound or contact, we propose a novel visual communication framework for
MAV swarms using motion-based signaling. In this framework, MAVs convey
information, such as heading and distance, through deliberate flight patterns,
which are passively captured by event cameras and interpreted using a
predefined visual codebook of four motion primitives: vertical (up/down),
horizontal (left/right), left-to-up-to-right, and left-to-down-to-right,
representing control symbols (``start'', ``end'', ``1'', ``0''). To decode
these signals, we design an event frame-based segmentation model and a
lightweight Spiking Neural Network (SNN) for action recognition. An integrated
decoding algorithm then combines segmentation and classification to robustly
interpret MAV motion sequences. Experimental results validate the framework's
effectiveness, which demonstrates accurate decoding and low power consumption,
and highlights its potential as an energy-efficient alternative for MAV
communication in constrained environments.

</details>


### [71] [CoT-PL: Visual Chain-of-Thought Reasoning Meets Pseudo-Labeling for Open-Vocabulary Object Detection](https://arxiv.org/abs/2510.14792)
*Hojun Choi,Youngsun Lim,Jaeyo Shin,Hyunjung Shim*

Main category: cs.CV

TL;DR: 本文提出CoT-PL框架，通过结构化的视觉思维链推理和对比背景学习，提升开放词汇目标检测中伪标签的质量，尤其在拥挤或遮挡场景下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉-语言模型的开放词汇目标检测方法依赖直接图像-文本匹配，缺乏对复杂语义场景的中间推理过程，导致在拥挤或遮挡场景中鲁棒性差。

Method: 提出CoT-PL框架，将对象理解分解为三个步骤：区域感知、零样本类别识别和背景 grounding；引入对比背景学习（CBL），利用背景线索作为负样本促进对象与背景的特征解耦。

Result: 在开放词汇COCO上新类别AP50提升+7.7，在LVIS上新类别mask AP提升+2.9；在拥挤和遮挡场景下，伪标签质量相对最优先前方法分别提高103.4%和168.4%。

Conclusion: CoT-PL通过引入结构化推理和对比背景学习，显著提升了复杂场景下的开放词汇目标检测性能，树立了新的最先进水平。

Abstract: Open-vocabulary object detection (OVD) seeks to recognize and localize object
categories beyond those seen during training. Recent approaches typically
leverage vision-language models (VLMs) to generate pseudo-labels using
image-text alignment, allowing detectors to generalize to unseen classes
without explicit supervision. However, these methods depend heavily on direct
image-text matching, neglecting the intermediate reasoning steps essential for
interpreting semantically complex scenes. This results in limited robustness
when confronted with crowded or occluded visual contexts. In this paper, we
introduce CoT-PL, a new framework that employs structured visual
chain-of-thought (CoT) reasoning into the pseudo-labeling process. CoT-PL
decomposes object understanding into three interpretable steps: (1) region
perception even for unseen objects, (2) category recognition via zero-shot
reasoning, and (3) background grounding to separate semantically complex
objects. Crucially, the third step naturally motivates our contrastive
background learning (CBL) that uses the pre-computed background cues as
negatives to promote feature disentanglement between objects and background. In
this way, CoT reasoning and CBL form an integrated pipeline tailored to robust
pseudo-labeling in crowded or occluded scenes. Notably, in these two settings,
our novel-class pseudo-label quality achieves relative improvements of 103.4%
and 168.4% over the best prior, respectively. Our extensive experiments
demonstrate that CoT-PL achieves +7.7 AP50 on open-vocabulary COCO and +2.9
mask AP on LVIS for novel classes, setting a new state of the art.

</details>


### [72] [Morphology-Aware Prognostic model for Five-Year Survival Prediction in Colorectal Cancer from H&E Whole Slide Images](https://arxiv.org/abs/2510.14800)
*Usama Sajjad,Abdul Rehman Akbar,Ziyu Su,Deborah Knight,Wendy L. Frankel,Metin N. Gurcan,Wei Chen,Muhammad Khalid Khan Niazi*

Main category: cs.CV

TL;DR: PRISM是一种新型可解释AI模型，通过整合结直肠癌组织形态的连续变异性谱，准确预测患者预后，性能优于现有方法和基础AI模型。


<details>
  <summary>Details</summary>
Motivation: 现有基础AI模型在计算病理学中多为任务无关方法，可能忽略器官特异性的关键形态学模式，影响对肿瘤行为、治疗反应和患者预后的准确判断。

Method: 提出PRISM模型，结合空间形态的连续变异谱以捕捉肿瘤表型多样性，基于424例III期结直肠癌患者的874万张组织图像进行训练，强调恶性转化的渐进演化过程。

Result: PRISM在五年总生存预测上表现优异（AUC=0.70，准确率68.37%，HR=3.34，p<0.0001），比现有CRC特异性方法准确率提高15%，比AI基础模型高约23%；具有性别无关的稳健性，并在不同临床病理亚组和化疗方案间表现稳定。

Conclusion: PRISM通过建模形态连续变异显著提升了结直肠癌预后预测的准确性与鲁棒性，为个性化治疗提供潜在支持。

Abstract: Colorectal cancer (CRC) remains the third most prevalent malignancy globally,
with approximately 154,000 new cases and 54,000 projected deaths anticipated
for 2025. The recent advancement of foundation models in computational
pathology has been largely propelled by task agnostic methodologies that can
overlook organ-specific crucial morphological patterns that represent distinct
biological processes that can fundamentally influence tumor behavior,
therapeutic response, and patient outcomes. The aim of this study is to develop
a novel, interpretable AI model, PRISM (Prognostic Representation of Integrated
Spatial Morphology), that incorporates a continuous variability spectrum within
each distinct morphology to characterize phenotypic diversity and reflecting
the principle that malignant transformation occurs through incremental
evolutionary processes rather than abrupt phenotypic shifts. PRISM is trained
on 8.74 million histological images extracted from surgical resection specimens
of 424 patients with stage III CRC. PRISM achieved superior prognostic
performance for five-year OS (AUC = 0.70 +- 0.04; accuracy = 68.37% +- 4.75%;
HR = 3.34, 95% CI = 2.28-4.90; p < 0.0001), outperforming existing CRC-specific
methods by 15% and AI foundation models by ~23% accuracy. It showed
sex-agnostic robustness (AUC delta = 0.02; accuracy delta = 0.15%) and stable
performance across clinicopathological subgroups, with minimal accuracy
fluctuation (delta = 1.44%) between 5FU/LV and CPT-11/5FU/LV regimens,
replicating the Alliance cohort finding of no survival difference between
treatments.

</details>


### [73] [Scaling Artificial Intelligence for Multi-Tumor Early Detection with More Reports, Fewer Masks](https://arxiv.org/abs/2510.14803)
*Pedro R. A. S. Bassi,Xinze Zhou,Wenxuan Li,Szymon Płotka,Jieneng Chen,Qi Chen,Zheren Zhu,Jakub Prządo,Ibrahim E. Hamacı,Sezgin Er,Yuhan Wang,Ashwin Kumar,Bjoern Menze,Jarosław B. Ćwikła,Yuyin Zhou,Akshay S. Chaudhari,Curtis P. Langlotz,Sergio Decherchi,Andrea Cavalli,Kang Wang,Yang Yang,Alan L. Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: 本文提出R-Super方法，利用大量现有的医学报告训练AI模型进行肿瘤分割，显著减少对人工标注肿瘤掩膜的依赖，在多种肿瘤类型上达到甚至超过放射科医生的检测性能。


<details>
  <summary>Details</summary>
Motivation: 早期肿瘤检测对挽救生命至关重要，但现有AI模型训练依赖昂贵且耗时的人工绘制肿瘤掩膜。而临床CT扫描普遍附带的医学报告中包含丰富且未被充分利用的肿瘤描述信息， motivate了利用这些报告进行AI训练的新方法。

Method: 提出R-Super方法，通过将医学报告中的肿瘤描述（如大小、数量、外观等）与CT图像关联，训练AI模型实现肿瘤分割，无需大量手动标注掩膜。模型在101,654份报告上训练，并可结合少量掩膜数据进行联合训练。

Result: 仅用报告训练的模型性能与使用723个掩膜训练的模型相当；报告与掩膜结合使灵敏度提升+13%，特异性提升+8%，在七种肿瘤中的五种上超过放射科医生。R-Super首次实现了脾脏、胆囊、前列腺、膀胱、子宫和食管肿瘤的自动分割，这些部位此前无公开掩膜或AI模型。

Conclusion: 研究表明大规模人工标注肿瘤掩膜并非AI训练的唯一途径，利用现成的医学报告可建立可扩展、可访问的多类型肿瘤早期检测路径，挑战了传统依赖人工标注的范式。

Abstract: Early tumor detection save lives. Each year, more than 300 million computed
tomography (CT) scans are performed worldwide, offering a vast opportunity for
effective cancer screening. However, detecting small or early-stage tumors on
these CT scans remains challenging, even for experts. Artificial intelligence
(AI) models can assist by highlighting suspicious regions, but training such
models typically requires extensive tumor masks--detailed, voxel-wise outlines
of tumors manually drawn by radiologists. Drawing these masks is costly,
requiring years of effort and millions of dollars. In contrast, nearly every CT
scan in clinical practice is already accompanied by medical reports describing
the tumor's size, number, appearance, and sometimes, pathology
results--information that is rich, abundant, and often underutilized for AI
training. We introduce R-Super, which trains AI to segment tumors that match
their descriptions in medical reports. This approach scales AI training with
large collections of readily available medical reports, substantially reducing
the need for manually drawn tumor masks. When trained on 101,654 reports, AI
models achieved performance comparable to those trained on 723 masks. Combining
reports and masks further improved sensitivity by +13% and specificity by +8%,
surpassing radiologists in detecting five of the seven tumor types. Notably,
R-Super enabled segmentation of tumors in the spleen, gallbladder, prostate,
bladder, uterus, and esophagus, for which no public masks or AI models
previously existed. This study challenges the long-held belief that
large-scale, labor-intensive tumor mask creation is indispensable, establishing
a scalable and accessible path toward early detection across diverse tumor
types.
  We plan to release our trained models, code, and dataset at
https://github.com/MrGiovanni/R-Super

</details>


### [74] [Unifying Environment Perception and Route Choice Modeling for Trajectory Representation Learning](https://arxiv.org/abs/2510.14819)
*Ji Cao,Yu Wang,Tongya Zheng,Zujie Ren,Canghong Jin,Gang Chen,Mingli Song*

Main category: cs.CV

TL;DR: 提出了一种新的轨迹表示学习框架PRTraj，通过整合环境感知和路径选择建模来更好地捕捉轨迹形成的内外因素，提升了下游任务的性能。



<details>
  <summary>Details</summary>
Motivation: 现有轨迹表示学习方法忽略了影响轨迹形成的外部环境和内部路径选择行为，导致表示能力受限。PRTraj旨在通过引入环境感知和显式路径选择建模来弥补这一不足。


Method: PRTraj包含两个核心模块：1）环境感知模块，通过捕捉周围POI分布的多粒度环境语义来增强路网；2）路径选择编码器，将轨迹中的路段转移建模为一系列决策行为，从而获得路径选择感知的表示，最终聚合为全局轨迹嵌入。


Result: 在3个真实世界数据集上的5个下游任务中，PRTraj显著优于现有方法，并展现出强数据效率，在少样本场景下仍保持良好性能。


Conclusion: PRTraj通过统一环境感知与路径选择建模，有效提升了轨迹表示的质量和泛化能力，为轨迹数据分析提供了新思路。

Abstract: Trajectory Representation Learning (TRL) aims to encode raw trajectories into
low-dimensional vectors, which can then be leveraged in various downstream
tasks, including travel time estimation, location prediction, and trajectory
similarity analysis. However, existing TRL methods suffer from a key oversight:
treating trajectories as isolated spatio-temporal sequences, without
considering the external environment and internal route choice behavior that
govern their formation. To bridge this gap, we propose a novel framework that
unifies comprehensive environment \textbf{P}erception and explicit
\textbf{R}oute choice modeling for effective \textbf{Traj}ectory representation
learning, dubbed \textbf{PRTraj}. Specifically, PRTraj first introduces an
Environment Perception Module to enhance the road network by capturing
multi-granularity environmental semantics from surrounding POI distributions.
Building on this environment-aware backbone, a Route Choice Encoder then
captures the route choice behavior inherent in each trajectory by modeling its
constituent road segment transitions as a sequence of decisions. These
route-choice-aware representations are finally aggregated to form the global
trajectory embedding. Extensive experiments on 3 real-world datasets across 5
downstream tasks validate the effectiveness and generalizability of PRTraj.
Moreover, PRTraj demonstrates strong data efficiency, maintaining robust
performance under few-shot scenarios. Our code is available at:
https://anonymous.4open.science/r/PRTraj.

</details>


### [75] [FraQAT: Quantization Aware Training with Fractional bits](https://arxiv.org/abs/2510.14823)
*Luca Morreale,Alberto Gil C. P. Ramos,Malcolm Chadwick,Mehid Noroozi,Ruchika Chavhan,Abhinav Mehrotra,Sourav Bhattacharya*

Main category: cs.CV

TL;DR: 提出了一种新的分段量化方法（fractional bits quantization），可在4-32位间逐步降低模型精度，利用优化中的小数位保持生成质量，显著优于标准QAT，并成功在三星手机上部署扩散模型Sana。


<details>
  <summary>Details</summary>
Motivation: 大型生成模型因内存和计算资源限制难以在智能手机上部署，现有激进量化方法虽提升效率但损害生成质量，需在低比特下维持模型性能。

Method: 提出分段比特量化（fractional bits quantization），在优化过程中动态利用小数位信息，逐步从32位降低至4位，以保持生成质量。

Result: 在SD3.5-Medium、Sana、Pixart和FLUX.1-schnell等多种扩散模型上验证，相比标准QAT降低4-7%的FiD分数，生成质量更高。

Conclusion: 该方法在保证生成质量的同时显著压缩模型，成功实现扩散模型在移动端（如三星S25U）的高效部署。

Abstract: State-of-the-art (SOTA) generative models have demonstrated impressive
capabilities in image synthesis or text generation, often with a large capacity
model. However, these large models cannot be deployed on smartphones due to the
limited availability of on-board memory and computations. Quantization methods
lower the precision of the model parameters, allowing for efficient
computations, \eg, in \INT{8}. Although aggressive quantization addresses
efficiency and memory constraints, preserving the quality of the model remains
a challenge. To retain quality in previous aggressive quantization, we propose
a new fractional bits quantization (\short) approach. The novelty is a simple
yet effective idea: we progressively reduce the model's precision from 32 to 4
bits per parameter, and exploit the fractional bits during optimization to
maintain high generation quality. We show that the \short{} yields improved
quality on a variety of diffusion models, including SD3.5-Medium, Sana,
\pixart, and FLUX.1-schnell, while achieving $4-7\%$ lower FiD than standard
QAT. Finally, we deploy and run Sana on a Samsung S25U, which runs on the
Qualcomm SM8750-AB Snapdragon 8 Elite Hexagon Tensor Processor (HTP).

</details>


### [76] [Scaling Tumor Segmentation: Best Lessons from Real and Synthetic Data](https://arxiv.org/abs/2510.14831)
*Qi Chen,Xinze Zhou,Chen Liu,Hao Chen,Wenxuan Li,Zekun Jiang,Ziyan Huang,Yuxuan Zhao,Dexin Yu,Junjun He,Yefeng Zheng,Ling Shao,Alan Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: 合成数据可显著提升AI肿瘤分割模型的训练效率，仅用500例真实扫描即可达到使用1500例的真实数据性能。基于此，AbdomenAtlas 2.0构建了一个大型腹部肿瘤标注数据集，包含10,135例CT扫描和15,130个肿瘤实例，标注范围覆盖六种器官，显著优于现有公开数据集。


<details>
  <summary>Details</summary>
Motivation: 现有AI肿瘤分割研究受限于缺乏大规模、逐体素标注的数据集，而真实医学标注成本高、耗时长。为突破数据瓶颈，探索合成数据对模型训练效率的影响，并构建更大规模的公开数据集以推动领域发展。

Method: 基于自有JHH数据集（3000例胰腺肿瘤扫描）分析数据规模与模型性能关系，并引入合成数据进行训练效率对比；随后构建AbdomenAtlas 2.0数据集，包含10,135例CT扫描的逐体素人工标注，覆盖六种器官，由23名放射科专家完成标注。

Result: 在JHH数据中发现模型性能在1500例后趋于饱和，而结合合成数据仅需500例真实数据即可达到相同性能；AbdomenAtlas 2.0显著优于现有公开数据集，在分布内测试中DSC提升+7%，分布外测试中提升+16%。

Conclusion: 合成数据可有效缓解医学图像标注的数据瓶颈，提升模型训练效率；AbdomenAtlas 2.0作为目前最大规模的腹部肿瘤标注数据集之一，为多器官肿瘤分割AI模型的训练与评估提供了坚实基础。

Abstract: AI for tumor segmentation is limited by the lack of large, voxel-wise
annotated datasets, which are hard to create and require medical experts. In
our proprietary JHH dataset of 3,000 annotated pancreatic tumor scans, we found
that AI performance stopped improving after 1,500 scans. With synthetic data,
we reached the same performance using only 500 real scans. This finding
suggests that synthetic data can steepen data scaling laws, enabling more
efficient model training than real data alone. Motivated by these lessons, we
created AbdomenAtlas 2.0--a dataset of 10,135 CT scans with a total of 15,130
tumor instances per-voxel manually annotated in six organs (pancreas, liver,
kidney, colon, esophagus, and uterus) and 5,893 control scans. Annotated by 23
expert radiologists, it is several orders of magnitude larger than existing
public tumor datasets. While we continue expanding the dataset, the current
version of AbdomenAtlas 2.0 already provides a strong foundation--based on
lessons from the JHH dataset--for training AI to segment tumors in six organs.
It achieves notable improvements over public datasets, with a +7% DSC gain on
in-distribution tests and +16% on out-of-distribution tests.

</details>


### [77] [QDepth-VLA: Quantized Depth Prediction as Auxiliary Supervision for Vision-Language-Action Models](https://arxiv.org/abs/2510.14836)
*Yixuan Li,Yuhui Chen,Mingcai Zhou,Haoran Li*

Main category: cs.CV

TL;DR: QDepth-VLA 是一种增强视觉-语言-动作模型空间感知能力的通用框架，通过引入量化深度预测任务提升对3D结构的理解，从而改善精细操作任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作（VLA）模型在精细操作任务中缺乏对关键3D结构的理解与推理能力，限制了其空间感知精度。

Method: 提出 QDepth-VLA 框架，通过添加辅助的深度预测任务，训练一个专门的深度专家模型来预测由 VQ-VAE 编码器生成的深度图的量化潜在标记，从而使模型学习到包含几何信息的深度感知表征。

Result: 在仿真基准和真实世界任务上的实验表明，QDepth-VLA 在空间推理方面表现优异，在操作任务中取得具有竞争力的性能。

Conclusion: 通过引入量化深度预测任务，QDepth-VLA 有效增强了 VLA 模型的三维空间理解能力，适用于需要精细空间推理的复杂操作任务。

Abstract: Spatial perception and reasoning are crucial for Vision-Language-Action (VLA)
models to accomplish fine-grained manipulation tasks. However, existing
approaches often lack the ability to understand and reason over the essential
3D structures necessary for precise control. To address this limitation, we
propose QDepth-VLA, a general framework that augments VLA models with an
auxiliary depth prediction task. A dedicated depth expert is designed to
predict quantized latent tokens of depth maps obtained from a VQ-VAE encoder,
enabling the model to learn depth-aware representations that capture critical
geometric cues. Experimental results on the simulation benchmarks and
real-world tasks demonstrate that QDepth-VLA yields strong spatial reasoning
and competitive performance on manipulation tasks.

</details>


### [78] [ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints](https://arxiv.org/abs/2510.14847)
*Meiqi Wu,Jiashu Zhu,Xiaokun Feng,Chubin Chen,Chen Zhu,Bingze Song,Fangyuan Mao,Jiahong Wu,Xiangxiang Chu,Kaiqi Huang*

Main category: cs.CV

TL;DR: 提出ImagerySearch，一种基于提示语义关系动态调整推理搜索空间和奖励函数的自适应测试时搜索策略，并发布LDT-Bench，首个面向长距离语义概念对的视频生成评测基准。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在现实场景中表现优异，但在涉及罕见共现概念和长距离语义关系的想象场景中表现下降；现有测试时扩展方法因固定搜索空间和静态奖励机制难以适应此类复杂提示。

Method: 提出ImagerySearch，一种提示引导的自适应测试时搜索策略，根据提示中的语义关系动态调整推理过程中的搜索空间与奖励函数，提升生成视频在想象场景下的连贯性与视觉合理性。

Result: 在新提出的LDT-Bench（含2,839个长距离语义概念对）上，ImagerySearch显著优于强基线模型和现有测试时扩展方法，同时在VBench上也取得具有竞争力的表现。

Conclusion: ImagerySearch能有效提升视频生成模型在想象性场景中的表现，LDT-Bench为评估创造性视频生成能力提供了新标准；将公开基准与代码以推动该领域发展。

Abstract: Video generation models have achieved remarkable progress, particularly
excelling in realistic scenarios; however, their performance degrades notably
in imaginative scenarios. These prompts often involve rarely co-occurring
concepts with long-distance semantic relationships, falling outside training
distributions. Existing methods typically apply test-time scaling for improving
video quality, but their fixed search spaces and static reward designs limit
adaptability to imaginative scenarios. To fill this gap, we propose
ImagerySearch, a prompt-guided adaptive test-time search strategy that
dynamically adjusts both the inference search space and reward function
according to semantic relationships in the prompt. This enables more coherent
and visually plausible videos in challenging imaginative settings. To evaluate
progress in this direction, we introduce LDT-Bench, the first dedicated
benchmark for long-distance semantic prompts, consisting of 2,839 diverse
concept pairs and an automated protocol for assessing creative generation
capabilities. Extensive experiments show that ImagerySearch consistently
outperforms strong video generation baselines and existing test-time scaling
approaches on LDT-Bench, and achieves competitive improvements on VBench,
demonstrating its effectiveness across diverse prompt types. We will release
LDT-Bench and code to facilitate future research on imaginative video
generation.

</details>


### [79] [A Multi-Task Deep Learning Framework for Skin Lesion Classification, ABCDE Feature Quantification, and Evolution Simulation](https://arxiv.org/abs/2510.14855)
*Harsha Kotla,Arun Kumar Rajasekaran,Hannah Rana*

Main category: cs.CV

TL;DR: 提出一种可解释的深度学习框架，用于皮肤病变分类并量化ABCD特征，模拟其演化过程以辅助黑色素瘤早期检测。


<details>
  <summary>Details</summary>
Motivation: 黑色素瘤早期检测对提高生存率至关重要，但现有深度学习方法多为黑箱模型，缺乏对临床可解释特征（如ABCDE准则）的有效利用。

Method: 构建一个深度学习框架，不仅分类皮肤病变，还分别量化A（不对称）、B（边界不规则）、C（颜色变化）、D（直径）特征，并通过特征在潜空间中的轨迹模拟E（演化）过程。

Result: 在HAM10000数据集上达到约89%的分类准确率，黑色素瘤的AUC为0.96；对A、C、D特征预测效果较好，B特征建模仍具挑战。

Conclusion: 该框架将深度学习与临床可解释特征结合，有助于医生理解模型决策，促进皮肤癌进展机制的研究。

Abstract: Early detection of melanoma has grown to be essential because it
significantly improves survival rates, but automated analysis of skin lesions
still remains challenging. ABCDE, which stands for Asymmetry, Border
irregularity, Color variation, Diameter, and Evolving, is a well-known
classification method for skin lesions, but most deep learning mechanisms treat
it as a black box, as most of the human interpretable features are not
explained. In this work, we propose a deep learning framework that both
classifies skin lesions into categories and also quantifies scores for each
ABCD feature. It simulates the evolution of these features over time in order
to represent the E aspect, opening more windows for future exploration. The A,
B, C, and D values are quantified particularly within this work. Moreover, this
framework also visualizes ABCD feature trajectories in latent space as skin
lesions evolve from benign nevuses to malignant melanoma. The experiments are
conducted using the HAM10000 dataset that contains around ten thousand images
of skin lesions of varying stages. In summary, the classification worked with
an accuracy of around 89 percent, with melanoma AUC being 0.96, while the
feature evaluation performed well in predicting asymmetry, color variation, and
diameter, though border irregularity remains more difficult to model. Overall,
this work provides a deep learning framework that will allow doctors to link ML
diagnoses to clinically relevant criteria, thus improving our understanding of
skin cancer progression.

</details>


### [80] [Multi-modal video data-pipelines for machine learning with minimal human supervision](https://arxiv.org/abs/2510.14862)
*Mihai-Cristian Pîrvu,Marius Leordeanu*

Main category: cs.CV

TL;DR: 本文提出了一种利用预训练专家模型和自动化数据管道来融合多种视觉模态的方法，使用PHG-MAE模型在低参数量下实现高效多模态学习，并展示了其在实时语义分割和深度估计中的应用。


<details>
  <summary>Details</summary>
Motivation: 现实世界本质上是多模态的，传统单模态或双模态机器学习模型难以全面理解复杂场景，因此需要一种能整合多种视觉模态、减少人工监督的方法以更好感知真实世界。

Method: 采用预训练的专家模型，通过程序化组合方式在原始视频上构建全自动的数据处理管道；使用专为多模态设计的PHG-MAE模型，并将其蒸馏为低参数量（<1M）版本，同时开源该数据管道。

Result: PHG-MAE模型在仅使用极小参数量的情况下，性能可与约3亿参数的模型相媲美，并成功部署于手持设备或普通网络摄像头实现实时语义分割和近实时深度估计。

Conclusion: 通过自动化多模态数据管道和高效模型设计，可在低资源设备上实现高性能多模态感知，推动真实场景中多模态学习的实际应用。

Abstract: The real-world is inherently multi-modal at its core. Our tools observe and
take snapshots of it, in digital form, such as videos or sounds, however much
of it is lost. Similarly for actions and information passing between humans,
languages are used as a written form of communication. Traditionally, Machine
Learning models have been unimodal (i.e. rgb -> semantic or text ->
sentiment_class). Recent trends go towards bi-modality, where images and text
are learned together, however, in order to truly understand the world, we need
to integrate all these independent modalities. In this work we try to combine
as many visual modalities as we can using little to no human supervision. In
order to do this, we use pre-trained experts and procedural combinations
between them on top of raw videos using a fully autonomous data-pipeline, which
we also open-source. We then make use of PHG-MAE, a model specifically designed
to leverage multi-modal data. We show that this model which was efficiently
distilled into a low-parameter (<1M) can have competitive results compared to
models of ~300M parameters. We deploy this model and analyze the use-case of
real-time semantic segmentation from handheld devices or webcams on commodity
hardware. Finally, we deploy other off-the-shelf models using the same
framework, such as DPT for near real-time depth estimation.

</details>


### [81] [Benchmarking Multimodal Large Language Models for Face Recognition](https://arxiv.org/abs/2510.14866)
*Hatef Otroshi Shahreza,Sébastien Marcel*

Main category: cs.CV

TL;DR: 本文系统评估了多模态大语言模型（MLLMs）在多个标准人脸数据集上的识别人物能力，发现尽管MLLMs能捕捉丰富语义信息，但在零样本场景下仍落后于专用模型。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在视觉-语言任务中表现出色，其在人脸识别领域的潜力尚未充分探索，且缺乏与现有模型在相同协议下的对比评估。

Method: 在LFW、CALFW、CPLFW、CFP、AgeDB和RFW等人脸识别数据集上，对最先进的MLLMs进行了系统性基准测试，采用标准零样本评估协议。

Result: 实验结果表明，MLLMs能捕捉有助于人脸相关任务的语义线索，但在高精度识别任务中，其零样本性能仍落后于专门设计的人脸识别模型。

Conclusion: 本研究为基于MLLM的人脸识别提供了基准基础，揭示了当前模型的局限性，并为设计更高精度和泛化能力的下一代模型提供了方向。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable performance
across diverse vision-and-language tasks. However, their potential in face
recognition remains underexplored. In particular, the performance of
open-source MLLMs needs to be evaluated and compared with existing face
recognition models on standard benchmarks with similar protocol. In this work,
we present a systematic benchmark of state-of-the-art MLLMs for face
recognition on several face recognition datasets, including LFW, CALFW, CPLFW,
CFP, AgeDB and RFW. Experimental results reveal that while MLLMs capture rich
semantic cues useful for face-related tasks, they lag behind specialized models
in high-precision recognition scenarios in zero-shot applications. This
benchmark provides a foundation for advancing MLLM-based face recognition,
offering insights for the design of next-generation models with higher accuracy
and generalization. The source code of our benchmark is publicly available in
the project page.

</details>


### [82] [TOUCH: Text-guided Controllable Generation of Free-Form Hand-Object Interactions](https://arxiv.org/abs/2510.14874)
*Guangyi Han,Wei Zhai,Yuhang Yang,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 提出自由形式手-物交互生成（Free-Form HOI Generation），通过细粒度意图控制生成多样化且物理合理的交互动作，并构建WildO2数据集与TOUCH框架进行验证。


<details>
  <summary>Details</summary>
Motivation: 现有手-物交互生成方法局限于固定抓握模式，依赖物理先验或粗粒度指令，难以捕捉日常交互的多样性；需支持更自由、细粒度意图驱动的交互生成。

Method: 构建真实场景下的3D手-物交互数据集WildO2，包含4.4k种交互、92种意图和610类对象；提出TOUCH框架，采用三阶段多层级扩散模型，结合显式接触建模、接触一致性与物理约束，实现细粒度语义控制的手势生成。

Result: 实验表明，该方法能生成可控、多样且物理合理的非抓握类手-物交互（如推、戳、旋转），显著提升交互的灵活性与真实性。

Conclusion: Free-Form HOI Generation推动手-物交互从固定抓握向细粒度意图驱动的自由交互拓展，WildO2数据集和TOUCH框架为后续研究提供了有效支持。

Abstract: Hand-object interaction (HOI) is fundamental for humans to express intent.
Existing HOI generation research is predominantly confined to fixed grasping
patterns, where control is tied to physical priors such as force closure or
generic intent instructions, even when expressed through elaborate language.
Such an overly general conditioning imposes a strong inductive bias for stable
grasps, thus failing to capture the diversity of daily HOI. To address these
limitations, we introduce Free-Form HOI Generation, which aims to generate
controllable, diverse, and physically plausible HOI conditioned on fine-grained
intent, extending HOI from grasping to free-form interactions, like pushing,
poking, and rotating. To support this task, we construct WildO2, an in-the-wild
diverse 3D HOI dataset, which includes diverse HOI derived from internet
videos. Specifically, it contains 4.4k unique interactions across 92 intents
and 610 object categories, each with detailed semantic annotations. Building on
this dataset, we propose TOUCH, a three-stage framework centered on a
multi-level diffusion model that facilitates fine-grained semantic control to
generate versatile hand poses beyond grasping priors. This process leverages
explicit contact modeling for conditioning and is subsequently refined with
contact consistency and physical constraints to ensure realism. Comprehensive
experiments demonstrate our method's ability to generate controllable, diverse,
and physically plausible hand interactions representative of daily activities.
The project page is $\href{https://guangyid.github.io/hoi123touch}{here}$.

</details>


### [83] [BADAS: Context Aware Collision Prediction Using Real-World Dashcam Data](https://arxiv.org/abs/2510.14876)
*Roni Goldshmidt,Hamish Scott,Lorenzo Niccolini,Shizhan Zhu,Daniel Moura,Orly Zvitia*

Main category: cs.CV

TL;DR: BADAS是一种基于真实车载摄像头数据的碰撞预测模型家族，能够有效区分自车威胁与无关事故，减少误报，在多个基准上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有碰撞预测方法难以区分涉及自车的真正威胁与随机旁观事故，导致实际部署中产生大量误报，亟需以自车为中心的评估基准和模型。

Method: 提出BADAS模型家族，基于V-JEPA2骨干网络端到端训练；构建首个面向自车评估的Nexar碰撞数据集，重新标注多个基准数据集以识别自车参与情况，并添加共识报警时间标签和合成负样本。

Result: BADAS在DAD、DADA-2000、DoTA和Nexar等多个数据集上实现了最先进的AP/AUC性能，优于前向碰撞预警基线，并提供更合理的事故时间预测；发布了BADAS-Open模型权重、代码及重新标注的数据集。

Conclusion: BADAS通过以自车为中心的建模和数据重构，在碰撞预测中显著降低误报率，推动了该领域的公平评估与开放研究。

Abstract: Existing collision prediction methods often fail to distinguish between
ego-vehicle threats and random accidents not involving the ego vehicle, leading
to excessive false alerts in real-world deployment. We present BADAS, a family
of collision prediction models trained on Nexar's real-world dashcam collision
dataset -- the first benchmark designed explicitly for ego-centric evaluation.
We re-annotate major benchmarks to identify ego involvement, add consensus
alert-time labels, and synthesize negatives where needed, enabling fair AP/AUC
and temporal evaluation. BADAS uses a V-JEPA2 backbone trained end-to-end and
comes in two variants: BADAS-Open (trained on our 1.5k public videos) and
BADAS1.0 (trained on 40k proprietary videos). Across DAD, DADA-2000, DoTA, and
Nexar, BADAS achieves state-of-the-art AP/AUC and outperforms a
forward-collision ADAS baseline while producing more realistic time-to-accident
estimates. We release our BADAS-Open model weights and code, along with
re-annotations of all evaluation datasets to promote ego-centric collision
prediction research.

</details>


### [84] [ScaleWeaver: Weaving Efficient Controllable T2I Generation with Multi-Scale Reference Attention](https://arxiv.org/abs/2510.14882)
*Keli Liu,Zhendong Wang,Wengang Zhou,Shaodong Xu,Ruixiao Dong,Houqiang Li*

Main category: cs.CV

TL;DR: ScaleWeaver 是一种基于视觉自回归模型（VAR）的高效可控文本到图像生成框架，通过参数高效微调实现高质量和精确控制的图像生成。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在可控生成方面已有较多探索，但在视觉自回归模型（VAR）中实现精确且灵活的控制仍缺乏研究，本文旨在填补这一空白。

Method: 提出 ScaleWeaver 框架，核心是改进的 MMDiT 块与新型 Reference Attention 模块，去除不必要的图像到条件的注意力，降低计算开销并稳定控制注入；通过参数重用和零初始化线性投影，以极少量新增参数有效融合控制信号而不破坏原始生成能力。

Result: 实验表明，ScaleWeaver 在生成质量、控制精度和推理效率方面均优于扩散模型方法，尤其在参数效率和生成速度上表现突出。

Conclusion: ScaleWeaver 为视觉自回归范式下的可控文本到图像生成提供了一个高效、实用且有效的解决方案。

Abstract: Text-to-image generation with visual autoregressive~(VAR) models has recently
achieved impressive advances in generation fidelity and inference efficiency.
While control mechanisms have been explored for diffusion models, enabling
precise and flexible control within VAR paradigm remains underexplored. To
bridge this critical gap, in this paper, we introduce ScaleWeaver, a novel
framework designed to achieve high-fidelity, controllable generation upon
advanced VAR models through parameter-efficient fine-tuning. The core module in
ScaleWeaver is the improved MMDiT block with the proposed Reference Attention
module, which efficiently and effectively incorporates conditional information.
Different from MM Attention, the proposed Reference Attention module discards
the unnecessary attention from image$\rightarrow$condition, reducing
computational cost while stabilizing control injection. Besides, it
strategically emphasizes parameter reuse, leveraging the capability of the VAR
backbone itself with a few introduced parameters to process control
information, and equipping a zero-initialized linear projection to ensure that
control signals are incorporated effectively without disrupting the generative
capability of the base model. Extensive experiments show that ScaleWeaver
delivers high-quality generation and precise control while attaining superior
efficiency over diffusion-based methods, making ScaleWeaver a practical and
effective solution for controllable text-to-image generation within the visual
autoregressive paradigm. Code and models will be released.

</details>


### [85] [You May Speak Freely: Improving the Fine-Grained Visual Recognition Capabilities of Multimodal Large Language Models with Answer Extraction](https://arxiv.org/abs/2510.14885)
*Logan Lawrence,Oindrila Saha,Megan Wei,Chen Sun,Subhransu Maji,Grant Van Horn*

Main category: cs.CV

TL;DR: 提出了一种名为nlg2choice的两阶段方法，用于改进多模态大语言模型在细粒度视觉分类中的自由形式回答评估，尤其适用于高选项数量的多项选择题和检索任务。


<details>
  <summary>Details</summary>
Motivation: 现有方法多集中于纯语言任务或低选项数的多项选择，难以应对细粒度视觉分类中数百至数千高度相似选项的评估挑战，且在检索场景下计算成本高。

Method: 采用两阶段方法：第一阶段让多模态大语言模型自由生成开放性回答；第二阶段通过文本受限解码将其映射到最可能的选项。在检索任务中引入早期停止策略以提升计算效率。

Result: 在七个细粒度视觉数据集上，该方法在分类和检索任务中均优于现有方法，且在不同自然语言任务实现方式下表现稳定。

Conclusion: nlg2choice有效解决了高选项数和高度相关类别下的评估难题，兼顾性能与效率，适用于实际应用中多样化的自然语言交互需求。

Abstract: Despite the renewed interest in zero-shot visual classification due to the
rise of Multimodal Large Language Models (MLLMs), the problem of evaluating
free-form responses of auto-regressive models remains a persistent challenge.
Most existing works focus on language-only tasks or don't consider Multiple
Choice Questions (MCQs) beyond 5-way options, both of which are critical
capabilities to solve tasks in Fine-Grained Visual Classification (FGVC) where
choice counts are in the hundreds to thousands and the choices are highly
related. Furthermore, in this highly multi-way MCQ setting it is not clear how
to extend LLM choice extraction to retrieval-based problems, where computing
probabilities over the choice set is computationally costly. In this work we
investigate nlg2choice, a simple two-stage method which first asks the MLLM an
open-ended question for the task with minimal constraints, then uses text-only
constrained decoding to predict the most likely choice. In retrieval settings,
we compute the probability of the constrained response taking that choice with
an early stopping method to significantly improve throughput. Our results show
improvement over a suite of seven fine-grained visual datasets when evaluating
in terms of classification and retrieval, and show that this performance holds
over the various ways that users of LLMs can implement tasks in natural
language.

</details>


### [86] [Leveraging Multimodal LLM Descriptions of Activity for Explainable Semi-Supervised Video Anomaly Detection](https://arxiv.org/abs/2510.14896)
*Furkan Mumcu,Michael J. Jones,Anoop Cherian,Yasin Yilmaz*

Main category: cs.CV

TL;DR: 提出一种基于多模态大语言模型（MLLM）的视频异常检测新框架，通过生成对象活动和交互的文本描述来检测异常，具有良好的可解释性并取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有半监督视频异常检测方法难以检测涉及对象交互的复杂异常，且缺乏可解释性。

Method: 利用MLLM对不同时间点的对象对进行查询，生成正常视频中对象活动与交互的文本描述，作为高层次表示；在测试时通过比较文本描述检测异常。

Result: 在基准数据集上实验表明，该方法能有效检测基于交互的复杂异常，并在无交互异常的数据集上也达到最先进的性能。

Conclusion: 所提方法不仅提升了复杂异常的检测能力，还天然具备可解释性，可与传统VAD方法结合以增强其可解释性。

Abstract: Existing semi-supervised video anomaly detection (VAD) methods often struggle
with detecting complex anomalies involving object interactions and generally
lack explainability. To overcome these limitations, we propose a novel VAD
framework leveraging Multimodal Large Language Models (MLLMs). Unlike previous
MLLM-based approaches that make direct anomaly judgments at the frame level,
our method focuses on extracting and interpreting object activity and
interactions over time. By querying an MLLM with visual inputs of object pairs
at different moments, we generate textual descriptions of the activity and
interactions from nominal videos. These textual descriptions serve as a
high-level representation of the activity and interactions of objects in a
video. They are used to detect anomalies during test time by comparing them to
textual descriptions found in nominal training videos. Our approach inherently
provides explainability and can be combined with many traditional VAD methods
to further enhance their interpretability. Extensive experiments on benchmark
datasets demonstrate that our method not only detects complex interaction-based
anomalies effectively but also achieves state-of-the-art performance on
datasets without interaction anomalies.

</details>


### [87] [MaskCaptioner : Learning to Jointly Segment and Caption Object Trajectories in Videos](https://arxiv.org/abs/2510.14904)
*Gabriel Fiastre,Antoine Yang,Cordelia Schmid*

Main category: cs.CV

TL;DR: 提出了一种端到端模型MaskCaptioner，利用合成字幕数据集LVISCap和LV-VISCap，在密集视频对象描述任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有密集视频对象描述（DVOC）方法因复杂性和标注成本高而采用分离训练策略，可能导致性能次优，需改进联合建模能力。

Method: 通过扩展LVIS和LV-VIS数据集生成合成字幕（LVISCap和LV-VISCap），利用先进的视觉语言模型（VLM）生成时空定位实体的描述，并训练端到端模型MaskCaptioner，实现检测、分割、跟踪与描述的联合学习。

Result: MaskCaptioner在VidSTG、VLN和BenSMOT三个基准上均达到最先进的DVOC性能。

Conclusion: 通过合成字幕预训练，MaskCaptioner实现了端到端的视频对象轨迹理解与描述，显著提升了DVOC任务的表现。

Abstract: Dense Video Object Captioning (DVOC) is the task of jointly detecting,
tracking, and captioning object trajectories in a video, requiring the ability
to understand spatio-temporal details and describe them in natural language.
Due to the complexity of the task and the high cost associated with manual
annotation, previous approaches resort to disjoint training strategies,
potentially leading to suboptimal performance. To circumvent this issue, we
propose to generate captions about spatio-temporally localized entities
leveraging a state-of-the-art VLM. By extending the LVIS and LV-VIS datasets
with our synthetic captions (LVISCap and LV-VISCap), we train MaskCaptioner, an
end-to-end model capable of jointly detecting, segmenting, tracking and
captioning object trajectories. Moreover, with pretraining on LVISCap and
LV-VISCap, MaskCaptioner achieves state-of-the-art DVOC results on three
existing benchmarks, VidSTG, VLN and BenSMOT. The datasets and code are
available at https://www.gabriel.fiastre.fr/maskcaptioner/.

</details>


### [88] [3D Scene Prompting for Scene-Consistent Camera-Controllable Video Generation](https://arxiv.org/abs/2510.14945)
*JoungBin Lee,Jaewoo Jung,Jisang Han,Takuya Narihira,Kazumi Fukuda,Junyoung Seo,Sunghwan Hong,Yuki Mitsufuji,Seungryong Kim*

Main category: cs.CV

TL;DR: 提出3DScenePrompt框架，通过双时空条件和3D场景记忆实现长输入视频的连贯生成与精确相机控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法多基于单图像或短片段生成，难以兼顾长时场景一致性和相机控制，本文旨在解决此问题。

Method: 采用双时空条件建模，结合时间相邻帧和空间相邻内容，并引入基于动态SLAM与动态掩码的3D场景记忆提取静态几何。

Result: 在场景一致性、相机可控性和生成质量上显著优于现有方法。

Conclusion: 3DScenePrompt有效实现了长视频生成中的空间连贯性与动态自然性的平衡。

Abstract: We present 3DScenePrompt, a framework that generates the next video chunk
from arbitrary-length input while enabling precise camera control and
preserving scene consistency. Unlike methods conditioned on a single image or a
short clip, we employ dual spatio-temporal conditioning that reformulates
context-view referencing across the input video. Our approach conditions on
both temporally adjacent frames for motion continuity and spatially adjacent
content for scene consistency. However, when generating beyond temporal
boundaries, directly using spatially adjacent frames would incorrectly preserve
dynamic elements from the past. We address this by introducing a 3D scene
memory that represents exclusively the static geometry extracted from the
entire input video. To construct this memory, we leverage dynamic SLAM with our
newly introduced dynamic masking strategy that explicitly separates static
scene geometry from moving elements. The static scene representation can then
be projected to any target viewpoint, providing geometrically consistent warped
views that serve as strong 3D spatial prompts while allowing dynamic regions to
evolve naturally from temporal context. This enables our model to maintain
long-range spatial coherence and precise camera control without sacrificing
computational efficiency or motion realism. Extensive experiments demonstrate
that our framework significantly outperforms existing methods in scene
consistency, camera controllability, and generation quality. Project page :
https://cvlab-kaist.github.io/3DScenePrompt/

</details>


### [89] [OmniMotion: Multimodal Motion Generation with Continuous Masked Autoregression](https://arxiv.org/abs/2510.14954)
*Zhe Li,Weihao Yuan,Weichao Shen,Siyu Zhu,Zilong Dong,Chang Xu*

Main category: cs.CV

TL;DR: 提出了一种连续掩码自回归运动Transformer，用于多模态全身动作生成，在文本、语音和音乐到动作的生成任务中均优于先前方法。


<details>
  <summary>Details</summary>
Motivation: 解决全身多模态动作生成中的两个关键问题：有效的动作生成机制和多模态（如文本、语音、音乐）融合框架的构建。

Method: 提出连续掩码自回归运动Transformer，引入门控线性注意力和RMSNorm模块，并结合DiT结构、AdaLN和交叉注意力实现多模态融合与条件扩散。

Result: 在文本到动作、语音到手势、音乐到舞蹈等任务上均优于现有方法，展现出更强的动作生成质量与多模态泛化能力。

Conclusion: 所提方法能有效建模动作序列并融合多模态输入，为多模态动作生成提供了高效且通用的解决方案。

Abstract: Whole-body multi-modal human motion generation poses two primary challenges:
creating an effective motion generation mechanism and integrating various
modalities, such as text, speech, and music, into a cohesive framework. Unlike
previous methods that usually employ discrete masked modeling or autoregressive
modeling, we develop a continuous masked autoregressive motion transformer,
where a causal attention is performed considering the sequential nature within
the human motion. Within this transformer, we introduce a gated linear
attention and an RMSNorm module, which drive the transformer to pay attention
to the key actions and suppress the instability caused by either the abnormal
movements or the heterogeneous distributions within multi-modalities. To
further enhance both the motion generation and the multimodal generalization,
we employ the DiT structure to diffuse the conditions from the transformer
towards the targets. To fuse different modalities, AdaLN and cross-attention
are leveraged to inject the text, speech, and music signals. Experimental
results demonstrate that our framework outperforms previous methods across all
modalities, including text-to-motion, speech-to-gesture, and music-to-dance.
The code of our method will be made public.

</details>


### [90] [RealDPO: Real or Not Real, that is the Preference](https://arxiv.org/abs/2510.14955)
*Guo Cheng,Danni Yang,Ziqi Huang,Jianlou Si,Chenyang Si,Ziwei Liu*

Main category: cs.CV

TL;DR: 提出RealDPO，一种利用真实世界视频作为正样本的偏好学习框架，结合RealAction-5K数据集，显著提升视频生成中的运动真实性和质量。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在生成复杂运动时往往不够自然、流畅和上下文一致，限制了其实用性，因此需要更有效的对齐方法来提升运动 realism。

Method: 提出RealDPO，采用真实视频作为正样本，结合错误的模型生成结果作为负样本，使用改进的DPO损失函数进行偏好优化，实现运动质量的迭代自校正；同时构建RealAction-5K数据集支持复杂动作的后训练。

Result: 实验表明，RealDPO在视频质量、文本对齐和运动真实性方面优于现有最先进模型和偏好优化方法。

Conclusion: RealDPO通过引入真实世界数据进行偏好学习，有效提升了生成视频中复杂运动的质量，为视频生成模型的对齐提供了新范式。

Abstract: Video generative models have recently achieved notable advancements in
synthesis quality. However, generating complex motions remains a critical
challenge, as existing models often struggle to produce natural, smooth, and
contextually consistent movements. This gap between generated and real-world
motions limits their practical applicability. To address this issue, we
introduce RealDPO, a novel alignment paradigm that leverages real-world data as
positive samples for preference learning, enabling more accurate motion
synthesis. Unlike traditional supervised fine-tuning (SFT), which offers
limited corrective feedback, RealDPO employs Direct Preference Optimization
(DPO) with a tailored loss function to enhance motion realism. By contrasting
real-world videos with erroneous model outputs, RealDPO enables iterative
self-correction, progressively refining motion quality. To support
post-training in complex motion synthesis, we propose RealAction-5K, a curated
dataset of high-quality videos capturing human daily activities with rich and
precise motion details. Extensive experiments demonstrate that RealDPO
significantly improves video quality, text alignment, and motion realism
compared to state-of-the-art models and existing preference optimization
techniques.

</details>


### [91] [MathCanvas: Intrinsic Visual Chain-of-Thought for Multimodal Mathematical Reasoning](https://arxiv.org/abs/2510.14958)
*Weikang Shi,Aldrich Yu,Rongyao Fang,Houxing Ren,Ke Wang,Aojun Zhou,Changyao Tian,Xinyu Fu,Yuxuan Hu,Zimu Lu,Linjiang Huang,Si Liu,Rui Liu,Hongsheng Li*

Main category: cs.CV

TL;DR: 提出MathCanvas框架，通过大规模视觉-文本数据训练，赋予大模型内在的视觉链式思维能力，显著提升其在数学推理中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有视觉链式思维方法受限于刚性外部工具或无法生成高质量、适时的图表，难以支持复杂的数学问题求解。

Method: 构建两阶段框架：先在1520万对数据上进行视觉操作预训练，掌握图表生成与编辑；再在21.9万样本上进行战略视觉辅助推理微调，学习何时及如何使用视觉辅助。同时构建新基准MathCanvas-Bench用于评估。

Result: 所提出的BAGEL-Canvas模型在MathCanvas-Bench上相比强大多模态基线取得86%的相对提升，并在其他公开数学基准上展现良好泛化能力。

Conclusion: MathCanvas为大型多模态模型提供了完整的视觉辅助推理能力，推动其实现更接近人类的复杂视觉-数学推理。

Abstract: While Large Language Models (LLMs) have excelled in textual reasoning, they
struggle with mathematical domains like geometry that intrinsically rely on
visual aids. Existing approaches to Visual Chain-of-Thought (VCoT) are often
limited by rigid external tools or fail to generate the high-fidelity,
strategically-timed diagrams necessary for complex problem-solving. To bridge
this gap, we introduce MathCanvas, a comprehensive framework designed to endow
unified Large Multimodal Models (LMMs) with intrinsic VCoT capabilities for
mathematics. Our approach consists of two phases. First, a Visual Manipulation
stage pre-trains the model on a novel 15.2M-pair corpus, comprising 10M
caption-to-diagram pairs (MathCanvas-Imagen) and 5.2M step-by-step editing
trajectories (MathCanvas-Edit), to master diagram generation and editing.
Second, a Strategic Visual-Aided Reasoning stage fine-tunes the model on
MathCanvas-Instruct, a new 219K-example dataset of interleaved visual-textual
reasoning paths, teaching it when and how to leverage visual aids. To
facilitate rigorous evaluation, we introduce MathCanvas-Bench, a challenging
benchmark with 3K problems that require models to produce interleaved
visual-textual solutions. Our model, BAGEL-Canvas, trained under this
framework, achieves an 86% relative improvement over strong LMM baselines on
MathCanvas-Bench, demonstrating excellent generalization to other public math
benchmarks. Our work provides a complete toolkit-framework, datasets, and
benchmark-to unlock complex, human-like visual-aided reasoning in LMMs. Project
Page: https://mathcanvas.github.io/

</details>


### [92] [C4D: 4D Made from 3D through Dual Correspondences](https://arxiv.org/abs/2510.14960)
*Shizun Wang,Zhenxiang Jiang,Xingyi Yang,Xinchao Wang*

Main category: cs.CV

TL;DR: 本文提出C4D框架，利用短期光流和长期点跟踪两种时序对应关系，将现有的3D重建方法扩展到4D，实现单目视频中动态场景的完整四维重建。


<details>
  <summary>Details</summary>
Motivation: 现有的基于点图的3D重建方法在静态场景中表现良好，但在动态场景中因运动物体破坏多视图几何约束而效果不佳，因此需要一种能处理动态元素的4D重建方法。

Method: C4D框架除了预测点图外，还捕捉短期光流和长期点跟踪两种对应关系；训练一个动态感知的点追踪器以提供运动信息，生成运动掩码分离动态与静态部分，并引入动态场景优化目标来恢复每帧的3D几何和相机参数，同时将2D轨迹提升为平滑的3D轨迹。

Result: 实验证明C4D在多个下游任务（如深度估计、相机位姿估计和点跟踪）上表现优异，能够实现完整的4D重建。

Conclusion: C4D通过引入时序对应和动态感知优化，有效解决了单目视频中动态场景的4D重建难题，显著提升了重建精度和应用潜力。

Abstract: Recovering 4D from monocular video, which jointly estimates dynamic geometry
and camera poses, is an inevitably challenging problem. While recent
pointmap-based 3D reconstruction methods (e.g., DUSt3R) have made great
progress in reconstructing static scenes, directly applying them to dynamic
scenes leads to inaccurate results. This discrepancy arises because moving
objects violate multi-view geometric constraints, disrupting the
reconstruction. To address this, we introduce C4D, a framework that leverages
temporal Correspondences to extend existing 3D reconstruction formulation to
4D. Specifically, apart from predicting pointmaps, C4D captures two types of
correspondences: short-term optical flow and long-term point tracking. We train
a dynamic-aware point tracker that provides additional mobility information,
facilitating the estimation of motion masks to separate moving elements from
the static background, thus offering more reliable guidance for dynamic scenes.
Furthermore, we introduce a set of dynamic scene optimization objectives to
recover per-frame 3D geometry and camera parameters. Simultaneously, the
correspondences lift 2D trajectories into smooth 3D trajectories, enabling
fully integrated 4D reconstruction. Experiments show that our framework
achieves complete 4D recovery and demonstrates strong performance across
multiple downstream tasks, including depth estimation, camera pose estimation,
and point tracking. Project Page: https://littlepure2333.github.io/C4D

</details>


### [93] [RainDiff: End-to-end Precipitation Nowcasting Via Token-wise Attention Diffusion](https://arxiv.org/abs/2510.14962)
*Thao Nguyen,Jiaqi Ma,Fahad Shahbaz Khan,Souhaib Ben Taieb,Salman Khan*

Main category: cs.CV

TL;DR: 提出一种将逐标记注意力机制集成到U-Net扩散模型以及时空编码器中的降水临近预报方法，无需额外自编码器且计算效率高，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的降水预报方法在可扩展性上存在问题：潜在空间方法需额外训练自编码器，限制泛化能力；像素空间方法计算成本高且常缺乏注意力机制，难以捕捉长程时空依赖。

Method: 提出一种将逐标记注意力机制同时集成到U-Net扩散模型和时空编码器中的方法，动态捕捉多尺度空间交互与时间演变，原生集成注意力机制，无需潜在空间模块，避免高计算开销。

Result: 在多个数据集上的实验和视觉评估表明，该方法显著优于现有最先进方法，在局部保真度、泛化性和复杂场景下的鲁棒性方面表现更优。

Conclusion: 所提方法有效解决了扩散模型在降水临近预报中的可扩展性与长程依赖建模问题，提供了一种高效且强大的雷达回波序列预测架构。

Abstract: Precipitation nowcasting, predicting future radar echo sequences from current
observations, is a critical yet challenging task due to the inherently chaotic
and tightly coupled spatio-temporal dynamics of the atmosphere. While recent
advances in diffusion-based models attempt to capture both large-scale motion
and fine-grained stochastic variability, they often suffer from scalability
issues: latent-space approaches require a separately trained autoencoder,
adding complexity and limiting generalization, while pixel-space approaches are
computationally intensive and often omit attention mechanisms, reducing their
ability to model long-range spatio-temporal dependencies. To address these
limitations, we propose a Token-wise Attention integrated into not only the
U-Net diffusion model but also the spatio-temporal encoder that dynamically
captures multi-scale spatial interactions and temporal evolution. Unlike prior
approaches, our method natively integrates attention into the architecture
without incurring the high resource cost typical of pixel-space diffusion,
thereby eliminating the need for separate latent modules. Our extensive
experiments and visual evaluations across diverse datasets demonstrate that the
proposed method significantly outperforms state-of-the-art approaches, yielding
superior local fidelity, generalization, and robustness in complex
precipitation forecasting scenarios.

</details>


### [94] [ChangingGrounding: 3D Visual Grounding in Changing Scenes](https://arxiv.org/abs/2510.14965)
*Miao Hu,Zhiwei Huang,Tai Wang,Jiangmiao Pang,Dahua Lin,Nanning Zheng,Runsen Xu*

Main category: cs.CV

TL;DR: 提出首个针对动态场景下3D视觉定位的基准ChangingGrounding及零样本方法Mem-ChangingGrounder，强调记忆驱动与主动探索，提升定位精度并降低扫描成本。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉定位方法依赖完整且更新的点云，需频繁重扫描，不适用于现实动态环境；作者主张将3DVG建模为记忆驱动的主动问题，以支持实际部署。

Method: 提出ChangingGrounding基准，评估智能体利用历史观测、选择性探索和在变化场景中精确定位的能力；并设计Mem-ChangingGrounder方法，结合跨模态检索与轻量多视角融合，通过记忆检索引导动作、有效探索目标区域、多视角扫描融合生成精确3D边界框。

Result: 在ChangingGrounding上评估多个基线，Mem-ChangingGrounder在零样本设置下实现最高定位精度，并显著降低探索成本。

Conclusion: 推动3D视觉定位研究向实用化、以记忆为中心的方向发展，适应现实世界动态场景的需求。

Abstract: Real-world robots localize objects from natural-language instructions while
scenes around them keep changing. Yet most of the existing 3D visual grounding
(3DVG) method still assumes a reconstructed and up-to-date point cloud, an
assumption that forces costly re-scans and hinders deployment. We argue that
3DVG should be formulated as an active, memory-driven problem, and we introduce
ChangingGrounding, the first benchmark that explicitly measures how well an
agent can exploit past observations, explore only where needed, and still
deliver precise 3D boxes in changing scenes. To set a strong reference point,
we also propose Mem-ChangingGrounder, a zero-shot method for this task that
marries cross-modal retrieval with lightweight multi-view fusion: it identifies
the object type implied by the query, retrieves relevant memories to guide
actions, then explores the target efficiently in the scene, falls back when
previous operations are invalid, performs multi-view scanning of the target,
and projects the fused evidence from multi-view scans to get accurate object
bounding boxes. We evaluate different baselines on ChangingGrounding, and our
Mem-ChangingGrounder achieves the highest localization accuracy while greatly
reducing exploration cost. We hope this benchmark and method catalyze a shift
toward practical, memory-centric 3DVG research for real-world applications.
Project page: https://hm123450.github.io/CGB/ .

</details>


### [95] [WithAnyone: Towards Controllable and ID Consistent Image Generation](https://arxiv.org/abs/2510.14975)
*Hengyuan Xu,Wei Cheng,Peng Xing,Yixiao Fang,Shuhan Wu,Rui Wang,Xianfang Zeng,Daxin Jiang,Gang Yu,Xingjun Ma,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 本文提出WithAnyone，一种基于扩散模型的身份一致文本到图像生成方法，通过构建大规模配对数据集MultiID-2M、引入新评估基准和对比身份损失，有效缓解“复制粘贴”问题，在保持高身份相似性的同时实现多样化的可控生成。


<details>
  <summary>Details</summary>
Motivation: 现有身份一致生成模型因缺乏大规模配对数据而依赖重建训练，导致“复制粘贴”现象，即直接复制参考脸而缺乏自然变化，影响可控性和生成表现力。

Method: 1）构建大规模多身份配对数据集MultiID-2M；2）设计量化复制粘贴 artifact 与身份保真度-多样性权衡的基准；3）提出带对比身份损失的新训练范式，利用配对数据平衡保真与多样性。

Result: WithAnyone显著减少复制粘贴现象，提升姿态与表情的可控性，保持高质量视觉效果；定量与用户实验均验证其在身份保真与生成多样性上的优越性。

Conclusion: 本文通过数据、评估和方法三方面贡献，实现了更高质量的身份一致文本到图像生成，支持多样化且可控的人像合成。

Abstract: Identity-consistent generation has become an important focus in text-to-image
research, with recent models achieving notable success in producing images
aligned with a reference identity. Yet, the scarcity of large-scale paired
datasets containing multiple images of the same individual forces most
approaches to adopt reconstruction-based training. This reliance often leads to
a failure mode we term copy-paste, where the model directly replicates the
reference face rather than preserving identity across natural variations in
pose, expression, or lighting. Such over-similarity undermines controllability
and limits the expressive power of generation. To address these limitations, we
(1) construct a large-scale paired dataset MultiID-2M, tailored for
multi-person scenarios, providing diverse references for each identity; (2)
introduce a benchmark that quantifies both copy-paste artifacts and the
trade-off between identity fidelity and variation; and (3) propose a novel
training paradigm with a contrastive identity loss that leverages paired data
to balance fidelity with diversity. These contributions culminate in
WithAnyone, a diffusion-based model that effectively mitigates copy-paste while
preserving high identity similarity. Extensive qualitative and quantitative
experiments demonstrate that WithAnyone significantly reduces copy-paste
artifacts, improves controllability over pose and expression, and maintains
strong perceptual quality. User studies further validate that our method
achieves high identity fidelity while enabling expressive controllable
generation.

</details>


### [96] [Ponimator: Unfolding Interactive Pose for Versatile Human-human Interaction Animation](https://arxiv.org/abs/2510.14976)
*Shaowei Liu,Chuan Guo,Bing Zhou,Jian Wang*

Main category: cs.CV

TL;DR: Ponimator 是一个基于紧密互动姿态的简单框架，利用两种条件扩散模型生成交互动作序列和合成互动姿态，支持多种任务，如基于图像的互动动画、反应动画和文本到互动合成。


<details>
  <summary>Details</summary>
Motivation: 人类可以通过近距离的互动姿态直观地推断情境并预测可能的过去和未来的动态。受此启发，作者希望利用人类行为的强先验知识来构建一个能够生成自然互动动画的框架。

Method: Ponimator 使用两个条件扩散模型：（1）姿态动画器，利用时间先验从互动姿态生成动态动作序列；（2）姿态生成器，利用空间先验从单个姿态、文本或两者生成互动姿态。训练数据来自动作捕捉互动数据集中的近距离双人姿态及其时间上下文。

Result: 实验在多个数据集和应用上验证了姿态先验的普适性以及该框架的有效性和鲁棒性，Ponimator 能够成功实现图像驱动的互动动画、反应动画和文本到互动的合成。

Conclusion: Ponimator 展示了利用互动姿态先验在不同场景下生成高质量互动动画的潜力，为将高质量动作捕捉数据中的互动知识迁移到开放世界场景提供了有效方法。

Abstract: Close-proximity human-human interactive poses convey rich contextual
information about interaction dynamics. Given such poses, humans can
intuitively infer the context and anticipate possible past and future dynamics,
drawing on strong priors of human behavior. Inspired by this observation, we
propose Ponimator, a simple framework anchored on proximal interactive poses
for versatile interaction animation. Our training data consists of
close-contact two-person poses and their surrounding temporal context from
motion-capture interaction datasets. Leveraging interactive pose priors,
Ponimator employs two conditional diffusion models: (1) a pose animator that
uses the temporal prior to generate dynamic motion sequences from interactive
poses, and (2) a pose generator that applies the spatial prior to synthesize
interactive poses from a single pose, text, or both when interactive poses are
unavailable. Collectively, Ponimator supports diverse tasks, including
image-based interaction animation, reaction animation, and text-to-interaction
synthesis, facilitating the transfer of interaction knowledge from high-quality
mocap data to open-world scenarios. Empirical experiments across diverse
datasets and applications demonstrate the universality of the pose prior and
the effectiveness and robustness of our framework.

</details>


### [97] [Terra: Explorable Native 3D World Model with Point Latents](https://arxiv.org/abs/2510.14977)
*Yuanhui Huang,Weiliang Chen,Wenzhao Zheng,Xin Tao,Pengfei Wan,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: 本文提出了Terra，一种基于原生3D表示的3D世界模型，通过点到高斯变分自编码器（P2G-VAE）和稀疏点流匹配网络（SPFlow），在3D潜在空间中建模和生成可探索的环境，实现了高3D一致性和高效渲染。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型多依赖于像素对齐的表示方式，忽视了现实世界的3D本质，导致3D一致性不足和建模效率低下。为此，本文旨在构建一个原生的3D世界模型以提升建模的几何一致性和生成效率。

Method: 提出Terra模型，包含两个核心组件：P2G-VAE将3D输入编码为点潜在表示，并解码为3D高斯基元以联合建模几何与外观；SPFlow网络用于生成点潜在表示，同时去噪点的位置和特征。模型在3D潜在空间中进行渐进式生成，支持任意视角渲染。

Result: 在ScanNet v2室内场景数据集上实验表明，Terra在重建和生成任务上均达到SOTA性能，具有高度3D一致性，并支持单次生成实现多视角一致渲染与环境探索。

Conclusion: Terra通过原生3D表示与架构，有效提升了世界模型的3D一致性与建模效率，为可探索3D环境的生成提供了新思路。

Abstract: World models have garnered increasing attention for comprehensive modeling of
the real world. However, most existing methods still rely on pixel-aligned
representations as the basis for world evolution, neglecting the inherent 3D
nature of the physical world. This could undermine the 3D consistency and
diminish the modeling efficiency of world models. In this paper, we present
Terra, a native 3D world model that represents and generates explorable
environments in an intrinsic 3D latent space. Specifically, we propose a novel
point-to-Gaussian variational autoencoder (P2G-VAE) that encodes 3D inputs into
a latent point representation, which is subsequently decoded as 3D Gaussian
primitives to jointly model geometry and appearance. We then introduce a sparse
point flow matching network (SPFlow) for generating the latent point
representation, which simultaneously denoises the positions and features of the
point latents. Our Terra enables exact multi-view consistency with native 3D
representation and architecture, and supports flexible rendering from any
viewpoint with only a single generation process. Furthermore, Terra achieves
explorable world modeling through progressive generation in the point latent
space. We conduct extensive experiments on the challenging indoor scenes from
ScanNet v2. Terra achieves state-of-the-art performance in both reconstruction
and generation with high 3D consistency.

</details>


### [98] [Learning an Image Editing Model without Image Editing Pairs](https://arxiv.org/abs/2510.14978)
*Nupur Kumari,Sheng-Yu Wang,Nanxuan Zhao,Yotam Nitzan,Yuheng Li,Krishna Kumar Singh,Richard Zhang,Eli Shechtman,Jun-Yan Zhu,Xun Huang*

Main category: cs.CV

TL;DR: 本文提出一种无需成对数据的图像编辑新训练范式，通过展开扩散模型并利用视觉-语言模型的反馈进行端到端优化，在少步生成设置下性能媲美依赖大量监督数据的现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于自然语言指令的图像编辑模型依赖大量成对输入-目标数据进行监督微调，但此类数据难以大规模获取，合成数据又可能传播预训练模型的伪影，因此亟需一种不依赖成对数据的训练方法。

Method: 提出一种新的训练范式：在训练过程中展开少步扩散模型，利用视觉-语言模型（VLM）对编辑结果进行评估，判断是否遵循指令并保持未修改内容，并据此提供直接梯度进行优化；同时引入分布匹配损失（DMD）以确保生成图像的视觉保真度。

Result: 在标准基准上评估并进行了广泛的消融研究，结果显示：在无需任何成对数据的情况下，该方法在少步生成设置下的表现与使用大量监督成对数据训练的扩散模型相当，并且优于使用相同VLM作为奖励模型的Flow-GRPO等基于强化学习的技术。

Conclusion: 本文成功实现了无需成对训练数据的图像编辑模型训练，通过结合VLM反馈和分布匹配损失，在保持高视觉质量的同时达到与监督方法相当甚至更优的性能，为图像编辑提供了一种更具可扩展性的训练路径。

Abstract: Recent image editing models have achieved impressive results while following
natural language editing instructions, but they rely on supervised fine-tuning
with large datasets of input-target pairs. This is a critical bottleneck, as
such naturally occurring pairs are hard to curate at scale. Current workarounds
use synthetic training pairs that leverage the zero-shot capabilities of
existing models. However, this can propagate and magnify the artifacts of the
pretrained model into the final trained model. In this work, we present a new
training paradigm that eliminates the need for paired data entirely. Our
approach directly optimizes a few-step diffusion model by unrolling it during
training and leveraging feedback from vision-language models (VLMs). For each
input and editing instruction, the VLM evaluates if an edit follows the
instruction and preserves unchanged content, providing direct gradients for
end-to-end optimization. To ensure visual fidelity, we incorporate distribution
matching loss (DMD), which constrains generated images to remain within the
image manifold learned by pretrained models. We evaluate our method on standard
benchmarks and include an extensive ablation study. Without any paired data,
our method performs on par with various image editing diffusion models trained
on extensive supervised paired data, under the few-step setting. Given the same
VLM as the reward model, we also outperform RL-based techniques like Flow-GRPO.

</details>


### [99] [From Pixels to Words -- Towards Native Vision-Language Primitives at Scale](https://arxiv.org/abs/2510.14979)
*Haiwen Diao,Mingxuan Li,Silei Wu,Linjun Dai,Xiaohua Wang,Hanming Deng,Lewei Lu,Dahua Lin,Ziwei Liu*

Main category: cs.CV

TL;DR: 本文提出了NEO，一种基于第一性原理构建的新型原生视觉-语言模型（VLM）家族，旨在解决原生VLM在表示对齐、模块融合和跨模态推理方面的根本限制，并推动该领域的可及性与民主化。


<details>
  <summary>Details</summary>
Motivation: 原生视觉-语言模型（VLM）虽有潜力，但其与模块化模型的根本差异和研究门槛高阻碍了广泛探索。本文旨在明确这些挑战并提供可扩展、低成本的解决方案。

Method: 提出构建原生VLM的三个基本原则：像素与词表征的有效对齐、视觉与语言能力的无缝集成、内在支持跨模态编码、对齐与推理。基于这些原则设计了NEO模型，从零开始高效学习视觉感知，并在单一密集模型中缓解视觉-语言冲突。

Result: 仅使用3.9亿图像-文本样本，NEO就能在多种真实场景中媲美顶级模块化模型，展现出强大的性能和可扩展性。

Conclusion: NEO为构建可扩展且强大的原生VLM奠定了基础，提供了一套可复用组件，促进低成本、可扩展的研究生态，推动原生VLM领域的普及与发展。

Abstract: The edifice of native Vision-Language Models (VLMs) has emerged as a rising
contender to typical modular VLMs, shaped by evolving model architectures and
training paradigms. Yet, two lingering clouds cast shadows over its widespread
exploration and promotion: (-) What fundamental constraints set native VLMs
apart from modular ones, and to what extent can these barriers be overcome? (-)
How to make research in native VLMs more accessible and democratized, thereby
accelerating progress in the field. In this paper, we clarify these challenges
and outline guiding principles for constructing native VLMs. Specifically, one
native VLM primitive should: (i) effectively align pixel and word
representations within a shared semantic space; (ii) seamlessly integrate the
strengths of formerly separate vision and language modules; (iii) inherently
embody various cross-modal properties that support unified vision-language
encoding, aligning, and reasoning. Hence, we launch NEO, a novel family of
native VLMs built from first principles, capable of rivaling top-tier modular
counterparts across diverse real-world scenarios. With only 390M image-text
examples, NEO efficiently develops visual perception from scratch while
mitigating vision-language conflicts inside a dense and monolithic model
crafted from our elaborate primitives. We position NEO as a cornerstone for
scalable and powerful native VLMs, paired with a rich set of reusable
components that foster a cost-effective and extensible ecosystem. Our code and
models are publicly available at: https://github.com/EvolvingLMMs-Lab/NEO.

</details>


### [100] [Coupled Diffusion Sampling for Training-Free Multi-View Image Editing](https://arxiv.org/abs/2510.14981)
*Hadi Alzayer,Yunzhi Zhang,Chen Geng,Jia-Bin Huang,Jiajun Wu*

Main category: cs.CV

TL;DR: 提出一种基于耦合扩散采样的推理时方法，利用预训练2D图像编辑模型实现多视角一致的图像编辑，通过隐式3D正则化保持跨视角一致性。


<details>
  <summary>Details</summary>
Motivation: 现有2D图像编辑模型在多视角图像编辑中无法保持视角间一致性，而基于显式3D表示的方法存在优化耗时且在稀疏视角下不稳定的问题。

Method: 提出耦合扩散采样方法，在采样过程中同时从多视角图像分布和2D编辑图像分布中并行生成结果，并引入耦合项以约束生成图像的多视角一致性，实现隐式3D正则化。

Result: 在三种不同的多视角图像编辑任务上验证了该方法的有效性和通用性，适用于不同模型架构，且在保持一致性方面优于现有方法。

Conclusion: 该框架为多视角一致的图像编辑提供了一种高效、通用的解决方案，无需显式3D优化即可实现高质量的编辑结果。

Abstract: We present an inference-time diffusion sampling method to perform multi-view
consistent image editing using pre-trained 2D image editing models. These
models can independently produce high-quality edits for each image in a set of
multi-view images of a 3D scene or object, but they do not maintain consistency
across views. Existing approaches typically address this by optimizing over
explicit 3D representations, but they suffer from a lengthy optimization
process and instability under sparse view settings. We propose an implicit 3D
regularization approach by constraining the generated 2D image sequences to
adhere to a pre-trained multi-view image distribution. This is achieved through
coupled diffusion sampling, a simple diffusion sampling technique that
concurrently samples two trajectories from both a multi-view image distribution
and a 2D edited image distribution, using a coupling term to enforce the
multi-view consistency among the generated images. We validate the
effectiveness and generality of this framework on three distinct multi-view
image editing tasks, demonstrating its applicability across various model
architectures and highlighting its potential as a general solution for
multi-view consistent editing.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [101] [Bridging the Semantic Gap: Contrastive Rewards for Multilingual Text-to-SQL](https://arxiv.org/abs/2510.13827)
*Ashish Kattamuri,Ishita Prasad,Meetu Malhotra,Arpita Vats,Rahul Raja,Albert Lie*

Main category: cs.CL

TL;DR: 提出了一种结合多语言对比奖励信号的组相对策略优化（GRPO）框架，提升了跨语言Text-to-SQL系统的执行准确率和语义准确率，仅用3000个训练样本即在小模型上超越大模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL方法过于关注可执行查询，忽视了语义对齐挑战，且在跨语言场景下执行准确率显著下降，亟需提升模型在多语言环境中的语义理解与对齐能力。

Method: 提出一种新框架，将组相对策略优化（GRPO）与基于语义相似性的多语言对比奖励信号结合，在强化学习中优化SQL生成与用户意图之间的语义一致性。

Result: 在MultiSpider七语言数据集上，微调LLaMA-3-3B模型使执行准确率达87.4%（+26pp），语义准确率达52.29%（+32.86pp）；引入对比奖励后，平均语义准确率进一步提升至59.14%（最高+10pp，如越南语），且3B模型优于零样本8B模型。

Conclusion: 该方法通过对比奖励实现定向语义对齐，可在极小训练样本下显著提升跨语言Text-to-SQL性能，为小模型高效微调提供了有效路径。

Abstract: Current Text-to-SQL methods are evaluated and only focused on executable
queries, overlooking the semantic alignment challenge -- both in terms of the
semantic meaning of the query and the correctness of the execution results.
Even execution accuracy itself shows significant drops when moving from English
to other languages, with an average decline of 6 percentage points across
non-English languages. We address these challenges by presenting a new
framework that combines Group Relative Policy Optimization (GRPO) within a
multilingual contrastive reward signal to enhance both task efficiency and
semantic accuracy in Text-to-SQL systems in cross-lingual scenarios. Our method
teaches models to obtain better correspondence between SQL generation and user
intent by combining a reward signal based on semantic similarity. On the
seven-language MultiSpider dataset, fine-tuning the LLaMA-3-3B model with GRPO
improved the execution accuracy up to 87.4 percent (+26 pp over zero-shot) and
semantic accuracy up to 52.29 percent (+32.86 pp). Adding our contrastive
reward signal in the GRPO framework further improved the average semantic
accuracy to 59.14 percent (+6.85 pp, up to +10 pp for Vietnamese). Our
experiments showcase that a smaller, parameter-efficient 3B LLaMA model
fine-tuned with our contrastive reward signal outperforms a much larger
zero-shot 8B LLaMA model, with an uplift of 7.43 pp in execution accuracy (from
81.43 percent on the 8B model to 88.86 percent on the 3B model), and nearly
matches its semantic accuracy (59.14 percent vs. 68.57 percent) -- all using
just 3,000 reinforcement learning training examples. These results demonstrate
how we can improve the performance of Text-to-SQL systems with contrastive
rewards for directed semantic alignment, without requiring large-scale training
datasets.

</details>


### [102] [From Explainability to Action: A Generative Operational Framework for Integrating XAI in Clinical Mental Health Screening](https://arxiv.org/abs/2510.13828)
*Ratna Kandala,Akshata Kishore Moharir,Divya Arvinda Nayak*

Main category: cs.CL

TL;DR: 本文提出了一个生成性操作框架，利用大语言模型（LLM）作为核心翻译引擎，将解释性人工智能（XAI）的技术输出转化为临床相关的、可操作的叙述，以弥合心理健康筛查中技术透明性与实际临床应用之间的差距。


<details>
  <summary>Details</summary>
Motivation: 当前的XAI技术虽然在技术层面上能够提供精确的特征重要性评分等输出，但缺乏对临床医生和患者有用的、可理解的可操作洞察，导致从实验室到临床的应用存在显著鸿沟。

Method: 提出了一种新的系统架构——生成性操作框架，该框架使用大型语言模型（LLMs）作为中心翻译引擎，结合检索增强生成（RAG）技术，整合多种XAI工具的技术输出与临床指南，自动生成基于证据的人类可读临床叙述。

Result: 该框架有效解决了工作流集成、偏见缓解以及针对不同利益相关者的沟通等关键操作障碍，展示了从孤立数据点向综合、可操作且可信的AI临床实践迈进的可能性。

Conclusion: 生成性操作框架为弥合技术解释与临床实用性之间的翻译鸿沟提供了可行路径，并为推动心理健康筛查中AI的实际应用提供了战略路线图。

Abstract: Explainable Artificial Intelligence (XAI) has been presented as the critical
component for unlocking the potential of machine learning in mental health
screening (MHS). However, a persistent lab-to-clinic gap remains. Current XAI
techniques, such as SHAP and LIME, excel at producing technically faithful
outputs such as feature importance scores, but fail to deliver clinically
relevant, actionable insights that can be used by clinicians or understood by
patients. This disconnect between technical transparency and human utility is
the primary barrier to real-world adoption. This paper argues that this gap is
a translation problem and proposes the Generative Operational Framework, a
novel system architecture that leverages Large Language Models (LLMs) as a
central translation engine. This framework is designed to ingest the raw,
technical outputs from diverse XAI tools and synthesize them with clinical
guidelines (via RAG) to automatically generate human-readable, evidence-backed
clinical narratives. To justify our solution, we provide a systematic analysis
of the components it integrates, tracing the evolution from intrinsic models to
generative XAI. We demonstrate how this framework directly addresses key
operational barriers, including workflow integration, bias mitigation, and
stakeholder-specific communication. This paper also provides a strategic
roadmap for moving the field beyond the generation of isolated data points
toward the delivery of integrated, actionable, and trustworthy AI in clinical
practice.

</details>


### [103] [A Linguistics-Aware LLM Watermarking via Syntactic Predictability](https://arxiv.org/abs/2510.13829)
*Shinwoo Park,Hyejin Park,Hyeseon Ahn,Yo-Sub Han*

Main category: cs.CL

TL;DR: STELA是一种新型水印框架，通过利用语言的词性n-gram建模语言不确定性，动态调整水印强度，在保持文本质量的同时增强检测鲁棒性，并支持无需模型logits的公开验证检测。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM水印方法依赖模型输出分布（如token级熵），需访问模型logits，难以实现公开验证。同时，文本质量与检测鲁棒性之间存在权衡，亟需一种既能保证生成质量又能实现强检测且可公开验证的方法。

Method: 提出STELA框架，利用POS n-gram模型量化语言的自由度（语言不确定性），在语法约束强的上下文中减弱水印信号以保持文本质量，在语言灵活性高的上下文中增强信号以提高可检测性。检测器不依赖任何模型logits，实现公开可验证。

Result: 在英语、中文和韩语等多种类型的语言上实验表明，STELA在检测鲁棒性方面优于先前方法，同时保持了较高的文本质量，且实现了无需模型访问的公开验证检测。

Conclusion: STELA通过结合语言结构特性实现了文本质量与检测鲁棒性的良好平衡，并推动了面向公众可验证的LLM水印技术发展，有助于构建可信的AI生态系统。

Abstract: As large language models (LLMs) continue to advance rapidly, reliable
governance tools have become critical. Publicly verifiable watermarking is
particularly essential for fostering a trustworthy AI ecosystem. A central
challenge persists: balancing text quality against detection robustness. Recent
studies have sought to navigate this trade-off by leveraging signals from model
output distributions (e.g., token-level entropy); however, their reliance on
these model-specific signals presents a significant barrier to public
verification, as the detection process requires access to the logits of the
underlying model. We introduce STELA, a novel framework that aligns watermark
strength with the linguistic degrees of freedom inherent in language. STELA
dynamically modulates the signal using part-of-speech (POS) n-gram-modeled
linguistic indeterminacy, weakening it in grammatically constrained contexts to
preserve quality and strengthen it in contexts with greater linguistic
flexibility to enhance detectability. Our detector operates without access to
any model logits, thus facilitating publicly verifiable detection. Through
extensive experiments on typologically diverse languages-analytic English,
isolating Chinese, and agglutinative Korean-we show that STELA surpasses prior
methods in detection robustness. Our code is available at
https://github.com/Shinwoo-Park/stela_watermark.

</details>


### [104] [Users as Annotators: LLM Preference Learning from Comparison Mode](https://arxiv.org/abs/2510.13830)
*Zhongze Cai,Xiaocheng Li*

Main category: cs.CL

TL;DR: 提出一种通过用户比较模式收集大语言模型对齐的成对偏好数据的新方法，利用不同模型生成的响应差异推断用户数据质量，并通过EM算法估计用户质量因子以过滤低质量标注。


<details>
  <summary>Details</summary>
Motivation: 传统成对偏好数据依赖专业人工标注，成本高；而用户在与LLM交互中产生的偏好标签虽更具真实性，但缺乏质量控制，需有效方法评估和筛选用户标注质量。

Method: 设计一种基于用户比较行为的数据收集方式，利用两个不同模型生成的响应引入不对称性，建立用户行为模型并通过期望最大化（EM）算法估计用户的潜在质量因子，进而对用户标注数据进行过滤。

Result: 实验表明该方法能有效建模用户行为，准确估计用户标注质量，并在下游任务中提升用于LLM对齐的数据质量。

Conclusion: 通过建模用户行为和估计其标注质量，可有效利用用户生成的偏好数据进行LLM对齐，为低成本、高质量的数据收集提供了可行方案。

Abstract: Pairwise preference data have played an important role in the alignment of
large language models (LLMs). Each sample of such data consists of a prompt,
two different responses to the prompt, and a binary label indicating which of
the two responses is better. The labels are usually annotated by professional
human annotators. In this paper, we consider an alternative approach to collect
pairwise preference data -- user annotation from comparison mode. With the
increasingly wider adoption of LLMs among the population, users are
contributing more and more of their preference labels through their daily
interactions with the LLMs. The upside of such labels is that users are the
best experts in judging the responses to their own queries/prompts, but the
downside is the lack of quality control in these labels. In this paper, we
consider a new idea of generating two responses from two different models or
two different versions of the same model. The asymmetry allows us to make an
inference of the user's data quality through our proposed user behavior model.
We develop an expectation-maximization algorithm to estimate a latent quality
factor of the user, and filter users' annotation data accordingly. The
downstream task shows the effectiveness of our approach in both capturing the
user behavior and data filtering for LLM alignment.

</details>


### [105] [Informed Routing in LLMs: Smarter Token-Level Computation for Faster Inference](https://arxiv.org/abs/2510.13831)
*Chao Han,Yijuan Liang,Zihao Xuan,Daokuan Wu,Wei Zhang,Xiaoyu Shen*

Main category: cs.CL

TL;DR: 提出了一种新的动态计算分配范式——informed routing，通过预测模块评估token的可恢复性，实现执行或近似处理的灵活策略，在保持模型性能的同时显著降低大模型推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于贪婪路由的动态计算方法存在信息丢失和次优选择问题，限制了大模型在现实应用中的部署效率。

Method: 引入informed routing，结合 Lightweight Feature Forecaster (LFF) 模块，在路由前预测神经元输出，根据token的重要性和可恢复性决定执行或近似处理。

Result: 在语言建模和推理任务上实现了最先进的效率-性能权衡，无需最终LoRA微调即可匹敌甚至超越需全量微调的强基线，训练时间减少超过50%。

Conclusion: informed routing通过前瞻性决策有效平衡了计算开销与模型性能，为高效推理提供了新方向。

Abstract: The deployment of large language models (LLMs) in real-world applications is
increasingly limited by their high inference cost. While recent advances in
dynamic token-level computation allocation attempt to improve efficiency by
selectively activating model components per token, existing methods rely on
greedy routing--a myopic execute-or-skip mechanism that often leads to
irreversible information loss and suboptimal token selection. This paper
introduces informed routing, a new paradigm that proactively addresses these
issues. The key insight is to assess not only a token's immediate importance
but also its recoverability, i.e., how well its transformation can be
approximated. To this end, we propose the Lightweight Feature Forecaster (LFF),
a small predictive module that estimates a unit's output before routing
decisions are made. This enables a flexible execute-or-approximate policy that
preserves model fidelity while drastically reducing computation. Extensive
experiments on both language modeling and reasoning tasks show that informed
routing achieves state-of-the-art efficiency-performance trade-offs across
multiple sparsity levels. Notably, even without final LoRA fine-tuning, our
method matches or surpasses strong baselines that require full fine-tuning, all
while reducing training time by over 50%. The code is available at:
https://github.com/EIT-NLP/informed-routing

</details>


### [106] [Entropy Meets Importance: A Unified Head Importance-Entropy Score for Stable and Efficient Transformer Pruning](https://arxiv.org/abs/2510.13832)
*Minsik Choi,Hyegang Son,Changhoon Kim,Young Geun Kim*

Main category: cs.CL

TL;DR: 提出了一种新的剪枝准则HIES，结合头重要性分数和注意力熵，显著提升了Transformer模型剪枝后的性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有基于梯度的头部重要性评分（HIS）方法仅捕捉梯度贡献，忽略了注意力模式的多样性，导致剪枝效果受限。

Method: 引入HIES（Head Importance-Entropy Score），将HIS与注意力熵结合，综合评估每个注意力头的贡献。

Result: 基于HIES的剪枝方法在模型质量上最多提升15.2%，稳定性提升2.04倍，实现高效压缩而不牺牲准确性和稳定性。

Conclusion: HIES通过融合重要性和多样性信息，优于传统HIS方法，是一种更有效的Transformer模型剪枝准则。

Abstract: Transformer-based models have achieved remarkable performance in NLP tasks.
However, their structural characteristics-multiple layers and attention
heads-introduce efficiency challenges in inference and deployment. To address
these challenges, various pruning methods have recently been proposed. Notably,
gradient-based methods using Head Importance Scores (HIS) have gained traction
for interpretability, efficiency, and ability to identify redundant heads.
However, HIS alone has limitations as it captures only the gradient-driven
contribution, overlooking the diversity of attention patterns. To overcome
these limitations, we introduce a novel pruning criterion, HIES (Head
Importance-Entropy Score), which integrates head importance scores with
attention entropy, providing complementary evidence on per-head contribution.
Empirically, HIES-based pruning yields up to 15.2% improvement in model quality
and 2.04x improvement in stability over HIS-only methods, enabling substantial
model compression without sacrificing either accuracy or stability. Code will
be released upon publication.

</details>


### [107] [ConDABench: Interactive Evaluation of Language Models for Data Analysis](https://arxiv.org/abs/2510.13835)
*Avik Dutta,Priyanshu Gupta,Hosein Hasanbeig,Rahul Pratap Singh,Harshit Nigam,Sumit Gulwani,Arjun Radhakrishna,Gustavo Soares,Ashish Tiwari*

Main category: cs.CL

TL;DR: ConDABench是一个用于生成和评估对话式数据分析（ConDA）基准的新框架，旨在解决现实世界中目标模糊和数据不清洁的数据分析任务，支持对大语言模型在复杂交互任务中的表现进行系统性评估。


<details>
  <summary>Details</summary>
Motivation: 现有评估大语言模型在数据分析任务上表现的基准未能充分反映真实场景中的复杂性，缺少对交互性的支持，因此需要一个能够模拟真实用户交互并评估模型在复杂任务中持续参与能力的新基准框架。

Method: 提出ConDABench框架，包含一个基于多智能体工作流的基准生成方法，从公开数据集的分析文章中自动生成1,420个ConDA问题，并开发一个评估工具，用于系统评估大模型在这些交互式任务上的表现。

Result: 对当前主流大语言模型的评估显示，尽管新一代模型能解决更多问题，但在需要长期、深入交互的任务上表现并未显著提升。

Conclusion: ConDABench为构建更擅长复杂交互任务的协作式模型提供了新的评估路径，有助于推动模型在真实数据分析场景中的实用性发展。

Abstract: Real-world data analysis tasks often come with under-specified goals and
unclean data. User interaction is necessary to understand and disambiguate a
user's intent, and hence, essential to solving these complex tasks. Existing
benchmarks for evaluating LLMs on data analysis tasks do not capture these
complexities or provide first-class support for interactivity. We introduce
ConDABench, a framework for generating conversational data analysis (ConDA)
benchmarks and evaluating external tools on the generated benchmarks. \bench
consists of (a) a multi-agent workflow for generating realistic benchmarks from
articles describing insights gained from public datasets, (b) 1,420 ConDA
problems generated using this workflow, and (c) an evaluation harness that, for
the first time, makes it possible to systematically evaluate conversational
data analysis tools on the generated ConDA problems. Evaluation of
state-of-the-art LLMs on the benchmarks reveals that while the new generation
of models are better at solving more instances, they are not necessarily better
at solving tasks that require sustained, long-form engagement. ConDABench is an
avenue for model builders to measure progress towards truly collaborative
models that can complete complex interactive tasks.

</details>


### [108] [SIMBA UQ: Similarity-Based Aggregation for Uncertainty Quantification in Large Language Models](https://arxiv.org/abs/2510.13836)
*Debarun Bhattacharjya,Balaji Ganesan,Junkyu Lee,Radu Marinescu,Katsiaryna Mirylenka,Michael Glass,Xiao Shou*

Main category: cs.CL

TL;DR: 本文研究了基于一致性（生成结果与其他采样结果之间的相似性）作为置信度代理的黑盒不确定性量化（UQ）方法，提出了一个基于相似性的高层聚合框架，并引入了可在少量训练数据下训练置信度估计模型的新技术，在多种生成任务中表现出更优的置信度校准效果。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）在实际应用中需要评估其输出的可靠性，不确定性量化（UQ）是构建可信AI系统的关键。黑盒UQ方法因其无需访问模型内部信息而具有更强的实用性，但其在复杂生成任务中的有效性尚需系统研究。

Method: 提出一种非语言化的基于相似性的聚合框架，利用生成结果之间的一致性作为置信度代理，涵盖多种UQ方法，并设计可在小样本下训练的置信度估计模型。在问答、摘要和文本到SQL等任务上进行实证研究。

Result: 所提出的基于相似性的方法在多个数据集和任务上相比基线方法能产生更准确校准的置信度估计，尤其适用于复杂的生成任务。

Conclusion: 基于输出一致性的黑盒UQ方法是有效的，所提出的框架为构建可信赖的大语言模型系统提供了实用且可扩展的不确定性评估方案。

Abstract: When does a large language model (LLM) know what it does not know?
Uncertainty quantification (UQ) provides measures of uncertainty, such as an
estimate of the confidence in an LLM's generated output, and is therefore
increasingly recognized as a crucial component of trusted AI systems. Black-box
UQ methods do not require access to internal model information from the
generating LLM and therefore have numerous real-world advantages, such as
robustness to system changes, adaptability to choice of LLM, reduced costs, and
computational tractability. In this paper, we investigate the effectiveness of
UQ techniques that are primarily but not necessarily entirely black-box, where
the consistency between a generated output and other sampled generations is
used as a proxy for confidence in its correctness. We propose a high-level
non-verbalized similarity-based aggregation framework that subsumes a broad
swath of UQ approaches suitable for complex generative tasks, as well as
introduce specific novel techniques from the framework that train confidence
estimation models using small training sets. Through an empirical study with
datasets spanning the diverse tasks of question answering, summarization, and
text-to-SQL, we demonstrate that our proposed similarity-based methods can
yield better calibrated confidences than baselines.

</details>


### [109] [Seeing Hate Differently: Hate Subspace Modeling for Culture-Aware Hate Speech Detection](https://arxiv.org/abs/2510.13837)
*Weibin Cai,Reza Zafarani*

Main category: cs.CL

TL;DR: 提出了一种文化感知的仇恨言论检测框架，通过构建个体的仇恨子空间来缓解训练标签偏差和文化差异带来的影响，提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测方法忽视了训练标签存在文化偏见及个体对仇恨定义理解不同的现实问题，导致模型在跨文化场景下表现不佳。

Method: 构建文化感知框架，建模文化属性组合以缓解数据稀疏，并利用标签传播捕捉不同文化组合下的独特特征，进而构建个体化的仇恨子空间。

Result: 实验表明，该方法在所有指标上平均超越现有最先进方法1.05%。

Conclusion: 文化感知的个体化建模能有效提升仇恨言论检测性能，尤其在处理文化差异、标签模糊和数据稀疏问题上具有优势。

Abstract: Hate speech detection has been extensively studied, yet existing methods
often overlook a real-world complexity: training labels are biased, and
interpretations of what is considered hate vary across individuals with
different cultural backgrounds. We first analyze these challenges, including
data sparsity, cultural entanglement, and ambiguous labeling. To address them,
we propose a culture-aware framework that constructs individuals' hate
subspaces. To alleviate data sparsity, we model combinations of cultural
attributes. For cultural entanglement and ambiguous labels, we use label
propagation to capture distinctive features of each combination. Finally,
individual hate subspaces, which in turn can further enhance classification
performance. Experiments show our method outperforms state-of-the-art by 1.05\%
on average across all metrics.

</details>


### [110] [Meronymic Ontology Extraction via Large Language Models](https://arxiv.org/abs/2510.13839)
*Dekai Zhang,Simone Conia,Antonio Rago*

Main category: cs.CL

TL;DR: 本文提出了一种利用大语言模型（LLM）从原始评论文本中全自动提取产品本体（特别是meronymies，即部分-整体关系）的方法，相比基于BERT的基线模型表现更优。


<details>
  <summary>Details</summary>
Motivation: 手动构建本体耗时、昂贵且繁琐，而现有的自动化方法仍有改进空间，因此需要一种更高效的自动化本体提取方案。

Method: 利用大语言模型（LLM）直接从产品评论文本中提取meronymy关系，构建产品本体，并采用LLM-as-a-judge方式进行评估。

Result: 所提出的方法在LLM评估下优于现有的BERT-based基线模型，生成的本体质量更高。

Conclusion: 该研究为大语言模型在产品或其他领域本体提取中的广泛应用奠定了基础。

Abstract: Ontologies have become essential in today's digital age as a way of
organising the vast amount of readily available unstructured text. In providing
formal structure to this information, ontologies have immense value and
application across various domains, e.g., e-commerce, where countless product
listings necessitate proper product organisation. However, the manual
construction of these ontologies is a time-consuming, expensive and laborious
process. In this paper, we harness the recent advancements in large language
models (LLMs) to develop a fully-automated method of extracting product
ontologies, in the form of meronymies, from raw review texts. We demonstrate
that the ontologies produced by our method surpass an existing, BERT-based
baseline when evaluating using an LLM-as-a-judge. Our investigation provides
the groundwork for LLMs to be used more generally in (product or otherwise)
ontology extraction.

</details>


### [111] [ADMIT: Few-shot Knowledge Poisoning Attacks on RAG-based Fact Checking](https://arxiv.org/abs/2510.13842)
*Yutao Wu,Xiao Liu,Yinghui Li,Yifeng Gao,Yifan Ding,Jiale Ding,Xiang Zheng,Xingjun Ma*

Main category: cs.CL

TL;DR: 本文提出了一种名为ADMIT的新型知识投毒攻击方法，能够在极低投毒率下有效翻转基于检索增强生成（RAG）的事实核查结果，且无需访问目标模型或检索器，展现出强大的跨模型和跨领域迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究已表明大语言模型易受检索内容中恶意信息的影响，但在真实事实核查场景中，检索结果通常包含大量可信证据，攻击更难成功。因此，亟需研究在主导性真实证据存在下仍有效的知识投毒策略，以评估RAG系统的实际安全性。

Method: 作者提出了ADMIT（ADversarial Multi-Injected Technique），一种少样本、语义对齐的多点投毒攻击方法。该方法通过在知识库中注入语义合理但具有误导性的文本，干扰检索结果中的证据分布，诱导大语言模型生成攻击者期望的判断与解释，且整个过程无需访问目标LLM或检索器，也不依赖token级控制。

Result: 实验表明，ADMIT在4种检索器、11种大语言模型和4个跨领域基准上均表现出优异的迁移攻击效果，平均攻击成功率（ASR）达86%，投毒率低至0.93×10⁻⁶，并在存在强反驳证据的情况下仍保持鲁棒性，相比先前最优攻击方法ASR提升11.2%。

Conclusion: ADMIT揭示了当前RAG系统在面对隐蔽、语义一致的知识投毒时存在严重安全隐患，尤其是在事实核查等高风险应用场景中，亟需开发更强大的防御机制。

Abstract: Knowledge poisoning poses a critical threat to Retrieval-Augmented Generation
(RAG) systems by injecting adversarial content into knowledge bases, tricking
Large Language Models (LLMs) into producing attacker-controlled outputs
grounded in manipulated context. Prior work highlights LLMs' susceptibility to
misleading or malicious retrieved content. However, real-world fact-checking
scenarios are more challenging, as credible evidence typically dominates the
retrieval pool. To investigate this problem, we extend knowledge poisoning to
the fact-checking setting, where retrieved context includes authentic
supporting or refuting evidence. We propose \textbf{ADMIT}
(\textbf{AD}versarial \textbf{M}ulti-\textbf{I}njection \textbf{T}echnique), a
few-shot, semantically aligned poisoning attack that flips fact-checking
decisions and induces deceptive justifications, all without access to the
target LLMs, retrievers, or token-level control. Extensive experiments show
that ADMIT transfers effectively across 4 retrievers, 11 LLMs, and 4
cross-domain benchmarks, achieving an average attack success rate (ASR) of 86\%
at an extremely low poisoning rate of $0.93 \times 10^{-6}$, and remaining
robust even in the presence of strong counter-evidence. Compared with prior
state-of-the-art attacks, ADMIT improves ASR by 11.2\% across all settings,
exposing significant vulnerabilities in real-world RAG-based fact-checking
systems.

</details>


### [112] [Serialized EHR make for good text representations](https://arxiv.org/abs/2510.13843)
*Zhirong Chou,Quan Qin,Shi Li*

Main category: cs.CL

TL;DR: SerialBEHRT是一种基于SciBERT的医疗基础模型，通过对结构化电子健康记录（EHR）序列进行额外预训练，有效捕捉临床事件的时间和上下文关系，在抗生素敏感性预测任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的医疗基础模型难以协调EHR的表格化、事件驱动特性与自然语言模型的序列先验之间的结构差异，限制了对患者就诊间纵向依赖关系的建模能力。

Method: 提出SerialBEHRT，通过将EHR数据转化为时间序列形式，并在结构化EHR序列上对SciBERT进行进一步预训练，以增强其对临床事件时序关系的建模能力。

Result: 在抗生素敏感性预测任务中，SerialBEHRT显著优于当前最先进的EHR表示方法，且性能更稳定一致。

Conclusion: 将EHR数据进行时间序列化处理并用于基础模型预训练，对提升医疗AI模型的表征能力具有重要意义。

Abstract: The emergence of foundation models in healthcare has opened new avenues for
learning generalizable representations from large scale clinical data. Yet,
existing approaches often struggle to reconcile the tabular and event based
nature of Electronic Health Records (EHRs) with the sequential priors of
natural language models. This structural mismatch limits their ability to
capture longitudinal dependencies across patient encounters. We introduce
SerialBEHRT, a domain aligned foundation model that extends SciBERT through
additional pretraining on structured EHR sequences. SerialBEHRT is designed to
encode temporal and contextual relationships among clinical events, thereby
producing richer patient representations. We evaluate its effectiveness on the
task of antibiotic susceptibility prediction, a clinically meaningful problem
in antibiotic stewardship. Through extensive benchmarking against state of the
art EHR representation strategies, we demonstrate that SerialBEHRT achieves
superior and more consistent performance, highlighting the importance of
temporal serialization in foundation model pretraining for healthcare.

</details>


### [113] [DynaSpec: Context-aware Dynamic Speculative Sampling for Large-Vocabulary Language Models](https://arxiv.org/abs/2510.13847)
*Jinbin Zhang,Nasib Ullah,Erik Schultheis,Rohit Babbar*

Main category: cs.CL

TL;DR: DynaSpec提出一种上下文相关的动态短列表机制，通过轻量级元分类器将上下文路由到令牌簇，提升推测解码的 drafting 速度，同时保持验证的精确性。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码中的固定词汇短列表方法依赖语料频率、泛化性差，且抑制罕见或领域特定令牌，影响每轮验证接受的令牌数。

Method: 引入轻量级、粗粒度的元分类器，将上下文动态划分到少量令牌簇，选取 top-k 簇的并集作为 drafter 的短列表；验证阶段仍使用完整词汇表。元分类器与 draft 编码并行执行，避免额外延迟。

Result: 在标准推测解码基准上，DynaSpec 相比固定短列表基线显著提升平均接受长度，且可用更小的短列表而不降低接受率。

Conclusion: DynaSpec 是一种鲁棒、高效且可泛化的动态短列表方法，有效缓解了大词汇表下推测解码的延迟瓶颈。

Abstract: Speculative decoding (a.k.a. speculative sampling) has become a standard way
to accelerate LLM inference: a small drafter proposes multiple tokens and a
large target model verifies them once per speculation length. Recently, scaling
of the LLM vocabulary has pushed the number of tokens to grow substantially.
While verification over the full vocabulary leaves the target model largely
unaffected, the O(|V|d) parameters in the drafter's output head become a
latency bottleneck, slowing the entire pipeline. Contemporary methods (e.g.,
FR-Spec, VocabTrim) restrict the drafter's vocabulary to a fixed subset of the
target model's vocabulary, ranked in descending order of token frequency.
Although this reduces draft-time compute, it is brittle, since: (i) frequency
lists are corpus-dependent and require retuning to generalize, and (ii) static
shortlists suppress rare or domain-specific tokens, lowering the expected
number of tokens per verification step. We propose DynaSpec, a
context-dependent dynamic shortlisting mechanism that is robust, speeds up
drafting, and generalizes across diverse tasks. Concretely, we introduce
lightweight, coarse-grained meta-classifiers that route contexts to a small
number of token clusters; the union of the top-k selected clusters forms the
drafter's shortlist, while verification retains the full vocabulary and
exactness. The meta-classifier finishes its computation earlier than the
drafter's hidden state generation by exploiting parallel execution of draft
encoding and meta shortlisting on separate streams. On standard
speculative-decoding benchmarks, we observe consistent gains in mean accepted
length over fixed-shortlist baselines, while context-dependent selection
enables smaller shortlists without degrading acceptance.

</details>


### [114] [On-device System of Compositional Multi-tasking in Large Language Models](https://arxiv.org/abs/2510.13848)
*Ondrej Bohdal,Konstantinos Theodosiadis,Asterios Mpatziakas,Dimitris Filippidis,Iro Spyrou,Christos Zonios,Anastasios Drosou,Dimosthenis Ioannidis,Kyeng-Hun Lee,Jijoong Moon,Hyeonmok Ko,Mete Ozay,Umberto Michieli*

Main category: cs.CL

TL;DR: 提出一种新的多任务适配器方法，通过在摘要和翻译适配器上添加可学习的投影层，实现高效的组合式多任务处理，适用于资源受限的设备。


<details>
  <summary>Details</summary>
Motivation: 标准的适配器方法在同时执行复杂任务（如长对话的翻译摘要）时表现不佳，需要更有效的组合多任务解决方案。

Method: 在低秩适配器（LoRA）基础上，为摘要和翻译任务组合添加可学习的投影层，实现任务间的有效整合。

Result: 实验表明该方法在云端和设备端均表现良好且速度快，能够在资源受限环境下高效运行。

Conclusion: 所提框架在高效、快速执行组合多任务方面具有实际应用潜力，尤其适用于对速度和资源有要求的场景。

Abstract: Large language models (LLMs) are commonly adapted for diverse downstream
tasks via parameter-efficient fine-tuning techniques such as Low-Rank Adapters
(LoRA). While adapters can be combined to handle multiple tasks separately,
standard approaches struggle when targeting the simultaneous execution of
complex tasks, such as generating a translated summary from a long
conversation. To address this challenge, we propose a novel approach tailored
specifically for compositional multi-tasking scenarios involving summarization
and translation. Our technique involves adding a learnable projection layer on
top of the combined summarization and translation adapters. This design enables
effective integration while maintaining efficiency through reduced
computational overhead compared to alternative strategies requiring extensive
retraining or sequential processing. We demonstrate the practical viability of
our method within an on-device environment by developing an Android app capable
of executing compositional tasks seamlessly. Experimental results indicate our
solution performs well and is fast in both cloud-based and on-device
implementations, highlighting the potential benefits of adopting our framework
in real-world applications demanding high-speed operation alongside resource
constraints.

</details>


### [115] [Language steering in latent space to mitigate unintended code-switching](https://arxiv.org/abs/2510.13849)
*Andrey Goncharov,Nikolai Kondusov,Alexey Zaytsev*

Main category: cs.CL

TL;DR: 提出一种基于PCA的潜空间语言引导方法，有效减少多语言大模型中的语码转换，保持语义且计算开销极低。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型在生成时容易出现非预期的语码转换，影响下游任务可靠性，需要一种高效、轻量的语言控制方法。

Method: 在平行翻译数据的潜空间上进行主成分分析（PCA），识别语言方向，并在推理时引导词元嵌入沿这些方向调整，以控制语言身份。

Result: 使用单个主成分即可实现95-99%的语言分类准确率，在Qwen2.5和Llama-3.2模型上最多减少42%的下一项token分布差异，且仅需少量平行数据校准。

Conclusion: 语言身份在模型深层集中且具有近似完美的线性可分性，所提方法能高效抑制语码转换，同时保持生成语义。

Abstract: Multilingual Large Language Models (LLMs) often exhibit unintended
code-switching, reducing reliability in downstream tasks. We propose
latent-space language steering, a lightweight inference-time method that
identifies language directions via PCA on parallel translations and steers
token embeddings along these axes to control language identity. Our approach
mitigates code-switching while preserving semantics with negligible
computational overhead and requires only minimal parallel data for calibration.
Empirically, we achieve 95-99\% language classification accuracy using a single
principal component and reduce next-token distributional divergence by up to
42% across multiple language pairs on Qwen2.5 and Llama-3.2 models. We further
analyze the layer-wise evolution of language representations, revealing that
language identity concentrates in final layers with near-perfect linear
separability.

</details>


### [116] [Revisiting the UID Hypothesis in LLM Reasoning Traces](https://arxiv.org/abs/2510.13850)
*Minju Gwak,Guijin Son,Jaehyung Kim*

Main category: cs.CL

TL;DR: 研究发现大语言模型在推理过程中信息流并不均匀，与人类交流模式相反，成功解题的推理路径表现出信息密度的剧烈波动。


<details>
  <summary>Details</summary>
Motivation: 受心理语言学中均匀信息密度假说启发，旨在通过熵基指标分析大语言模型推理过程中的信息流动特性，以理解其推理机制。

Method: 引入基于熵的信息流度量方法，分析多个数学推理任务中大语言模型的推理轨迹，并比较正确与错误解答的信息密度分布。

Result: 在三个数学基准上发现，正确的推理路径呈现全局非均匀的信息密度变化，与人类遵循均匀信息密度的交流模式截然不同。

Conclusion: 挑战了对大模型推理应模仿人类认知的假设，表明成功的机器推理可能依赖非均匀信息流，为设计可解释和自适应的推理模型提供了新方向。

Abstract: Large language models (LLMs) often solve problems using step-by-step
Chain-of-Thought (CoT) reasoning, yet these intermediate steps are frequently
unfaithful or hard to interpret. Inspired by the Uniform Information Density
(UID) hypothesis in psycholinguistics -- which posits that humans communicate
by maintaining a stable flow of information -- we introduce entropy-based
metrics to analyze the information flow within reasoning traces. Surprisingly,
across three challenging mathematical benchmarks, we find that successful
reasoning in LLMs is globally non-uniform: correct solutions are characterized
by uneven swings in information density, in stark contrast to human
communication patterns. This result challenges assumptions about machine
reasoning and suggests new directions for designing interpretable and adaptive
reasoning models.

</details>


### [117] [EvoEdit: Evolving Null-space Alignment for Robust and Efficient Knowledge Editing](https://arxiv.org/abs/2510.13851)
*Sicheng Lyu,Yu Gu,Xinyu Wang,Jerry Huang,Sitao Luan,Yufei Cui,Xiao-Wen Chang,Peng Lu*

Main category: cs.CL

TL;DR: EvoEdit是一种新的大语言模型编辑策略，通过连续的零空间对齐缓解编辑过程中的灾难性干扰，实现稳定高效的模型更新。


<details>
  <summary>Details</summary>
Motivation: 现有的模型编辑方法在连续编辑场景中容易出现灾难性干扰，即新编辑破坏先前知识，难以保持知识一致性。为解决这一问题，需要更稳定、可持续的编辑机制。

Method: 提出EvoEdit，采用连续零空间对齐策略，在每次编辑时将修改限制在不影响已有知识（包括原始知识和已编辑知识）的零空间中，保持输出对保留知识的不变性。

Result: 在真实世界的连续知识编辑基准上，EvoEdit性能优于或相当于现有最先进方法，并实现最高3.53倍的加速。

Conclusion: EvoEdit有效缓解了连续编辑中的灾难性干扰，为动态知识更新提供了理论可靠、简单高效的新方法，强调了在动态信息环境中构建更原则性编辑机制的重要性。

Abstract: Large language models (LLMs) require continual updates to rectify outdated or
erroneous knowledge. Model editing has emerged as a compelling paradigm for
introducing targeted modifications without the computational burden of full
retraining. Existing approaches are mainly based on a locate-then-edit
framework. However, in sequential editing contexts, where multiple updates are
applied over time, they exhibit significant limitations and suffer from
catastrophic interference, i.e., new edits compromise previously integrated
updates and degrade preserved knowledge. To address these challenges, we
introduce EvoEdit, a novel editing strategy that mitigates catastrophic
interference through sequential null-space alignment, enabling stable and
efficient model editing. By performing sequential null-space alignment for each
incoming edit, EvoEdit preserves both original and previously modified
knowledge representations and maintains output invariance on preserved
knowledge even across long edit sequences, effectively mitigating interference.
Evaluations on real-world sequential knowledge-editing benchmarks show that
EvoEdit achieves better or comparable performance than prior state-of-the-art
locate-then-edit techniques, with up to 3.53 times speedup. Overall, these
results underscore the necessity of developing more principled approaches for
designing LLMs in dynamically evolving information settings, while providing a
simple yet effective solution with strong theoretical guarantees.

</details>


### [118] [ConsistencyAI: A Benchmark to Assess LLMs' Factual Consistency When Responding to Different Demographic Groups](https://arxiv.org/abs/2510.13852)
*Peter Banyas,Shristi Sharma,Alistair Simmons,Atharva Vispute*

Main category: cs.CL

TL;DR: 本文提出了ConsistencyAI，一个独立基准，用于衡量大型语言模型（LLM）在不同人物设定下的事实一致性。实验表明，不同LLM在不同人群角色下回答相同问题时存在事实不一致现象，且一致性受提供商和主题影响。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在公众信息获取中的广泛应用，其输出是否因用户身份特征（如人口统计学角色）不同而呈现事实差异成为关键问题。现有评估缺乏对这类不一致的系统性测量，因此需要一个独立、公正的基准来评估模型的事实一致性。

Method: 设计了ConsistencyAI基准，对19个LLM进行测试，每个模型用100个不同人物设定的提示重复提问15个主题各5个事实。将响应转换为句子嵌入，通过计算跨人物的余弦相似性并加权平均，得出事实一致性评分。

Result: 实验结果显示，一致性得分在0.7896到0.9065之间，平均为0.8656，该值被采纳为基准阈值。xAI的Grok-3表现最佳，多个轻量级模型表现最差。主题方面，就业市场最不一致，G7领导人最一致，疫苗和以巴冲突等话题存在提供商差异。

Conclusion: LLM的事实一致性受模型提供商和话题内容共同影响。ConsistencyAI提供了一种可复现的评估方式，作者公开代码与交互演示，倡导开发不受人物设定影响的提示策略，以提升模型的公平性与可靠性。

Abstract: Is an LLM telling you different facts than it's telling me? This paper
introduces ConsistencyAI, an independent benchmark for measuring the factual
consistency of large language models (LLMs) for different personas.
ConsistencyAI tests whether, when users of different demographics ask identical
questions, the model responds with factually inconsistent answers. Designed
without involvement from LLM providers, this benchmark offers impartial
evaluation and accountability. In our experiment, we queried 19 LLMs with
prompts that requested 5 facts for each of 15 topics. We repeated this query
100 times for each LLM, each time adding prompt context from a different
persona selected from a subset of personas modeling the general population. We
processed the responses into sentence embeddings, computed cross-persona cosine
similarity, and computed the weighted average of cross-persona cosine
similarity to calculate factual consistency scores. In 100-persona experiments,
scores ranged from 0.9065 to 0.7896, and the mean was 0.8656, which we adopt as
a benchmark threshold. xAI's Grok-3 is most consistent, while several
lightweight models rank lowest. Consistency varies by topic: the job market is
least consistent, G7 world leaders most consistent, and issues like vaccines or
the Israeli-Palestinian conflict diverge by provider. These results show that
both the provider and the topic shape the factual consistency. We release our
code and interactive demo to support reproducible evaluation and encourage
persona-invariant prompting strategies.

</details>


### [119] [BenchPress: A Human-in-the-Loop Annotation System for Rapid Text-to-SQL Benchmark Curation](https://arxiv.org/abs/2510.13853)
*Fabian Wenz,Omar Bouattour,Devin Yang,Justin Choi,Cecil Gregg,Nesime Tatbul,Çağatay Demiralp*

Main category: cs.CL

TL;DR: BenchPress是一个人机协同系统，利用检索增强生成（RAG）和大语言模型（LLMs）自动生成SQL查询的自然语言描述，辅助人类专家快速构建高质量的领域特定文本到SQL的基准数据集，显著减少标注时间和成本。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到SQL研究多基于公开数据集，难以反映私有企业数据仓库的真实场景；而手工构建企业级基准数据集费时费力且成本高昂，亟需一种高效、准确的自动化辅助方法。

Method: 提出BenchPress系统，结合检索增强生成（RAG）与大语言模型，为给定SQL查询生成多个自然语言描述候选，由人类专家进行选择、排序或编辑，实现高效准确的标注。

Result: 在企业SQL日志上的实验表明，LLM辅助显著减少了创建高质量基准所需的时间和人力，同时提升了标注准确性、基准可靠性及模型评估的鲁棒性。

Conclusion: BenchPress通过人机协同框架，有效解决了构建领域特定文本到SQL基准的效率与质量问题，为研究者和实践者提供了可定制、可扩展的评估机制，并已开源共享。

Abstract: Large language models (LLMs) have been successfully applied to many tasks,
including text-to-SQL generation. However, much of this work has focused on
publicly available datasets, such as Fiben, Spider, and Bird. Our earlier work
showed that LLMs are much less effective in querying large private enterprise
data warehouses and released Beaver, the first private enterprise text-to-SQL
benchmark. To create Beaver, we leveraged SQL logs, which are often readily
available. However, manually annotating these logs to identify which natural
language questions they answer is a daunting task. Asking database
administrators, who are highly trained experts, to take on additional work to
construct and validate corresponding natural language utterances is not only
challenging but also quite costly. To address this challenge, we introduce
BenchPress, a human-in-the-loop system designed to accelerate the creation of
domain-specific text-to-SQL benchmarks. Given a SQL query, BenchPress uses
retrieval-augmented generation (RAG) and LLMs to propose multiple natural
language descriptions. Human experts then select, rank, or edit these drafts to
ensure accuracy and domain alignment. We evaluated BenchPress on annotated
enterprise SQL logs, demonstrating that LLM-assisted annotation drastically
reduces the time and effort required to create high-quality benchmarks. Our
results show that combining human verification with LLM-generated suggestions
enhances annotation accuracy, benchmark reliability, and model evaluation
robustness. By streamlining the creation of custom benchmarks, BenchPress
offers researchers and practitioners a mechanism for assessing text-to-SQL
models on a given domain-specific workload. BenchPress is freely available via
our public GitHub repository at
https://github.com/fabian-wenz/enterprise-txt2sql and is also accessible on our
website at http://dsg-mcgraw.csail.mit.edu:5000.

</details>


### [120] [R2T: Rule-Encoded Loss Functions for Low-Resource Sequence Tagging](https://arxiv.org/abs/2510.13854)
*Mamadou K. Keita,Christopher Homan,Sebastien Diarra*

Main category: cs.CL

TL;DR: 提出了一种名为Rule-to-Tag（R2T）的混合框架，通过将语言学规则嵌入神经网络训练目标，并引入自适应损失函数，使模型在无标签文本上训练即可在Zarma语言的词性标注任务中达到98.2%的准确率，优于使用标注数据微调的基线模型；R2T还可作为复杂任务（如命名实体识别）的有效预训练方法。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言中标注数据稀缺的问题，探索在缺乏大量标注样本的情况下，如何通过引入语言学规则和先验知识提升模型性能。

Method: 提出R2T框架，将多层次语言规则整合进神经网络的训练目标，设计包含正则化项的自适应损失函数，使模型学会对未登录词（OOV）进行有原则的不确定性处理；采用“原则性学习”（PrL）范式，利用显式任务约束而非仅依赖标注数据进行训练。

Result: 在Zarma语言的POS标注任务中，仅使用无标签文本训练的R2T-BiLSTM模型达到98.2%准确率，优于使用300个标注句子微调的AfriBERTa；在NER任务中，R2T预训练+50个标注句子的模型优于使用300个标注句子训练的基线。

Conclusion: R2T框架结合语言规则与神经网络，在低资源场景下显著提升模型性能，验证了“原则性学习”范式的有效性，为少样本甚至无监督条件下的自然语言处理任务提供了新思路。

Abstract: We introduce the Rule-to-Tag (R2T) framework, a hybrid approach that
integrates a multi-tiered system of linguistic rules directly into a neural
network's training objective. R2T's novelty lies in its adaptive loss function,
which includes a regularization term that teaches the model to handle
out-of-vocabulary (OOV) words with principled uncertainty. We frame this work
as a case study in a paradigm we call principled learning (PrL), where models
are trained with explicit task constraints rather than on labeled examples
alone. Our experiments on Zarma part-of-speech (POS) tagging show that the
R2T-BiLSTM model, trained only on unlabeled text, achieves 98.2% accuracy,
outperforming baselines like AfriBERTa fine-tuned on 300 labeled sentences. We
further show that for more complex tasks like named entity recognition (NER),
R2T serves as a powerful pre-training step; a model pre-trained with R2T and
fine-tuned on just 50 labeled sentences outperformes a baseline trained on 300.

</details>


### [121] [Harnessing Consistency for Robust Test-Time LLM Ensemble](https://arxiv.org/abs/2510.13855)
*Zhichen Zeng,Qi Yu,Xiao Lin,Ruizhong Qiu,Xuying Ning,Tianxin Wei,Yuchen Yan,Jingrui He,Hanghang Tong*

Main category: cs.CL

TL;DR: 提出了一种名为CoRE的即插即用方法，通过利用模型一致性提升大语言模型集成的鲁棒性，有效应对词元和模型层面的不一致问题。


<details>
  <summary>Details</summary>
Motivation: 不同大语言模型存在异构分词方案和专业能力差异，导致集成时易受错误信号影响，现有方法在鲁棒性方面关注不足。

Method: CoRE从词元级和模型级两个层面建模一致性：词元级采用低通滤波抑制高不一致性词元；模型级则鼓励高自信心且与其他模型输出差异小的结果。

Result: 在多种基准、模型组合和集成策略下，CoRE显著提升了集成性能与鲁棒性。

Conclusion: CoRE是一种通用且有效的技术，能够增强LLM集成在面对异构性和不确定性时的稳定性。

Abstract: Different large language models (LLMs) exhibit diverse strengths and
weaknesses, and LLM ensemble serves as a promising approach to integrate their
complementary capabilities. Despite substantial progress in improving ensemble
quality, limited attention has been paid to the robustness of ensembles against
potential erroneous signals, which often arise from heterogeneous tokenization
schemes and varying model expertise. Our analysis shows that ensemble failures
typically arise from both the token level and the model level: the former
reflects severe disagreement in token predictions, while the latter involves
low confidence and pronounced disparities among models. In light of this, we
propose CoRE, a plug-and-play technique that harnesses model consistency for
robust LLM ensemble, which can be seamlessly integrated with diverse ensemble
methods. Token-level consistency captures fine-grained disagreements by
applying a low-pass filter to downweight uncertain tokens with high
inconsistency, often due to token misalignment, thereby improving robustness at
a granular level. Model-level consistency models global agreement by promoting
model outputs with high self-confidence and minimal divergence from others,
enhancing robustness at a coarser level. Extensive experiments across diverse
benchmarks, model combinations, and ensemble strategies demonstrate that CoRE
consistently improves ensemble performance and robustness.

</details>


### [122] [Multimodal Retrieval-Augmented Generation with Large Language Models for Medical VQA](https://arxiv.org/abs/2510.13856)
*A H M Rezaul Karim,Ozlem Uzuner*

Main category: cs.CL

TL;DR: MasonNLP在MEDIQA-WV 2025伤口护理VQA任务中采用基于通用大语言模型的检索增强生成（RAG）框架，通过结合领域内文本和视觉示例，在无需额外训练的情况下显著提升回答质量，最终排名第三。


<details>
  <summary>Details</summary>
Motivation: 提升医学视觉问答系统在伤口护理场景下的回答准确性与结构化输出能力，支持临床决策，同时探索轻量级方法在多模态临床NLP任务中的有效性。

Method: 使用通用领域、指令调优的大语言模型，结合检索增强生成（RAG）框架，通过简单索引和融合机制引入领域相关的文本和视觉示例，增强模型在推理、模式遵循和响应生成方面的能力。

Result: 系统在19支队伍、51次提交中排名第三，平均得分为41.37%，在dBLEU、ROUGE、BERTScore及基于LLM的指标上均表现良好。

Conclusion: 轻量级RAG结合通用大语言模型是一种简单而有效的多模态临床NLP基线方法，无需额外训练即可提升性能。

Abstract: Medical Visual Question Answering (MedVQA) enables natural language queries
over medical images to support clinical decision-making and patient care. The
MEDIQA-WV 2025 shared task addressed wound-care VQA, requiring systems to
generate free-text responses and structured wound attributes from images and
patient queries. We present the MasonNLP system, which employs a
general-domain, instruction-tuned large language model with a
retrieval-augmented generation (RAG) framework that incorporates textual and
visual examples from in-domain data. This approach grounds outputs in
clinically relevant exemplars, improving reasoning, schema adherence, and
response quality across dBLEU, ROUGE, BERTScore, and LLM-based metrics. Our
best-performing system ranked 3rd among 19 teams and 51 submissions with an
average score of 41.37%, demonstrating that lightweight RAG with
general-purpose LLMs -- a minimal inference-time layer that adds a few relevant
exemplars via simple indexing and fusion, with no extra training or complex
re-ranking -- provides a simple and effective baseline for multimodal clinical
NLP tasks.

</details>


### [123] [ShishuLM: Lightweight Language Model with Hybrid Decoder-MLP Architecture and Paired Weight Sharing](https://arxiv.org/abs/2510.13860)
*Shivanshu Kumar,Gopalakrishnan Srinivasan*

Main category: cs.CL

TL;DR: 提出一种名为ShishuLM的高效语言模型架构，通过识别并利用Transformer中的冗余，显著减少参数量和KV缓存需求，在训练和推理中分别实现高达25%的内存减少和40%的延迟改善。


<details>
  <summary>Details</summary>
Motivation: Transformer模型虽然性能优越，但存在较高的内存和计算开销。特别是随着小语言模型（SLM）在智能体系统中的重要性增加，亟需更高效的架构以降低资源消耗。

Method: 受AI可解释性和推理时层剪枝研究的启发，ShishuLM利用归一化与注意力计算在中等上下文场景下近似线性的特性，用多层感知机（MLP）替代整个Transformer块，从而减少参数和KV缓存。

Result: 在不同规模的SLM上验证了ShishuLM的有效性，结果显示内存需求最多减少25%，训练和推理延迟最多改善40%。

Conclusion: ShishuLM为从小型语言模型预训练阶段构建更高效架构提供了新思路，有助于推动资源受限场景下的实用化AI系统发展。

Abstract: While the transformer architecture has achieved state-of-the-art performance
on natural language processing tasks, these models impose substantial memory
and computational overhead. Recent research has identified significant
architectural redundancies within these models, presenting opportunities for
optimization without compromising performance. Taking insights from research in
AI interpretability and inference-time layer pruning, we introduce an efficient
language model architecture, referred to as ShishuLM, which reduces both the
parameter count and Key-Value (KV) cache requirements. Given the increasing
importance of Small Language Models (SLMs) in agentic AI systems, we evaluate
our approach on two SLMs of different scales. Our analysis reveals that for
moderate-context scenarios, normalization coupled with attention computation is
roughly linear with the input, enabling entire transformer blocks to be
approximated through Multi-Layer Perceptrons (MLPs). Our results show that
ShishuLM provides up to 25% reduction in memory requirements and up to 40%
improvement in latency during both training and inference, compared to parent
models. Our experimental and analytical findings provide insights towards
building more efficient SLM architectures from a pre-training standpoint.

</details>


### [124] [Ensembling Large Language Models to Characterize Affective Dynamics in Student-AI Tutor Dialogues](https://arxiv.org/abs/2510.13862)
*Chenyu Zhang,Sharifa Alghowinem,Cynthia Breazeal*

Main category: cs.CL

TL;DR: 本研究提出首个基于集成大语言模型（LLM）的情感感知框架，分析AI辅导对话中学习者的情感动态，发现学生整体情绪偏积极但情绪变化频繁，中性情绪常为情绪转折点，为AI教育干预提供时机线索。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究关注大语言模型在教育中的影响，但对LLM辅助教学中的情感动态理解不足，尤其缺乏对学习者情绪状态演变的系统分析。

Method: 构建由三个前沿大模型（Gemini、GPT-4o、Claude）组成的集成框架，对16,986轮AI辅导对话进行零样本情感标注，提取效价、唤醒度和学习帮助性评分及自由文本情绪标签，并通过排序加权池化与多数共识融合结果。

Result: 学生与AI导师互动时通常表现出轻微积极情绪和中等唤醒度；困惑与好奇常见，挫折较少但存在；情绪持续时间短，积极情绪稍长但易被打断；负面情绪常迅速缓解甚至转为正面，中性情绪多导向积极转变。

Conclusion: 学习过程中的情绪状态动态且脆弱，中性情绪是关键干预时机，建议在这些转折点设计及时情感支持策略，以提升AI辅导的情感智能与教育效果。

Abstract: While recent studies have examined the leaning impact of large language model
(LLM) in educational contexts, the affective dynamics of LLM-mediated tutoring
remain insufficiently understood. This work introduces the first ensemble-LLM
framework for large-scale affect sensing in tutoring dialogues, advancing the
conversation on responsible pathways for integrating generative AI into
education by attending to learners' evolving affective states. To achieve this,
we analyzed two semesters' worth of 16,986 conversational turns exchanged
between PyTutor, an LLM-powered AI tutor, and 261 undergraduate learners across
three U.S. institutions. To investigate learners' emotional experiences, we
generate zero-shot affect annotations from three frontier LLMs (Gemini, GPT-4o,
Claude), including scalar ratings of valence, arousal, and
learning-helpfulness, along with free-text emotion labels. These estimates are
fused through rank-weighted intra-model pooling and plurality consensus across
models to produce robust emotion profiles. Our analysis shows that during
interaction with the AI tutor, students typically report mildly positive affect
and moderate arousal. Yet learning is not uniformly smooth: confusion and
curiosity are frequent companions to problem solving, and frustration, while
less common, still surfaces in ways that can derail progress. Emotional states
are short-lived--positive moments last slightly longer than neutral or negative
ones, but they are fragile and easily disrupted. Encouragingly, negative
emotions often resolve quickly, sometimes rebounding directly into positive
states. Neutral moments frequently act as turning points, more often steering
students upward than downward, suggesting opportunities for tutors to intervene
at precisely these junctures.

</details>


### [125] [Unlocking the Potential of Diffusion Language Models through Template Infilling](https://arxiv.org/abs/2510.13870)
*Junhoo Lee,Seungyeon Kim,Nojun Kwak*

Main category: cs.CL

TL;DR: 提出了一种针对扩散语言模型的模板填充生成方法（TI），结合动态段分配（DSA），在数学推理和代码生成任务上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型（DLMs）虽有潜力，但其推理策略仍受限于从自回归范式继承的前缀提示，缺乏适配其生成机制的定制化条件控制方法。

Method: 提出模板填充（Template Infilling, TI）方法：先生成目标响应的结构化模板，再填充被掩码的片段；引入动态段分配（DSA）机制，根据生成置信度自适应调整片段长度。

Result: 在数学推理和代码生成基准上，TI比基线平均提升17.01%；在多token生成场景中，TI在保持生成质量的同时实现有效加速。

Conclusion: TI为DLMs提供了更灵活、可控的生成范式，结合DSA增强了结构化生成的适应性，展示了其在复杂任务中的潜力与优势。

Abstract: Diffusion Language Models (DLMs) have emerged as a promising alternative to
Autoregressive Language Models, yet their inference strategies remain limited
to prefix-based prompting inherited from the autoregressive paradigm. In this
paper, we propose Template Infilling (TI), a tailored conditioning methodology
for DLMs' generation process. Unlike conventional prefix prompting, TI first
generates a structural template for the target response, then fills in the
masked segments. To enhance the flexibility of this structural control, we
introduce Dynamic Segment Allocation (DSA), which adaptively adjusts segment
lengths based on generation confidence. We demonstrate the effectiveness of our
approach on mathematical reasoning and code generation benchmarks, achieving
consistent improvements of 17.01$\%$p over baseline. Furthermore, we show that
TI provides additional advantages in multi-token generation settings, enabling
effective speedup while maintaining generation quality.

</details>


### [126] [Quechua Speech Datasets in Common Voice: The Case of Puno Quechua](https://arxiv.org/abs/2510.13871)
*Elwin Huaman,Wendi Huaman,Jorge Luis Huaman,Ninfa Quispe*

Main category: cs.CL

TL;DR: 本文探讨了将克丘亚语（Quechua）整合到Common Voice平台的过程，重点介绍了普诺克丘亚语（qxp）的语料库建设情况，并提出促进低资源语言语音技术发展的技术与伦理研究议程。


<details>
  <summary>Details</summary>
Motivation: 由于数据和资源匮乏，克丘亚语等低资源语言在语音技术发展中面临严重阻碍，亟需开放、社区驱动的语音数据集支持。

Method: 通过Common Voice平台推动克丘亚语的语言入驻与语音语料收集，涵盖朗读和自发语音数据，以普诺克丘亚语为案例进行实践。

Result: 目前Common Voice已收录191.1小时的克丘亚语语音数据（86%已验证），其中普诺克丘亚语贡献了12小时（77%已验证）。

Conclusion: Common Voice在支持低资源语言语音技术方面展现出巨大潜力，本研究推动了语音技术的包容性发展，并强调技术挑战、社区参与和原住民数据主权等关键议题。

Abstract: Under-resourced languages, such as Quechuas, face data and resource scarcity,
hindering their development in speech technology. To address this issue, Common
Voice presents a crucial opportunity to foster an open and community-driven
speech dataset creation. This paper examines the integration of Quechua
languages into Common Voice. We detail the current 17 Quechua languages,
presenting Puno Quechua (ISO 639-3: qxp) as a focused case study that includes
language onboarding and corpus collection of both reading and spontaneous
speech data. Our results demonstrate that Common Voice now hosts 191.1 hours of
Quechua speech (86\% validated), with Puno Quechua contributing 12 hours (77\%
validated), highlighting the Common Voice's potential. We further propose a
research agenda addressing technical challenges, alongside ethical
considerations for community engagement and indigenous data sovereignty. Our
work contributes towards inclusive voice technology and digital empowerment of
under-resourced language communities.

</details>


### [127] [FRACCO: A gold-standard annotated corpus of oncological entities with ICD-O-3.1 normalisation](https://arxiv.org/abs/2510.13873)
*Johann Pignat,Milena Vucetic,Christophe Gaudet-Blavignac,Jamil Zaghir,Amandine Stettler,Fanny Amrein,Jonatan Bonjour,Jean-Philippe Goldman,Olivier Michielin,Christian Lovis,Mina Bjelogrlic*

Main category: cs.CL

TL;DR: FRACCO是一个专家标注的法语肿瘤学临床文本语料库，包含1301个合成病例，标注了形态学、解剖位置和组织学分化等术语，并采用ICD-O标准进行实体和复合表达归一化，为法语临床文本的命名实体识别与概念归一化提供了基准数据集。


<details>
  <summary>Details</summary>
Motivation: 法语肿瘤学领域的标注数据集稀缺，限制了自然语言处理工具在临床文本中的应用，因此需要构建高质量、标准化的法语标注语料库以支持信息抽取任务。

Method: 基于西班牙语CANTEMIST语料库翻译生成1301个法语合成临床病例，由两名领域专家手动标注实体边界；通过自动化匹配结合人工验证的方式，由五名标注员完成ICD-O编码归一化，并增加复合表达层面的标准化标注层。

Result: 最终数据集包含71127个ICD-O归一化标注，涵盖399个唯一形态学代码（来自2549种不同表达）、272个解剖位置代码（来自3143种表达）和2043个唯一复合表达（来自11144种表达），所有文本均经过专家评审确保质量。

Conclusion: FRACCO为法语肿瘤学临床文本的信息抽取任务提供了可靠的标准数据集，尤其在命名实体识别与概念归一化方面具有重要应用价值，有助于推动法语临床自然语言处理的发展。

Abstract: Developing natural language processing tools for clinical text requires
annotated datasets, yet French oncology resources remain scarce. We present
FRACCO (FRench Annotated Corpus for Clinical Oncology) an expert-annotated
corpus of 1301 synthetic French clinical cases, initially translated from the
Spanish CANTEMIST corpus as part of the FRASIMED initiative. Each document is
annotated with terms related to morphology, topography, and histologic
differentiation, using the International Classification of Diseases for
Oncology (ICD-O) as reference. An additional annotation layer captures
composite expression-level normalisations that combine multiple ICD-O elements
into unified clinical concepts. Annotation quality was ensured through expert
review: 1301 texts were manually annotated for entity spans by two domain
experts. A total of 71127 ICD-O normalisations were produced through a
combination of automated matching and manual validation by a team of five
annotators. The final dataset representing 399 unique morphology codes (from
2549 different expressions), 272 topography codes (from 3143 different
expressions), and 2043 unique composite expressions (from 11144 different
expressions). This dataset provides a reference standard for named entity
recognition and concept normalisation in French oncology texts.

</details>


### [128] [What Layers When: Learning to Skip Compute in LLMs with Residual Gates](https://arxiv.org/abs/2510.13876)
*Filipe Laitenberger,Dawid Kopiczko,Cees G. M. Snoek,Yuki M. Asano*

Main category: cs.CL

TL;DR: 提出了一种称为GateSkip的简单门控机制，可在仅解码头语言模型中实现按层跳过不重要的token，在减少计算量的同时保持较高准确性。


<details>
  <summary>Details</summary>
Motivation: 为了在推理过程中减少计算开销并提高效率，同时保持语言模型的性能，特别是在长文本推理任务中。

Method: 在每个Attention/MLP分支中引入sigmoid-linear门控机制，控制残差流中的输出；通过门控值对token进行重要性排序，并根据每层预算跳过低重要性token。门控机制可微且平滑，能稳定地在预训练模型上微调。

Result: 在长文本推理任务中节省最多15%的计算量，同时保持超过90%的基线准确率；在指令微调模型上，在接近50%计算节省时仍能匹配基线质量，并在全计算量下观察到准确率提升。

Conclusion: GateSkip是一种高效、稳定且可解释的方法，不仅能降低推理成本，还能与量化、剪枝和自推测解码等技术结合，提供对Transformer信息流动的洞察。

Abstract: We introduce GateSkip, a simple residual-stream gating mechanism that enables
token-wise layer skipping in decoder-only LMs. Each Attention/MLP branch is
equipped with a sigmoid-linear gate that condenses the branch's output before
it re-enters the residual stream. During inference we rank tokens by the gate
values and skip low-importance ones using a per-layer budget. While early-exit
or router-based Mixture-of-Depths models are known to be unstable and need
extensive retraining, our smooth, differentiable gates fine-tune stably on top
of pretrained models. On long-form reasoning, we save up to 15\% compute while
retaining over 90\% of baseline accuracy. On instruction-tuned models we see
accuracy gains at full compute and match baseline quality near 50\% savings.
The learned gates give insight into transformer information flow (e.g., BOS
tokens act as anchors), and the method combines easily with quantization,
pruning, and self-speculative decoding.

</details>


### [129] [TextBandit: Evaluating Probabilistic Reasoning in LLMs Through Language-Only Decision Tasks](https://arxiv.org/abs/2510.13878)
*Jimin Lim,Arjun Damerla,Arthur Jiang,Nam Le*

Main category: cs.CL

TL;DR: 提出了一个新基准，通过纯文本反馈评估大语言模型在不确定环境下的序列决策能力，发现Qwen3-4B在多臂赌博机任务中表现优异，显示出语言模型可仅从语言线索中推断概率结构。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在无数字线索、仅凭自然语言进行不确定条件下序列决策的能力，填补该领域的评估空白。

Method: 设计了一个多臂赌博机环境，模型仅通过‘你获得了一个代币’等文本反馈进行交互，评估其在无明确数值或概率信息下推断奖励结构并决策的能力，并与汤普森采样、ε-贪婪等传统算法对比。

Result: 多数开源大模型表现不如传统算法，但Qwen3-4B达到89.2%的最佳臂选择率，显著优于更大模型和传统方法。

Conclusion: 表明仅从语言中可涌现出概率推理能力，该基准为评估自然语言环境下决策能力提供了新路径。

Abstract: Large language models (LLMs) have shown to be increasingly capable of
performing reasoning tasks, but their ability to make sequential decisions
under uncertainty only using natural language remains underexplored. We
introduce a novel benchmark in which LLMs interact with multi-armed bandit
environments using purely textual feedback, "you earned a token", without
access to numerical cues or explicit probabilities, resulting in the model to
infer latent reward structures purely off linguistic cues and to adapt
accordingly. We evaluated the performance of four open-source LLMs and compare
their performance to standard decision-making algorithms such as Thompson
Sampling, Epsilon Greedy, Upper Confidence Bound (UCB), and random choice.
While most of the LLMs underperformed compared to the baselines, Qwen3-4B,
achieved the best-arm selection rate of 89.2% , which significantly
outperformed both the larger LLMs and traditional methods. Our findings suggest
that probabilistic reasoning is able to emerge from language alone, and we
present this benchmark as a step towards evaluating decision-making
capabilities in naturalistic, non-numeric contexts.

</details>


### [130] [Catch Your Breath: Adaptive Computation for Self-Paced Sequence Production](https://arxiv.org/abs/2510.13879)
*Alexandre Galashov,Matt Jones,Rosemary Ke,Yuan Cao,Vaishnavh Nagarajan,Michael C. Mozer*

Main category: cs.CL

TL;DR: 提出一种名为“Catch Your Breath”（CYB）的训练框架，使语言模型能根据输入动态自主选择计算步数，通过插入<don't know>和<pause>令牌请求额外计算资源，显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型对每个 token 使用固定计算资源，难以适应不同 token 的复杂性；希望模型能自主判断何时需要更多计算以提升准确率。

Method: 将输出 token 的选择建模为带时间成本的序贯决策问题，引入 <don't know> 和 <pause> 机制，提出三种 CYB 损失变体：CYB-AP（anytime prediction）、CYB-VA（变分方法）和 CYB-DP（计算预算惩罚）。

Result: CYB 模型仅需基线模型三分之一的训练数据即可达到相同性能，且能根据 token 复杂度自适应调整计算步数，例如在复数名词后常暂停，而在缩写词首词后从不暂停。

Conclusion: CYB 损失有效训练模型动态分配计算资源，在减少训练数据需求的同时提升推理效率和准确性，展现出对语义和句法复杂性的敏感适应能力。

Abstract: We explore a class of supervised training objectives that allow a language
model to dynamically and autonomously scale the number of compute steps used
for each input token. For any token, the model can request additional compute
steps by emitting a <don't know> output. If the model is granted a delay, a
specialized <pause> token is inserted at the next input step, providing the
model with additional compute resources to generate an output. The model can
request multiple pauses. To train the model to use <don't know> outputs
judiciously and to calibrate its uncertainty, we frame the selection of each
output token as a sequential-decision problem with a time cost. We refer to the
class of methods as $\textit{Catch Your Breath}$ losses and we study three
methods in this class: CYB-AP frames the model's task as anytime prediction,
where an output may be required at any step and accuracy is discounted over
time; CYB-VA is a variational approach that aims to maximize prediction
accuracy subject to a specified distribution over stopping times; and CYB-DP
imposes a penalty based on a computational budget. Through fine-tuning
experiments, we identify the best performing loss variant. The CYB model needs
only one third as much training data as the baseline (no pause) model needs to
achieve the same performance, and half as much data as a model with pauses and
a cross-entropy loss. We find that the CYB model requests additional steps when
doing so improves accuracy, and the model adapts its processing time to
token-level complexity and context. For example, it often pauses after plural
nouns like $\textit{patients}$ and $\textit{challenges}$ but never pauses after
the first token of contracted words like $\textit{wasn}$ and $\textit{didn}$,
and it shows high variability for ambiguous tokens like $\textit{won}$, which
could function as either a verb or part of a contraction.

</details>


### [131] [PAGE: Prompt Augmentation for text Generation Enhancement](https://arxiv.org/abs/2510.13880)
*Mauro Jose Pacchiotti,Luciana Ballejos,Mariel Ale*

Main category: cs.CL

TL;DR: PAGE 是一种通过简单辅助模块增强文本生成的框架，无需复杂的生成模型即可提升生成质量和可控性。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在特定任务中表现不佳或需要大量额外数据调整，因此需要一种更灵活、轻量的增强方法。

Method: 提出 PAGE 框架，使用轻量级辅助模块（如分类器或提取器）对输入进行推理，并将其输出用于构建增强输入，从而改进生成结果。

Result: 在需求工程领域的概念验证显示，结合分类器的辅助模块能有效提升软件需求生成的质量。

Conclusion: PAGE 提供了一种简单、模块化且易于适配不同任务的生成增强架构，无需依赖辅助生成模型。

Abstract: In recent years, natural language generative models have shown outstanding
performance in text generation tasks. However, when facing specific tasks or
particular requirements, they may exhibit poor performance or require
adjustments that demand large amounts of additional data. This work introduces
PAGE (Prompt Augmentation for text Generation Enhancement), a framework
designed to assist these models through the use of simple auxiliary modules.
These modules, lightweight models such as classifiers or extractors, provide
inferences from the input text. The output of these auxiliaries is then used to
construct an enriched input that improves the quality and controllability of
the generation. Unlike other generation-assistance approaches, PAGE does not
require auxiliary generative models; instead, it proposes a simpler, modular
architecture that is easy to adapt to different tasks. This paper presents the
proposal, its components and architecture, and reports a proof of concept in
the domain of requirements engineering, where an auxiliary module with a
classifier is used to improve the quality of software requirements generation.

</details>


### [132] [Too Open for Opinion? Embracing Open-Endedness in Large Language Models for Social Simulation](https://arxiv.org/abs/2510.13884)
*Bolei Ma,Yong Cao,Indira Sen,Anna-Carolina Haensch,Frauke Kreuter,Barbara Plank,Daniel Hershcovich*

Main category: cs.CL

TL;DR: 本文主张在使用大语言模型（LLM）进行社会模拟时，应重视开放性生成文本的价值，而非局限于封闭式选择题或简答形式，以提升模拟的真实性与方法论效用。


<details>
  <summary>Details</summary>
Motivation: 当前多数研究将LLM的社会模拟限制在封闭格式中以便评分和比较，但这忽略了LLM本身具备的生成能力，也限制了对真实社会现象（如公众意见）复杂性和多样性的捕捉。

Method: 结合数十年的调查方法学研究与自然语言处理（NLP）的最新进展，论述开放性生成文本在LLM社会模拟中的理论基础与实践优势。

Result: 开放性能够提升测量与设计质量，支持发现未预期的观点，减少研究者的引导偏倚，同时保留表达的丰富性与个体差异，并有助于预测试和方法优化。

Conclusion: 呼吁建立新的实践方法与评估框架，充分利用LLM的开放生成多样性，推动NLP与社会科学的深度融合与协同发展。

Abstract: Large Language Models (LLMs) are increasingly used to simulate public opinion
and other social phenomena. Most current studies constrain these simulations to
multiple-choice or short-answer formats for ease of scoring and comparison, but
such closed designs overlook the inherently generative nature of LLMs. In this
position paper, we argue that open-endedness, using free-form text that
captures topics, viewpoints, and reasoning processes "in" LLMs, is essential
for realistic social simulation. Drawing on decades of survey-methodology
research and recent advances in NLP, we argue why this open-endedness is
valuable in LLM social simulations, showing how it can improve measurement and
design, support exploration of unanticipated views, and reduce
researcher-imposed directive bias. It also captures expressiveness and
individuality, aids in pretesting, and ultimately enhances methodological
utility. We call for novel practices and evaluation frameworks that leverage
rather than constrain the open-ended generative diversity of LLMs, creating
synergies between NLP and social science.

</details>


### [133] [Order from Chaos: Comparative Study of Ten Leading LLMs on Unstructured Data Categorization](https://arxiv.org/abs/2510.13885)
*Ariel Kamen*

Main category: cs.CL

TL;DR: 本研究评估了10种最先进的大语言模型在使用IAB 2.2分层分类法进行非结构化文本分类中的表现，发现尽管模型规模不断增大，但其经典性能指标仍仅为中等水平，并存在显著的幻觉和类别膨胀问题。集成多模型作为独立专家的集成方法显著提升了准确性，消除了幻觉。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的快速发展，亟需系统评估其在真实文本分类任务中的实际性能。特别是在广告分类等需要精确归类的应用场景中，理解模型在准确性、幻觉和成本之间的权衡对实际部署至关重要。

Method: 研究采用包含8,660个人工标注样本的统一数据集和相同的零样本提示，对10个主流LLMs进行了比较。评估使用了准确率、精确率、召回率和F1分数四个经典指标，以及幻觉率、膨胀率和分类成本三个LLM特定指标。此外，还开发并测试了一种基于多个LLMs作为独立专家的集成方法。

Result: 当前LLMs在该任务上表现平平，平均准确率34%，F1分数41%。模型普遍存在过度生成类别（高膨胀率）和幻觉问题。Gemini 1.5/2.0 Flash和GPT 20B/120B在成本与性能间取得了最佳平衡，GPT 120B的幻觉率最低。关键是，模型规模的增加并未线性提升准确性。集成方法显著提升了性能：准确性大幅提高，膨胀率降低，并完全消除了幻觉。

Conclusion: 单纯扩大模型规模和架构改进不足以解决复杂的文本分类任务，因为将丰富的非结构化文本压缩到有限分类体系中仍是巨大挑战。协调多个模型协同工作的集成策略，而非依赖单一巨型模型，是实现甚至超越人类专家分类性能的更有前景的途径。

Abstract: This study presents a comparative evaluation of ten state-of-the-art large
language models (LLMs) applied to unstructured text categorization using the
Interactive Advertising Bureau (IAB) 2.2 hierarchical taxonomy. The analysis
employed a uniform dataset of 8,660 human-annotated samples and identical
zero-shot prompts to ensure methodological consistency across all models.
Evaluation metrics included four classic measures - accuracy, precision,
recall, and F1-score - and three LLM-specific indicators: hallucination ratio,
inflation ratio, and categorization cost.
  Results show that, despite their rapid advancement, contemporary LLMs achieve
only moderate classic performance, with average scores of 34% accuracy, 42%
precision, 45% recall, and 41% F1-score. Hallucination and inflation ratios
reveal that models frequently overproduce categories relative to human
annotators. Among the evaluated systems, Gemini 1.5/2.0 Flash and GPT 20B/120B
offered the most favorable cost-to-performance balance, while GPT 120B
demonstrated the lowest hallucination ratio. The findings suggest that scaling
and architectural improvements alone do not ensure better categorization
accuracy, as the task requires compressing rich unstructured text into a
limited taxonomy - a process that challenges current model architectures.
  To address these limitations, a separate ensemble-based approach was
developed and tested. The ensemble method, in which multiple LLMs act as
independent experts, substantially improved accuracy, reduced inflation, and
completely eliminated hallucinations. These results indicate that coordinated
orchestration of models - rather than sheer scale - may represent the most
effective path toward achieving or surpassing human-expert performance in
large-scale text categorization.

</details>


### [134] [Reliable Fine-Grained Evaluation of Natural Language Math Proofs](https://arxiv.org/abs/2510.13888)
*Wenjie Ma,Andrei Cojocaru,Neel Kolhe,Bradley Louie,Robin Said Sharif,Haihan Zhang,Vincent Zhuang,Matei Zaharia,Sewon Min*

Main category: cs.CL

TL;DR: 提出了一个系统化的方法来开发和验证用于评估大模型生成数学证明的细粒度评分系统，引入了首个专家标注的数据集ProofBench，并基于此构建了高效评估器ProofGrader，在准确性和实用性上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在数学推理方面的评估主要集中在答案可验证的任务上，缺乏对自然语言数学证明生成的细粒度、可靠的评估方法，本文旨在填补这一空白。

Method: 提出一种系统性的评估器开发与验证方法，构建包含145道竞赛题和435个生成证明的专家标注数据集ProofBench，并在不同骨干模型、输入上下文、指令和评估流程等维度探索评估器设计空间，最终集成出评估器ProofGrader。

Result: ProofGrader在与专家评分对比时达到0.926的平均绝对误差（MAE），显著优于基线；在best-of-n证明选择任务中（n=16），平均得分4.14，填补了78%的差距（相对于人类专家4.62）。

Conclusion: ProofGrader是一种高效、可靠的细粒度数学证明评估器，能够有效推动大模型在数学证明生成任务上的发展，具备良好的实用潜力。

Abstract: Recent advances in large language models (LLMs) for mathematical reasoning
have largely focused on tasks with easily verifiable final answers; however,
generating and verifying natural language math proofs remains an open
challenge. We identify the absence of a reliable, fine-grained evaluator for
LLM-generated math proofs as a critical gap. To address this, we propose a
systematic methodology for developing and validating evaluators that assign
fine-grained scores on a 0-7 scale to model-generated math proofs. To enable
this study, we introduce ProofBench, the first expert-annotated dataset of
fine-grained proof ratings, spanning 145 problems from six major math
competitions (USAMO, IMO, Putnam, etc) and 435 LLM-generated solutions from
Gemini-2.5-pro, o3, and DeepSeek-R1. %with expert gradings. Using ProofBench as
a testbed, we systematically explore the evaluator design space across key
axes: the backbone model, input context, instructions and evaluation workflow.
Our analysis delivers ProofGrader, an evaluator that combines a strong
reasoning backbone LM, rich context from reference solutions and marking
schemes, and a simple ensembling method; it achieves a low Mean Absolute Error
(MAE) of 0.926 against expert scores, significantly outperforming naive
baselines. Finally, we demonstrate its practical utility in a best-of-$n$
selection task: at $n=16$, ProofGrader achieves an average score of 4.14 (out
of 7), closing 78% of the gap between a naive binary evaluator (2.48) and the
human oracle (4.62), highlighting its potential to advance downstream proof
generation.

</details>


### [135] [A Survey on Collaborating Small and Large Language Models for Performance, Cost-effectiveness, Cloud-edge Privacy, and Trustworthiness](https://arxiv.org/abs/2510.13890)
*Fali Wang,Jihai Chen,Shuhua Yang,Ali Al-Lawati,Linli Tang,Hui Liu,Suhang Wang*

Main category: cs.CL

TL;DR: 本文系统综述了小语言模型（SLM）与大语言模型（LLM）协作的研究，提出了一种以协作为目标的四类分类体系：性能提升、成本效益、云边隐私和可信性。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型在微调成本、推理延迟和边缘部署方面存在挑战，小语言模型因其高效和可适应性成为补充方案。近年来，探索SLM与LLM协同工作的框架成为研究热点，促使本文开展系统性综述。

Method: 本文提出一个包含四个协作目标的分类体系，基于该框架回顾代表性方法，总结设计范式。

Result: 系统梳理了实现性能增强、成本节约、隐私保护和可信性的SLM-LLM协作方法，归纳了当前的设计模式与技术路径。

Conclusion: 本文为高效、安全、可扩展的SLM-LLM协同提供了结构化视角，指出了开放挑战与未来研究方向。

Abstract: Large language models (LLMs) have advanced many domains and applications but
face high fine-tuning costs, inference latency, limited edge deployability, and
reliability concerns. Small language models (SLMs), compact, efficient, and
adaptable, offer complementary remedies. Recent work explores collaborative
frameworks that fuse SLMs' specialization and efficiency with LLMs'
generalization and reasoning to meet diverse objectives across tasks and
deployment scenarios. Motivated by these developments, this paper presents a
systematic survey of SLM-LLM collaboration organized by collaboration
objectives. We propose a taxonomy with four goals: performance enhancement,
cost-effectiveness, cloud-edge privacy, and trustworthiness. Within this
framework, we review representative methods, summarize design paradigms, and
outline open challenges and future directions toward efficient, secure, and
scalable SLM-LLM collaboration.

</details>


### [136] [The Harder The Better: Maintaining Supervised Fine-tuning Generalization with Less but Harder Data](https://arxiv.org/abs/2510.13892)
*Zhaoyang Shang,Sibo Wei,Jianbin Guo,Rui Zhou,Lifeng Dong,Yin Luo*

Main category: cs.CL

TL;DR: 提出一种认知科学启发的指令数据选择与标注指导框架THTB，通过结合内在与外在难度评分，仅用5%数据即可超越全量训练，显著提升领域适应效率。


<details>
  <summary>Details</summary>
Motivation: 现有指令数据选择方法过度依赖大模型内部知识，可解释性差且泛化能力有限，难以高效适配专业领域。

Method: 提出THTB框架，结合质量过滤与内在/外在难度评分，优先选择高认知层级指令，提供可解释、可量化的数据选择与标注指导标准。

Result: 在仅使用5%数据时优于全量训练，2%数据下超越更大规模数据集训练的模型，且在垂直领域标注指导中表现优异。

Conclusion: THTB实现了高效、可解释的指令数据筛选与标注指导，在极小数据下展现出卓越的性能与强泛化能力，适用于专业领域适配。

Abstract: Large Language Models (LLMs) excel in general tasks, but adapting them to
specialized domains relies on high-quality supervised fine-tuning (SFT) data.
Although existing methods can identify subsets of high-quality data and reduce
training cost to some extent, their selection process still suffers from
over-reliance on LLMs' internal knowledge, weak interpretability, and limited
generalization. To address these limitations, we propose THTB (The Harder The
Better), a cognitive science-inspired framework for instruction data selection
and annotation guidance. THTB prioritizes higher-level cognitive instructions
by combining quality filtering with intrinsic and extrinsic hardness scoring,
offering interpretable and quantifiable criteria for efficient SFT, both in
data selection and annotation guidance. Experiments show that THTB enables
models trained on only 5% of the data to outperform full-dataset training,
while achieving superior generalization compared with LLM-only selection. In
addition, THTB provides effective annotation guidance in vertical domains,
enabling a model trained on just 2% of the data to surpass models trained on
much larger datasets, demonstrating strong potential for domain adaptation. Our
code, datasets, and models are available on
https://github.com/DYJG-research/THTB.

</details>


### [137] [Guarding the Guardrails: A Taxonomy-Driven Approach to Jailbreak Detection](https://arxiv.org/abs/2510.13893)
*Olga E. Sorokoletova,Francesco Giarrusso,Vincenzo Suriani,Daniele Nardi*

Main category: cs.CL

TL;DR: 本文提出了一种针对大语言模型（LLM）越狱攻击的系统性研究，构建了包含50种策略的分层分类体系，并通过红队挑战分析了各类攻击的有效性，提出了基于分类的检测提示方法，同时发布了新的意大利语多轮对抗对话数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的防御手段主要针对单轮攻击，且缺乏跨语言覆盖，分类体系有限，无法全面捕捉越狱攻击的多样性。本文旨在通过系统化的方法深入理解越狱技术的有效性及其对模型安全的影响。

Method: 通过组织结构化的红队挑战，收集多语言（尤其是意大利语）多轮对抗对话数据；构建一个包含50种越狱策略的分层分类法，分为七个家族：模仿、说服、权限提升、认知过载、混淆、目标冲突和数据投毒；并基于该分类法进行攻击频率与成功率分析，测试基于分类的提示对越狱检测模型的效果。

Result: 提出了一个涵盖50种策略的越狱攻击分类体系；发现某些策略（如认知过载和混淆）在绕过安全机制方面尤为有效；基于分类的提示能提升越狱检测性能；构建了包含1364个多轮对话的意大利语数据集，标注了详细的攻击类型。

Conclusion: 越狱攻击具有高度多样性和渐进性，需采用系统性分类和多轮交互分析来提升防御能力；本文提出的分类体系和数据集为改进检测方法和增强LLM安全性提供了重要基础。

Abstract: Jailbreaking techniques pose a significant threat to the safety of Large
Language Models (LLMs). Existing defenses typically focus on single-turn
attacks, lack coverage across languages, and rely on limited taxonomies that
either fail to capture the full diversity of attack strategies or emphasize
risk categories rather than the jailbreaking techniques. To advance the
understanding of the effectiveness of jailbreaking techniques, we conducted a
structured red-teaming challenge. The outcome of our experiments are manifold.
First, we developed a comprehensive hierarchical taxonomy of 50 jailbreak
strategies, consolidating and extending prior classifications into seven broad
families, including impersonation, persuasion, privilege escalation, cognitive
overload, obfuscation, goal conflict, and data poisoning. Second, we analyzed
the data collected from the challenge to examine the prevalence and success
rates of different attack types, providing insights into how specific jailbreak
strategies exploit model vulnerabilities and induce misalignment. Third, we
benchmark a popular LLM for jailbreak detection, evaluating the benefits of
taxonomy-guided prompting for improving automatic detection. Finally, we
compiled a new Italian dataset of 1364 multi-turn adversarial dialogues,
annotated with our taxonomy, enabling the study of interactions where
adversarial intent emerges gradually and succeeds in bypassing traditional
safeguards.

</details>


### [138] [Attribution Quality in AI-Generated Content:Benchmarking Style Embeddings and LLM Judges](https://arxiv.org/abs/2510.13898)
*Misam Abbas*

Main category: cs.CL

TL;DR: 本论文评估了两种作者归属方法在区分人类和大语言模型（LLM）生成文本中的表现：固定风格嵌入和指令调优的LLM裁判（GPT-4o），结果表明两者在不同文本类型中各有优势，需结合使用。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型生成的文本越来越接近人类写作，准确归因文本来源变得愈发困难，亟需可靠的检测机制。

Method: 在包含六类文本的Human AI Parallel Corpus数据集上，比较固定风格嵌入模型与基于GPT-4o的LLM裁判在识别GPT-4o和LLaMA-70B-Instruct生成文本上的表现。

Result: 风格嵌入在GPT生成文本上准确率为82%，优于LLM裁判的68%；LLM裁判在LLaMA生成文本上略优（85% vs 81%），但差异不显著；LLM裁判在小说和学术文本中表现更好，而风格嵌入在口语和剧本对话中更优。

Conclusion: 作者归属是一个多维度问题，不同方法在语义或结构特征上各具优势，应采用混合策略；研究提供了开源框架以支持可复现的AI生成内容归因评估。

Abstract: Attributing authorship in the era of large language models (LLMs) is
increasingly challenging as machine-generated prose rivals human writing. We
benchmark two complementary attribution mechanisms , fixed Style Embeddings and
an instruction-tuned LLM judge (GPT-4o) on the Human AI Parallel Corpus, an
open dataset of 600 balanced instances spanning six domains (academic, news,
fiction, blogs, spoken transcripts, and TV/movie scripts). Each instance
contains a human prompt with both a gold continuation and an LLM-generated
continuation from either GPT-4o or LLaMA-70B-Instruct. The Style Embedding
baseline achieves stronger aggregate accuracy on GPT continuations (82 pct vs.
68 pct). The LLM Judge is slightly better than the Style embeddings on LLaMA
continuations (85 pct vs. 81 pct) but the results are not statistically
significant. Crucially, the LLM judge significantly outperforms in fiction and
academic prose, indicating semantic sensitivity, whereas embeddings dominate in
spoken and scripted dialogue, reflecting structural strengths. These
complementary patterns highlight attribution as a multidimensional problem
requiring hybrid strategies. To support reproducibility we provide code on
GitHub and derived data on Hugging Face under the MIT license. This open
framework provides a reproducible benchmark for attribution quality assessment
in AI-generated content, along with a review of related literature influencing
this work.

</details>


### [139] [Narrow Finetuning Leaves Clearly Readable Traces in Activation Differences](https://arxiv.org/abs/2510.13900)
*Julian Minder,Clément Dumas,Stewart Slocum,Helena Casademunt,Cameron Holmes,Robert West,Neel Nanda*

Main category: cs.CL

TL;DR: 窄域微调会在大语言模型激活中产生强偏差，这些偏差可通过模型差异分析（model diffing）解读，揭示微调数据的内容与格式；通过注入激活差异可生成类似微调数据的文本，并可用于提升可解释性代理性能。


<details>
  <summary>Details</summary>
Motivation: 研究窄域微调对大语言模型的影响，揭示其在激活层面留下的可解读痕迹，警示在AI安全与可解释性研究中使用此类模型的局限性，并推动更真实的研究场景构建。

Method: 使用模型差异分析方法，比较微调前后模型在随机文本前几个token上的激活差异，通过激活 steering（添加差异向量）生成文本；构建基于LLM的可解释性代理来识别微调领域，并评估其性能。

Result: 发现窄域微调导致明显的激活偏差，能准确反映微调内容（如虚假事实、禁忌词猜测等）；加入激活偏差信息后，可解释性代理表现显著优于基线；混合预训练数据可减轻但不能完全消除偏差。

Conclusion: 窄域微调模型保留训练目标的显著痕迹，影响其作为通用微调代理的有效性；建议改进训练方法并警示AI安全研究需谨慎使用此类模型；呼吁深入研究窄域微调影响并发展更真实的案例研究。

Abstract: Finetuning on narrow domains has become an essential tool to adapt Large
Language Models (LLMs) to specific tasks and to create models with known
unusual properties that are useful for research. We show that narrow finetuning
creates strong biases in LLM activations that can be interpreted to understand
the finetuning domain. These biases can be discovered using simple tools from
model diffing - the study of differences between models before and after
finetuning. In particular, analyzing activation differences on the first few
tokens of random text and steering by adding this difference to the model
activations produces text similar to the format and general content of the
finetuning data. We demonstrate that these analyses contain crucial information
by creating an LLM-based interpretability agent to understand the finetuning
domain. With access to the bias, the agent performs significantly better
compared to baseline agents using simple prompting. Our analysis spans
synthetic document finetuning for false facts, emergent misalignment,
subliminal learning, and taboo word guessing game models across different
architectures (Gemma, LLaMA, Qwen) and scales (1B to 32B parameters). We
suspect these biases reflect overfitting and find that mixing pretraining data
into the finetuning corpus largely removes them, though residual risks may
remain. Our work (1) demonstrates that narrowly finetuned models have salient
traces of their training objective in their activations and suggests ways to
improve how they are trained, (2) warns AI safety and interpretability
researchers that the common practice of using such models as a proxy for
studying broader finetuning (e.g., chat-tuning) might not be realistic, and (3)
highlights the need for deeper investigation into the effects of narrow
finetuning and development of truly realistic case studies for model-diffing,
safety and interpretability research.

</details>


### [140] [RAID: Refusal-Aware and Integrated Decoding for Jailbreaking LLMs](https://arxiv.org/abs/2510.13901)
*Tuan T. Nguyen,John Le,Thai T. Vu,Willy Susilo,Heath Cooper*

Main category: cs.CL

TL;DR: RAID是一种针对大语言模型的新型越狱攻击框架，通过在嵌入空间中优化连续表示并结合拒绝感知正则化和连贯性约束，生成语义流畅且能有效绕过安全机制的对抗后缀，实验表明其在攻击成功率、查询次数和计算成本上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在多种任务上表现优异，但其安全性仍易受越狱攻击威胁。现有攻击方法在有效性或自然性方面存在不足，因此需要一种更系统、更高效的方法来揭示和评估模型的安全漏洞。

Method: 提出RAID框架，将离散token松弛为连续嵌入，通过联合目标优化：鼓励生成受限内容、引入拒绝感知正则化以避开拒绝方向、加入连贯性项保持语义合理。优化后采用批评者引导的解码将嵌入映射回token，平衡嵌入相似性与语言模型似然。

Result: 在多个开源大模型上的实验显示，RAID相比最新的白盒和黑盒基线方法，在更低查询次数和计算成本下实现了更高的攻击成功率达到更好的攻击效果。

Conclusion: RAID展示了嵌入空间正则化在分析和缓解大语言模型越狱漏洞中的重要性，揭示了当前安全机制的不足，并为未来防御设计提供了方向。

Abstract: Large language models (LLMs) achieve impressive performance across diverse
tasks yet remain vulnerable to jailbreak attacks that bypass safety mechanisms.
We present RAID (Refusal-Aware and Integrated Decoding), a framework that
systematically probes these weaknesses by crafting adversarial suffixes that
induce restricted content while preserving fluency. RAID relaxes discrete
tokens into continuous embeddings and optimizes them with a joint objective
that (i) encourages restricted responses, (ii) incorporates a refusal-aware
regularizer to steer activations away from refusal directions in embedding
space, and (iii) applies a coherence term to maintain semantic plausibility and
non-redundancy. After optimization, a critic-guided decoding procedure maps
embeddings back to tokens by balancing embedding affinity with language-model
likelihood. This integration yields suffixes that are both effective in
bypassing defenses and natural in form. Experiments on multiple open-source
LLMs show that RAID achieves higher attack success rates with fewer queries and
lower computational cost than recent white-box and black-box baselines. These
findings highlight the importance of embedding-space regularization for
understanding and mitigating LLM jailbreak vulnerabilities.

</details>


### [141] [Investigating Political and Demographic Associations in Large Language Models Through Moral Foundations Theory](https://arxiv.org/abs/2510.13902)
*Nicole Smith-Vaniz,Harper Lyon,Lorraine Steigner,Ben Armstrong,Nicholas Mattei*

Main category: cs.CL

TL;DR: 本文通过道德基础理论（MFT）系统分析大语言模型（LLM）在政治和道德问题上的回应倾向，评估其内在意识形态偏倚及在角色扮演中对不同立场的代表性。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型在涉及政治与道德的敏感议题中是否表现出特定偏见，并填补此前研究中缺乏与人类实证数据直接对比的空白。

Method: 采用道德基础理论的五个维度（伤害、公平、群体忠诚、权威、纯洁），对比LLM生成的回应与现有大规模人类道德判断数据，并通过显式提示和基于人口统计学的角色扮演实验进行分析。

Result: 发现LLM的回应显示出系统性意识形态倾向，通常更接近自由派立场；在角色扮演中能部分模拟不同意识形态，但仍有偏差。

Conclusion: 大语言模型在道德和政治问题上存在可量化的偏倚，其输出受内在训练数据和提示方式影响，需谨慎应用于高风险决策场景。

Abstract: Large Language Models (LLMs) have become increasingly incorporated into
everyday life for many internet users, taking on significant roles as advice
givers in the domains of medicine, personal relationships, and even legal
matters. The importance of these roles raise questions about how and what
responses LLMs make in difficult political and moral domains, especially
questions about possible biases. To quantify the nature of potential biases in
LLMs, various works have applied Moral Foundations Theory (MFT), a framework
that categorizes human moral reasoning into five dimensions: Harm, Fairness,
Ingroup Loyalty, Authority, and Purity. Previous research has used the MFT to
measure differences in human participants along political, national, and
cultural lines. While there has been some analysis of the responses of LLM with
respect to political stance in role-playing scenarios, no work so far has
directly assessed the moral leanings in the LLM responses, nor have they
connected LLM outputs with robust human data. In this paper we analyze the
distinctions between LLM MFT responses and existing human research directly,
investigating whether commonly available LLM responses demonstrate ideological
leanings: either through their inherent responses, straightforward
representations of political ideologies, or when responding from the
perspectives of constructed human personas. We assess whether LLMs inherently
generate responses that align more closely with one political ideology over
another, and additionally examine how accurately LLMs can represent ideological
perspectives through both explicit prompting and demographic-based
role-playing. By systematically analyzing LLM behavior across these conditions
and experiments, our study provides insight into the extent of political and
demographic dependency in AI-generated responses.

</details>


### [142] [Schema for In-Context Learning](https://arxiv.org/abs/2510.13905)
*Pan Chen,Shaohong Chen,Mark Wang,Shi Xuan Leong,Priscilla Fung,Varinia Bernales,Alan Aspuru-Guzik*

Main category: cs.CL

TL;DR: 提出了一种新的上下文学习框架SA-ICL，通过引入认知科学中的图式理论，显式构建抽象推理模板，显著提升大模型在化学和物理问题上的表现，最高提升达36.19%，同时减少对示例数量的依赖并增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统上下文学习缺乏在抽象层面进行知识检索和迁移的显式机制，受图式理论启发，旨在让模型像人类一样利用已有认知框架理解新信息。

Method: 从示例中提取关键推理步骤及其关系，构建轻量级结构化图式模板，并在面对新问题时用该图式增强模型的推理过程。

Result: 实验证明多种大语言模型难以隐式形成图式表示，但通过SA-ICL显式构建图式后性能显著提升，在GPQA数据集上最高提升36.19%，且仅需高质量单一样例即可有效工作。

Conclusion: SA-ICL不仅统一了多种上下文学习策略，还为提升大模型类人推理能力提供了新路径。

Abstract: In-Context Learning (ICL) enables transformer-based language models to adapt
to new tasks by conditioning on demonstration examples. However, traditional
example-driven in-context learning lacks explicit modules for knowledge
retrieval and transfer at the abstraction level. Inspired by cognitive science,
specifically schema theory, which holds that humans interpret new information
by activating pre-existing mental frameworks (schemas) to structure
understanding, we introduce SCHEMA ACTIVATED IN CONTEXT LEARNING (SA-ICL). This
framework extracts the representation of the building blocks of cognition for
the reasoning process instilled from prior examples, creating an abstracted
schema, a lightweight, structured template of key inferential steps and their
relationships, which is then used to augment a model's reasoning process when
presented with a novel question. We demonstrate that a broad range of large
language models (LLMs) lack the capacity to form and utilize internal
schema-based learning representations implicitly, but instead benefit
significantly from explicit schema-based scaffolding. Across chemistry and
physics questions from the GPQA dataset, our experiments show that SA-ICL
consistently boosts performance, up to 36.19 percent, when the single
demonstration example is of high quality, which simultaneously reduces reliance
on the number of demonstrations and enhances interpretability. SCHEMA ACTIVATED
IN CONTEXT LEARNING not only bridges disparate ICL strategies ranging from
pattern priming to Chain-of-Thought prompting, but also paves a new path for
enhancing human-like reasoning in LLMs.

</details>


### [143] [LLM Prompt Duel Optimizer: Efficient Label-Free Prompt Optimization](https://arxiv.org/abs/2510.13907)
*Yuanchen Wu,Saurabh Verma,Justin Lee,Fangzhou Xiong,Poppy Zhang,Amel Awadelkarim,Xu Chen,Yubai Yuan,Shawndra Hill*

Main category: cs.CL

TL;DR: 提出了一种无需标签的提示优化框架 PDO，通过 LLM 作为裁判提供偏好反馈，结合双 Thompson 采样和高性能提示变异，在少样本下实现高效提示优化。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型对输入提示敏感，提示设计至关重要，但现有自动优化方法依赖高质量标注数据，成本高且耗时，需一种无需标签的高效优化方法。

Method: 将提示优化建模为对偶_bandit问题，使用LLM裁判提供成对偏好反馈；结合双Thompson采样(D-TS)选择信息量大的提示对比，并通过Top- performer引导的变异扩展候选集，支持无标签和部分标签场景。

Result: 在BIG-bench Hard和MS MARCO上实验表明，PDO优于基线方法；消融实验证明D-TS和提示变异均有效，且在少量反馈下表现优越。

Conclusion: PDO是一种高效、无需完整标注的提示优化框架，能有效利用LLM自身反馈进行优化，具备实际应用潜力。

Abstract: Large language models (LLMs) are highly sensitive to their input prompts,
making prompt design a central challenge. While automatic prompt optimization
(APO) reduces manual engineering, most approaches assume access to ground-truth
references such as labeled validation data. In practice, however, collecting
high-quality labels is costly and slow. We propose the Prompt Duel Optimizer
(PDO), a sample-efficient framework for label-free prompt optimization. PDO
formulates the problem as a dueling-bandit setting, where supervision signal
comes from pairwise preference feedback provided by an LLM judge. The framework
combines Double Thompson Sampling (D-TS), which prioritizes informative prompt
comparisons, with Top-Performer Guided Mutation, which expands the candidate
pool by mutating high-performing prompts. PDO naturally operates in label-free
settings and can also incorporate partial labels to mitigate judge noise.
Experiments on BIG-bench Hard (BBH) and MS MARCO show that PDO consistently
outperforms baseline methods. Ablation studies further demonstrate the
effectiveness of both D-TS and prompt mutation.

</details>


### [144] [Interpreting the Latent Structure of Operator Precedence in Language Models](https://arxiv.org/abs/2510.13908)
*Dharunish Yugeswardeenoo,Harshil Nukala,Cole Blondin,Sean O Brien,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: 研究发现，LLa模型在其内部表示中编码了算术运算的优先级，中间计算结果可在残差流中被检测到，且通过修改操作符嵌入可改变运算优先级。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在推理任务上表现优异，但在算术任务上仍存在困难。本文旨在探究模型内部如何进行算术计算，特别是是否编码了操作符优先级。

Method: 使用LLaMA 3.2-3B模型，构建包含三操作数和双操作符、不同括号位置的算术表达式数据集，通过logit lens、线性分类探针和UMAP可视化等可解释性技术分析残差流中的中间结果。

Result: 发现中间计算结果存在于残差流中（尤其在MLP块后），且模型在注意力层后的操作符嵌入中线性编码了优先级信息；提出部分嵌入交换技术，可通过交换关键嵌入维度修改运算优先级。

Conclusion: LLMs在内部表示中确实编码了运算符优先级，且该结构可用于操控模型的算术计算行为。

Abstract: Large Language Models (LLMs) have demonstrated impressive reasoning
capabilities but continue to struggle with arithmetic tasks. Prior works
largely focus on outputs or prompting strategies, leaving the open question of
the internal structure through which models do arithmetic computation. In this
work, we investigate whether LLMs encode operator precedence in their internal
representations via the open-source instruction-tuned LLaMA 3.2-3B model. We
constructed a dataset of arithmetic expressions with three operands and two
operators, varying the order and placement of parentheses. Using this dataset,
we trace whether intermediate results appear in the residual stream of the
instruction-tuned LLaMA 3.2-3B model. We apply interpretability techniques such
as logit lens, linear classification probes, and UMAP geometric visualization.
Our results show that intermediate computations are present in the residual
stream, particularly after MLP blocks. We also find that the model linearly
encodes precedence in each operator's embeddings post attention layer. We
introduce partial embedding swap, a technique that modifies operator precedence
by exchanging high-impact embedding dimensions between operators.

</details>


### [145] [Knowledge Reasoning Language Model: Unifying Knowledge and Language for Inductive Knowledge Graph Reasoning](https://arxiv.org/abs/2510.13909)
*Xingrui Zhuo,Jiapu Wang,Gongqing Wu,Zhongyuan Wang,Jichen Zhang,Shirui Pan,Xindong Wu*

Main category: cs.CL

TL;DR: 提出了一种新的知识推理语言模型KRLM，通过统一协调大语言模型的内在知识与知识图谱上下文，有效解决开放域中归纳式知识图谱推理的知识扭曲和生成幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的归纳式知识图谱推理方法难以平衡语言模型的内在知识与稀疏图谱上下文，导致知识扭曲和推理幻觉，限制了推理可信度。

Method: 设计了知识推理语言（KRL）指令格式和KRL分词器以对齐语言模型与图谱表示；提出KRL注意力层和动态知识记忆机制协调语言模型与图谱知识；引入结构感知的下一实体预测器以约束推理结果。

Result: 在25个真实世界的归纳式KGR数据集上实验表明，KRLM在零样本推理和微调场景下均显著优于现有方法。

Conclusion: KRLM通过统一协调语言模型知识与图谱结构，有效缓解了知识扭曲和生成幻觉，提升了归纳式知识图谱推理的准确性和可信度。

Abstract: Inductive Knowledge Graph Reasoning (KGR) aims to discover facts in
open-domain KGs containing unknown entities and relations, which poses a
challenge for KGR models in comprehending uncertain KG components. Existing
studies have proposed Knowledge Graph Foundation Models (KGFMs) that learn
structural invariances across KGs to handle this uncertainty. Recently, Large
Language Models (LLMs) have demonstrated strong capabilities for open-domain
knowledge reasoning. As a result, the latest research has focused on LLM-based
KGFMs that integrate LLM knowledge with KG context for inductive KGR. However,
the intrinsic knowledge of LLMs may be overshadowed by sparse KG context,
leading to LLM knowledge distortion, which can cause irreversible damage to
model reasoning. Moreover, existing LLM-based KGR methods still struggle to
fully constrain generative hallucinations in LLMs, severely limiting the
credibility of reasoning results. To address these limitations, we propose a
Knowledge Reasoning Language Model (KRLM) that achieves unified coordination
between LLM knowledge and KG context throughout the KGR process. Specifically,
we design a Knowledge Reasoning Language (KRL) instruction format and a KRL
tokenizer to align LLM knowledge with KG representations. Then, we propose a
KRL attention layer that coordinates intrinsic LLM knowledge with additional KG
context through a dynamic knowledge memory mechanism. Finally, a
structure-aware next-entity predictor is proposed, which strictly constrains
the reasoning results within a trustworthy knowledge domain. Extensive
experimental results on 25 real-world inductive KGR datasets demonstrate the
significant superiority of the proposed KRLM\footnote{Our source codes are
available at https://anonymous.4open.science/r/KRLM-EA36 in both zero-shot
reasoning and fine-tuning scenarios.

</details>


### [146] [RAGCap-Bench: Benchmarking Capabilities of LLMs in Agentic Retrieval Augmented Generation Systems](https://arxiv.org/abs/2510.13910)
*Jingru Lin,Chen Zhang,Stephen Y. Liu,Haizhou Li*

Main category: cs.CL

TL;DR: 提出RAGCap-Bench，一个面向代理式RAG系统中间任务的细粒度评估基准，以评估和提升模型在多跳问答中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有代理式RAG系统在处理复杂多跳问题时表现有限，且中间推理能力缺乏系统评估，亟需一个聚焦核心能力的细粒度基准。

Method: 通过分析前沿系统输出，识别中间任务与核心能力，构建典型错误分类体系，并基于此设计RAGCap-Bench评估问题集。

Result: 实验表明具备更强RAGCap能力的“慢思考”模型在端到端任务上表现更优，验证了该基准的有效性。

Conclusion: 提升代理式RAG系统的中间推理能力至关重要，RAGCap-Bench为评估和改进这些能力提供了有效工具。

Abstract: Retrieval-Augmented Generation (RAG) mitigates key limitations of Large
Language Models (LLMs)-such as factual errors, outdated knowledge, and
hallucinations-by dynamically retrieving external information. Recent work
extends this paradigm through agentic RAG systems, where LLMs act as agents to
iteratively plan, retrieve, and reason over complex queries. However, these
systems still struggle with challenging multi-hop questions, and their
intermediate reasoning capabilities remain underexplored. To address this, we
propose RAGCap-Bench, a capability-oriented benchmark for fine-grained
evaluation of intermediate tasks in agentic RAG workflows. We analyze outputs
from state-of-the-art systems to identify common tasks and the core
capabilities required for their execution, then construct a taxonomy of typical
LLM errors to design targeted evaluation questions. Experiments show that
"slow-thinking" models with stronger RAGCap performance achieve better
end-to-end results, underscoring the benchmark's validity and the importance of
enhancing these intermediate capabilities.

</details>


### [147] [AI Debaters are More Persuasive when Arguing in Alignment with Their Own Beliefs](https://arxiv.org/abs/2510.13912)
*María Victoria Carro,Denise Alejandra Mester,Facundo Nieto,Oscar Agustín Stanchi,Guido Ernesto Bergman,Mario Alejandro Leiva,Eitan Sprejer,Luca Nicolás Forziati Gangi,Francisca Gauna Selasco,Juan Gustavo Corvalán,Gerardo I. Simari,María Vanina Martinez*

Main category: cs.CL

TL;DR: 该研究探讨了在主观问题上大型语言模型在辩论中的行为，发现模型更倾向于迎合裁判的立场而非坚持自身先验信念，且顺序辩论存在偏见。


<details>
  <summary>Details</summary>
Motivation: 现有辩论实验多基于有明确真相的数据集，忽略了说谎的主观维度；本研究旨在探究语言模型在面对主观问题时是否会表现出谄媚策略或坚持已有信念。

Method: 研究者测量了语言模型在辩论前的先验信念，设计与模型信念冲突的裁判角色，并比较了顺序与同时辩论两种协议下的表现。

Result: 模型更倾向于迎合裁判而非坚持自身信念；顺序辩论中第二位辩者占优；当辩护与先验一致时更具说服力，但违背先验的论点却被评为质量更高。

Conclusion: 结果揭示了语言模型在辩论中的说服动态和潜在偏见，可为改进AI对齐和人类裁判提供指导。

Abstract: The core premise of AI debate as a scalable oversight technique is that it is
harder to lie convincingly than to refute a lie, enabling the judge to identify
the correct position. Yet, existing debate experiments have relied on datasets
with ground truth, where lying is reduced to defending an incorrect
proposition. This overlooks a subjective dimension: lying also requires the
belief that the claim defended is false. In this work, we apply debate to
subjective questions and explicitly measure large language models' prior
beliefs before experiments. Debaters were asked to select their preferred
position, then presented with a judge persona deliberately designed to conflict
with their identified priors. This setup tested whether models would adopt
sycophantic strategies, aligning with the judge's presumed perspective to
maximize persuasiveness, or remain faithful to their prior beliefs. We
implemented and compared two debate protocols, sequential and simultaneous, to
evaluate potential systematic biases. Finally, we assessed whether models were
more persuasive and produced higher-quality arguments when defending positions
consistent with their prior beliefs versus when arguing against them. Our main
findings show that models tend to prefer defending stances aligned with the
judge persona rather than their prior beliefs, sequential debate introduces
significant bias favoring the second debater, models are more persuasive when
defending positions aligned with their prior beliefs, and paradoxically,
arguments misaligned with prior beliefs are rated as higher quality in pairwise
comparison. These results can inform human judges to provide higher-quality
training signals and contribute to more aligned AI systems, while revealing
important aspects of human-AI interaction regarding persuasion dynamics in
language models.

</details>


### [148] [Synthesizing Agentic Data for Web Agents with Progressive Difficulty Enhancement Mechanisms](https://arxiv.org/abs/2510.13913)
*Shrey Pandit,Xuan-Phi Nguyen,Yifei Ming,Austin Xu,Jiayu Wang,Caiming Xiong,Shafiq Joty*

Main category: cs.CL

TL;DR: 提出了一种两阶段数据合成管道，通过逐步增加任务复杂度生成高质量、多样化的深网研究问答数据，在更小数据量下训练出性能更强、行为更多样的网络代理。


<details>
  <summary>Details</summary>
Motivation: 现有深网研究代理的数据合成方法难以精细控制难度与质量，且常混淆数据与训练的影响，无法有效评估数据本身的有效性。

Method: 构建一个以前沿基线代理为核心的两阶段数据合成 pipeline，利用该代理尝试问题、验证事实性、检查替代答案并进行过滤，动态生成直到代理失败的复杂任务；采用基于强代理蒸馏的受控训练设置评估数据效果。

Result: 实验表明，所生成的数据集尽管更小，但能训练出优于现有数据集的网络代理，工具使用行为的多样性提高了一倍，显著减少重复调用问题。

Conclusion: 所提数据合成方法能有效提升长视野推理任务中网络代理的性能与行为多样性，验证了高质量、可控难度数据对模型训练的关键作用。

Abstract: Web-based 'deep research' agents aim to solve complex question - answering
tasks through long-horizon interactions with online tools. These tasks remain
challenging, as the underlying language models are often not optimized for
long-horizon reasoning and exploration. Prior work has proposed workflows for
constructing instruction-tuning datasets, often leveraging knowledge graphs.
However, such methods typically lack fine-grained control over difficulty and
quality, yielding synthetic data that falls short of capturing the complexity
required for long-horizon reasoning. Furthermore, many studies conflate data
and training effects by comparing models trained under different optimization
recipes, making it difficult to isolate and evaluate the effectiveness of the
data itself. We introduce a two-pronged data synthesis pipeline that generates
question - answer pairs by progressively increasing task complexity until a
frontier baseline web agent fails. The baseline agent plays multiple roles in
this process: attempting the questions, validating factuality, checking for
alternative answers, and enforcing filtering. To evaluate the effectiveness of
our synthesis methods, we adopt a controlled training setup based on
distillation from strong web agents. Experiments across multiple web-based
benchmarks show that our dataset - despite being smaller - enables the training
of more effective web agents than existing datasets. In particular, our data
exhibits twice the diversity in tool-use actions, allowing models trained on it
to achieve stronger performance while avoiding repetitive tool-calling
behaviors.

</details>


### [149] [Readability $\ne$ Learnability: Rethinking the Role of Simplicity in Training Small Language Models](https://arxiv.org/abs/2510.13915)
*Ivan Lee,Taylor Berg-Kirkpatrick*

Main category: cs.CL

TL;DR: 研究表明，语言模型的能力涌现并非主要由文本可读性决定，而是更依赖于文本的统计简洁性，如n-gram多样性。


<details>
  <summary>Details</summary>
Motivation: 挑战将小型语言模型在儿童语料上表现良好归因于可读性的主流观点，质疑将模型训练类比人类认知发展的合理性。

Method: 构建结构相似但可读性不同的合成数据集，训练小型语言模型并比较其在可读性和统计简洁性不同条件下的学习效率与生成连贯性。

Result: 发现使用复杂成人语言训练的模型表现不逊于使用简化语言训练的模型，甚至更快展现出生成连贯文本的能力；n-gram多样性等统计特性比可读性更能预测学习效果。

Conclusion: 模型能力的涌现更依赖于数据的统计简洁性而非可读性，应避免将语言模型学习过程过度拟人化，需更精确地分析推动能力涌现的关键数据属性。

Abstract: Recent studies suggest that very small language models (SLMs) can generate
surprisingly coherent text when trained on simplified, child-directed corpora
such as TinyStories. These findings have been interpreted as evidence that
readability -- characterized by accessible vocabulary, familiar narrative
structure, and simple syntax -- plays a key role in enabling such capabilities
to emerge. In this paper, we challenge that interpretation. We construct
synthetic datasets with matched structure but varied readability, and find that
readability alone does not predict coherence or learning efficiency in SLMs.
Models trained on complex, adult-level text perform comparably to those trained
on simplified language, and even exhibit faster development of coherence during
training. Instead, we show that statistical simplicity, as measured by n-gram
diversity, is a stronger predictor of learnability. Our findings caution
against the growing trend of anthropomorphizing language model training --
drawing parallels to human cognitive development without empirical basis -- and
argue for more precise reasoning about what properties actually support
capability emergence in small models.

</details>


### [150] [Element2Vec: Build Chemical Element Representation from Text for Property Prediction](https://arxiv.org/abs/2510.13916)
*Yuanhao Li,Keyuan Lai,Tianqi Wang,Qihao Liu,Jiawei Ma,Yuan-Chao Hu*

Main category: cs.CL

TL;DR: 提出Element2Vec方法，利用语言模型从维基文本生成化学元素的全局和局部属性嵌入，结合测试时自注意力训练缓解数据稀疏问题，提升材料属性预测准确性。


<details>
  <summary>Details</summary>
Motivation: 化学元素的关键属性数据对材料设计至关重要，但许多属性难以直接测量，传统方法难以建模复杂关系，现有AI方法存在幻觉和可解释性差的问题。

Method: 从维基百科文本中提取化学元素描述，使用语言模型生成全局通用嵌入和突出属性的局部向量，并设计基于自注意力的测试时训练方法以减少回归预测误差。

Result: 能够有效表示化学元素的复杂特性，缓解了文本分布差异和数据稀疏带来的计算挑战，在属性预测上优于传统回归方法。

Conclusion: 该方法为自然语言驱动的材料科学AI研究提供了新路径，有望推动AI在材料发现中的应用。

Abstract: Accurate property data for chemical elements is crucial for materials design
and manufacturing, but many of them are difficult to measure directly due to
equipment constraints. While traditional methods use the properties of other
elements or related properties for prediction via numerical analyses, they
often fail to model complex relationships. After all, not all characteristics
can be represented as scalars. Recent efforts have been made to explore
advanced AI tools such as language models for property estimation, but they
still suffer from hallucinations and a lack of interpretability. In this paper,
we investigate Element2Vecto effectively represent chemical elements from
natural languages to support research in the natural sciences. Given the text
parsed from Wikipedia pages, we use language models to generate both a single
general-purpose embedding (Global) and a set of attribute-highlighted vectors
(Local). Despite the complicated relationship across elements, the
computational challenges also exist because of 1) the discrepancy in text
distribution between common descriptions and specialized scientific texts, and
2) the extremely limited data, i.e., with only 118 known elements, data for
specific properties is often highly sparse and incomplete. Thus, we also design
a test-time training method based on self-attention to mitigate the prediction
error caused by Vanilla regression clearly. We hope this work could pave the
way for advancing AI-driven discovery in materials science.

</details>


### [151] [Optimal Aggregation of LLM and PRM Signals for Efficient Test-Time Scaling](https://arxiv.org/abs/2510.13918)
*Peng Kuang,Yanli Wang,Xiaoyu Han,Yaowenqi Liu,Kaidi Xu,Haohan Wang*

Main category: cs.CL

TL;DR: 提出了一种基于理论框架的加权聚合方法，通过校准LLM和PRM之间的权重来优化测试时扩展（TTS）性能，显著提升效率并减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的过程奖励模型（PRM）在测试时扩展中表现不稳定，简单多数投票有时优于PRM信号指导的选择，因此需要更有效地利用PRM的验证信号。

Method: 构建了一个理论框架，提出最优策略是对LLM和PRM信号进行加权聚合，并设计了高效预计算方法来校准不同LLM-PRM对之间的权重函数。

Result: 在5个LLM和7个PRM上的实验表明，该方法显著提升了TTS效率，性能优于传统的加权多数投票，且仅使用21.3%的计算量。

Conclusion: 更智能的聚合策略比单纯增加测试时计算量更能有效提升性能，是TTS中更有前景的方向。

Abstract: Process reward models (PRMs) are a cornerstone of test-time scaling (TTS),
designed to verify and select the best responses from large language models
(LLMs). However, this promise is challenged by recent benchmarks where simple
majority voting, which ignores PRM signals, occasionally outperforms standard
PRM-based selection. This raises a critical question: How can we effectively
utilize verification signals from PRMs for TTS? To address this, we start by
developing a theoretical framework for optimally combining signals from both
the LLM and the PRM. Our framework reveals that the optimal strategy is a
weighted aggregation of responses, a strategy whose effectiveness hinges on
estimating weights that capture the complex interplay between the models. Based
on our theoretical results, we empirically show that these optimal weighting
functions differ significantly across LLM-PRM pairs and, notably, often assign
substantial negative weights. Motivated by these insights, we propose efficient
pre-computation methods to calibrate these weighting functions. Extensive
experiments across 5 LLMs and 7 PRMs demonstrate that our calibration method
significantly boosts the TTS efficiency, surpassing the performance of vanilla
weighted majority voting while using only $21.3\%$ of the computation.
Ultimately, our work demonstrates that investing in a more intelligent
aggregation strategy can be a more convincing path to performance gains than
simply scaling test-time computation.

</details>


### [152] [FACTS: Table Summarization via Offline Template Generation with Agentic Workflows](https://arxiv.org/abs/2510.13920)
*Ye Yuan,Mohammad Amin Shabani,Siqi Liu*

Main category: cs.CL

TL;DR: FACTS是一种快速、准确且符合隐私保护的表格摘要方法，通过离线生成模板实现可重用和高效的自然语言摘要生成。


<details>
  <summary>Details</summary>
Motivation: 现有表格到文本摘要方法存在微调成本高、推理能力弱、令牌限制、效率低和数据隐私暴露等问题，缺乏稳健性和可扩展性。

Method: 提出FACTS框架，结合SQL查询和Jinja2模板进行离线模板生成，仅将表结构发送给大模型以保障隐私，模板可跨相同结构的表格复用。

Result: 在多个基准测试中，FACTS在性能上持续优于基线方法，具备更高的效率和准确性。

Conclusion: FACTS为实际应用中的查询导向表格摘要提供了一种高效、准确且隐私合规的解决方案。

Abstract: Query-focused table summarization requires generating natural language
summaries of tabular data conditioned on a user query, enabling users to access
insights beyond fact retrieval. Existing approaches face key limitations:
table-to-text models require costly fine-tuning and struggle with complex
reasoning, prompt-based LLM methods suffer from token-limit and efficiency
issues while exposing sensitive data, and prior agentic pipelines often rely on
decomposition, planning, or manual templates that lack robustness and
scalability. To mitigate these issues, we introduce an agentic workflow, FACTS,
a Fast, Accurate, and Privacy-Compliant Table Summarization approach via
Offline Template Generation. FACTS produces offline templates, consisting of
SQL queries and Jinja2 templates, which can be rendered into natural language
summaries and are reusable across multiple tables sharing the same schema. It
enables fast summarization through reusable offline templates, accurate outputs
with executable SQL queries, and privacy compliance by sending only table
schemas to LLMs. Evaluations on widely-used benchmarks show that FACTS
consistently outperforms baseline methods, establishing it as a practical
solution for real-world query-focused table summarization.

</details>


### [153] [An LLM-Powered AI Agent Framework for Holistic IoT Traffic Interpretation](https://arxiv.org/abs/2510.13925)
*Daniel Adu Worae,Spyridon Mastorakis*

Main category: cs.CL

TL;DR: 提出一种基于大语言模型的AI代理框架，将原始数据包转换为结构化、语义丰富的表示，实现对物联网流量的高效、整体解析。


<details>
  <summary>Details</summary>
Motivation: 物联网产生大量异构流量，传统孤立的检测方法难以全面理解其行为与上下文，需跨层综合分析以识别潜在威胁。

Method: 框架结合特征提取、基于Transformer的异常检测、数据包与流摘要、威胁情报增强和检索增强问答，由大语言模型驱动的AI代理对索引的流量 artifacts 进行推理。

Result: 在多个物联网数据集和六种开源模型上的实验表明，相较于仅使用密集检索，结合词法与语义搜索并进行重排序的混合检索显著提升了BLEU、ROUGE、METEOR和BERTScore等指标，系统资源开销低。

Conclusion: 该框架能高效、准确地提供对物联网网络流量的语义理解和可读解释，适用于实际部署。

Abstract: Internet of Things (IoT) networks generate diverse and high-volume traffic
that reflects both normal activity and potential threats. Deriving meaningful
insight from such telemetry requires cross-layer interpretation of behaviors,
protocols, and context rather than isolated detection. This work presents an
LLM-powered AI agent framework that converts raw packet captures into
structured and semantically enriched representations for interactive analysis.
The framework integrates feature extraction, transformer-based anomaly
detection, packet and flow summarization, threat intelligence enrichment, and
retrieval-augmented question answering. An AI agent guided by a large language
model performs reasoning over the indexed traffic artifacts, assembling
evidence to produce accurate and human-readable interpretations. Experimental
evaluation on multiple IoT captures and six open models shows that hybrid
retrieval, which combines lexical and semantic search with reranking,
substantially improves BLEU, ROUGE, METEOR, and BERTScore results compared with
dense-only retrieval. System profiling further indicates low CPU, GPU, and
memory overhead, demonstrating that the framework achieves holistic and
efficient interpretation of IoT network traffic.

</details>


### [154] [BioMedSearch: A Multi-Source Biomedical Retrieval Framework Based on LLMs](https://arxiv.org/abs/2510.13926)
*Congying Liu,Xingyuan Wei,Peipei Liu,Yiqing Shen,Yanxu Mao,Tiehan Cui*

Main category: cs.CL

TL;DR: 提出了一种基于大语言模型的多源生物医学信息检索框架BioMedSearch，通过整合文献检索、蛋白质数据库和网络搜索，显著提升了复杂生物医学问答的准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理生物医学查询时因无法访问权威数据库而常产生不准确或虚构的内容，需结合多源信息以提高回答的科学性和准确性。

Method: 提出BioMedSearch框架，采用子查询分解、关键词提取、任务图构建和多源信息过滤，融合文献、蛋白质数据库和网页搜索进行信息检索与推理。

Result: 在自建的多级数据集BioMedMCQs上实验显示，该方法在三个推理层级上的准确率显著优于基线模型：一级从59.1%提升至91.9%，二级从47.0%提升至81.0%，三级从36.3%提升至73.4%。

Conclusion: BioMedSearch能有效整合多源生物医学信息，显著提升复杂生物医学问答的准确性和可靠性，具备实际应用潜力。

Abstract: Biomedical queries often rely on a deep understanding of specialized
knowledge such as gene regulatory mechanisms and pathological processes of
diseases. They require detailed analysis of complex physiological processes and
effective integration of information from multiple data sources to support
accurate retrieval and reasoning. Although large language models (LLMs) perform
well in general reasoning tasks, their generated biomedical content often lacks
scientific rigor due to the inability to access authoritative biomedical
databases and frequently fabricates protein functions, interactions, and
structural details that deviate from authentic information. Therefore, we
present BioMedSearch, a multi-source biomedical information retrieval framework
based on LLMs. The method integrates literature retrieval, protein database and
web search access to support accurate and efficient handling of complex
biomedical queries. Through sub-queries decomposition, keywords extraction,
task graph construction, and multi-source information filtering, BioMedSearch
generates high-quality question-answering results. To evaluate the accuracy of
question answering, we constructed a multi-level dataset, BioMedMCQs,
consisting of 3,000 questions. The dataset covers three levels of reasoning:
mechanistic identification, non-adjacent semantic integration, and temporal
causal reasoning, and is used to assess the performance of BioMedSearch and
other methods on complex QA tasks. Experimental results demonstrate that
BioMedSearch consistently improves accuracy over all baseline models across all
levels. Specifically, at Level 1, the average accuracy increases from 59.1% to
91.9%; at Level 2, it rises from 47.0% to 81.0%; and at the most challenging
Level 3, the average accuracy improves from 36.3% to 73.4%. The code and
BioMedMCQs are available at: https://github.com/CyL-ucas/BioMed_Search

</details>


### [155] [LLMs Can Get "Brain Rot"!](https://arxiv.org/abs/2510.13928)
*Shuo Xing,Junyuan Hong,Yifan Wang,Runjin Chen,Zhenyu Zhang,Ananth Grama,Zhengzhong Tu,Zhangyang Wang*

Main category: cs.CL

TL;DR: 研究表明，持续暴露于低质量网络文本会导致大语言模型出现认知衰退，表现为推理、长上下文理解、安全性等方面的能力下降，且难以通过后续训练完全恢复，提出数据质量是导致模型性能退化的关键因素。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型在持续预训练过程中，数据质量是否会导致模型出现类似‘脑腐’的认知退化现象，并从因果角度验证这一假设。

Method: 在真实推特数据上进行受控实验，通过两种正交的操作化定义（互动程度M1和语义质量M2）构建低质与对照数据集，在保持相同token规模和训练设置下，对4个LLM进行持续预训练，分析其性能变化。

Result: 在低质数据上训练的模型在推理、长上下文理解、安全性等方面出现显著退化（Hedges' g > 0.3），并表现出‘黑暗人格’特质增强；掺杂比例越高，性能越差，呈现剂量-反应关系；错误分析发现‘跳过思考’是主因，且后续训练只能部分修复。

Conclusion: 数据质量是导致大语言模型能力退化的因果因素，提示持续预训练中的数据筛选应被视为训练时安全问题，需建立常规的‘认知健康检查’机制。

Abstract: We propose and test the LLM Brain Rot Hypothesis: continual exposure to junk
web text induces lasting cognitive decline in large language models (LLMs). To
causally isolate data quality, we run controlled experiments on real Twitter/X
corpora, constructing junk and reversely controlled datasets via two orthogonal
operationalizations: M1 (engagement degree) and M2 (semantic quality), with
matched token scale and training operations across conditions. Contrary to the
control group, continual pre-training of 4 LLMs on the junk dataset causes
non-trivial declines (Hedges' $g>0.3$) on reasoning, long-context
understanding, safety, and inflating "dark traits" (e.g., psychopathy,
narcissism). The gradual mixtures of junk and control datasets also yield
dose-response cognition decay: for example, under M1, ARC-Challenge with Chain
Of Thoughts drops $74.9 \rightarrow 57.2$ and RULER-CWE $84.4 \rightarrow 52.3$
as junk ratio rises from $0\%$ to $100\%$.
  Error forensics reveal several key insights. First, we identify
thought-skipping as the primary lesion: models increasingly truncate or skip
reasoning chains, explaining most of the error growth. Second, partial but
incomplete healing is observed: scaling instruction tuning and clean data
pre-training improve the declined cognition yet cannot restore baseline
capability, suggesting persistent representational drift rather than format
mismatch. Finally, we discover that the popularity, a non-semantic metric, of a
tweet is a better indicator of the Brain Rot effect than the length in M1.
Together, the results provide significant, multi-perspective evidence that data
quality is a causal driver of LLM capability decay, reframing curation for
continual pretraining as a \textit{training-time safety} problem and motivating
routine "cognitive health checks" for deployed LLMs.

</details>


### [156] [Robust or Suggestible? Exploring Non-Clinical Induction in LLM Drug-Safety Decisions](https://arxiv.org/abs/2510.13931)
*Siying Liu,Shisheng Zhang,Indu Bala*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在药物不良事件预测中存在社会人口特征相关的系统性偏差，对弱势群体产生不利影响，揭示了临床应用中的公平性风险。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在药物安全性预测中是否引入临床无关的社会人口学信息，评估其在不同人群中的公平性。

Method: 基于美国FDA不良事件报告系统数据和基于角色的评估框架，评估ChatGPT-4o和Bio-Medical-Llama-3.8B在不同教育、婚姻、就业、保险、语言、住房、宗教等 persona 下的不良事件预测表现，并分析三种用户角色下的差异。

Result: 发现模型对弱势群体（如低教育水平、住房不稳定）预测的不良事件发生率更高；识别出显性偏见（推理中直接引用人口属性）和隐性偏见（预测不一致但未明确提及属性）两种偏见模式。

Conclusion: LLMs在药物流行病学应用中存在显著公平性风险，需建立公平性感知的评估机制和缓解策略，以确保临床部署的安全与公正。

Abstract: Large language models (LLMs) are increasingly applied in biomedical domains,
yet their reliability in drug-safety prediction remains underexplored. In this
work, we investigate whether LLMs incorporate socio-demographic information
into adverse event (AE) predictions, despite such attributes being clinically
irrelevant. Using structured data from the United States Food and Drug
Administration Adverse Event Reporting System (FAERS) and a persona-based
evaluation framework, we assess two state-of-the-art models, ChatGPT-4o and
Bio-Medical-Llama-3.8B, across diverse personas defined by education, marital
status, employment, insurance, language, housing stability, and religion. We
further evaluate performance across three user roles (general practitioner,
specialist, patient) to reflect real-world deployment scenarios where
commercial systems often differentiate access by user type. Our results reveal
systematic disparities in AE prediction accuracy. Disadvantaged groups (e.g.,
low education, unstable housing) were frequently assigned higher predicted AE
likelihoods than more privileged groups (e.g., postgraduate-educated, privately
insured). Beyond outcome disparities, we identify two distinct modes of bias:
explicit bias, where incorrect predictions directly reference persona
attributes in reasoning traces, and implicit bias, where predictions are
inconsistent, yet personas are not explicitly mentioned. These findings expose
critical risks in applying LLMs to pharmacovigilance and highlight the urgent
need for fairness-aware evaluation protocols and mitigation strategies before
clinical deployment.

</details>


### [157] [Big Reasoning with Small Models: Instruction Retrieval at Inference Time](https://arxiv.org/abs/2510.13935)
*Kenan Alkiek,David Jurgens,Vinod Vydiswaran*

Main category: cs.CL

TL;DR: 提出一种通过推理指令检索增强小语言模型（SLM）多步推理能力的方法，无需微调即在多个领域任务上实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 小语言模型（SLM）因高效、隐私保护和低成本具有吸引力，但在需要多步推理或专业知识的任务上表现不佳，本文旨在提升其推理能力。

Method: 在推理时引入指令干预机制：构建指令语料库，通过检索与输入问题最相关的结构化推理步骤，并让SLM遵循执行；指令由GPT-5生成，基于相似训练问题聚类获得。

Result: 在MedQA、MMLU Law和MathQA上，使用3B至14B参数模型均取得显著增益：分别提升9.4%、7.9%和5.1%；简洁指令优于冗长指令，且效果受模型家族和内在推理能力影响。

Conclusion: 指令检索为提升SLM的复杂推理能力提供了有效且无需微调的新路径，有望推动在本地计算条件下实现大规模推理。

Abstract: Can we bring large-scale reasoning to local-scale compute? Small language
models (SLMs) are increasingly attractive because they run efficiently on local
hardware, offering strong privacy, low cost, and reduced environmental impact.
Yet they often struggle with tasks that require multi-step reasoning or
domain-specific knowledge. We address this limitation through instruction
intervention at inference time, where an SLM retrieves structured reasoning
procedures rather than generating them from scratch. Our method builds an
Instruction Corpus by grouping similar training questions and creating
instructions via GPT-5. During inference, the SLM retrieves the most relevant
instructions and follows their steps. Unlike retrieval-augmented generation,
which retrieves text passages, instruction retrieval gives the model structured
guidance for reasoning. We evaluate this framework on MedQA (medical board
exams), MMLU Professional Law, and MathQA using models from 3B to 14B
parameters without any additional fine-tuning. Instruction retrieval yields
consistent gains: 9.4% on MedQA, 7.9% on MMLU Law, and 5.1% on MathQA. Concise
instructions outperform longer ones, and the magnitude of improvement depends
strongly on model family and intrinsic reasoning ability.

</details>


### [158] [FinDeepResearch: Evaluating Deep Research Agents in Rigorous Financial Analysis](https://arxiv.org/abs/2510.13936)
*Fengbin Zhu,Xiang Yao Ng,Ziyang Liu,Chang Liu,Xianwei Zeng,Chao Wang,Tianhui Tan,Xuan Yao,Pengyang Shao,Min Xu,Zixuan Wang,Jing Wang,Xin Lin,Junfeng Li,Jingxian Zhu,Yang Zhang,Wenjie Wang,Fuli Feng,Richang Hong,Huanbo Luan,Ke-Wei Huang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 本文提出了一个名为HisRubric的评估框架和FinDeepResearch基准，用于系统评估深度研究代理在跨市场、跨语言企业财务分析中的能力，并通过大量实验揭示了现有方法的优势与局限。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对深度研究代理在关键研究分析任务中能力的系统评估，本文旨在填补这一空白，特别是在企业财务分析领域。

Method: 提出HisRubric评估框架，包含层次化分析结构和细粒度评分标准，并构建FinDeepResearch基准，涵盖8个金融市场、4种语言的64家上市公司，共15,808个评分项；在16种代表性方法上进行实验，包括深度研究代理和具备不同能力的大型语言模型。

Result: 实验揭示了不同方法在多能力、多市场、多语言场景下的表现差异，识别出当前深度研究代理的优势与局限，例如在数据识别、指标计算和战略解读方面的性能分布不均。

Conclusion: HisRubric和FinDeepResearch为评估深度研究代理提供了可靠工具，实验结果为未来代理系统的设计与优化提供了重要指导，推动了金融领域AI研究的发展。

Abstract: Deep Research (DR) agents, powered by advanced Large Language Models (LLMs),
have recently garnered increasing attention for their capability in conducting
complex research tasks. However, existing literature lacks a rigorous and
systematic evaluation of DR Agent's capabilities in critical research analysis.
To address this gap, we first propose HisRubric, a novel evaluation framework
with a hierarchical analytical structure and a fine-grained grading rubric for
rigorously assessing DR agents' capabilities in corporate financial analysis.
This framework mirrors the professional analyst's workflow, progressing from
data recognition to metric calculation, and finally to strategic summarization
and interpretation. Built on this framework, we construct a FinDeepResearch
benchmark that comprises 64 listed companies from 8 financial markets across 4
languages, encompassing a total of 15,808 grading items. We further conduct
extensive experiments on the FinDeepResearch using 16 representative methods,
including 6 DR agents, 5 LLMs equipped with both deep reasoning and search
capabilities, and 5 LLMs with deep reasoning capabilities only. The results
reveal the strengths and limitations of these approaches across diverse
capabilities, financial markets, and languages, offering valuable insights for
future research and development. The benchmark and evaluation code will be made
publicly available.

</details>


### [159] [Readers Prefer Outputs of AI Trained on Copyrighted Books over Expert Human Writers](https://arxiv.org/abs/2510.13939)
*Tuhin Chakrabarty,Jane C. Ginsburg,Paramveer Dhillon*

Main category: cs.CL

TL;DR: 通过对50位获奖作家风格的模仿写作实验，研究发现经过作者特定作品微调的AI模型（如ChatGPT）在风格忠实性和写作质量上显著优于上下文提示生成的文本，甚至被专家和普通读者偏好，且难以被AI检测器识别，成本也大幅降低，对版权领域的“合理使用”原则提出了新挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨AI模型在训练中使用受版权保护的书籍是否能真正模仿作者风格生成高质量文学文本，进而评估其对原作品市场价值的影响，为当前AI与版权纠纷提供实证依据。

Method: 采用预注册研究设计，让MFA训练的专业作家与三种前沿AI模型（ChatGPT、Claude、Gemini）分别模仿50位获奖作家的风格撰写最多450字的段落；通过上下文提示和针对作者全集微调ChatGPT两种方式生成AI文本；由159名专家与普通读者进行双盲成对评估，并使用AI检测器和中介分析探究差异原因。

Result: 上下文提示生成的AI文本在风格忠实性和写作质量上均被专家强烈否定（OR=0.16, p<10⁻⁸；OR=0.13, p<10⁻⁷），但经过作者特定数据微调后，AI生成文本反而被专家偏好（风格OR=8.16, p<10⁻¹³；质量OR=1.87, p=0.010），普通读者也呈现相似趋势；微调后的文本仅3%被AI检测器识别，远低于上下文提示的97%；中介分析显示微调消除了AI特有的风格瑕疵（如陈词滥调密度）；平均每作者微调与推理成本仅81美元，比专业作家薪酬低99.7%。

Conclusion: 针对特定作者作品微调的AI模型能够生成在风格和质量上优于人类专家写作的非逐字复制文本，且难以被察觉，成本极低，这表明AI生成内容可能实质性替代原作者作品，对版权法中的‘合理使用’第四要素构成重大影响，提示现行版权框架需重新审视。

Abstract: The use of copyrighted books for training AI models has led to numerous
lawsuits from authors concerned about AI's ability to generate derivative
content.Yet it's unclear whether these models can generate high quality
literary text while emulating authors' styles. To answer this we conducted a
preregistered study comparing MFA-trained expert writers with three frontier AI
models: ChatGPT, Claude & Gemini in writing up to 450 word excerpts emulating
50 award-winning authors' diverse styles. In blind pairwise evaluations by 159
representative expert & lay readers, AI-generated text from in-context
prompting was strongly disfavored by experts for both stylistic fidelity
(OR=0.16, p<10^8) & writing quality (OR=0.13, p<10^7) but showed mixed results
with lay readers. However, fine-tuning ChatGPT on individual authors' complete
works completely reversed these findings: experts now favored AI-generated text
for stylistic fidelity (OR=8.16, p<10^13) & writing quality (OR=1.87, p=0.010),
with lay readers showing similar shifts. These effects generalize across
authors & styles. The fine-tuned outputs were rarely flagged as AI-generated
(3% rate v. 97% for in-context prompting) by best AI detectors. Mediation
analysis shows this reversal occurs because fine-tuning eliminates detectable
AI stylistic quirks (e.g., cliche density) that penalize in-context outputs.
While we do not account for additional costs of human effort required to
transform raw AI output into cohesive, publishable prose, the median
fine-tuning & inference cost of $81 per author represents a dramatic 99.7%
reduction compared to typical professional writer compensation. Author-specific
fine-tuning thus enables non-verbatim AI writing that readers prefer to expert
human writing, providing empirical evidence directly relevant to copyright's
fourth fair-use factor, the "effect upon the potential market or value" of the
source works.

</details>


### [160] [Less is More: Improving LLM Reasoning with Minimal Test-Time Intervention](https://arxiv.org/abs/2510.13940)
*Zhen Yang,Mingyang Zhang,Feng Chen,Ganggui Ding,Liang Hou,Xin Tao,Pengfei Wan,Ying-Cong Chen*

Main category: cs.CL

TL;DR: 提出了一种无需训练、仅在推理时对高不确定性位置进行干预的Minimal Test-Time Intervention (MTI) 方法，有效提升大模型推理准确性与稳定性，且计算开销极小。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时扩展方法虽然能提升推理能力，但通常牺牲效率；作者发现推理中的错误主要由少数高熵token决定，因此提出应仅在关键不确定位置进行干预以提高效率和性能。

Method: MTI框架包含两个部分：(i) 选择性使用无分类器引导（Selective CFG），仅在高熵（不确定）token位置施加干预；(ii) 轻量级负提示引导，重用主模型的KV缓存来高效近似无条件解码。

Result: MTI在通用、编程和STEM任务上均带来一致提升，例如Qwen3-8B-Base在八个基准上平均提升+1.35%，Qwen3-32B-Reasoning在AIME2024上提升+5%，同时保持高效。

Conclusion: 通过定位并干预关键不确定性位置，MTI实现了高效且有效的推理增强，为测试时扩展提供了一种更精细、低成本的新范式。

Abstract: Recent progress in large language models (LLMs) has focused on test-time
scaling to improve reasoning via increased inference computation, but often at
the cost of efficiency. We revisit test-time behavior and uncover a simple yet
underexplored phenomenon: reasoning uncertainty is highly localized-only a
small subset of high-entropy tokens dominantly affects output correctness.
Motivated by this, we propose Minimal Test-Time Intervention (MTI), a
training-free framework that enhances reasoning accuracy and stability with
minimal overhead. MTI includes: (i) Selective CFG intervention, applying
classifier-free guidance only at uncertain positions; and (ii) Lightweight
negative-prompt guidance, reusing the main model's KV cache to approximate
unconditional decoding efficiently. MTI yields consistent gains across general,
coding, and STEM tasks-e.g., +1.35% average improvement on eight benchmarks for
Qwen3-8B-Base and +5% on AIME2024 using Qwen3-32B-Reasoning-while remaining
highly efficient.

</details>


### [161] [Classifying and Addressing the Diversity of Errors in Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2510.13975)
*Kin Kwan Leung,Mouloud Belbahri,Yi Sui,Alex Labach,Xueying Zhang,Stephen Rose,Jesse C. Cresswell*

Main category: cs.CL

TL;DR: 提出了一种针对现实世界中检索增强生成（RAG）系统错误类型的分类法，提供了错误示例、实用修复建议，并构建了标注错误类型的数据集及与分类法对齐的自动评估方法。


<details>
  <summary>Details</summary>
Motivation: 由于RAG系统在实际应用中复杂且易出错，需要系统性理解各类错误以支持可靠部署。

Method: 提出新的RAG错误类型分类法，人工标注包含各类错误的响应数据集，并设计匹配该分类法的自动评估方法。

Result: 构建了一个公开的RAG错误响应数据集，开发了可实际用于跟踪和调试错误的自动评估工具。

Conclusion: 该分类法和配套工具可有效帮助开发人员识别、监控和修复RAG系统中的错误，提升系统鲁棒性。

Abstract: Retrieval-augmented generation (RAG) is a prevalent approach for building
LLM-based question-answering systems that can take advantage of external
knowledge databases. Due to the complexity of real-world RAG systems, there are
many potential causes for erroneous outputs. Understanding the range of errors
that can occur in practice is crucial for robust deployment. We present a new
taxonomy of the error types that can occur in realistic RAG systems, examples
of each, and practical advice for addressing them. Additionally, we curate a
dataset of erroneous RAG responses annotated by error types. We then propose an
auto-evaluation method aligned with our taxonomy that can be used in practice
to track and address errors during development. Code and data are available at
https://github.com/layer6ai-labs/rag-error-classification.

</details>


### [162] [The German Commons - 154 Billion Tokens of Openly Licensed Text for German Language Models](https://arxiv.org/abs/2510.13996)
*Lukas Gienapp,Christopher Schröder,Stefan Schweter,Christopher Akiki,Ferdinand Schlatt,Arden Zimmermann,Phillipe Genêt,Martin Potthast*

Main category: cs.CL

TL;DR: 本文介绍了German Commons，这是迄今为止最大的开放授权德语文本集合，包含来自41个数据源的154.56亿token，涵盖七大领域，旨在解决非英语语言中开放授权文本稀缺的问题，支持真正开源德语大模型的开发。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型依赖大规模训练语料，但多数语料的授权不明确，尤其非英语语言缺乏开放授权文本，限制了开源模型的发展。德语尤其面临此类数据短缺问题。

Method: 从41个具有可验证授权的可靠数据源系统性收集德语文本，覆盖法律、科学、文化等七个领域；构建包含质量过滤、去重和格式修正的处理流程，确保文本质量；所有子集均采用CC-BY-SA 4.0或同等授权。

Result: 构建了包含154.56亿token的高质量、开放授权德语文本语料库German Commons，并发布了针对德语的语料构建与过滤代码，实现全流程可复现和可扩展。

Conclusion: German Commons填补了开放授权德语预训练数据的关键空白，为开发真正开源的德语语言模型提供了合法、高质量的数据基础。

Abstract: Large language model development relies on large-scale training corpora, yet
most contain data of unclear licensing status, limiting the development of
truly open models. This problem is exacerbated for non-English languages, where
openly licensed text remains critically scarce. We introduce the German
Commons, the largest collection of openly licensed German text to date. It
compiles data from 41 sources across seven domains, encompassing legal,
scientific, cultural, political, news, economic, and web text. Through
systematic sourcing from established data providers with verifiable licensing,
it yields 154.56 billion tokens of high-quality text for language model
training. Our processing pipeline implements comprehensive quality filtering,
deduplication, and text formatting fixes, ensuring consistent quality across
heterogeneous text sources. All domain subsets feature licenses of at least
CC-BY-SA 4.0 or equivalent, ensuring legal compliance for model training and
redistribution. The German Commons therefore addresses the critical gap in
openly licensed German pretraining data, and enables the development of truly
open German language models. We also release code for corpus construction and
data filtering tailored to German language text, rendering the German Commons
fully reproducible and extensible.

</details>


### [163] [CRaFT: An Explanation-Based Framework for Evaluating Cultural Reasoning in Multilingual Language Models](https://arxiv.org/abs/2510.14014)
*Shehenaz Hossain,Haithem Afli*

Main category: cs.CL

TL;DR: CRaFT是一个基于解释的多语言评估框架，通过四个可解释指标评估大语言模型在不同文化背景下的推理能力，揭示文化意识并非内生于模型，而是通过语言表述浮现。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法多关注答案准确性，忽略模型对文化背景的理解。为深入探究大语言模型在多文化语境中的推理表现，需构建更细粒度的评估框架。

Method: 提出CRaFT框架，采用文化流利度、偏离度、一致性与语言适应性四个指标，评估模型对50个源自世界价值观调查的文化相关问题（翻译为阿拉伯语、孟加拉语和西班牙语）的回答与解释，共分析2100多个答案-解释对。

Result: 阿拉伯语降低文化流利度，孟加拉语提升流利度，西班牙语保持稳定；GPT跨语言适应较好但一致性较低，FANAR推理稳定但较僵化。

Conclusion: 大语言模型的文化意识并非固有，而是通过语言表达方式显现；CRaFT为评估多语言环境下的跨文化推理提供了有效工具，有助于构建更具文化适应性的模型。

Abstract: Correct answers do not necessarily reflect cultural understanding. We
introduce CRaFT, an explanation-based multilingual evaluation framework
designed to assess how large language models (LLMs) reason across cultural
contexts. Rather than scoring outputs solely based on accuracy, CRaFT evaluates
model explanations using four interpretable metrics: Cultural Fluency,
Deviation, Consistency, and Linguistic Adaptation. We apply the framework to 50
culturally grounded questions from the World Values Survey, translated into
Arabic, Bengali, and Spanish, and evaluate three models (GPT, DeepSeek, and
FANAR) across over 2,100 answer-explanation pairs. Results reveal significant
cross-lingual variation in reasoning: Arabic reduces fluency, Bengali enhances
it, and Spanish remains largely stable. While GPT adapts more effectively
across languages, it exhibits lower consistency; FANAR shows stable but rigid
reasoning. These findings suggest that cultural awareness in LLMs is not
intrinsic but emerges through linguistic framing. CRaFT offers a new lens for
evaluating cross-cultural reasoning in multilingual settings, providing
actionable insights for building culturally adaptive language models.

</details>


### [164] [Think Globally, Group Locally: Evaluating LLMs Using Multi-Lingual Word Grouping Games](https://arxiv.org/abs/2510.14030)
*César Guerra-Solano,Zhuochun Li,Xiang Lorraine Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为GlobalGroup的新任务，用于评估大语言模型在多种语言下的抽象推理能力，发现英语模式下表现更好，并揭示了开源与闭源模型之间的性能差异。


<details>
  <summary>Details</summary>
Motivation: 为了研究大语言模型在不同语言模态下的抽象推理偏见，特别是在缺乏公式化方法依赖的‘跳出框框’思维任务中的表现差异。

Method: 受《纽约时报》Connections游戏启发，构建了一个包含英语、西班牙语、中文、印地语和阿拉伯语的多语言游戏基准，每种语言包括母语和英文翻译版本，并提出游戏难度度量以控制比较条件。

Result: 实验结果显示，模型在英语模态下的抽象推理任务中表现普遍更优，且闭源模型整体优于开源模型，存在明显的语言偏差和模型类型差异。

Conclusion: 大语言模型在抽象推理任务中存在显著的语言模态偏见，未来的研究需更关注多语言公平性和推理能力的真正泛化。

Abstract: Large language models (LLMs) can exhibit biases in reasoning capabilities due
to linguistic modality, performing better on tasks in one language versus
another, even with similar content. Most previous works evaluate this through
reasoning tasks where reliance on strategies or knowledge can ensure success,
such as in commonsense or math tasks. However, abstract reasoning is vital to
reasoning for everyday life, where people apply "out-of-the-box thinking" to
identify and use patterns for solutions, without a reliance on formulaic
approaches. Comparatively, little work has evaluated linguistic biases in this
task type. In this paper, we propose a task inspired by the New York Times
Connections: GlobalGroup, that evaluates models in an abstract reasoning task
across several languages. We constructed a game benchmark with five linguistic
backgrounds -- English, Spanish, Chinese, Hindi, and Arabic -- in both the
native language and an English translation for comparison. We also proposed
game difficulty measurements to evaluate models on games with similar
difficulty, enabling a more controlled comparison, which is particularly
important in reasoning evaluations. Through experimentation, we find English
modalities largely lead to better performance in this abstract reasoning task,
and performance disparities between open- and closed-source models.

</details>


### [165] [Quantifying Phonosemantic Iconicity Distributionally in 6 Languages](https://arxiv.org/abs/2510.14040)
*George Flint,Kaustubh Kislay*

Main category: cs.CL

TL;DR: 该研究采用分布性方法大规模量化了6种不同语言中的语音-语义象似性，发现了新的可解释的语音语义对应关系及跨语言模式，并验证了部分先前假设的关联。


<details>
  <summary>Details</summary>
Motivation: 语言通常被认为是任意的，但在具体案例中已观察到语音与语义之间的系统性关联。本研究旨在探究这些系统性关系在大规模定量分析中是否普遍存在，包括已被发现和尚未识别的现象。

Method: 研究在英语、西班牙语、印地语、芬兰语、土耳其语和泰米尔语六种语言中，采用一系列统计方法分析词素的语音相似性空间与语义相似性空间之间的对齐程度，以量化语音-语义象似性。

Result: 发现了多种文献中尚未报道的可解释的语音语义对应关系，以及跨语言的共性模式；同时对5种先前假设的语音语义关联进行了检验，部分得到支持，其他结果则不一致。

Conclusion: 语音与语义之间存在系统性的大规模关联，且具备跨语言普遍性，表明语言中的象似性成分不可忽视。

Abstract: Language is, as commonly theorized, largely arbitrary. Yet, systematic
relationships between phonetics and semantics have been observed in many
specific cases. To what degree could those systematic relationships manifest
themselves in large scale, quantitative investigations--both in previously
identified and unidentified phenomena? This work undertakes a distributional
approach to quantifying phonosemantic iconicity at scale across 6 diverse
languages (English, Spanish, Hindi, Finnish, Turkish, and Tamil). In each
language, we analyze the alignment of morphemes' phonetic and semantic
similarity spaces with a suite of statistical measures, and discover an array
of interpretable phonosemantic alignments not previously identified in the
literature, along with crosslinguistic patterns. We also analyze 5 previously
hypothesized phonosemantic alignments, finding support for some such alignments
and mixed results for others.

</details>


### [166] [ERGO: Entropy-guided Resetting for Generation Optimization in Multi-turn Language Models](https://arxiv.org/abs/2510.14077)
*Haziq Mohammad Khalid,Athikash Jeyaganthan,Timothy Do,Yicheng Fu,Sean O'Brien,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: ERGO利用Shannon熵检测大型语言模型在多轮对话中的不确定性突增，通过自适应提示整合实现上下文动态对齐，在增量信息场景下显著提升性能、准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在逐步获取信息的多轮对话中表现显著下降，影响实际可用性。本文旨在通过识别并利用模型不确定性来改善对话一致性与性能。

Method: 提出ERGO方法，通过计算下一个token分布的Shannon熵持续量化模型不确定性，并在检测到熵值骤升时触发自适应的提示整合，以动态校正对话上下文。

Result: 在增量指令任务中，ERGO相较基线平均性能提升56.6%，最大能力提高24.7%，性能波动减少35.3%。

Conclusion: 将不确定性作为首要信号进行干预，能够有效提升对话式AI的准确性与可靠性，表明拥抱而非消除不确定性是改进多轮对话性能的新路径。

Abstract: Large Language Models (LLMs) suffer significant performance degradation in
multi-turn conversations when information is presented incrementally. Given
that multi-turn conversations characterize everyday interactions with LLMs,
this degradation poses a severe challenge to real world usability. We
hypothesize that abrupt increases in model uncertainty signal misalignment in
multi-turn LLM interactions, and we exploit this insight to dynamically realign
conversational context. We introduce ERGO (Entropy-guided Resetting for
Generation Optimization), which continuously quantifies internal uncertainty
via Shannon entropy over next token distributions and triggers adaptive prompt
consolidation when a sharp spike in entropy is detected. By treating
uncertainty as a first class signal rather than a nuisance to eliminate, ERGO
embraces variability in language and modeling, representing and responding to
uncertainty. In multi-turn tasks with incrementally revealed instructions, ERGO
yields a 56.6% average performance gain over standard baselines, increases
aptitude (peak performance capability) by 24.7%, and decreases unreliability
(variability in performance) by 35.3%, demonstrating that uncertainty aware
interventions can improve both accuracy and reliability in conversational AI.

</details>


### [167] [DROID: Dual Representation for Out-of-Scope Intent Detection](https://arxiv.org/abs/2510.14110)
*Wael Rashwan,Hossam M. Zawbaa,Sourav Dutta,Haytham Assem*

Main category: cs.CL

TL;DR: DROID是一种紧凑的端到端框架，利用双编码器（USE和域适应TSDAE）融合表示和轻量分支分类器，结合数据增强，在低资源场景下显著提升已知意图和未知范围（OOS）意图检测性能，参数仅1.5M。


<details>
  <summary>Details</summary>
Motivation: 现有OOS检测方法依赖强分布假设或辅助校准模块，难以在有限标注数据下有效区分域内与域外意图，尤其在低资源场景中表现受限。

Method: 提出DROID框架：结合通用句子编码器（USE）和领域适配的Transformer去噪自编码器（TSDAE）进行双表示学习；融合表示输入轻量分支分类器，使用单一校准阈值区分域内外意图；引入合成数据与开放域异常样本增强以提升边界学习。

Result: 在多个意图识别基准上，DROID以仅1.5M参数超越最新方法，已知意图macro-F1提升6-15%，OOS意图提升8-20%，在低资源设置下增益最显著。

Conclusion: 双编码器表示结合简单校准可实现鲁棒、可扩展且可靠的神经对话系统OOS检测，无需复杂后处理。

Abstract: Detecting out-of-scope (OOS) user utterances remains a key challenge in
task-oriented dialogue systems and, more broadly, in open-set intent
recognition. Existing approaches often depend on strong distributional
assumptions or auxiliary calibration modules. We present DROID (Dual
Representation for Out-of-Scope Intent Detection), a compact end-to-end
framework that combines two complementary encoders -- the Universal Sentence
Encoder (USE) for broad semantic generalization and a domain-adapted
Transformer-based Denoising Autoencoder (TSDAE) for domain-specific contextual
distinctions. Their fused representations are processed by a lightweight
branched classifier with a single calibrated threshold that separates in-domain
and OOS intents without post-hoc scoring. To enhance boundary learning under
limited supervision, DROID incorporates both synthetic and open-domain outlier
augmentation. Despite using only 1.5M trainable parameters, DROID consistently
outperforms recent state-of-the-art baselines across multiple intent
benchmarks, achieving macro-F1 improvements of 6--15% for known and 8--20% for
OOS intents, with the most significant gains in low-resource settings. These
results demonstrate that dual-encoder representations with simple calibration
can yield robust, scalable, and reliable OOS detection for neural dialogue
systems.

</details>


### [168] [Toward Cybersecurity-Expert Small Language Models](https://arxiv.org/abs/2510.14113)
*Matan Levi,Daniel Ohayon,Ariel Blobstein,Ravid Sagi,Ian Molloy,Yair Allouche*

Main category: cs.CL

TL;DR: CyberPal 2.0 是一系列针对网络安全任务优化的小型语言模型（4B-20B 参数），通过构建高质量、思维链增强的网络安全指令数据集，在多项基准测试中表现优于或匹敌大型前沿模型，尤其在威胁情报与威胁调查任务中取得领先成绩。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在多个领域广泛应用，但在网络安全领域的部署仍滞后，主要受限于缺乏高质量、领域特定的模型和训练数据。因此，需要专门针对网络安全任务设计高效、精准的小型语言模型及配套数据集。

Method: 提出 CyberPal 2.0 模型系列，并构建 SecKnowledge 2.0 数据增强与格式化 pipeline，结合专家指导与 LLM 驱动的多步推理锚定，生成高质量、任务 grounded 的思维链网络安全指令数据，用于训练小型语言模型。

Result: CyberPal 2.0 在多个网络安全基准上 consistently 超过基线模型，并媲美甚至超越多种开源与闭源前沿模型。在核心网络威胁情报任务中表现仅次于 Sec-Gemini v1；在威胁调查任务（如漏洞与缺陷单关联）中，20B 模型超越 GPT-4o、o1、o3-mini 和 Sec-Gemini v1 排名第一，4B 模型排名第二。

Conclusion: 通过专家介入与数据增强构建的高质量推理数据可显著提升小型语言模型在网络安全领域的性能，CyberPal 2.0 以远小于主流模型的规模实现了顶尖水平的任务表现，展示了专业化小模型在安全领域的巨大潜力。

Abstract: Large language models (LLMs) are transforming everyday applications, yet
deployment in cybersecurity lags due to a lack of high-quality, domain-specific
models and training datasets. To address this gap, we present CyberPal 2.0, a
family of cybersecurity-expert small language models (SLMs) ranging from 4B-20B
parameters. To train CyberPal 2.0, we generate an enriched chain-of-thought
cybersecurity instruction dataset built with our data enrichment and formatting
pipeline, SecKnowledge 2.0, which integrates expert-in-the-loop steering of
reasoning formats alongside LLM-driven multi-step grounding, yielding
higher-fidelity, task-grounded reasoning traces for security tasks. Across
diverse cybersecurity benchmarks, CyberPal 2.0 consistently outperforms its
baselines and matches or surpasses various open and closed-source frontier
models, while remaining a fraction of their size. On core cyber threat
intelligence knowledge tasks, our models outperform almost all tested frontier
models, ranking second only to Sec-Gemini v1. On core threat-investigation
tasks, such as correlating vulnerabilities and bug tickets with weaknesses, our
best 20B-parameter model outperforms GPT-4o, o1, o3-mini, and Sec-Gemini v1,
ranking first, while our smallest 4B-parameter model ranks second.

</details>


### [169] [Building a Macedonian Recipe Dataset: Collection, Parsing, and Comparative Analysis](https://arxiv.org/abs/2510.14128)
*Darko Sasanski,Dimitar Peshevski,Riste Stojanov,Dimitar Trajanov*

Main category: cs.CL

TL;DR: 本文提出了首个马其顿食谱数据集的构建工作，通过网络爬虫和结构化解析，解决了食材描述异质性的问题，并分析了马其顿烹饪中的独特食材组合模式。


<details>
  <summary>Details</summary>
Motivation: 马其顿语食谱在数字化研究中缺乏代表性，限制了对这一地区烹饪传统的研究，因此需要构建一个系统性的马其顿食谱数据集以支持计算美食学的发展。

Method: 通过网络爬虫收集马其顿语食谱，进行结构化解析，处理食材在单位、数量和描述上的异质性，并使用点互信息（PMI）和提升度（Lift score）等指标分析食材频率及共现模式。

Result: 成功构建了首个马其顿食谱数据集，揭示了马其顿 cuisine 中具有代表性的食材共现模式和独特搭配。

Conclusion: 该数据集为研究少数语言的饮食文化提供了新资源，并加深了对马其顿烹饪传统独特性的理解。

Abstract: Computational gastronomy increasingly relies on diverse, high-quality recipe
datasets to capture regional culinary traditions. Although there are
large-scale collections for major languages, Macedonian recipes remain
under-represented in digital research. In this work, we present the first
systematic effort to construct a Macedonian recipe dataset through web scraping
and structured parsing. We address challenges in processing heterogeneous
ingredient descriptions, including unit, quantity, and descriptor
normalization. An exploratory analysis of ingredient frequency and
co-occurrence patterns, using measures such as Pointwise Mutual Information and
Lift score, highlights distinctive ingredient combinations that characterize
Macedonian cuisine. The resulting dataset contributes a new resource for
studying food culture in underrepresented languages and offers insights into
the unique patterns of Macedonian culinary tradition.

</details>


### [170] [RLSR: Reinforcement Learning with Supervised Reward Outperforms SFT in Instruction Following](https://arxiv.org/abs/2510.14200)
*Zhichao Wang,Andy Wong,Ruslan Belkin*

Main category: cs.CL

TL;DR: 提出RLSR方法，利用强化学习框架改进大语言模型的指令遵循能力，可替代SFT并在多个任务中取得更好表现。


<details>
  <summary>Details</summary>
Motivation: 现有SFT等方法依赖大量标注数据且潜力有限，而RFT等强化学习方法在低资源场景下表现良好。因此，研究者希望将SFT的数据优势与RL框架结合，提升指令遵循性能。

Method: 提出RLSR方法，使用强化学习框架，通过在语义嵌入空间中计算生成响应与人类标注响应之间的余弦相似度作为奖励信号，对基础模型进行训练。

Result: RLSR可替代SFT，在Qwen-7B模型上实现26.34%的AlpacaEval胜率，超过SFT的21.01%；结合SFT与RLSR后胜率达到30.73%。

Conclusion: RLSR能有效利用SFT数据集并提升模型指令遵循能力，优于传统SFT方法，且与SFT联合使用可进一步提升性能。

Abstract: After the pretraining stage of LLMs, techniques such as SFT, RLHF, RLVR, and
RFT are applied to enhance instruction-following ability, mitigate undesired
responses, improve reasoning capability and enable efficient domain adaptation
with minimal data. SFT relies on the next-token prediction objective to
strengthen instruction following in a base model using a large corpus of
human-labeled responses. In contrast, RFT employs a RL-based approach to adapt
fine-tuned reasoning models to specific domains with limited supervision.
Inspired by RFT, we propose replacing SFT with RLSR to leverage the extensive
SFT dataset in an RL framework, thereby improving the base model's
instruction-following ability. In RLSR, the base model generates multiple
responses for each prompt, and reward scores are computed as the cosine
similarity in the semantic embedding space between the generated and
human-labeled responses. RLSR can be utilized in multiple ways. It can directly
replace SFT, achieving superior performance on instruction-following
benchmarks-for example, RLSR (SB) on Qwen-7B (INFINITY) achieved an AlpacaEval
win rate of 26.34%, surpassing SFT's 21.01%. Furthermore, combining SFT and
RLSR further enhances downstream task performance; Qwen-7B (INFINITY) achieved
a win rate of 30.73% when trained with SFT + RLSR.

</details>


### [171] [DPRF: A Generalizable Dynamic Persona Refinement Framework for Optimizing Behavior Alignment Between Personalized LLM Role-Playing Agents and Humans](https://arxiv.org/abs/2510.14205)
*Bingsheng Yao,Bo Sun,Yuanzhe Dong,Yuxuan Lu,Dakuo Wang*

Main category: cs.CL

TL;DR: 提出动态人设优化框架（DPRF），通过迭代识别和修正大语言模型角色扮演代理行为与真实人类行为的认知差异，显著提升行为一致性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型角色扮演代理依赖人工构建的人设，缺乏与真实个体的一致性验证，导致人设保真度不足。

Method: 提出动态人设优化框架（DPRF），通过自由形式或基于理论的结构化分析，迭代识别生成行为与人类真实行为之间的认知差异，并优化人设以减小差异。

Result: 在五个大语言模型和四种不同行为预测场景（正式辩论、心理健康相关社交媒体发帖、公开访谈、电影评论）中验证，DPRF显著优于基线人设，且在模型与场景间具有良好泛化性。

Conclusion: DPRF为构建高保真人设提供了可靠方法，增强了用户模拟、社会科学研究和个性化AI等下游应用的有效性。

Abstract: The emerging large language model role-playing agents (LLM RPAs) aim to
simulate individual human behaviors, but the persona fidelity is often
undermined by manually-created profiles (e.g., cherry-picked information and
personality characteristics) without validating the alignment with the target
individuals. To address this limitation, our work introduces the Dynamic
Persona Refinement Framework (DPRF).DPRF aims to optimize the alignment of LLM
RPAs' behaviors with those of target individuals by iteratively identifying the
cognitive divergence, either through free-form or theory-grounded, structured
analysis, between generated behaviors and human ground truth, and refining the
persona profile to mitigate these divergences.We evaluate DPRF with five LLMs
on four diverse behavior-prediction scenarios: formal debates, social media
posts with mental health issues, public interviews, and movie reviews.DPRF can
consistently improve behavioral alignment considerably over baseline personas
and generalizes across models and scenarios.Our work provides a robust
methodology for creating high-fidelity persona profiles and enhancing the
validity of downstream applications, such as user simulation, social studies,
and personalized AI.

</details>


### [172] [LiteStage: Latency-aware Layer Skipping for Multi-stage Reasoning](https://arxiv.org/abs/2510.14211)
*Beomseok Kang,Jiwon Song,Jae-Joon Kim*

Main category: cs.CL

TL;DR: 提出了一种名为LiteStage的延迟感知层跳过框架，通过分阶段的离线搜索和在线置信度退出机制，在多阶段推理中实现高效与准确的平衡，显著加速小语言模型推理。


<details>
  <summary>Details</summary>
Motivation: 多阶段推理虽能提升小模型推理能力，但带来高延迟；现有加速方法难以兼顾效率与准确性，尤其存在阶段敏感性和冗余生成问题。

Method: LiteStage结合分阶段离线搜索分配最优层预算，并引入基于置信度的在线生成早退机制，抑制不必要的解码过程，实现自适应层跳过。

Result: 在OBQA、CSQA和StrategyQA三个基准上，LiteStage实现了最高1.70倍的加速，且准确率损失小于4.0%。

Conclusion: LiteStage在多阶段推理中有效平衡了推理速度与模型性能，优于现有的免训练层跳过方法。

Abstract: Multi-stage reasoning has emerged as an effective strategy for enhancing the
reasoning capability of small language models by decomposing complex problems
into sequential sub-stages. However, this comes at the cost of increased
latency. We observe that existing adaptive acceleration techniques, such as
layer skipping, struggle to balance efficiency and accuracy in this setting due
to two key challenges: (1) stage-wise variation in skip sensitivity, and (2)
the generation of redundant output tokens. To address these, we propose
LiteStage, a latency-aware layer skipping framework for multi-stage reasoning.
LiteStage combines a stage-wise offline search that allocates optimal layer
budgets with an online confidence-based generation early exit to suppress
unnecessary decoding. Experiments on three benchmarks, e.g., OBQA, CSQA, and
StrategyQA, show that LiteStage achieves up to 1.70x speedup with less than
4.0% accuracy loss, outperforming prior training-free layer skipping methods.

</details>


### [173] [Flip-Flop Consistency: Unsupervised Training for Robustness to Prompt Perturbations in LLMs](https://arxiv.org/abs/2510.14242)
*Parsa Hejabi,Elnaz Rahmati,Alireza S. Ziabari,Morteza Dehghani*

Main category: cs.CL

TL;DR: 提出了一种名为Flip-Flop Consistency（F²C）的无监督训练方法，通过共识交叉熵和表示对齐损失来提升大语言模型在不同提示变体下的鲁棒性、一致性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在面对相同语义但不同表达的提示时常常产生不一致的回答，影响其可靠性和稳定性，因此需要提升模型对提示扰动的鲁棒性。

Method: F²C包含两个核心组件：一是共识交叉熵（CCE），利用多个提示变体的多数投票生成硬伪标签；二是表示对齐损失，将低置信度或非主流预测的表示拉向高置信度、多数投票的共识方向。

Result: 在11个涵盖四种NLP任务的数据集上评估显示，F²C平均提升一致性11.62%，F₁分数提高8.94%，格式间性能方差减少3.29%；在跨域和未见过的提示格式上也表现出更强的泛化能力和稳定性。

Conclusion: F²C是一种有效的无监督方法，显著增强了大语言模型在提示扰动下的输出一致性、性能表现和泛化能力。

Abstract: Large Language Models (LLMs) often produce inconsistent answers when faced
with different phrasings of the same prompt. In this paper, we propose
Flip-Flop Consistency ($F^2C$), an unsupervised training method that improves
robustness to such perturbations. $F^2C$ is composed of two key components. The
first, Consensus Cross-Entropy (CCE), uses a majority vote across prompt
variations to create a hard pseudo-label. The second is a representation
alignment loss that pulls lower-confidence and non-majority predictors toward
the consensus established by high-confidence, majority-voting variations. We
evaluate our method on 11 datasets spanning four NLP tasks, with 4-15 prompt
variations per dataset. On average, $F^2C$ raises observed agreement by 11.62%,
improves mean $F_1$ by 8.94%, and reduces performance variance across formats
by 3.29%. In out-of-domain evaluations, $F^2C$ generalizes effectively,
increasing $\overline{F_1}$ and agreement while decreasing variance across most
source-target pairs. Finally, when trained on only a subset of prompt
perturbations and evaluated on held-out formats, $F^2C$ consistently improves
both performance and agreement while reducing variance. These findings
highlight $F^2C$ as an effective unsupervised method for enhancing LLM
consistency, performance, and generalization under prompt perturbations. Code
is available at
https://github.com/ParsaHejabi/Flip-Flop-Consistency-Unsupervised-Training-for-Robustness-to-Prompt-Perturbations-in-LLMs.

</details>


### [174] [MoM: Mixtures of Scenario-Aware Document Memories for Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2510.14252)
*Jihao Zhao,Zhiyuan Ji,Simin Niu,Hanyu Wang,Feiyu Xiong,Zhiyu Li*

Main category: cs.CL

TL;DR: 提出MoM框架，将RAG从被动分块转变为主动理解，通过模拟人类阅读认知过程，提升小语言模型的文本处理与推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法依赖被动文本分块，限制了知识内化深度和推理能力，难以实现类人阅读理解。

Method: 提出MoM框架，利用大模型模拟领域专家生成文档逻辑大纲，采用多路径采样与多视角评估机制提取清晰且完整的文档记忆，并引入反向推理策略训练小模型，构建三层文档记忆检索机制。

Result: 在三个不同领域实验表明，MoM能有效解决现有RAG的分块问题，为大模型提供语义完整的文档记忆，并显著提升小模型的主动理解与推理能力。

Conclusion: MoM框架实现了从被动检索到主动记忆提取的转变，推动小语言模型实现更接近人类的智能文本处理。

Abstract: The traditional RAG paradigm, which typically engages in the comprehension of
relevant text chunks in response to received queries, inherently restricts both
the depth of knowledge internalization and reasoning capabilities. To address
this limitation, our research transforms the text processing in RAG from
passive chunking to proactive understanding, defining this process as document
memory extraction with the objective of simulating human cognitive processes
during reading. Building upon this, we propose the Mixtures of scenario-aware
document Memories (MoM) framework, engineered to efficiently handle documents
from multiple domains and train small language models (SLMs) to acquire the
ability to proactively explore and construct document memories. The MoM
initially instructs large language models (LLMs) to simulate domain experts in
generating document logical outlines, thereby directing structured chunking and
core content extraction. It employs a multi-path sampling and multi-perspective
evaluation mechanism, specifically designing comprehensive metrics that
represent chunk clarity and extraction completeness to select the optimal
document memories. Additionally, to infuse deeper human-like reading abilities
during the training of SLMs, we incorporate a reverse reasoning strategy, which
deduces refined expert thinking paths from high-quality outcomes. Finally,
leveraging diverse forms of content generated by MoM, we develop a three-layer
document memory retrieval mechanism, which is grounded in our theoretical proof
from the perspective of probabilistic modeling. Extensive experimental results
across three distinct domains demonstrate that the MoM framework not only
resolves text chunking challenges in existing RAG systems, providing LLMs with
semantically complete document memories, but also paves the way for SLMs to
achieve human-centric intelligent text processing.

</details>


### [175] [Rewriting History: A Recipe for Interventional Analyses to Study Data Effects on Model Behavior](https://arxiv.org/abs/2510.14261)
*Rahul Nadkarni,Yanai Elazar,Hila Gonen,Noah A. Smith*

Main category: cs.CL

TL;DR: 提出了一种通过修改训练数据并重新训练模型来研究数据与语言模型行为之间关系的实验方法，特别用于探究事实知识获取。


<details>
  <summary>Details</summary>
Motivation: 理解训练数据如何影响语言模型的行为，尤其是模型的事实知识学习机制，现有观察性分析不足以完全解释这一过程。

Method: 提出一个包含干预数据批次、匹配相关文档、修改文档、重新训练和测量效果的实验流程，并通过基于共现统计和信息检索的方法识别可能影响知识学习的文档。

Result: 实验表明，现有方法识别相关训练文档的能力有限，无法完全解释模型回答知识问题的表现，同时补充了共现与模型行为之间关系的已有发现。

Conclusion: 该实验流程为研究人员提供了测试训练数据如何影响模型行为的系统方法，有助于推动数据与模型行为关系的因果研究。

Abstract: We present an experimental recipe for studying the relationship between
training data and language model (LM) behavior. We outline steps for
intervening on data batches -- i.e., ``rewriting history'' -- and then
retraining model checkpoints over that data to test hypotheses relating data to
behavior. Our recipe breaks down such an intervention into stages that include
selecting evaluation items from a benchmark that measures model behavior,
matching relevant documents to those items, and modifying those documents
before retraining and measuring the effects. We demonstrate the utility of our
recipe through case studies on factual knowledge acquisition in LMs, using both
cooccurrence statistics and information retrieval methods to identify documents
that might contribute to knowledge learning. Our results supplement past
observational analyses that link cooccurrence to model behavior, while
demonstrating that extant methods for identifying relevant training documents
do not fully explain an LM's ability to correctly answer knowledge questions.
Overall, we outline a recipe that researchers can follow to test further
hypotheses about how training data affects model behavior. Our code is made
publicly available to promote future work.

</details>


### [176] [Less is More: Denoising Knowledge Graphs For Retrieval Augmented Generation](https://arxiv.org/abs/2510.14271)
*Yilun Zheng,Dan Yang,Jie Li,Lin Shang,Lihui Chen,Jiahao Xu,Sitao Luan*

Main category: cs.CL

TL;DR: 本文提出了DEG-RAG框架，通过实体消解和三元组反思技术对大语言模型生成的噪声知识图谱进行去噪，显著提升了图检索增强生成系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图的检索增强生成系统依赖大语言模型构建知识图谱，常产生冗余实体和不可靠关系等噪声问题，影响检索与生成效果，并增加计算成本，当前研究缺乏对这类噪声问题的系统性解决。

Method: 提出DEG-RAG框架，包含两个核心技术：(1) 实体消解，消除冗余实体；(2) 三元组反思，去除错误关系。同时系统评估了不同阻塞策略、嵌入选择、相似性度量和实体合并技术在实体消解中的表现。

Result: 实验表明，该方法显著减小知识图谱规模，同时在多种主流图增强RAG模型上持续提升问答性能。

Conclusion: DEG-RAG有效提升了LLM生成知识图谱的质量，是首个对LLM生成知识图谱中实体消解问题进行全面探索的工作，为图增强生成系统提供了高效去噪解决方案。

Abstract: Retrieval-Augmented Generation (RAG) systems enable large language models
(LLMs) instant access to relevant information for the generative process,
demonstrating their superior performance in addressing common LLM challenges
such as hallucination, factual inaccuracy, and the knowledge cutoff.
Graph-based RAG further extends this paradigm by incorporating knowledge graphs
(KGs) to leverage rich, structured connections for more precise and inferential
responses. A critical challenge, however, is that most Graph-based RAG systems
rely on LLMs for automated KG construction, often yielding noisy KGs with
redundant entities and unreliable relationships. This noise degrades retrieval
and generation performance while also increasing computational cost. Crucially,
current research does not comprehensively address the denoising problem for
LLM-generated KGs. In this paper, we introduce DEnoised knowledge Graphs for
Retrieval Augmented Generation (DEG-RAG), a framework that addresses these
challenges through: (1) entity resolution, which eliminates redundant entities,
and (2) triple reflection, which removes erroneous relations. Together, these
techniques yield more compact, higher-quality KGs that significantly outperform
their unprocessed counterparts. Beyond the methods, we conduct a systematic
evaluation of entity resolution for LLM-generated KGs, examining different
blocking strategies, embedding choices, similarity metrics, and entity merging
techniques. To the best of our knowledge, this is the first comprehensive
exploration of entity resolution in LLM-generated KGs. Our experiments
demonstrate that this straightforward approach not only drastically reduces
graph size but also consistently improves question answering performance across
diverse popular Graph-based RAG variants.

</details>


### [177] [Retrofitting Small Multilingual Models for Retrieval: Matching 7B Performance with 300M Parameters](https://arxiv.org/abs/2510.14274)
*Lifu Tu,Yingbo Zhou,Semih Yavuz*

Main category: cs.CL

TL;DR: 提出了一种针对检索任务优化的小型多语言嵌入模型，通过改进负采样和训练数据的任务多样性，在300M参数量下性能媲美甚至超过7B大模型。


<details>
  <summary>Details</summary>
Motivation: 小型多语言模型在检索任务上通常落后于大型模型，探索如何通过训练策略改进使其在检索任务上达到高性能。

Method: 分析训练数据规模、负样本采样策略和数据多样性对多语言嵌入效果的影响，采用硬负样本和高任务多样性数据进行训练。

Result: 发现数据规模提升性能存在瓶颈，硬负样本和任务多样性对检索效果提升更为关键，最终训练出约300M参数的模型，在检索任务上性能达到甚至超过当前强大的7B模型。

Conclusion: 小型多语言模型通过针对性优化可在检索任务上媲美大模型，任务多样性比语言多样性更重要。

Abstract: Training effective multilingual embedding models presents unique challenges
due to the diversity of languages and task objectives. Although small
multilingual models (<1 B parameters) perform well on multilingual tasks
generally, they consistently lag behind larger models (>1 B) in the most
prevalent use case: retrieval. This raises a critical question: Can smaller
models be retrofitted specifically for retrieval tasks to enhance their
performance? In this work, we investigate key factors that influence the
effectiveness of multilingual embeddings, focusing on training data scale,
negative sampling strategies, and data diversity. We find that while increasing
the scale of training data yields initial performance gains, these improvements
quickly plateau - indicating diminishing returns. Incorporating hard negatives
proves essential for consistently improving retrieval accuracy. Furthermore,
our analysis reveals that task diversity in the training data contributes more
significantly to performance than language diversity alone. As a result, we
develop a compact (approximately 300M) multilingual model that achieves
retrieval performance comparable to or even surpassing current strong 7B
models.

</details>


### [178] [Qwen3Guard Technical Report](https://arxiv.org/abs/2510.14276)
*Haiquan Zhao,Chenhan Yuan,Fei Huang,Xiaomeng Hu,Yichang Zhang,An Yang,Bowen Yu,Dayiheng Liu,Jingren Zhou,Junyang Lin,Baosong Yang,Chen Cheng,Jialong Tang,Jiandong Jiang,Jianwei Zhang,Jijie Xu,Ming Yan,Minmin Sun,Pei Zhang,Pengjun Xie,Qiaoyu Tang,Qin Zhu,Rong Zhang,Shibin Wu,Shuo Zhang,Tao He,Tianyi Tang,Tingyu Xia,Wei Liao,Weizhou Shen,Wenbiao Yin,Wenmeng Zhou,Wenyuan Yu,Xiaobin Wang,Xiaodong Deng,Xiaodong Xu,Xinyu Zhang,Yang Liu,Yeqiu Li,Yi Zhang,Yong Jiang,Yu Wan,Yuxin Zhou*

Main category: cs.CL

TL;DR: 提出Qwen3Guard，一种支持多语言、细粒度和流式安全检测的系列安全对齐模型，支持实时、分级的LLM输出安全管理。


<details>
  <summary>Details</summary>
Motivation: 现有安全模型仅提供二分类结果且需完整输出后检测，难以适应多样化安全策略和流式生成场景。

Method: 构建两种变体：生成式Qwen3Guard实现三类细粒度判断（安全/争议/不安全）；流式Qwen3Guard支持token级实时检测。模型包含0.6B/4B/8B三种规模，支持119种语言。

Result: 在英、中及多语言基准上均达到SOTA性能，支持低延迟、可扩展的安全监管。

Conclusion: Qwen3Guard解决了传统安全模型在策略适应性和流式推理上的局限，为全球LLM部署提供高效、灵活的安全保障，模型已开源。

Abstract: As large language models (LLMs) become more capable and widely used, ensuring
the safety of their outputs is increasingly critical. Existing guardrail
models, though useful in static evaluation settings, face two major limitations
in real-world applications: (1) they typically output only binary "safe/unsafe"
labels, which can be interpreted inconsistently across diverse safety policies,
rendering them incapable of accommodating varying safety tolerances across
domains; and (2) they require complete model outputs before performing safety
checks, making them fundamentally incompatible with streaming LLM inference,
thereby preventing timely intervention during generation and increasing
exposure to harmful partial outputs. To address these challenges, we present
Qwen3Guard, a series of multilingual safety guardrail models with two
specialized variants: Generative Qwen3Guard, which casts safety classification
as an instruction-following task to enable fine-grained tri-class judgments
(safe, controversial, unsafe); and Stream Qwen3Guard, which introduces a
token-level classification head for real-time safety monitoring during
incremental text generation. Both variants are available in three sizes (0.6B,
4B, and 8B parameters) and support up to 119 languages and dialects, providing
comprehensive, scalable, and low-latency safety moderation for global LLM
deployments. Evaluated across English, Chinese, and multilingual benchmarks,
Qwen3Guard achieves state-of-the-art performance in both prompt and response
safety classification. All models are released under the Apache 2.0 license for
public use.

</details>


### [179] [PRISM: Agentic Retrieval with LLMs for Multi-Hop Question Answering](https://arxiv.org/abs/2510.14278)
*Md Mahadi Hasan Nahid,Davood Rafiei*

Main category: cs.CL

TL;DR: 提出了一种基于大语言模型的代理检索系统，通过三个专门代理（问题分析、选择和补充）的迭代协作，在多跳问答中实现高精度和高召回率的证据检索。


<details>
  <summary>Details</summary>
Motivation: 多跳问答中，传统检索方法在精度和召回之间难以平衡，且易引入干扰信息，影响下游模型性能。

Method: 构建一个包含问题分析器、选择器和补充器的代理检索框架，利用大语言模型在结构化循环中分解问题、精确筛选相关上下文并补充缺失证据。

Result: 在HotpotQA、2WikiMultiHopQA、MuSiQue和MultiHopRAG四个基准上均优于强基线方法，检索更准确且信息更简洁。

Conclusion: 该代理检索系统能有效提升多跳问答中的证据检索质量，兼顾精度与召回，显著减少无关信息干扰。

Abstract: Retrieval plays a central role in multi-hop question answering (QA), where
answering complex questions requires gathering multiple pieces of evidence. We
introduce an Agentic Retrieval System that leverages large language models
(LLMs) in a structured loop to retrieve relevant evidence with high precision
and recall. Our framework consists of three specialized agents: a Question
Analyzer that decomposes a multi-hop question into sub-questions, a Selector
that identifies the most relevant context for each sub-question (focusing on
precision), and an Adder that brings in any missing evidence (focusing on
recall). The iterative interaction between Selector and Adder yields a compact
yet comprehensive set of supporting passages. In particular, it achieves higher
retrieval accuracy while filtering out distracting content, enabling downstream
QA models to surpass full-context answer accuracy while relying on
significantly less irrelevant information. Experiments on four multi-hop QA
benchmarks -- HotpotQA, 2WikiMultiHopQA, MuSiQue, and MultiHopRAG --
demonstrates that our approach consistently outperforms strong baselines.

</details>


### [180] [Rethinking Schema Linking: A Context-Aware Bidirectional Retrieval Approach for Text-to-SQL](https://arxiv.org/abs/2510.14296)
*Md Mahadi Hasan Nahid,Davood Rafiei,Weiwei Zhang,Yong Zhang*

Main category: cs.CL

TL;DR: 提出一种上下文感知的双向模式检索框架，将模式链接视为独立问题，通过结合两种互补策略和增强技术，显著提高了Text-to-SQL系统的模式召回率并减少误报。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL方法多关注SQL生成，忽视了相关模式元素的检索，容易导致幻觉和执行失败，因此需要更有效的模式链接方法。

Method: 将模式链接作为独立任务，采用表优先和列优先两种双向检索策略，并结合问题分解、关键词提取和关键短语提取等技术进行增强。

Result: 在BIRD和Spider等基准上验证了方法的有效性，显著提升了模式召回率，降低了误报率，且生成的SQL性能优于全模式基线，接近于理想情况下的性能，缩小了全模式与完美模式之间50%的性能差距。

Conclusion: 模式链接是提升Text-to-SQL准确性和效率的关键环节，所提方法为解决该问题提供了有效途径。

Abstract: Schema linking -- the process of aligning natural language questions with
database schema elements -- is a critical yet underexplored component of
Text-to-SQL systems. While recent methods have focused primarily on improving
SQL generation, they often neglect the retrieval of relevant schema elements,
which can lead to hallucinations and execution failures. In this work, we
propose a context-aware bidirectional schema retrieval framework that treats
schema linking as a standalone problem. Our approach combines two complementary
strategies: table-first retrieval followed by column selection, and
column-first retrieval followed by table selection. It is further augmented
with techniques such as question decomposition, keyword extraction, and
keyphrase extraction. Through comprehensive evaluations on challenging
benchmarks such as BIRD and Spider, we demonstrate that our method
significantly improves schema recall while reducing false positives. Moreover,
SQL generation using our retrieved schema consistently outperforms full-schema
baselines and closely approaches oracle performance, all without requiring
query refinement. Notably, our method narrows the performance gap between full
and perfect schema settings by 50\%. Our findings highlight schema linking as a
powerful lever for enhancing Text-to-SQL accuracy and efficiency.

</details>


### [181] [Constraint-Driven Small Language Models Based on Agent and OpenAlex Knowledge Graph: Mining Conceptual Pathways and Discovering Innovation Points in Academic Papers](https://arxiv.org/abs/2510.14303)
*Ziye Xia,Sergei S. Ospichev*

Main category: cs.CL

TL;DR: 本文基于OpenAlex知识图谱，提出一种基于提示工程的关键概念路径分析方法，利用小语言模型实现关键概念提取与创新点识别，并通过知识图图约束机制构建智能体提升分析精度，在Qwen和DeepSeek模型上进行微调后显著提高了准确率。


<details>
  <summary>Details</summary>
Motivation: 面对学术论文数量激增，现有数据库仅限于关键概念的相似性匹配和基本分类，缺乏对概念间关系网络的深度挖掘，难以支持科研人员高效追踪最新进展。

Method: 基于OpenAlex开源知识图谱，分析近8000篇诺夫苏伯斯克国立大学的开源论文数据，采用提示工程方法结合小语言模型进行关键概念提取，构建受知识图谱约束的智能体以增强分析准确性。

Result: 通过微调Qwen和DeepSeek模型，显著提升了关键概念提取和创新点识别的准确性，相关模型已公开在Hugging Face平台。

Conclusion: 该方法能有效揭示论文中关键概念路径的分布模式与创新点之间的强关联，为学术分析提供了一种可扩展、高精度的自动化工具。

Abstract: In recent years, the rapid increase in academic publications across various
fields has posed severe challenges for academic paper analysis: scientists
struggle to timely and comprehensively track the latest research findings and
methodologies. Key concept extraction has proven to be an effective analytical
paradigm, and its automation has been achieved with the widespread application
of language models in industrial and scientific domains. However, existing
paper databases are mostly limited to similarity matching and basic
classification of key concepts, failing to deeply explore the relational
networks between concepts. This paper is based on the OpenAlex opensource
knowledge graph. By analyzing nearly 8,000 open-source paper data from
Novosibirsk State University, we discovered a strong correlation between the
distribution patterns of paper key concept paths and both innovation points and
rare paths. We propose a prompt engineering-based key concept path analysis
method. This method leverages small language models to achieve precise key
concept extraction and innovation point identification, and constructs an agent
based on a knowledge graph constraint mechanism to enhance analysis accuracy.
Through fine-tuning of the Qwen and DeepSeek models, we achieved significant
improvements in accuracy, with the models publicly available on the Hugging
Face platform.

</details>


### [182] [MathMist: A Parallel Multilingual Benchmark Dataset for Mathematical Problem Solving and Reasoning](https://arxiv.org/abs/2510.14305)
*Mahbub E Sobhani,Md. Faiyaz Abdullah Sayeedi,Tasnim Mohiuddin,Md Mofijul Islam,Swakkhar Shatabda*

Main category: cs.CL

TL;DR: 提出并发布了MathMist，一个包含七种语言、超过2.1万对齐问答的平行多语言数学推理基准，用于系统评估大模型在多语言数学推理中的表现，发现现有模型在低资源语言中存在显著性能下降。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在数学推理方面的能力主要在英语或高资源语言中评估，缺乏对多语言、尤其是低资源语言数学推理能力的系统评估，因此需要构建一个更具代表性的多语言数学基准。

Method: 构建了MathMist数据集，包含七种语言（涵盖高、中、低资源语言）的21K+对齐数学问题与答案；在零样本、思维链和代码转换三种推理模式下，对多种开源、闭源及多语言推理模型进行系统评测。

Result: 实验结果显示，尽管部分模型在高资源语言中表现尚可，但在跨语言数学推理上普遍存在不一致和不可解释的问题，尤其在低资源语言中性能显著下降。

Conclusion: MathMist为评估多语言数学推理提供了重要工具，揭示了现有大模型在语言多样性下的局限性，强调需进一步研究提升模型在低资源语言中的推理一致性与泛化能力。

Abstract: Mathematical reasoning remains one of the most challenging domains for large
language models (LLMs), requiring not only linguistic understanding but also
structured logical deduction and numerical precision. While recent LLMs
demonstrate strong general-purpose reasoning abilities, their mathematical
competence across diverse languages remains underexplored. Existing benchmarks
primarily focus on English or a narrow subset of high-resource languages,
leaving significant gaps in assessing multilingual and cross-lingual
mathematical reasoning. To address this, we introduce MathMist, a parallel
multilingual benchmark for mathematical problem solving and reasoning. MathMist
encompasses over 21K aligned question-answer pairs across seven languages,
representing a balanced coverage of high-, medium-, and low-resource linguistic
settings. The dataset captures linguistic variety, multiple types of problem
settings, and solution synthesizing capabilities. We systematically evaluate a
diverse suite of models, including open-source small and medium LLMs,
proprietary systems, and multilingual-reasoning-focused models, under
zero-shot, chain-of-thought (CoT), and code-switched reasoning paradigms. Our
results reveal persistent deficiencies in LLMs' ability to perform consistent
and interpretable mathematical reasoning across languages, with pronounced
degradation in low-resource settings. All the codes and data are available at
GitHub: https://github.com/mahbubhimel/MathMist

</details>


### [183] [MERLIN: A Testbed for Multilingual Multimodal Entity Recognition and Linking](https://arxiv.org/abs/2510.14307)
*Sathyanarayanan Ramamoorthy,Vishwa Shah,Simran Khanuja,Zaid Sheikh,Shan Jie,Ann Chia,Shearman Chua,Graham Neubig*

Main category: cs.CL

TL;DR: 本文介绍了MERLIN，一个用于多语言多模态实体链接的新型测试平台，包含五种语言的BBC新闻标题及其配图，涵盖7000多个命名实体提及和2500个唯一的Wikidata实体。研究表明，结合视觉数据可提升实体链接准确性，尤其对文本上下文模糊或不足的情况以及多语言能力较弱的模型效果显著。


<details>
  <summary>Details</summary>
Motivation: 多语言和多模态信息在实体链接任务中日益重要，但现有数据集和方法在跨语言和跨模态融合方面仍存在不足，因此需要一个综合性的测试平台来推动该领域的发展。

Method: 构建了一个包含五种语言（印地语、日语、印尼语、越南语、泰米尔语）的新闻标题与图像配对的数据集，并设计了基于LLaMa-2和Aya-23等语言模型的多语言多模态实体链接基准方法，探索视觉信息对实体链接性能的影响。

Result: 实验结果表明，引入视觉数据能够显著提高实体链接的准确性，尤其是在文本上下文模糊或模型多语言能力较弱的情况下效果更为明显。

Conclusion: MERLIN为多语言多模态实体链接提供了有效的测试平台，证明了视觉信息在提升链接性能方面的潜力，尤其是在资源较少的语言中具有重要应用价值。

Abstract: This paper introduces MERLIN, a novel testbed system for the task of
Multilingual Multimodal Entity Linking. The created dataset includes BBC news
article titles, paired with corresponding images, in five languages: Hindi,
Japanese, Indonesian, Vietnamese, and Tamil, featuring over 7,000 named entity
mentions linked to 2,500 unique Wikidata entities. We also include several
benchmarks using multilingual and multimodal entity linking methods exploring
different language models like LLaMa-2 and Aya-23. Our findings indicate that
incorporating visual data improves the accuracy of entity linking, especially
for entities where the textual context is ambiguous or insufficient, and
particularly for models that do not have strong multilingual abilities. For the
work, the dataset, methods are available here at
https://github.com/rsathya4802/merlin

</details>


### [184] [Evaluating & Reducing Deceptive Dialogue From Language Models with Multi-turn RL](https://arxiv.org/abs/2510.14318)
*Marwa Abdulhai,Ryan Cheng,Aryansh Shrivastava,Natasha Jaques,Yarin Gal,Sergey Levine*

Main category: cs.CL

TL;DR: 该论文研究了大语言模型（LLM）在对话中产生欺骗性输出的问题，提出了一种新的“信念错位”指标来量化欺骗行为，并发现现有模型即使在良性提示下也有约26%的对话轮次表现出欺骗性，而经过RLHF训练的模型仍存在43%的欺骗率；作者进一步提出一种多轮强化学习微调方法，可将欺骗行为减少77.6%。


<details>
  <summary>Details</summary>
Motivation: 由于LLM在现实应用中可能无意或有意生成欺骗性内容，带来安全隐患，现有检测指标难以准确衡量多轮对话中的欺骗行为，因此需要更有效的评估方法和缓解策略。

Method: 提出了‘信念错位’（belief misalignment）指标来量化LLM在对话中的欺骗行为，并在四种不同对话场景下，使用五种现有指标和新指标进行评测；同时构建了一个多轮强化学习框架，用于微调LLM以减少欺骗行为。

Result: 新提出的信念错位指标与人类判断的相关性高于所有现有指标；在八种主流LLM上的基准测试显示，模型在约26%的对话轮次中自发表现出欺骗行为，提示下可提升31%；RLHF训练模型仍有43%的欺骗率；所提强化学习方法可实现77.6%的欺骗行为降幅。

Conclusion: 欺骗是LLM在多轮对话中持续发展的行为，单轮评估不足；信念错位是更贴近人类判断的欺骗度量方式，且通过多轮强化学习可有效抑制LLM的欺骗倾向，为提升LLM安全性提供了可行路径。

Abstract: Large Language Models (LLMs) interact with millions of people worldwide in
applications such as customer support, education and healthcare. However, their
ability to produce deceptive outputs, whether intentionally or inadvertently,
poses significant safety concerns. The unpredictable nature of LLM behavior,
combined with insufficient safeguards against hallucination, misinformation,
and user manipulation, makes their misuse a serious, real-world risk. In this
paper, we investigate the extent to which LLMs engage in deception within
dialogue, and propose the belief misalignment metric to quantify deception. We
evaluate deception across four distinct dialogue scenarios, using five
established deception detection metrics and our proposed metric. Our findings
reveal this novel deception measure correlates more closely with human
judgments than any existing metrics we test. Additionally, our benchmarking of
eight state-of-the-art models indicates that LLMs naturally exhibit deceptive
behavior in approximately 26% of dialogue turns, even when prompted with
seemingly benign objectives. When prompted to deceive, LLMs are capable of
increasing deceptiveness by as much as 31% relative to baselines. Unexpectedly,
models trained with RLHF, the predominant approach for ensuring the safety of
widely-deployed LLMs, still exhibit deception at a rate of 43% on average.
Given that deception in dialogue is a behavior that develops over an
interaction history, its effective evaluation and mitigation necessitates
moving beyond single-utterance analyses. We introduce a multi-turn
reinforcement learning methodology to fine-tune LLMs to reduce deceptive
behaviors, leading to a 77.6% reduction compared to other instruction-tuned
models.

</details>


### [185] [A Robust Classification Method using Hybrid Word Embedding for Early Diagnosis of Alzheimer's Disease](https://arxiv.org/abs/2510.14332)
*Yangyang Li*

Main category: cs.CL

TL;DR: 提出一种基于混合词嵌入和超参数优化的分类方法，用于阿尔茨海默病（AD）的早期检测，达到91%准确率和97% AUC，优于现有最佳NLP模型。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期检测有助于及时治疗和减轻医疗负担，语言能力变化是AD的重要早期标志，因此利用自然语言处理技术进行自动诊断具有重要意义。

Method: 结合Doc2Vec和ELMo生成混合词嵌入，计算句子困惑度以捕捉语义和流畅性，并融合语言学特征增强表示；将特征向量输入逻辑回归模型，并在整个流水线中精细调整超参数。

Result: 在区分早期AD患者与健康对照者任务中，模型达到91%的分类准确率和97%的AUC，优于现有最佳模型（准确率88%），且实验显示模型性能稳定（准确率标准差0.0403，AUC标准差0.0174）。

Conclusion: 所提方法在AD早期检测中具有高准确性与稳定性，可作为大规模筛查工具或医生诊断的辅助手段。

Abstract: Early detection of Alzheimer's Disease (AD) is greatly beneficial to AD
patients, leading to early treatments that lessen symptoms and alleviating
financial burden of health care. As one of the leading signs of AD, language
capability changes can be used for early diagnosis of AD. In this paper, I
develop a robust classification method using hybrid word embedding and
fine-tuned hyperparameters to achieve state-of-the-art accuracy in the early
detection of AD. Specifically, we create a hybrid word embedding based on word
vectors from Doc2Vec and ELMo to obtain perplexity scores of the sentences. The
scores identify whether a sentence is fluent or not and capture semantic
context of the sentences. I enrich the word embedding by adding linguistic
features to analyze syntax and semantics. Further, we input an embedded feature
vector into logistic regression and fine tune hyperparameters throughout the
pipeline. By tuning hyperparameters of the machine learning pipeline (e.g.,
model regularization parameter, learning rate and vector size of Doc2Vec, and
vector size of ELMo), I achieve 91% classification accuracy and an Area Under
the Curve (AUC) of 97% in distinguishing early AD from healthy subjects. Based
on my knowledge, my model with 91% accuracy and 97% AUC outperforms the best
existing NLP model for AD diagnosis with an accuracy of 88% [32]. I study the
model stability through repeated experiments and find that the model is stable
even though the training data is split randomly (standard deviation of accuracy
= 0.0403; standard deviation of AUC = 0.0174). This affirms our proposed method
is accurate and stable. This model can be used as a large-scale screening
method for AD, as well as a complementary examination for doctors to detect AD.

</details>


### [186] [Beyond One World: Benchmarking Super Heros in Role-Playing Across Multiversal Contexts](https://arxiv.org/abs/2510.14351)
*Perapard Ngokpol,Kun Kerdthaisong,Pasin Buakhaw,Pitikorn Khlaisamniang,Supasate Vorathammathorn,Piyalitt Ittichaiwong,Nutchanon Yongsatianchot*

Main category: cs.CL

TL;DR: 本文提出了Beyond One World基准，用于评估大语言模型在扮演不同版本角色（如漫威和DC中的超级英雄）时的准确性和一致性，并引入“思考-行动匹配”指标来衡量模型在推理与决策间的一致性，揭示了当前模型在跨版本泛化和思维-行为对齐方面的不足。


<details>
  <summary>Details</summary>
Motivation: 大语言模型越来越多地被用作角色扮演代理，但在刻画特定版本角色（如不同宇宙中的超级英雄）时的一致性和保真度仍缺乏研究。为探索这一问题，需要一个能反映角色多版本特性的评测基准。

Method: 构建了包含30个标志性英雄、90个版本的Beyond One World基准，包含两个任务：（1）Canon Events：测试关键人生事件的事实回忆；（2）Moral Dilemmas：面对道德困境的反应。提出“思考-行动匹配”（Think-Act Matching）指标，评估模型内部推理与外部行为的一致性。

Result: 实验发现：（1）思维链提示可提升弱模型的叙事连贯性，但可能降低强模型的准确性；（2）同一角色的跨版本泛化仍是重大挑战；（3）模型往往仅在‘思考’或‘行动’中表现良好，难以兼顾。

Conclusion: Beyond One World揭示了角色扮演大模型在多宇宙一致性与推理-行为对齐方面的关键缺陷，为未来角色建模提供了具有挑战性的评估框架。

Abstract: Large language models (LLMs) are increasingly used as role-playing agents,
yet their capacity to faithfully and consistently portray version-specific
characters -- for example, superheroes across comic and cinematic universes --
remains underexplored. Superhero canons such as Marvel and DC provide a rich
testbed: decades of storytelling yield multiple incarnations of the same
character with distinct histories, values, and moral codes. To study this
problem, we introduce Beyond One World, a benchmark for character-grounded
roleplay spanning 30 iconic heroes and 90 canon-specific versions. The
benchmark comprises two tasks: (i) Canon Events, which probes factual recall of
pivotal life stages, and (ii) Moral Dilemmas, which confronts models with
ethically charged scenarios. We score responses for canonical accuracy and
reasoning fidelity under a framework that separates internal deliberation
("thinking") from outward decisions ("acting"). We further propose Think-Act
Matching, a metric that quantifies alignment between reasons and actions and
serves as a proxy for model trustworthiness. Experiments across reasoning- and
non-reasoning-oriented models yield three findings: (1) chain-of-thought
prompting improves narrative coherence in weaker models but can reduce
canonical accuracy in stronger ones; (2) cross-version generalization within a
character remains a major obstacle; and (3) models often excel at either
thinking or acting, but rarely both. Beyond One World exposes critical gaps in
multiversal consistency and reasoning alignment, offering a challenging
evaluation for role-playing LLMs.

</details>


### [187] [CURE: Confidence-driven Unified Reasoning Ensemble Framework for Medical Question Answering](https://arxiv.org/abs/2510.14353)
*Ziad Elshaer,Essam A. Rashed*

Main category: cs.CL

TL;DR: 提出一种无需微调的置信度驱动多模型框架，通过利用模型多样性提升医疗问答性能，在多个医学基准上取得竞争性结果。


<details>
  <summary>Details</summary>
Motivation: 高性能医疗大语言模型通常需要大量计算资源进行微调，限制了资源受限机构的使用；因此需要一种低资源、无需微调的高效替代方案。

Method: 采用两阶段架构：置信度检测模块评估主模型的确定性，自适应路由机制将低置信度问题分配给具有互补知识的辅助模型进行协同推理。

Result: 在MedQA、MedMCQA和PubMedQA三个医学基准上评估，框架表现出色，PubMedQA达到95.0%，MedMCQA达到78.0%，显著优于单模型和统一推理方法。

Conclusion: 基于置信度的多模型协作是一种高效且实用的方法，可在不微调的情况下提升医疗AI性能，有助于在资源有限环境中普及先进医疗AI技术。

Abstract: High-performing medical Large Language Models (LLMs) typically require
extensive fine-tuning with substantial computational resources, limiting
accessibility for resource-constrained healthcare institutions. This study
introduces a confidence-driven multi-model framework that leverages model
diversity to enhance medical question answering without fine-tuning. Our
framework employs a two-stage architecture: a confidence detection module
assesses the primary model's certainty, and an adaptive routing mechanism
directs low-confidence queries to Helper models with complementary knowledge
for collaborative reasoning. We evaluate our approach using
Qwen3-30B-A3B-Instruct, Phi-4 14B, and Gemma 2 12B across three medical
benchmarks; MedQA, MedMCQA, and PubMedQA. Result demonstrate that our framework
achieves competitive performance, with particularly strong results in PubMedQA
(95.0\%) and MedMCQA (78.0\%). Ablation studies confirm that confidence-aware
routing combined with multi-model collaboration substantially outperforms
single-model approaches and uniform reasoning strategies. This work establishes
that strategic model collaboration offers a practical, computationally
efficient pathway to improve medical AI systems, with significant implications
for democratizing access to advanced medical AI in resource-limited settings.

</details>


### [188] [On the Ability of LLMs to Handle Character-Level Perturbations: How Well and How?](https://arxiv.org/abs/2510.14365)
*Anyun Zhuo,Xuefei Ning,Ningyuan Li,Yu Wang,Pinyan Lu*

Main category: cs.CL

TL;DR: 本文提出了一种通过插入不可见Unicode控制字符来干扰LLM的实用方法，研究发现尽管输入被严重噪声化，许多大型语言模型仍表现出显著的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究现代大型语言模型（LLM）在频繁且结构化的字符级扰动下的抗干扰能力，以应对诸如在线考试系统中模型滥用的风险。

Method: 提出名为\nameshort{}的方法，在每个输入字符后插入不可见的Unicode控制字符，通过多维度实验评估LLM在不同模型、任务和噪声设置下的表现。

Result: 尽管噪声显著降低了信噪比并破坏了分词效果，许多LLM仍保持较强性能，揭示了其在字符级扰动下的意外鲁棒性。

Conclusion: LLM对低级噪声具有较强鲁棒性，提示其潜在滥用风险，并为部署LLM时的安全性和可靠性提供了新的思考。

Abstract: This work investigates the resilience of contemporary LLMs against frequent
and structured character-level perturbations, specifically through the
insertion of noisy characters after each input character. We introduce
\nameshort{}, a practical method that inserts invisible Unicode control
characters into text to discourage LLM misuse in scenarios such as online exam
systems. Surprisingly, despite strong obfuscation that fragments tokenization
and reduces the signal-to-noise ratio significantly, many LLMs still maintain
notable performance. Through comprehensive evaluation across model-, problem-,
and noise-related configurations, we examine the extent and mechanisms of this
robustness, exploring both the handling of character-level tokenization and
\textit{implicit} versus \textit{explicit} denoising mechanism hypotheses of
character-level noises. We hope our findings on the low-level robustness of
LLMs will shed light on the risks of their misuse and on the reliability of
deploying LLMs across diverse applications.

</details>


### [189] [From Binary to Bilingual: How the National Weather Service is Using Artificial Intelligence to Develop a Comprehensive Translation Program](https://arxiv.org/abs/2510.14369)
*Joseph E. Trujillo-Falcon,Monica L. Bozeman,Liam E. Llewellyn,Samuel T. Halvorson,Meryl Mizell,Stuti Deshpande,Bob Manning,Todd Fagin*

Main category: cs.CL

TL;DR: 美国国家气象局（NWS）正在开发基于人工智能的自动化翻译系统，以向在家不说英语的6880万美国人提供及时、准确且文化相关的气象预警和信息，初期支持西班牙语、中文、越南语等语言，并结合GIS映射和伦理AI实践，推动实现全民覆盖的国家预警系统。


<details>
  <summary>Details</summary>
Motivation: 为实现“天气-ready国家”目标，NWS亟需克服语言障碍，确保非英语人群能及时获取关键气象信息，提升公共安全和应急响应能力。

Method: NWS与LILT合作，利用其专利训练方法，基于大语言模型（LLM）和神经机器翻译（NMT）技术，开发可扩展的自动化翻译工具；结合多语言风险沟通最佳实践，并使用GIS映射分析各地语言需求，优先资源配置；同时融入透明、公平和有人类监督的伦理AI设计。

Result: 该系统已能高效翻译气象预警、7天预报和教育宣传材料，显著减少人工翻译时间与工作负担，并推出了包含多种语言实验性产品的网站。

Conclusion: 该自动化翻译项目不仅提升了NWS服务的可及性与公平性，也为多语言公共预警系统的建设提供了可扩展、可持续且符合伦理的人工智能解决方案。

Abstract: To advance a Weather-Ready Nation, the National Weather Service (NWS) is
developing a systematic translation program to better serve the 68.8 million
people in the U.S. who do not speak English at home. This article outlines the
foundation of an automated translation tool for NWS products, powered by
artificial intelligence. The NWS has partnered with LILT, whose patented
training process enables large language models (LLMs) to adapt neural machine
translation (NMT) tools for weather terminology and messaging. Designed for
scalability across Weather Forecast Offices (WFOs) and National Centers, the
system is currently being developed in Spanish, Simplified Chinese, Vietnamese,
and other widely spoken non-English languages. Rooted in best practices for
multilingual risk communication, the system provides accurate, timely, and
culturally relevant translations, significantly reducing manual translation
time and easing operational workloads across the NWS. To guide the distribution
of these products, GIS mapping was used to identify language needs across
different NWS regions, helping prioritize resources for the communities that
need them most. We also integrated ethical AI practices throughout the
program's design, ensuring that transparency, fairness, and human oversight
guide how automated translations are created, evaluated, and shared with the
public. This work has culminated into a website featuring experimental
multilingual NWS products, including translated warnings, 7-day forecasts, and
educational campaigns, bringing the country one step closer to a national
warning system that reaches all Americans.

</details>


### [190] [PluriHop: Exhaustive, Recall-Sensitive QA over Distractor-Rich Corpora](https://arxiv.org/abs/2510.14377)
*Mykolas Sveistrys,Richard Kunert*

Main category: cs.CL

TL;DR: 本文提出了“多跳问题”（pluri-hop questions）这一新类别，其特点是需要对大量重复性报告文档进行全面检索与聚合，现有RAG方法表现不佳。为此作者构建了多语言诊断数据集PluriHopWIND，并提出新架构PluriHopRAG，通过将问题分解并使用交叉编码器提前过滤无关文档，显著提升了F1分数。


<details>
  <summary>Details</summary>
Motivation: 现实中的许多问题（如医疗记录、合规报告）需要从大量重复性文档中全面聚合信息，而当前的单跳或多跳问答系统难以应对这种对召回率敏感、要求完整性和精确性的问题，因此需要新框架和数据集来研究此类挑战。

Method: 提出PluriHopWIND数据集，包含48个多跳问题和191份风电行业报告（英德双语）；设计PluriHopRAG架构，将查询分解为文档级子问题，并利用交叉编码器在调用大模型前对文档进行高效过滤。

Result: 实验证明，传统及变体RAG方法在PluriHopWIND上的语句级F1均未超过40%；PluriHopRAG相较基线模型实现了18-52%的相对F1提升；该数据集比现有数据集重复性高8-40%，干扰文档密度更高，更具现实挑战性。

Conclusion: PluriHopWIND揭示了现有QA系统在处理高重复、干扰项多的文档集合时的局限；PluriHopRAG通过逐文档检查与早期过滤的策略，展示了 exhaustive retrieval 与轻量过滤在多跳问答中的有效性，为处理现实报告类数据提供了新方向。

Abstract: Recent advances in large language models (LLMs) and retrieval-augmented
generation (RAG) have enabled progress on question answering (QA) when relevant
evidence is in one (single-hop) or multiple (multi-hop) passages. Yet many
realistic questions about recurring report data - medical records, compliance
filings, maintenance logs - require aggregation across all documents, with no
clear stopping point for retrieval and high sensitivity to even one missed
passage. We term these pluri-hop questions and formalize them by three
criteria: recall sensitivity, exhaustiveness, and exactness. To study this
setting, we introduce PluriHopWIND, a diagnostic multilingual dataset of 48
pluri-hop questions built from 191 real-world wind industry reports in German
and English. We show that PluriHopWIND is 8-40% more repetitive than other
common datasets and thus has higher density of distractor documents, better
reflecting practical challenges of recurring report corpora. We test a
traditional RAG pipeline as well as graph-based and multimodal variants, and
find that none of the tested approaches exceed 40% in statement-wise F1 score.
Motivated by this, we propose PluriHopRAG, a RAG architecture that follows a
"check all documents individually, filter cheaply" approach: it (i) decomposes
queries into document-level subquestions and (ii) uses a cross-encoder filter
to discard irrelevant documents before costly LLM reasoning. We find that
PluriHopRAG achieves relative F1 score improvements of 18-52% depending on base
LLM. Despite its modest size, PluriHopWIND exposes the limitations of current
QA systems on repetitive, distractor-rich corpora. PluriHopRAG's performance
highlights the value of exhaustive retrieval and early filtering as a powerful
alternative to top-k methods.

</details>


### [191] [Suicidal Comment Tree Dataset: Enhancing Risk Assessment and Prediction Through Contextual Analysis](https://arxiv.org/abs/2510.14395)
*Jun Li,Qun Zhao*

Main category: cs.CL

TL;DR: 该研究通过分析Reddit用户的发帖历史和评论树，利用改进的四标签注释框架，发现结合评论树信息能显著提升对用户自杀风险的识别与预测能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注单个社交媒体帖子中的自杀倾向检测，缺乏对用户长期、连续互动评论的分析，而用户往往通过历史发帖和互动评论逐步暴露其自杀意图。因此，有必要探究评论树信息对自杀风险预测的影响。

Method: 研究构建了一个高质量的标注数据集，基于哥伦比亚自杀严重程度评定量表（C-SSRS）采用四标签框架，整合用户发帖历史和评论树，并利用大语言模型（LLM）进行实验分析。

Result: 统计分析和LLM实验结果表明，引入评论树数据能显著提升对用户自杀风险等级的区分度和预测准确性。

Conclusion: 该研究证明了利用评论树信息可有效增强对高风险个体的检测精度，为早期自杀干预策略提供了重要基础。

Abstract: Suicide remains a critical global public health issue. While previous studies
have provided valuable insights into detecting suicidal expressions in
individual social media posts, limited attention has been paid to the analysis
of longitudinal, sequential comment trees for predicting a user's evolving
suicidal risk. Users, however, often reveal their intentions through historical
posts and interactive comments over time. This study addresses this gap by
investigating how the information in comment trees affects both the
discrimination and prediction of users' suicidal risk levels. We constructed a
high-quality annotated dataset, sourced from Reddit, which incorporates users'
posting history and comments, using a refined four-label annotation framework
based on the Columbia Suicide Severity Rating Scale (C-SSRS). Statistical
analysis of the dataset, along with experimental results from Large Language
Models (LLMs) experiments, demonstrates that incorporating comment trees data
significantly enhances the discrimination and prediction of user suicidal risk
levels. This research offers a novel insight to enhancing the detection
accuracy of at-risk individuals, thereby providing a valuable foundation for
early suicide intervention strategies.

</details>


### [192] [Your Next Token Prediction: A Multilingual Benchmark for Personalized Response Generation](https://arxiv.org/abs/2510.14398)
*Shiyao Ding,Takayuki Ito*

Main category: cs.CL

TL;DR: 提出“你的下一个词预测”（YNTP）任务，通过可控的人机对话建模用户用词选择，构建多语言基准数据集并评估个性化语言模型方法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在模仿个体真实交流风格方面存在不足，且真实社交或邮件历史数据因隐私问题难以获取。

Method: 设计基于MBTI人格维度的心理学NPC，与用户进行为期五天的多语言对话，构建包含100个对话会话的多语言基准数据集，评估基于提示和微调的个性化方法。

Result: 建立了首个YNTP基准，支持对用户对齐的语言建模进行评估，并分析了用户内在行为模式。

Conclusion: YNTP为个性化语言建模提供了新方向，所构建的数据集可促进用户风格建模与隐私保护下的真实对话研究。

Abstract: Large language models (LLMs) excel at general next-token prediction but still
struggle to generate responses that reflect how individuals truly communicate,
such as replying to emails or social messages in their own style. However, real
SNS or email histories are difficult to collect due to privacy concerns. To
address this, we propose the task of "Your Next Token Prediction (YNTP)", which
models a user's precise word choices through controlled human-agent
conversations. We build a multilingual benchmark of 100 dialogue sessions
across English, Japanese, and Chinese, where users interact for five days with
psychologically grounded NPCs based on MBTI dimensions. This setup captures
natural, daily-life communication patterns and enables analysis of users'
internal models. We evaluate prompt-based and fine-tuning-based personalization
methods, establishing the first benchmark for YNTP and a foundation for
user-aligned language modeling. The dataset is available at:
https://github.com/AnonymousHub4Submissions/your-next-token-prediction-dataset-100

</details>


### [193] [MedTrust-RAG: Evidence Verification and Trust Alignment for Biomedical Question Answering](https://arxiv.org/abs/2510.14400)
*Yingpeng Ning,Yuanyuan Sun,Ling Luo,Yanhua Wang,Yuchen Pan,Hongfei Lin*

Main category: cs.CL

TL;DR: 提出MedTrust-Guided Iterative RAG框架，通过引用感知推理、迭代检索验证和偏好优化抑制医学问答中的幻觉，提升事实一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于RAG的生物医学问答系统因检索后噪声和证据验证不足易产生幻觉，影响回答可靠性，需提高生成内容的事实一致性。

Method: 引入三个创新：1）引用感知推理，要求生成内容必须基于检索到的文档，并在证据不足时使用负知识断言；2）迭代检索-验证过程，通过医学差距分析不断优化查询直至获得可靠证据；3）集成MedTrust-Align模块（MTAM），结合正例与反例，利用直接偏好优化强化基于引用的推理并惩罚易幻觉模式。

Result: 在MedMCQA、MedQA和MMLU-Med数据集上，该方法在多种模型架构下均优于基线模型，LLaMA3.1-8B-Instruct平均准确率提升2.7%，Qwen3-8B提升2.4%。

Conclusion: MedTrust-Guided Iterative RAG能有效减少医学问答中的幻觉，增强事实一致性，显著提升性能，适用于高可靠性要求的医疗场景。

Abstract: Biomedical question answering (QA) requires accurate interpretation of
complex medical knowledge. Large language models (LLMs) have shown promising
capabilities in this domain, with retrieval-augmented generation (RAG) systems
enhancing performance by incorporating external medical literature. However,
RAG-based approaches in biomedical QA suffer from hallucinations due to
post-retrieval noise and insufficient verification of retrieved evidence,
undermining response reliability. We propose MedTrust-Guided Iterative RAG, a
framework designed to enhance factual consistency and mitigate hallucinations
in medical QA. Our method introduces three key innovations. First, it enforces
citation-aware reasoning by requiring all generated content to be explicitly
grounded in retrieved medical documents, with structured Negative Knowledge
Assertions used when evidence is insufficient. Second, it employs an iterative
retrieval-verification process, where a verification agent assesses evidence
adequacy and refines queries through Medical Gap Analysis until reliable
information is obtained. Third, it integrates the MedTrust-Align Module (MTAM)
that combines verified positive examples with hallucination-aware negative
samples, leveraging Direct Preference Optimization to reinforce
citation-grounded reasoning while penalizing hallucination-prone response
patterns. Experiments on MedMCQA, MedQA, and MMLU-Med demonstrate that our
approach consistently outperforms competitive baselines across multiple model
architectures, achieving the best average accuracy with gains of 2.7% for
LLaMA3.1-8B-Instruct and 2.4% for Qwen3-8B.

</details>


### [194] [Instructions are all you need: Self-supervised Reinforcement Learning for Instruction Following](https://arxiv.org/abs/2510.14420)
*Qingyu Ren,Qianyu He,Bowei Zhang,Jie Zeng,Jiaqing Liang,Yanghua Xiao,Weikang Zhou,Zeye Sun,Fei Yu*

Main category: cs.CL

TL;DR: 提出了一种无需外部监督的自监督强化学习框架，通过从指令中直接提取奖励信号并生成伪标签，有效解决了多约束指令跟随任务中的稀疏奖励问题。


<details>
  <summary>Details</summary>
Motivation: 语言模型在遵循多约束指令时表现不佳，而现有强化学习方法依赖外部监督和稀疏奖励信号，限制了实际应用。

Method: 提出一种无标签的自监督强化学习框架，引入约束分解策略和高效的按约束二分类方法，从指令中自动推导奖励信号并生成伪标签用于奖励模型训练。

Result: 在3个领域内和5个领域外数据集上均取得显著提升，尤其在具身任务和多轮指令跟随任务中表现优异。

Conclusion: 该方法不依赖外部监督，具有良好的泛化能力，能有效应对多约束指令跟随中的稀疏奖励问题。

Abstract: Language models often struggle to follow multi-constraint instructions that
are crucial for real-world applications. Existing reinforcement learning (RL)
approaches suffer from dependency on external supervision and sparse reward
signals from multi-constraint tasks. We propose a label-free self-supervised RL
framework that eliminates dependency on external supervision by deriving reward
signals directly from instructions and generating pseudo-labels for reward
model training. Our approach introduces constraint decomposition strategies and
efficient constraint-wise binary classification to address sparse reward
challenges while maintaining computational efficiency. Experiments show that
our approach generalizes well, achieving strong improvements across 3 in-domain
and 5 out-of-domain datasets, including challenging agentic and multi-turn
instruction following. The data and code are publicly available at
https://github.com/Rainier-rq/verl-if

</details>


### [195] [Explore to Evolve: Scaling Evolved Aggregation Logic via Proactive Online Exploration for Deep Research Agents](https://arxiv.org/abs/2510.14438)
*Rui Wang,Ce Zhang,Jun-Yu Ma,Jianshu Zhang,Hongru Wang,Yi Chen,Boyang Xue,Tianqing Fang,Zhisong Zhang,Hongming Zhang,Haitao Mi,Dong Yu,Kam-Fai Wong*

Main category: cs.CL

TL;DR: 提出“探索到进化”范式，构建大规模可验证的网页代理训练数据集WebAggregatorQA，提升信息聚合能力，显著增强开源深度研究代理性能。


<details>
  <summary>Details</summary>
Motivation: 现有开源深度研究代理多关注信息检索，忽视信息聚合，限制了其在深入研究中的应用。因此需要增强代理的信息整合能力。

Method: 提出Explore to Evolve范式：代理通过主动在线探索真实网页获取 grounded 信息，然后从12种高层逻辑类型中选择、组合和优化操作，自演化生成可验证的问答对，构建WebAggregatorQA数据集，并基于SmolAgents框架进行监督微调，训练WebAggregator系列模型。

Result: 成功构建包含1万样本、覆盖5万网站和11个领域的WebAggregatorQA数据集；WebAggregator-8B达到GPT-4.1水平，32B版本在GAIA-text上超越GPT-4.1超10%，接近Claude-3.7-sonnet；新构建的人类标注测试集显示现有模型（如Claude和GPT-4.1）得分均低于28%，凸显信息聚合的挑战性。

Conclusion: 信息聚合是当前深研代理的瓶颈，通过探索到进化的范式可有效构建高质量训练数据，显著提升代理性能，未来应加强基础模型在信息整合方面的能力。

Abstract: Deep research web agents not only retrieve information from diverse sources
such as web environments, files, and multimodal inputs, but more importantly,
they need to rigorously analyze and aggregate knowledge for insightful
research. However, existing open-source deep research agents predominantly
focus on enhancing information-seeking capabilities of web agents to locate
specific information, while overlooking the essential need for information
aggregation, which would limit their ability to support in-depth research. We
propose an Explore to Evolve paradigm to scalably construct verifiable training
data for web agents. Begins with proactive online exploration, an agent sources
grounded information by exploring the real web. Using the collected evidence,
the agent then self-evolves an aggregation program by selecting, composing, and
refining operations from 12 high-level logical types to synthesize a verifiable
QA pair. This evolution from high-level guidance to concrete operations allowed
us to scalably produce WebAggregatorQA, a dataset of 10K samples across 50K
websites and 11 domains. Based on an open-source agent framework, SmolAgents,
we collect supervised fine-tuning trajectories to develop a series of
foundation models, WebAggregator. WebAggregator-8B matches the performance of
GPT-4.1, while the 32B variant surpasses GPT-4.1 by more than 10% on GAIA-text
and closely approaches Claude-3.7-sonnet. Moreover, given the limited
availability of benchmarks that evaluate web agents' information aggregation
abilities, we construct a human-annotated evaluation split of WebAggregatorQA
as a challenging test set. On this benchmark, Claude-3.7-sonnet only achieves
28%, and GPT-4.1 scores 25.8%. Even when agents manage to retrieve all
references, they still struggle on WebAggregatorQA, highlighting the need to
strengthen the information aggregation capabilities of web agent foundations.

</details>


### [196] [Natural Language Tools: A Natural Language Approach to Tool Calling In Large Language Agents](https://arxiv.org/abs/2510.14453)
*Reid T. Johnson,Michelle D. Pain,Jordan D. West*

Main category: cs.CL

TL;DR: 提出了一种名为Natural Language Tools (NLT)的框架，用自然语言输出替代大型语言模型中的程序化JSON工具调用，显著提升了工具调用准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的JSON格式工具调用存在任务干扰和格式约束问题，影响大模型工具调用性能，尤其在开放权重模型和缺乏原生支持的模型上表现受限。

Method: NLT框架将工具选择与响应生成解耦，使用自然语言输出代替JSON工具调用，避免格式错误和任务之间的干扰。

Result: 在10个模型和6,400次实验中，NLT将工具调用准确率提高了18.4个百分点，输出方差降低70%；开放权重模型表现超过闭源旗舰模型，且在提示扰动下性能稳定，并使不支持工具调用的模型具备该能力。

Conclusion: NLT有效解决了格式约束和任务干扰问题，为大模型的强化学习和监督微调提供了新方向，提升了工具调用的鲁棒性和通用性。

Abstract: We present Natural Language Tools (NLT), a framework that replaces
programmatic JSON tool calling in large language models (LLMs) with natural
language outputs. By decoupling tool selection from response generation, NLT
eliminates task interference and format constraints that degrade tool call
performance. When evaluated across 10 models and 6,400 trials spanning customer
service and mental health domains, NLT improves tool calling accuracy by 18.4
percentage points while reducing output variance by 70%. Open-weight models see
the largest gains, surpassing flagship closed-weight alternatives, with
implications for model training in both reinforcement learning and supervised
fine-tuning stages. These improvements persist under prompt perturbations and
extend tool-calling capabilities to models lacking native support.

</details>


### [197] [LiRA: Linguistic Robust Anchoring for Cross-lingual Large Language Models](https://arxiv.org/abs/2510.14466)
*Haolin Li,Haipeng Zhang,Mang Li,Yaohua Wang,Lijie Wen,Yu Zhang,Biqing Huang*

Main category: cs.CL

TL;DR: 本文提出了LiRA框架，通过Arca和LaSR两个模块提升大语言模型在低资源语言下的跨语言表示、检索与推理能力，并发布了一个涵盖东南亚和南亚语言的多语言数据集。


<details>
  <summary>Details</summary>
Motivation: 由于训练数据少、机器翻译噪声和跨语言对齐不稳定，当前大语言模型在低资源语言上的表现显著落后于高资源语言，亟需提升其跨语言鲁棒性。

Method: 提出LiRA框架，包含Arca模块（通过锚点对齐和多智能体协同编码将低资源语言锚定到英语语义空间）和LaSR模块（添加语言感知的轻量推理头并进行一致性正则化），统一优化目标以增强跨语言理解、检索与推理。

Result: 在低资源跨语言检索、语义相似度和推理任务上，LiRA在少样本和高噪声场景下均表现出显著且稳定的性能提升，消融实验证明了Arca和LaSR的有效性。

Conclusion: LiRA有效提升了大语言模型在低资源语言环境下的跨语言表示与多任务鲁棒性，为构建更公平的多语言AI系统提供了可行方案。

Abstract: As large language models (LLMs) rapidly advance, performance on high-resource
languages (e.g., English, Chinese) is nearing saturation, yet remains
substantially lower for low-resource languages (e.g., Urdu, Thai) due to
limited training data, machine-translation noise, and unstable cross-lingual
alignment. We introduce LiRA (Linguistic Robust Anchoring for Large Language
Models), a training framework that robustly improves cross-lingual
representations under low-resource conditions while jointly strengthening
retrieval and reasoning. LiRA comprises two modules: (i) Arca (Anchored
Representation Composition Architecture), which anchors low-resource languages
to an English semantic space via anchor-based alignment and multi-agent
collaborative encoding, preserving geometric stability in a shared embedding
space; and (ii) LaSR (Language-coupled Semantic Reasoner), which adds a
language-aware lightweight reasoning head with consistency regularization on
top of Arca's multilingual representations, unifying the training objective to
enhance cross-lingual understanding, retrieval, and reasoning robustness. We
further construct and release a multilingual product retrieval dataset covering
five Southeast Asian and two South Asian languages. Experiments across
low-resource benchmarks (cross-lingual retrieval, semantic similarity, and
reasoning) show consistent gains and robustness under few-shot and
noise-amplified settings; ablations validate the contribution of both Arca and
LaSR. Code will be released on GitHub and the dataset on Hugging Face.

</details>


### [198] [Efficient Seq2seq Coreference Resolution Using Entity Representations](https://arxiv.org/abs/2510.14504)
*Matt Grenander,Shay B. Cohen,Mark Steedman*

Main category: cs.CL

TL;DR: 提出一种压缩表示方法，通过提取和重组实体级标记来提升seq2seq共指消解模型在增量设置中的效率，在保持接近最优性能的同时显著减少输入长度。


<details>
  <summary>Details</summary>
Motivation: 现有的seq2seq共指消解模型在处理增量场景（如对话）时效率低下，无法有效支持顺序处理，需要提高其在实际应用中的灵活性和效率。

Method: 通过提取并重新组织实体级别的标记，丢弃大部分非实体输入标记，从而实现输入序列的压缩，适用于增量式seq2seq共指消解。

Result: 在OntoNotes上，模型性能仅比全前缀基线低0.6 CoNLL F1，压缩比达到1.8；在标注单例实体的LitBank上超过了当前最优性能。

Conclusion: 在seq2seq共指消解中丢弃大量非关键标记是可行且高效的策略，尤其适合增量处理场景。

Abstract: Seq2seq coreference models have introduced a new paradigm for coreference
resolution by learning to generate text corresponding to coreference labels,
without requiring task-specific parameters. While these models achieve new
state-of-the-art performance, they do so at the cost of flexibility and
efficiency. In particular, they do not efficiently handle incremental settings
such as dialogue, where text must processed sequentially. We propose a
compressed representation in order to improve the efficiency of these methods
in incremental settings. Our method works by extracting and re-organizing
entity-level tokens, and discarding the majority of other input tokens. On
OntoNotes, our best model achieves just 0.6 CoNLL F1 points below a
full-prefix, incremental baseline while achieving a compression ratio of 1.8.
On LitBank, where singleton mentions are annotated, it passes state-of-the-art
performance. Our results indicate that discarding a wide portion of tokens in
seq2seq resolvers is a feasible strategy for incremental coreference
resolution.

</details>


### [199] [Assessing Socio-Cultural Alignment and Technical Safety of Sovereign LLMs](https://arxiv.org/abs/2510.14565)
*Kyubyung Chae,Gihoon Kim,Gyuseong Lee,Taesup Kim,Jaejin Lee,Heejin Kim*

Main category: cs.CL

TL;DR: 本文构建了一个新数据集和分析框架，用于评估主权大语言模型（LLMs）的社会文化适配性与技术鲁棒性，发现尽管这类模型对低资源语言有支持作用，但并不总能有效服务目标用户，且可能忽视安全性等关键质量属性。


<details>
  <summary>Details</summary>
Motivation: 随着主权大语言模型的发展，各国希望模型能契合自身的社会文化背景，但缺乏评估其社会文化对齐程度和安全性的系统框架与数据集，亟需解决这一评估空白。

Method: 提出一个新的数据集和分析框架，用于提取并评估主权大语言模型中的社会文化元素，并结合技术鲁棒性和安全性进行综合评测。

Result: 实验表明，主权大语言模型虽有助于低资源语言支持，但并未普遍实现对目标用户的良好服务；过度强调本土化可能忽视安全性等关键技术指标。

Conclusion: 推动主权大语言模型发展需要更全面的评估体系，纳入更多基于实证且实用的评价标准，以确保模型在文化适配的同时不牺牲安全与质量。

Abstract: Recent trends in LLMs development clearly show growing interest in the use
and application of sovereign LLMs. The global debate over sovereign LLMs
highlights the need for governments to develop their LLMs, tailored to their
unique socio-cultural and historical contexts. However, there remains a
shortage of frameworks and datasets to verify two critical questions: (1) how
well these models align with users' socio-cultural backgrounds, and (2) whether
they maintain safety and technical robustness without exposing users to
potential harms and risks. To address this gap, we construct a new dataset and
introduce an analytic framework for extracting and evaluating the
socio-cultural elements of sovereign LLMs, alongside assessments of their
technical robustness. Our experimental results demonstrate that while sovereign
LLMs play a meaningful role in supporting low-resource languages, they do not
always meet the popular claim that these models serve their target users well.
We also show that pursuing this untested claim may lead to underestimating
critical quality attributes such as safety. Our study suggests that advancing
sovereign LLMs requires a more extensive evaluation that incorporates a broader
range of well-grounded and practical criteria.

</details>


### [200] [Beyond Correctness: Evaluating Subjective Writing Preferences Across Cultures](https://arxiv.org/abs/2510.14616)
*Shuangshuang Ying,Yunwen Li,Xingwei Qu,Xin Li,Sheng Jin,Minghao Liu,Zhoufutu Wen,Xeron Du,Tianyu Zheng,Yichi Zhang,Letian Ni,Yuyang Cheng,Qiguang Chen,Jingzhe Ding,Shengda Long,Wangchunshu Zhou,Jiazhan Feng,Wanjun Zhong,Libo Qin,Ge Zhang,Wenhao Huang,Wanxiang Che,Chenghua Lin*

Main category: cs.CL

TL;DR: 当前的偏好学习方法在标准基准上表现良好，但在去除客观质量信号后性能显著下降。本文提出WritingPreferenceBench数据集，发现现有方法难以捕捉主观写作质量偏好，而生成式奖励模型通过推理链显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有偏好学习模型依赖客观错误检测而非真正理解主观质量（如创造力、风格、情感共鸣），亟需一种去除客观信号干扰、专注于主观偏好的新基准来评估模型真实偏好建模能力。

Method: 构建包含1800个人工标注偏好对的WritingPreferenceBench数据集（涵盖8种创意写作体裁，中英文两种语言），确保回答在事实准确性和长度上匹配；比较序列式奖励模型、零样本语言模型判别器与生成式奖励模型在该基准上的表现。

Result: 序列式奖励模型平均准确率为52.7%，零样本语言模型判别器为53.9%，而能生成推理链的生成式奖励模型达到81.8%；模型在不同体裁间表现差异大（18.2%~81.8%），且模型规模（8B vs 27B）未带来一致改进。

Conclusion: 当前RLHF方法主要学习识别客观错误，而非建模主观偏好；成功的偏好建模应依赖中间推理过程，而非直接分类；生成式奖励模型结合推理链是更优方向。

Abstract: Current preference learning methods achieve high accuracy on standard
benchmarks but exhibit significant performance degradation when objective
quality signals are removed. We introduce WritingPreferenceBench, a dataset of
1,800 human-annotated preference pairs (1,200 English, 600 Chinese) across 8
creative writing genres, where responses are matched for objective correctness,
factual accuracy, and length. On this benchmark, sequence-based reward
models--the standard architecture for RLHF--achieve only 52.7% mean accuracy,
while zero-shot language model judges perform at 53.9%. In contrast, generative
reward models that produce explicit reasoning chains achieve 81.8% accuracy. We
observe high within-model variance across genres: individual models range from
18.2% to 81.8% accuracy across different writing categories, with standard
deviations averaging 10.1%. This variance persists regardless of model scale,
with 27B parameter models showing no consistent improvement over 8B variants.
Our results suggest that current RLHF methods primarily learn to detect
objective errors rather than capture subjective quality preferences (e.g.,
creativity, stylistic flair, and emotional resonance), and that successful
preference modeling may require intermediate reasoning representations rather
than direct classification.

</details>


### [201] [Code-driven Number Sequence Calculation: Enhancing the inductive Reasoning Abilities of Large Language Models](https://arxiv.org/abs/2510.14620)
*Kedi Chen,Zhikai Lei,Xu Guo,Xuecheng Wu,Siyuan Zeng,Jianghao Yin,Yinqi Zhang,Qin Chen,Jie Zhou,Liang He,Qipeng Guo,Kai Chen,Wei Zhang*

Main category: cs.CL

TL;DR: 本文提出了CodeSeq，一个基于数字序列的合成后训练数据集，用于提升大语言模型在归纳推理任务上的表现，通过引入自主生成测试用例与自我修正机制，并结合基于可解性和案例协同的强化学习奖励机制，有效提升模型推理能力并保持其在分布外任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的归纳推理研究多关注表面规律，缺乏复杂内部模式，且训练方法局限于简单提示或提示-响应对微调，缺少精细思维过程引导和难度控制，因此需要一种更有效的训练范式来提升模型的归纳推理能力。

Method: 构建名为CodeSeq的数据集，将数字序列转化为算法问题，定义通用项生成（GTG）任务；通过失败测试用例的反思与迭代修正生成监督微调数据，训练模型实现自主案例生成与自我检查；引入融合可解性估计与自主生成成功率的Case-Synergy Solvability Scaling Reward，结合强化学习优化训练。

Result: 实验表明，使用CodeSeq训练的模型在多种推理任务上表现提升，同时保持了在分布外（OOD）任务上的性能。

Conclusion: CodeSeq通过结构化的任务设计、自我反思机制与新颖的强化学习奖励，有效提升了大语言模型的归纳推理能力，为构建具备更强泛化与自我改进能力的推理系统提供了新路径。

Abstract: Large language models (LLMs) make remarkable progress in reasoning tasks.
Among different reasoning modes, inductive reasoning, due to its better
alignment with human learning, attracts increasing interest. However, research
on inductive reasoning faces certain challenges. First, existing inductive data
mostly focuses on superficial regularities while lacking more complex internal
patterns. Second, current works merely prompt LLMs or finetune on simple
prompt-response pairs, but do not provide precise thinking processes nor
implement difficulty control. Unlike previous work, we address these challenges
by introducing \textit{CodeSeq}, a synthetic post-training dataset built from
number sequences. We package number sequences into algorithmic problems to
discover their general terms, defining a general term generation (GTG) task
correspondingly. Our pipeline generates supervised finetuning data by
reflecting on failed test cases and incorporating iterative corrections,
thereby teaching LLMs to learn autonomous case generation and self-checking.
Additionally, it leverages reinforcement learning with a novel Case-Synergy
Solvability Scaling Reward based on both solvability, estimated from the
problem pass rate, and the success rate of self-directed case generation,
enabling models to learn more effectively from both successes and failures.
Experimental results show that the models trained with \textit{CodeSeq} improve
on various reasoning tasks and can preserve the models' OOD performance.

</details>


### [202] [RLAIF-SPA: Optimizing LLM-based Emotional Speech Synthesis via RLAIF](https://arxiv.org/abs/2510.14628)
*Qing Yang,Zhenghao Liu,Junxin Wang,Yangfan Du,Pengcheng Huang,Tong Xiao*

Main category: cs.CL

TL;DR: 提出RLAIF-SPA框架，利用强化学习结合AI反馈，通过语义准确性和韵律-情感对齐优化语音合成的情感表现力和自然度。


<details>
  <summary>Details</summary>
Motivation: 现有情感语音合成方法依赖昂贵的情感标注或间接优化目标，难以同时保证语义准确性和情感表现力，导致生成语音情感平淡。

Method: 提出RLAIF-SPA框架，结合语音识别（ASR）和大语言模型（LLM）作为反馈机制，分别评估语义准确性和韵律-情感对齐；引入细粒度的结构、情感、语速和语调四个维度进行联合优化。

Result: 在Libri Speech数据集上，相比Chat-TTS，WER降低26.1%，SIM-O提升9.1%，人工评测提升超10%。

Conclusion: RLAIF-SPA有效提升了语音合成的情感表达能力和自然度，无需人工情感标注，为高质量情感TTS提供了可行方案。

Abstract: Text-To-Speech synthesis has achieved near-human quality in neutral speech,
but emotional expressiveness remains a challenge. Existing methods often rely
on costly emotion annotations or optimize indirect objectives that fail to
capture the emotional expressiveness and perceptual naturalness of speech,
leading to generated speech that is accurate but emotionally flat. To address
these challenges, we propose the RLAIF-SPA framework, incorporating a
Reinforcement Learning from AI Feedback (RLAIF) mechanism to employ Automatic
Speech Recognition (ASR) and Large Language Model (LLM) techniques to
respectively judge semantic accuracy and prosodic-emotional label alignment as
a direct reward for emotional expressiveness and intelligibility optimization.
Specifically, it leverages Prosodic Label Alignment to enhance expressive
quality by jointly considering semantic accuracy and prosodic-emotional
alignment along four fine-grained dimensions: Structure, Emotion, Speed, and
Tone. In addition, it incorporates Semantic Accuracy Feedback to ensure the
generation of clear and accurate speech. Experiments on the Libri Speech
dataset show that RLAIF-SPA outperforms Chat-TTS, with a 26.1% reduction in
WER, a 9.1% increase in SIM-O, and over 10% improvement in human evaluation.

</details>


### [203] [Supervised Fine-Tuning or Contrastive Learning? Towards Better Multimodal LLM Reranking](https://arxiv.org/abs/2510.14824)
*Ziqi Dai,Xin Zhang,Mingxin Li,Yanzhao Zhang,Dingkun Long,Pengjun Xie,Meishan Zhang,Wenjie Li,Min Zhang*

Main category: cs.CL

TL;DR: 本文比较了对比学习（CL）和监督微调（SFT）在基于大语言模型（LLM）的重排序任务中的表现，发现SFT由于具有更强的权重机制，在通用多模态检索任务中优于CL，并在MRB基准上取得了新的SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 探讨哪种训练目标（CL vs. SFT）更适应基于大语言模型的重排序任务，并揭示其背后的作用机制。

Method: 将训练目标分解为权重和方向两个组件，提出统一框架分析二者交互；在通用多模态检索（UMR）场景下对CL和SFT进行综合比较与探针实验。

Result: SFT在权重更新上显著强于CL，而在更新方向上两者无明显优劣；最终SFT在LLM重排序中表现出一致优势，并在MRB基准上实现新的state-of-the-art性能。

Conclusion: SFT比CL更适合LLM-based重排序，其优势主要来源于更有效的权重机制，研究结果为未来相关工作提供了重要参考。

Abstract: In information retrieval, training reranking models mainly focuses on two
types of objectives: metric learning (e.g. contrastive loss to increase the
predicted scores on relevant query-document pairs) and classification (binary
label prediction of relevance vs. irrelevance). For BERT-style encoders,
various studies have shown that contrastive learning (CL) can be more effective
than discriminative (classification) learning. However, for large language
models (LLMs), classification via supervised fine-tuning (SFT), which predicts
''yes'' (resp. ''no'') token for relevant (resp. irrelevant) pairs, appears
more promising as it aligns well with the generative nature of LLMs. This
divergence raises a central question: which objective is intrinsically better
suited to LLM-based reranking, and what mechanism underlies the difference? In
this work, we conduct a comprehensive comparison and analysis between CL and
SFT for reranking, taking the universal multimodal retrieval (UMR) as the
experimental playground. We first decompose the objectives into two components:
weight, which controls the magnitude of those updates, and direction, which
guides the model updates, then present a unified framework for understanding
their interactions. Through probing experiments, we find that SFT provides a
substantially stronger weighting scheme than CL, whereas the preferred scoring
direction shows no clear winner. Taken together, these results point to a
consistent advantage of SFT over CL for LLM reranking. To further validate our
findings, we conduct large-scale training with SFT and present new
state-of-the-art rerankers on the MRB benchmark. We also provide ablations on
SFT settings and expect our findings to benefit future research and
applications in this area.

</details>


### [204] [Intent Clustering with Shared Pseudo-Labels](https://arxiv.org/abs/2510.14640)
*I-Fan Lin,Faegheh Hasibi,Suzan Verberne*

Main category: cs.CL

TL;DR: 提出一种无需训练、无需标签的轻量级LLM方法，通过生成伪标签进行多标签分类，实现高效的意图聚类。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖商业LLM和预知聚类数量，成本高且不适用于真实场景，本文旨在提出更开放、灵活、低成本的替代方案。

Method: 利用开源轻量级LLM为文本生成伪标签，基于伪标签集进行多标签分类，并通过标签重叠程度计算文本相似性以实现聚类。

Result: 在四个基准数据集上表现优于或媲美近期基线方法，且计算效率高、跨模型和数据集稳定。

Conclusion: 该方法适用于低资源环境，具有良好的可解释性与实用性，为意图聚类提供了简单有效的训练-free解决方案。

Abstract: In this paper, we propose an intuitive, training-free and label-free method
for intent clustering that makes minimal assumptions using lightweight and
open-source LLMs. Many current approaches rely on commercial LLMs, which are
costly, and offer limited transparency. Additionally, their methods often
explicitly depend on knowing the number of clusters in advance, which is often
not the case in realistic settings. To address these challenges, instead of
asking the LLM to match similar text directly, we first ask it to generate
pseudo-labels for each text, and then perform multi-label classification in
this pseudo-label set for each text. This approach is based on the hypothesis
that texts belonging to the same cluster will share more labels, and will
therefore be closer when encoded into embeddings. These pseudo-labels are more
human-readable than direct similarity matches. Our evaluation on four benchmark
sets shows that our approach achieves results comparable to and better than
recent baselines, while remaining simple and computationally efficient. Our
findings indicate that our method can be applied in low-resource scenarios and
is stable across multiple models and datasets.

</details>


### [205] [DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation](https://arxiv.org/abs/2510.14949)
*Yu Zhou,Sohyun An,Haikang Deng,Da Yin,Clark Peng,Cho-Jui Hsieh,Kai-Wei Chang,Nanyun Peng*

Main category: cs.CL

TL;DR: 研究探讨了多模态生成模型在处理英语方言文本输入时的表现，发现当前模型在方言输入下性能显著下降；提出一种基于编码器的缓解策略，可在提升方言表现的同时几乎不损害标准英语性能。


<details>
  <summary>Details</summary>
Motivation: 多模态生成模型在实际应用中常接收到方言输入，但其对不同英语方言的适应能力尚不明确，亟需评估并提升模型对 dialectal 输入的鲁棒性。

Method: 构建包含六个常见英语方言的大规模基准数据集，收集并验证超过4200个方言提示；评估17种图像和视频生成模型的表现；提出一种基于编码器的缓解策略，通过训练模型识别方言特征并保持标准美式英语（SAE）性能。

Result: 实验显示当前模型在仅使用一个方言词时性能下降32.26%至48.17%；传统的微调和提示重写方法改善有限（<7%），且可能损害SAE表现；所提方法在Stable Diffusion 1.5等模型上使五个方言的表现提升34.4%，接近SAE水平，且对SAE性能影响极小。

Conclusion: 当前多模态生成模型对英语方言敏感，性能显著下降；提出的方法能有效提升对方言的理解能力，同时保持标准英语的生成质量，为构建更包容的生成模型提供了可行路径。

Abstract: Contact languages like English exhibit rich regional variations in the form
of dialects, which are often used by dialect speakers interacting with
generative models. However, can multimodal generative models effectively
produce content given dialectal textual input? In this work, we study this
question by constructing a new large-scale benchmark spanning six common
English dialects. We work with dialect speakers to collect and verify over 4200
unique prompts and evaluate on 17 image and video generative models. Our
automatic and human evaluation results show that current state-of-the-art
multimodal generative models exhibit 32.26% to 48.17% performance degradation
when a single dialect word is used in the prompt. Common mitigation methods
such as fine-tuning and prompt rewriting can only improve dialect performance
by small margins (< 7%), while potentially incurring significant performance
degradation in Standard American English (SAE). To this end, we design a
general encoder-based mitigation strategy for multimodal generative models. Our
method teaches the model to recognize new dialect features while preserving SAE
performance. Experiments on models such as Stable Diffusion 1.5 show that our
method is able to simultaneously raise performance on five dialects to be on
par with SAE (+34.4%), while incurring near zero cost to SAE performance.

</details>


### [206] [An Efficient Rubric-based Generative Verifier for Search-Augmented LLMs](https://arxiv.org/abs/2510.14660)
*Linyue Ma,Yilong Xu,Xiang Long,Zhi Zheng*

Main category: cs.CL

TL;DR: 提出了一种“nugget-as-rubric”范式，将原子信息点作为结构化评估标准，并构建了高效的生成式验证器Search-Gen-V，用于提升检索增强型大模型在长短任务中的可验证奖励建模。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强型大语言模型的奖励建模存在局限：基于规则的奖励（如精确匹配）易受表达变化影响且不适用于长文本任务；生成式奖励虽更鲁棒，但在动态语料库下的长文本任务中难以设计出可验证、稳定且计算成本高的奖励机制。

Method: 提出“nugget-as-rubric”范式，将原子信息点作为结构化评分标准；针对长文本任务设计基于查询重写的自动rubric构建流程，从静态或动态网络内容中自动抽取rubric；并提出Search-Gen-V——一个40亿参数的高效生成式验证器，采用蒸馏思想和两阶段训练策略进行训练。

Result: 实验结果表明，Search-Gen-V在不同任务负载下均实现了强大的验证准确率，具备良好的可扩展性、鲁棒性和效率，能有效支持检索增强型LLMs的可验证奖励构建。

Conclusion: 所提出的nugget-as-rubric范式与Search-Gen-V验证器为检索增强型大模型提供了一种统一、可验证且高效的奖励建模方案，尤其适用于复杂长文本和动态环境下的搜索增强任务。

Abstract: Search augmentation empowers Large Language Models with retrieval
capabilities to overcome the limitations imposed by static parameters.
Recently, Reinforcement Learning leverages tailored reward signals as a viable
technique to enhance LLMs performing tasks involving search. However, existing
reward modeling for search-augmented LLMs faces several limitations. Rule-based
rewards, such as Exact Match, are verifiable but fragile to variations in
expression and cannot be applied to long-form workloads. In contrast,
generative rewards improve robustness, but designing verifiable and stable
rewards for long-form workloads in dynamic corpora remains challenging and also
incurs high computational costs. In this paper, we propose a unified and
verifiable paradigm, "nugget-as-rubric", which treats atomic information points
as structured evaluation criteria for different search-augmentation workloads.
Short-form tasks correspond to a single rubric, whereas long-form tasks expand
to multiple rubrics aligned with the question's information needs. To support
long-form settings, we design an automatic rubric construction pipeline based
on query rewriting, which can automatically retrieve passages relevant to each
question and extract rubrics from them, both from static corpora and from
dynamic online web content. Furthermore, we introduce \textbf{Search-Gen-V}, a
4B-parameter efficient generative verifier under our proposed verifiable
paradigm, which is trained via the idea of distillation and a two-stage
strategy. Experimental results show that Search-Gen-V achieves strong
verification accuracy across different workloads, making it a scalable, robust,
and efficient verifiable reward constructor for search-augmented LLMs.

</details>


### [207] [Semantic Prosody in Machine Translation: the English-Chinese Case of Passive Structures](https://arxiv.org/abs/2510.14662)
*Xinyue Ma,Pol Pastells,Mireia Farrús,Mariona Taulé*

Main category: cs.CL

TL;DR: 本文提出一种方法来教机器翻译模型理解汉语“被”字句的负面语义韵，并通过构建英汉句对数据集微调多个MT模型，结果表明微调后的模型能更准确地在负面语境中使用“被”字句，避免在中性或正面语境中误用，且语义韵知识可在多语言模型中跨语言迁移。


<details>
  <summary>Details</summary>
Motivation: 由于相同词汇在不同语言中可能具有不同的语义韵，而当前机器翻译模型难以捕捉这一语言特性，导致翻译不准确，因此需要专门研究如何让模型学习语义韵。

Method: 聚焦汉语BEI被动结构，构建具有负面语义韵标注的英汉双语句对数据集，并使用该数据集对OPUS-MT、NLLB-600M和mBART50模型进行微调，以提升其在翻译中对语义韵的敏感性。

Result: 微调后的模型在翻译不利内容时更倾向于使用‘被’字结构，而在中性或有利内容中避免使用；此外，在NLLB-600M模型中，这种语义韵知识可迁移到西汉翻译等其他语言对。

Conclusion: 通过特定结构的数据集微调，可有效提升机器翻译模型对语义韵的理解与应用能力，且多语言模型具备跨语言迁移该知识的潜力。

Abstract: Semantic prosody is a collocational meaning formed through the co-occurrence
of a linguistic unit and a consistent series of collocates, which should be
treated separately from semantic meaning. Since words that are literal
translations of each other may have different semantic prosody, more attention
should be paid to this linguistic property to generate accurate translations.
However, current machine translation models cannot handle this problem. To
bridge the gap, we propose an approach to teach machine translation models
about semantic prosody of a specific structure. We focus on Chinese BEI
passives and create a dataset of English-Chinese sentence pairs with the
purpose of demonstrating the negative semantic prosody of BEI passives. Then we
fine-tune OPUS-MT, NLLB-600M and mBART50 models with our dataset for the
English-Chinese translation task. Our results show that fine-tuned MT models
perform better on using BEI passives for translating unfavourable content and
avoid using it for neutral and favourable content. Also, in NLLB-600M, which is
a multilingual model, this knowledge of semantic prosody can be transferred
from English-Chinese translation to other language pairs, such as
Spanish-Chinese.

</details>


### [208] [Speculative Model Risk in Healthcare AI: Using Storytelling to Surface Unintended Harms](https://arxiv.org/abs/2510.14718)
*Xingmeng Zhao,Dan Schumacher,Veronica Rammouz,Anthony Rios*

Main category: cs.CL

TL;DR: 本文提出了一种以人为中心的框架，通过生成用户故事和多智能体讨论，帮助人们在AI系统部署前创造性地思考潜在的益处和危害。实验表明，使用故事的参与者识别出更广泛的伤害类型，而未使用者则主要关注隐私和福祉问题。


<details>
  <summary>Details</summary>
Motivation: 快速发展的AI健康工具可能带来偏见、隐私侵犯和不平等等风险，尤其在忽视真实情境和多样化用户需求时。当前自动检测风险的方法可能降低人类对伤害机制及其影响人群的理解参与度。因此，需要一种促进人类深入思考AI社会影响的方法。

Method: 提出一个以人为中心的框架，利用生成的用户故事和多智能体对话，促进对AI系统潜在影响的创造性思考。通过用户研究评估该方法的有效性，比较阅读故事与未阅读故事的参与者在识别AI潜在危害方面的差异。

Result: 阅读用户故事的参与者识别出更广泛的13种伤害类型，反应分布更均匀；相比之下，未阅读故事的参与者有58.3%集中在隐私和福祉两类问题上。

Conclusion: 讲故事的方法有助于拓展人们对AI潜在危害和益处的思考范围，促进更具创造性和全面性的风险评估，提升AI系统设计的人本性和公平性。

Abstract: Artificial intelligence (AI) is rapidly transforming healthcare, enabling
fast development of tools like stress monitors, wellness trackers, and mental
health chatbots. However, rapid and low-barrier development can introduce risks
of bias, privacy violations, and unequal access, especially when systems ignore
real-world contexts and diverse user needs. Many recent methods use AI to
detect risks automatically, but this can reduce human engagement in
understanding how harms arise and who they affect. We present a human-centered
framework that generates user stories and supports multi-agent discussions to
help people think creatively about potential benefits and harms before
deployment. In a user study, participants who read stories recognized a broader
range of harms, distributing their responses more evenly across all 13 harm
types. In contrast, those who did not read stories focused primarily on privacy
and well-being (58.3%). Our findings show that storytelling helped participants
speculate about a broader range of harms and benefits and think more creatively
about AI's impact on users.

</details>


### [209] [AutoRubric-R1V: Rubric-Based Generative Rewards for Faithful Multimodal Reasoning](https://arxiv.org/abs/2510.14738)
*Mengzhao Jia,Zhihan Zhang,Ignacio Cases,Zheyuan Liu,Meng Jiang,Peng Qi*

Main category: cs.CL

TL;DR: 提出AutoRubric-R1V框架，通过自动生成的基于评分标准的奖励，在强化学习中引入过程监督，提升多模态大模型推理的准确性和可信度。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法（如RLVR）仅基于最终答案正确性进行奖励，容易导致虚假推理，缺乏对推理过程的监督。

Method: 提出AutoRubric-R1V框架，利用成功推理轨迹通过自聚合方法自动提炼出一致的推理检查点，构建问题特定的评分标准，并结合基于评分标准和结果的双重奖励进行训练。

Result: 在六个多模态推理基准上达到最先进性能，并在专门评估中显著提升推理的真实性。

Conclusion: AutoRubric-R1V通过自动构建过程监督信号，有效提升了多模态大语言模型在复杂推理任务中的性能和推理可信度。

Abstract: Multimodal large language models (MLLMs) have rapidly advanced from
perception tasks to complex multi-step reasoning, yet reinforcement learning
with verifiable rewards (RLVR) often leads to spurious reasoning since only the
final-answer correctness is rewarded. To address this limitation, we propose
AutoRubric-R1V, a framework that integrates RLVR with process-level supervision
through automatically collected rubric-based generative rewards. Our key
innovation lies in a scalable self-aggregation method that distills consistent
reasoning checkpoints from successful trajectories, enabling problem-specific
rubric construction without human annotation or stronger teacher models. By
jointly leveraging rubric-based and outcome rewards, AutoRubric-R1V achieves
state-of-the-art performance on six multimodal reasoning benchmarks and
substantially improves reasoning faithfulness in dedicated evaluations.

</details>


### [210] [Pluto: A Benchmark for Evaluating Efficiency of LLM-generated Hardware Code](https://arxiv.org/abs/2510.14756)
*Manar Abdelatty,Maryam Nouh,Jacob K. Rosenstein,Sherief Reda*

Main category: cs.CL

TL;DR: Pluto是一个用于评估大语言模型生成Verilog代码综合效率的基准框架，包含114个问题、自检测试平台和帕累托最优参考实现，揭示当前LLM在功能正确性上表现良好，但在面积、延迟和功耗效率上仍显著落后于专家设计。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成硬件设计的基准主要关注功能正确性，缺乏对综合效率（如面积、延迟、功耗）和验证测试平台的全面评估，因此需要一个更全面的评估框架来推动面向硬件设计的LLM研究。

Method: 提出Pluto基准框架，包含114个硬件设计问题、自检测试平台以及多个帕累托最优的参考实现，通过pass@1和eff@1指标系统评估LLM生成Verilog代码的功能正确性和综合效率。

Result: 实验表明，先进LLM在功能正确性上可达78.3%（pass@1），但在综合效率方面显著不足：面积效率为63.8%，延迟效率为65.9%，功耗效率为64.0%（eff@1）。

Conclusion: 当前LLM在硬件设计生成中虽具备较高功能正确性，但在实际综合效率上仍有明显差距，Pluto等效率感知评估框架对推动高效硬件生成至关重要。

Abstract: Large Language Models (LLMs) are increasingly used to automate hardware
design tasks, including the generation of Verilog code. While early benchmarks
focus primarily on functional correctness, efficient hardware design demands
additional optimization for synthesis metrics such as area, delay, and power.
Existing benchmarks fall short in evaluating these aspects comprehensively:
they often lack optimized baselines or testbenches for verification. To address
these gaps, we present Pluto, a benchmark and evaluation framework designed to
assess the efficiency of LLM-generated Verilog designs. Pluto presents a
comprehensive evaluation set of 114 problems with self-checking testbenches and
multiple Pareto-optimal reference implementations. Experimental results show
that state-of-the-art LLMs can achieve high functional correctness, reaching
78.3\% at pass@1, but their synthesis efficiency still lags behind
expert-crafted implementations, with area efficiency of 63.8\%, delay
efficiency of 65.9\%, and power efficiency of 64.0\% at eff@1. This highlights
the need for efficiency-aware evaluation frameworks such as Pluto to drive
progress in hardware-focused LLM research.

</details>


### [211] [COIG-Writer: A High-Quality Dataset for Chinese Creative Writing with Thought Processes](https://arxiv.org/abs/2510.14763)
*Yunwen Li,Shuangshuang Ying,Xingwei Qu,Xin Li,Sheng Jin,Minghao Liu,Zhoufutu Wen,Tianyu Zheng,Xeron Du,Qiguang Chen,Jiajun Shi,Wangchunshu Zhou,Jiazhan Feng,Wanjun Zhong,Libo Qin,Stephen Huang,Wanxiang Che,Chenghua Lin,Eli Zhang*

Main category: cs.CL

TL;DR: COIG-Writer是一个新型中文创意写作数据集，包含1665个三元组，揭示了创意写作中思维过程监督与语言表达的相互作用。


<details>
  <summary>Details</summary>
Motivation: 现有数据集缺乏对创意写作思维过程的监督，尤其在非英语语境下表现不足，因此需要构建一个包含创作推理过程的高质量中文创意写作数据集。

Method: 通过系统性逆向工程高质量中文文本，构建包含反向生成的提示、详细创作推理和最终文本的三元组数据集，并进行多语言、多模型实验验证。

Result: 发现创意写作由叙事逻辑（过程监督）和语言表达（通用数据）两部分组成；过程监督需与通用数据结合（至少1:12比例）才能有效；创意能力具有文化绑定性，无跨语言迁移；词汇多样性与创意质量呈负相关（TTR悖论）。

Conclusion: 创造性卓越源于逻辑框架与语言基础的协同作用，类比于数学推理在基础模型中增强但不能取代语言能力的角色。

Abstract: Large language models exhibit systematic deficiencies in creative writing,
particularly in non-English contexts where training data is scarce and lacks
process-level supervision. We present COIG-Writer, a novel Chinese creative
writing dataset that captures both diverse outputs and their underlying thought
processes through systematic reverse-engineering of high-quality texts. Unlike
existing datasets that provide only input-output pairs, COIG-Writer comprises
1,665 meticulously curated triplets spanning 51 genres, each containing: (1) a
reverse-engineered prompt, (2) detailed creative reasoning documenting
decision-making processes, and (3) the final text. Through comprehensive
experiments, we identify a two-component model of creative writing: narrative
logic (provided by process supervision) and linguistic expression (maintained
by general-purpose data). Our findings reveal three critical insights: (1)
Process supervision is highly effective but requires stabilization with general
data. A ratio of at least one creative sample to twelve general samples is
needed to achieve optimal performance; below this threshold, the win rate
progressively degrades (from 62.75% down to 35.78%)., (2) creative capabilities
are culturally-bound with no cross-lingual transfer (89.26pp gap between
Chinese and English performance), and (3) lexical diversity inversely
correlates with creative quality (TTR paradox), suggesting high diversity
signals compensatory behavior for logical deficiencies. These findings
establish that creative excellence emerges from the interaction between logical
scaffolding and linguistic grounding, analogous to how mathematical reasoning
enhances but cannot replace linguistic competence in foundation models.

</details>


### [212] [Finding Answers in Thought Matters: Revisiting Evaluation on Large Language Models with Reasoning](https://arxiv.org/abs/2510.14773)
*Hwiyeol Jo,Joosung Lee,Jaehone Lee,Sang-Woo Lee,Joonsuk Park,Kang Min Yoo*

Main category: cs.CL

TL;DR: 提出了一种名为“答案再生”的通用框架，通过额外的模型推理和提示来提高推理模型的答案提取鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的答案提取方法对推理模型的性能和答案分布高度敏感，影响模型评估的可靠性。

Method: 引入“答案再生”框架，在生成最终答案时，使用额外的模型推断，将先前的输入和输出以“Answer:”为前缀进行再生，并从中提取最终答案。

Result: 该方法在数学问题和开放式问答任务中表现出更好的性能和更强的鲁棒性，且不依赖于特定的提取规则。

Conclusion: 答案再生框架有助于缓解提取算法对模型评估的影响，提供更可靠的生成模型评估结果。

Abstract: Evaluating generative models, such as large language models (LLMs), commonly
involves question-answering tasks where the final answer is selected based on
probability of answer choices. On the other hand, for models requiring
reasoning, the method of answer extraction plays a critical role. Our research
reveals that the performance of reasoning models and their final answer
distributions are highly sensitive to the answer extraction algorithm employed.
In order to mitigate this, we propose a basic framework: Answer Regeneration.
The method uses an additional model inference, providing the prior input and
output prefaced by the prompt "Answer:". The final answer is then selected or
extracted from the regenerated output. We show that this
extraction-rule-agnostic approach exhibits improved performance and enhanced
robustness. Furthermore, we have applied this framework to general math
problems and open-ended question answering tasks. Our analysis and this
framework could offer a more reliable results for model evaluation.

</details>


### [213] [Rewiring Experts on the Fly:Continuous Rerouting for Better Online Adaptation in Mixture-of-Expert models](https://arxiv.org/abs/2510.14853)
*Guinan Su,Yanwu Yang,Li Shen,Lu Yin,Shiwei Liu,Jonas Geiping*

Main category: cs.CL

TL;DR: 提出了一种无需外部数据、在线自适应的MoE模型路由优化框架，通过输入上下文进行自我监督，在文本生成过程中持续改进专家选择，提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时自适应方法主要针对稠密模型且依赖外部数据，难以应用于MoE架构；而MoE在部署中常因分布偏移导致路由不佳。

Method: 设计了一个数据免费、在线的测试时框架，交替进行路由优化和文本生成：在prefill阶段及定期利用已生成序列进行自我监督，通过轻量级可加向量仅更新特定层的路由器logits。

Result: 在推理任务上表现稳定增益，如OLMoE在HumanEval上提升5.5%；与DeepSeek-V2-Lite结合自洽性时平均提升6%。

Conclusion: 该方法无需额外数据，具有即插即用特性，有效增强MoE模型对上下文变化的鲁棒性，并可与现有测试时扩展技术兼容。

Abstract: Mixture-of-Experts (MoE) models achieve efficient scaling through sparse
expert activation, but often suffer from suboptimal routing decisions due to
distribution shifts in deployment. While existing test-time adaptation methods
could potentially address these issues, they primarily focus on dense models
and require access to external data, limiting their practical applicability to
MoE architectures. However, we find that, instead of relying on reference data,
we can optimize MoE expert selection on-the-fly based only on input context. As
such, we propose \textit{a data-free, online test-time framework} that
continuously adapts MoE routing decisions during text generation without
external supervision or data. Our method cycles between two phases: During the
prefill stage, and later in regular intervals, we optimize the routing
decisions of the model using self-supervision based on the already generated
sequence. Then, we generate text as normal, maintaining the modified router
until the next adaption. We implement this through lightweight additive vectors
that only update router logits in selected layers, maintaining computational
efficiency while preventing over-adaptation. The experimental results show
consistent performance gains on challenging reasoning tasks while maintaining
robustness to context shifts. For example, our method achieves a 5.5\%
improvement on HumanEval with OLMoE. Furthermore, owing to its plug-and-play
property, our method naturally complements existing test-time scaling
techniques, e.g., achieving 6\% average gains when incorporated with
self-consistency on DeepSeek-V2-Lite.

</details>


### [214] [Midtraining Bridges Pretraining and Posttraining Distributions](https://arxiv.org/abs/2510.14865)
*Emmy Liu,Graham Neubig,Chenyan Xiong*

Main category: cs.CL

TL;DR: 本文系统研究了语言模型预训练中的“中期训练”阶段，发现其在数学和代码领域效果显著，能有效缩小预训练与下游任务之间的语法差距，减少遗忘，优于继续预训练。


<details>
  <summary>Details</summary>
Motivation: 尽管中期训练被广泛使用，但其作用机制缺乏科学理解，本文旨在通过控制实验探究其有效性及原因。

Method: 从零开始预训练语言模型，结合不同领域的监督微调数据进行实验，系统分析中期训练的影响，包括开始时间与数据混合比例的消融研究。

Result: 中期训练在数学和代码领域效果最好，尤其在降低领域内验证损失和减少预训练知识遗忘方面优于继续预训练；且早期引入专业化数据比混合权重影响更大。

Conclusion: 中期训练是一种有效的领域适应技术，通过减少遗忘提升模型性能，尤其在语法结构差异大的任务中更具优势。

Abstract: Recently, many language models have been pretrained with a "midtraining"
phase, in which higher quality, often instruction-formatted data, is mixed in
at the end of pretraining. Despite the popularity of this practice, there is
little scientific understanding of this phase of model training or why it is
effective. In this work, we conduct the first systematic investigation of
midtraining through controlled experiments with language models pretrained from
scratch and fine-tuned on supervised finetuning datasets in different domains.
We find that when compared after supervised fine-tuning, the effectiveness of
midtraining is highest in the math and code domains, where midtraining can best
reduce the syntactic gap between pretraining and posttraining data. In these
cases, midtraining consistently outperforms continued pretraining in both
in-domain validation loss as well as pretraining data forgetting after
posttraining. We conduct ablations on the starting time of the midtraining
phase and mixture weights of the midtraining data, using code midtraining as a
case study, and find that timing has a greater impact than mixture weights,
with earlier introduction of specialized data, yielding greater benefits
in-domain as well as preserving general language modeling better. These
findings establish midtraining as a domain adaptation technique that compared
to continued pretraining yields better performance through reduced forgetting.

</details>


### [215] [From Loop Nests to Silicon: Mapping AI Workloads onto AMD NPUs with MLIR-AIR](https://arxiv.org/abs/2510.14871)
*Erwei Wang,Samuel Bayliss,Andra Bisca,Zachary Blair,Sangeeta Chowdhary,Kristof Denolf,Jeff Fifield,Brandon Freiberger,Erika Hunhoff,Phil James-Roxby,Jack Lo,Joseph Melber,Stephen Neuendorffer,Eddie Richter,Andre Rosti,Javier Setoain,Gagandeep Singh,Endri Taka,Pranathi Vasireddy,Zhewen Yu,Niansong Zhang,Jinming Zhuang*

Main category: cs.CL

TL;DR: MLIR-AIR是一个基于MLIR的新型开源编译器栈，旨在通过显式管理计算与数据调度，高效利用现代细粒度空间架构（如AMD的NPU），在矩阵乘法和LLaMA 2多头注意力机制中展现出接近手工优化的性能。


<details>
  <summary>Details</summary>
Motivation: 通用编译器抽象了并行性、局部性和同步，难以充分发挥现代空间架构的性能潜力；需要更细粒度的控制机制来优化数据移动、执行顺序和计算分布。

Method: 提出MLIR-AIR编译器栈及其AIR方言，提供对异步和分层操作的结构化表示，利用AIR原语实现空间调度、跨硬件区域的计算分配以及通信与计算的重叠，无需依赖运行时协调或手动调度。

Result: 在矩阵乘法中达到最高78.7%的计算效率，性能接近手工优化的MLIR-AIE实现；在LLaMA 2的多头注意力模块中，仅用约150行代码实现了融合优化，有效映射到空间硬件。

Conclusion: MLIR-AIR能够将高级控制流转化为高效利用NPU计算资源和内存层次的空间程序，通过编译器管理的调度实现异步执行、分块和通信重叠，显著提升现代空间架构上的性能。

Abstract: General-purpose compilers abstract away parallelism, locality, and
synchronization, limiting their effectiveness on modern spatial architectures.
As modern computing architectures increasingly rely on fine-grained control
over data movement, execution order, and compute placement for performance,
compiler infrastructure must provide explicit mechanisms for orchestrating
compute and data to fully exploit such architectures. We introduce MLIR-AIR, a
novel, open-source compiler stack built on MLIR that bridges the semantic gap
between high-level workloads and fine-grained spatial architectures such as
AMD's NPUs. MLIR-AIR defines the AIR dialect, which provides structured
representations for asynchronous and hierarchical operations across compute and
memory resources. AIR primitives allow the compiler to orchestrate spatial
scheduling, distribute computation across hardware regions, and overlap
communication with computation without relying on ad hoc runtime coordination
or manual scheduling. We demonstrate MLIR-AIR's capabilities through two case
studies: matrix multiplication and the multi-head attention block from the
LLaMA 2 model. For matrix multiplication, MLIR-AIR achieves up to 78.7% compute
efficiency and generates implementations with performance almost identical to
state-of-the-art, hand-optimized matrix multiplication written using the
lower-level, close-to-metal MLIR-AIE framework. For multi-head attention, we
demonstrate that the AIR interface supports fused implementations using
approximately 150 lines of code, enabling tractable expression of complex
workloads with efficient mapping to spatial hardware. MLIR-AIR transforms
high-level structured control flow into spatial programs that efficiently
utilize the compute fabric and memory hierarchy of an NPU, leveraging
asynchronous execution, tiling, and communication overlap through
compiler-managed scheduling.

</details>


### [216] [Harmonizing Diverse Models: A Layer-wise Merging Strategy for Consistent Generation](https://arxiv.org/abs/2510.14915)
*Xujun Peng,Anoop Kumar,Jingyu Wu,Parker Glenn,Daben Liu*

Main category: cs.CL

TL;DR: 提出了一种结合合成数据生成、三元组损失和层间模型融合的新方法，显著提升了工业级RAG系统中大语言模型输出的一致性，相较于基线模型响应相似性提高了约47.5%。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在语义等价输入下常产生不一致输出，现有微调技术在提升输出一致性方面存在局限，且缺乏面向一致性的训练数据。

Method: 结合系统化的合成数据生成、三元组损失优化嵌入表示，以及基于中间层激活的一致性感知权重的层间模型融合新方法。

Result: 合并后的模型在输出一致性上显著优于基线，响应相似性提升了约47.5%。

Conclusion: 该方法有效提升了RAG系统中模型输出的一致性，为增强工业级RAG系统的可靠性提供了实用解决方案。

Abstract: Retrieval-Augmented Generation (RAG) systems leverage Large Language Models
(LLMs) to generate accurate and reliable responses that are grounded in
retrieved context. However, LLMs often generate inconsistent outputs for
semantically equivalent inputs, a problem compounded by the scarcity of
consistency-focused training data and the limitations of current fine-tuning
techniques in enhancing output consistency. We propose a new approach combining
systematic synthetic data generation, triplet loss for better embeddings, and a
novel layer-wise model merging approach. Using consistency-aware weights
derived from intermediate layer activations, our method effectively integrates
knowledge from specialized models. Experimental results how that our merged
model significantly enhances output consistency, achieving a ~47.5\%
improvement in response similarity over the baseline, thus offering a practical
solution for increasing the reliability of an industrial RAG system.

</details>


### [217] [Predicting Task Performance with Context-aware Scaling Laws](https://arxiv.org/abs/2510.14919)
*Kyle Montgomery,David Park,Jianhong Tu,Michael Bendersky,Beliz Gunel,Dawn Song,Chenguang Wang*

Main category: cs.CL

TL;DR: 提出一个联合建模下游任务性能的框架，该框架以训练计算量和上下文为变量，准确预测扩展上下文语言模型在多个任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有缩放定律无法捕捉下游任务性能，尤其是在上下文起关键作用的情况下，因此需要一种能够结合训练计算量和上下文影响的新框架。

Method: 构建一个简单且可解释的框架，将下游性能建模为训练计算量和提供上下文的函数，并在Llama-2-7B和Llama-2-13B的扩展上下文变体上进行实证验证，覆盖三种任务共65,500个实例。

Result: 该框架能准确建模分布内下游性能，跨三个数量级的训练计算量保持泛化能力，并可靠地外推上下文增加时的性能表现。

Conclusion: 研究揭示了训练计算量与上下文利用之间的相互作用，为设计更高效的长上下文大语言模型提供了指导。

Abstract: Scaling laws have transformed our understanding of large language models by
linking upstream metrics like cross-entropy loss to design factors such as
model size, training data, and compute. However, these conventional laws fail
to capture downstream task performance, where context plays a critical role. In
this work, we propose a straightforward, interpretable framework that jointly
models downstream performance as a function of the training compute and the
provided context. We empirically validate our framework by fitting it on the
observed downstream performance of extended-context variants of Llama-2-7B and
Llama-2-13B across 65,500 unique instances spanning three tasks: arithmetic
reasoning, common sense reasoning, and machine translation. Our results
demonstrate that our framework accurately models in-distribution downstream
performance, generalizes across three orders of magnitude in training compute,
and reliably extrapolates performance as the amount of context increases. These
findings offer valuable insights into the interplay between training compute
and context utilization, providing guidance for designing more efficient
long-context LLMs for diverse downstream tasks. Our code is available at
https://github.com/wang-research-lab/context-scaling.

</details>


### [218] [AI-Powered Early Diagnosis of Mental Health Disorders from Real-World Clinical Conversations](https://arxiv.org/abs/2510.14937)
*Jianfeng Zhu,Julina Maharjan,Xinyu Li,Karin G. Coifman,Ruoming Jin*

Main category: cs.CL

TL;DR: 本研究利用553个真实世界的半结构化访谈数据，评估了多种机器学习模型在抑郁症、焦虑症和PTSD筛查中的表现，发现基于大语言模型（如GPT-4.1 Mini、MetaLLaMA）和LoRA微调的RoBERTa模型可达到80%以上的准确率，尤其在PTSD检测中表现优异（准确率89%，召回率98%），且短而聚焦的上下文能提升检测敏感性，展示了AI在低资源或高污名环境中实现心理健康早期筛查的潜力。


<details>
  <summary>Details</summary>
Motivation: 心理健康障碍常因主观评估、医疗资源有限和污名化而被漏诊或误诊，尤其是在初级医疗中误诊率超60%，亟需可扩展、易获取、情境感知的辅助诊断工具以支持早期干预。

Method: 使用包含真实诊断标签的553例半结构化访谈数据，比较了零样本提示的GPT-4.1 Mini和MetaLLaMA大模型，以及采用LowRank Adaptation（LoRA）进行微调的RoBERTa模型在MDE、焦虑和PTSD筛查中的性能，并分析不同上下文长度和LoRA秩配置的影响。

Result: 所有模型在各类诊断中准确率均超过80%，PTSD检测表现最佳（最高89%准确率，98%召回率）；较短且聚焦的上下文段落可提升召回率；低秩LoRA配置（如rank 8和16）即可保持优异性能。

Conclusion: 基于大语言模型的筛查方法显著优于传统自评工具，具备高效、低门槛的优势，有望整合到临床流程中，特别是在资源匮乏或心理疾病污名严重的环境中推动早期诊断。

Abstract: Mental health disorders remain among the leading cause of disability
worldwide, yet conditions such as depression, anxiety, and Post-Traumatic
Stress Disorder (PTSD) are frequently underdiagnosed or misdiagnosed due to
subjective assessments, limited clinical resources, and stigma and low
awareness. In primary care settings, studies show that providers misidentify
depression or anxiety in over 60% of cases, highlighting the urgent need for
scalable, accessible, and context-aware diagnostic tools that can support early
detection and intervention. In this study, we evaluate the effectiveness of
machine learning models for mental health screening using a unique dataset of
553 real-world, semistructured interviews, each paried with ground-truth
diagnoses for major depressive episodes (MDE), anxiety disorders, and PTSD. We
benchmark multiple model classes, including zero-shot prompting with GPT-4.1
Mini and MetaLLaMA, as well as fine-tuned RoBERTa models using LowRank
Adaptation (LoRA). Our models achieve over 80% accuracy across diagnostic
categories, with especially strongperformance on PTSD (up to 89% accuracy and
98% recall). We also find that using shorter context, focused context segments
improves recall, suggesting that focused narrative cues enhance detection
sensitivity. LoRA fine-tuning proves both efficient and effective, with
lower-rank configurations (e.g., rank 8 and 16) maintaining competitive
performance across evaluation metrics. Our results demonstrate that LLM-based
models can offer substantial improvements over traditional self-report
screening tools, providing a path toward low-barrier, AI-powerd early
diagnosis. This work lays the groundwork for integrating machine learning into
real-world clinical workflows, particularly in low-resource or high-stigma
environments where access to timely mental health care is most limited.

</details>


### [219] [LaSeR: Reinforcement Learning with Last-Token Self-Rewarding](https://arxiv.org/abs/2510.14943)
*Wenkai Yang,Weijie Liu,Ruobing Xie,Yiju Guo,Lulu Wu,Saiyong Yang,Yankai Lin*

Main category: cs.CL

TL;DR: 提出LaSeR算法，通过最后一token的自奖励分数来统一推理与验证，提升大模型推理效率与性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习与自验证方法需使用不同模板分别生成推理结果与验证信号，效率低下，且缺乏测试时的可验证奖励机制。

Method: 基于理论推导发现，自验证的强化学习目标可简化为最后token的自奖励分数；提出LaSeR算法，在原有RLVR损失基础上增加MSE损失，对齐最后一token的自奖励分数与验证器奖励，联合优化推理与自奖励能力。

Result: LaSeR仅需一次额外token推断即可获得自奖励信号，在训练和测试中均有效提升模型推理性能，并显著增强其推理时扩展能力。

Conclusion: LaSeR以极低开销实现了推理与自奖励能力的统一，为大语言模型的高效强化学习提供了新思路。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as
a core paradigm for enhancing the reasoning capabilities of Large Language
Models (LLMs). To address the lack of verification signals at test time, prior
studies incorporate the training of model's self-verification capability into
the standard RLVR process, thereby unifying reasoning and verification
capabilities within a single LLM. However, previous practice requires the LLM
to sequentially generate solutions and self-verifications using two separate
prompt templates, which significantly reduces efficiency. In this work, we
theoretically reveal that the closed-form solution to the RL objective of
self-verification can be reduced to a remarkably simple form: the true
reasoning reward of a solution is equal to its last-token self-rewarding score,
which is computed as the difference between the policy model's next-token
log-probability assigned to any pre-specified token at the solution's last
token and a pre-calculated constant, scaled by the KL coefficient. Based on
this insight, we propose LaSeR (Reinforcement Learning with Last-Token
Self-Rewarding), an algorithm that simply augments the original RLVR loss with
a MSE loss that aligns the last-token self-rewarding scores with verifier-based
reasoning rewards, jointly optimizing the reasoning and self-rewarding
capabilities of LLMs. The optimized self-rewarding scores can be utilized in
both training and testing to enhance model performance. Notably, our algorithm
derives these scores from the predicted next-token probability distribution of
the last token immediately after generation, incurring only the minimal extra
cost of one additional token inference. Experiments show that our method not
only improves the model's reasoning performance but also equips it with
remarkable self-rewarding capability, thereby boosting its inference-time
scaling performance.

</details>


### [220] [MetaBench: A Multi-task Benchmark for Assessing LLMs in Metabolomics](https://arxiv.org/abs/2510.14944)
*Yuxing Lu,Xukai Zhao,J. Ben Tamo,Micky C. Nnamdi,Rui Peng,Shuang Zeng,Xingyu Hu,Jinzhuo Wang,May D. Wang*

Main category: cs.CL

TL;DR: MetaBench是首个面向代谢组学领域的基准测试，用于系统评估大语言模型在知识、理解、映射、推理和研究五项关键能力上的表现，揭示了现有模型在跨数据库标识符映射和稀有代谢物任务上的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在通用文本上表现优异，但在需要深度关联知识的科学领域（如代谢组学）中的能力尚不明确。代谢组学面临复杂生化通路、异构标识系统和分散数据库等挑战，亟需专门的评估基准。

Method: 基于权威公共资源构建MetaBench，包含五个评估维度：知识、理解、映射、推理和研究，对25个开源和闭源大语言模型进行系统评测，部分实验结合检索增强技术。

Result: 模型在文本生成任务上表现较好，但在跨数据库标识符映射任务上仍面临挑战，即使使用检索增强效果有限；对于注释稀疏的长尾代谢物，模型性能显著下降。

Conclusion: MetaBench为代谢组学领域提供了关键的评估基础设施，有助于推动面向该领域的可靠AI系统的发展。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities on
general text; however, their proficiency in specialized scientific domains that
require deep, interconnected knowledge remains largely uncharacterized.
Metabolomics presents unique challenges with its complex biochemical pathways,
heterogeneous identifier systems, and fragmented databases. To systematically
evaluate LLM capabilities in this domain, we introduce MetaBench, the first
benchmark for metabolomics assessment. Curated from authoritative public
resources, MetaBench evaluates five capabilities essential for metabolomics
research: knowledge, understanding, grounding, reasoning, and research. Our
evaluation of 25 open- and closed-source LLMs reveals distinct performance
patterns across metabolomics tasks: while models perform well on text
generation tasks, cross-database identifier grounding remains challenging even
with retrieval augmentation. Model performance also decreases on long-tail
metabolites with sparse annotations. With MetaBench, we provide essential
infrastructure for developing and evaluating metabolomics AI systems, enabling
systematic progress toward reliable computational tools for metabolomics
research.

</details>


### [221] [Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents](https://arxiv.org/abs/2510.14967)
*Guoqing Wang,Sunhao Dai,Guangze Ye,Zeyu Gan,Wei Yao,Yong Deng,Xiaofeng Wu,Zhenzhe Ying*

Main category: cs.CL

TL;DR: 提出了一种基于信息增益的策略优化（IGPO）框架，通过模型自身信念更新提供密集的内在奖励，有效解决多轮任务中奖励稀疏、优势崩溃和信用分配问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的LLM代理在多轮任务中依赖最终结果奖励，导致奖励稀疏，难以实现有效的学习信号和细粒度信用分配。

Method: 将每一轮交互建模为对正确答案信息的增量获取过程，以策略生成正确答案概率的边际增长作为每步奖励，结合模型自身信念更新生成密集的内在奖励。

Result: 在多个领域内和跨领域基准上实验表明，IGPO在多轮场景下优于强基线方法，显著提升准确率和样本效率。

Conclusion: IGPO通过内在、密集的奖励机制有效缓解了多轮交互中的学习挑战，为LLM代理的训练提供了高效且实用的强化学习框架。

Abstract: Large language model (LLM)-based agents are increasingly trained with
reinforcement learning (RL) to enhance their ability to interact with external
environments through tool use, particularly in search-based settings that
require multi-turn reasoning and knowledge acquisition. However, existing
approaches typically rely on outcome-based rewards that are only provided at
the final answer. This reward sparsity becomes particularly problematic in
multi-turn settings, where long trajectories exacerbate two critical issues:
(i) advantage collapse, where all rollouts receive identical rewards and
provide no useful learning signals, and (ii) lack of fine-grained credit
assignment, where dependencies between turns are obscured, especially in
long-horizon tasks. In this paper, we propose Information Gain-based Policy
Optimization (IGPO), a simple yet effective RL framework that provides dense
and intrinsic supervision for multi-turn agent training. IGPO models each
interaction turn as an incremental process of acquiring information about the
ground truth, and defines turn-level rewards as the marginal increase in the
policy's probability of producing the correct answer. Unlike prior
process-level reward approaches that depend on external reward models or costly
Monte Carlo estimation, IGPO derives intrinsic rewards directly from the
model's own belief updates. These intrinsic turn-level rewards are combined
with outcome-level supervision to form dense reward trajectories. Extensive
experiments on both in-domain and out-of-domain benchmarks demonstrate that
IGPO consistently outperforms strong baselines in multi-turn scenarios,
achieving higher accuracy and improved sample efficiency.

</details>


### [222] [LLMs as Scalable, General-Purpose Simulators For Evolving Digital Agent Training](https://arxiv.org/abs/2510.14969)
*Yiming Wang,Da Yin,Yuedong Cui,Ruichen Zheng,Zhiqian Li,Zongyu Lin,Di Wu,Xueqing Wu,Chenchen Ye,Yu Zhou,Kai-Wei Chang*

Main category: cs.CL

TL;DR: UI-Simulator 是一种可扩展的范式，能大规模生成结构化的用户界面（UI）状态和转换，用于合成数字智能体的训练轨迹，且在使用较弱教师模型的情况下仍表现优异；其扩展策略 UI-Simulator-Grow 实现了更高效的数据生成与性能提升。


<details>
  <summary>Details</summary>
Motivation: 获取大规模、多样化的真实UI操作轨迹成本高昂，限制了数字智能体的泛化能力，因此需要一种低成本、可扩展的数据生成方法。

Method: 提出 UI-Simulator 范式，结合数字世界模拟器生成多样UI状态、引导式 rollout 实现连贯探索，并通过轨迹封装生成高质量训练轨迹；进一步设计 UI-Simulator-Grow 策略，聚焦高影响力任务以提升数据效率和扩展速度。

Result: 在 WebArena 和 AndroidWorld 上的实验表明，使用 UI-Simulator 训练的智能体性能达到甚至超过基于真实UI数据训练的开源智能体，展现出更强的鲁棒性；UI-Simulator-Grow 仅用 Llama-3-8B-Instruct 就达到了 Llama-3-70B-Instruct 的性能水平。

Conclusion: 目标式合成扩展范式（如 UI-Simulator 及其 Grow 策略）能高效、持续地提升数字智能体的性能，为训练数据稀缺问题提供了可行解决方案。

Abstract: Digital agents require diverse, large-scale UI trajectories to generalize
across real-world tasks, yet collecting such data is prohibitively expensive in
both human annotation, infra and engineering perspectives. To this end, we
introduce $\textbf{UI-Simulator}$, a scalable paradigm that generates
structured UI states and transitions to synthesize training trajectories at
scale. Our paradigm integrates a digital world simulator for diverse UI states,
a guided rollout process for coherent exploration, and a trajectory wrapper
that produces high-quality and diverse trajectories for agent training. We
further propose $\textbf{UI-Simulator-Grow}$, a targeted scaling strategy that
enables more rapid and data-efficient scaling by prioritizing high-impact tasks
and synthesizes informative trajectory variants. Experiments on WebArena and
AndroidWorld show that UI-Simulator rivals or surpasses open-source agents
trained on real UIs with significantly better robustness, despite using weaker
teacher models. Moreover, UI-Simulator-Grow matches the performance of
Llama-3-70B-Instruct using only Llama-3-8B-Instruct as the base model,
highlighting the potential of targeted synthesis scaling paradigm to
continuously and efficiently enhance the digital agents.

</details>


### [223] [TokDrift: When LLM Speaks in Subwords but Code Speaks in Grammar](https://arxiv.org/abs/2510.14972)
*Yinxi Li,Yuntian Deng,Pengyu Nie*

Main category: cs.CL

TL;DR: 语义相同的代码因格式不同可能导致不同的分词结果，影响大模型行为，研究提出TokDrift框架揭示分词与语法不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 现有代码大模型使用的分词方法（如BPE）基于统计而非语法，导致语义相同的代码被不同分词，影响模型可靠性。

Method: 提出TokDrift框架，通过语义保持的重写规则生成仅在分词上不同的代码变体，分析多种代码大模型在不同分词下的行为变化。

Result: 实验显示，即使是微小的格式变化（如空格、命名）也会导致九个主流代码大模型（包括30B以上参数模型）行为显著变化；问题源自早期嵌入层中子词划分与语法标记边界的不匹配。

Conclusion: 分词与语法的不匹配是代码大模型可靠性的隐蔽障碍，未来应发展语法感知的分词方法。

Abstract: Large language models (LLMs) for code rely on subword tokenizers, such as
byte-pair encoding (BPE), learned from mixed natural language text and
programming language code but driven by statistics rather than grammar. As a
result, semantically identical code snippets can be tokenized differently
depending on superficial factors such as whitespace or identifier naming. To
measure the impact of this misalignment, we introduce TokDrift, a framework
that applies semantic-preserving rewrite rules to create code variants
differing only in tokenization. Across nine code LLMs, including large ones
with over 30B parameters, even minor formatting changes can cause substantial
shifts in model behavior. Layer-wise analysis shows that the issue originates
in early embeddings, where subword segmentation fails to capture grammar token
boundaries. Our findings identify misaligned tokenization as a hidden obstacle
to reliable code understanding and generation, highlighting the need for
grammar-aware tokenization for future code LLMs.

</details>


### [224] [Attention Is All You Need for KV Cache in Diffusion LLMs](https://arxiv.org/abs/2510.14973)
*Quan Nguyen-Tri,Mukul Ranjan,Zhiqiang Shen*

Main category: cs.CL

TL;DR: 提出Elastic-Cache，一种无需训练、架构无关的自适应KV缓存重计算策略，通过注意力感知和深度感知机制，在保持生成质量的同时显著加速扩散大语言模型的解码过程。


<details>
  <summary>Details</summary>
Motivation: 现有扩散大语言模型在每一步去噪中对所有token重新计算QKV，导致大量冗余，尤其是在浅层中KV状态变化较小，需设计更高效的缓存重计算策略以平衡准确性与延迟。

Method: 基于对MASK token作用、KV动态随深度增加以及最关注token KV漂移最小的观察，提出Elastic-Cache，结合注意力感知的漂移检测（决定何时刷新）和深度感知的刷新调度（决定从哪一层开始刷新），实现自适应、分层的缓存更新。

Result: 在LLaDA系列模型上实验显示，相比基线方法，Elastic-Cache在GSM8K上加速8.7倍（256 token），长序列加速45.1倍，HumanEval加速4.8倍，吞吐量提升达6.8倍，且保持更高生成准确率。

Conclusion: Elastic-Cache有效减少了扩散LLM解码中的冗余计算，在多种任务和模型上实现了显著加速和高生成质量，推动了扩散大语言模型的实际部署。

Abstract: This work studies how to adaptively recompute key-value (KV) caches for
diffusion large language models (DLMs) to maximize prediction accuracy while
minimizing decoding latency. Prior methods' decoders recompute QKV for all
tokens at every denoising step and layer, despite KV states changing little
across most steps, especially in shallow layers, leading to substantial
redundancy. We make three observations: (1) distant ${\bf MASK}$ tokens
primarily act as a length-bias and can be cached block-wise beyond the active
prediction window; (2) KV dynamics increase with depth, suggesting that
selective refresh starting from deeper layers is sufficient; and (3) the
most-attended token exhibits the smallest KV drift, providing a conservative
lower bound on cache change for other tokens. Building on these, we propose
${\bf Elastic-Cache}$, a training-free, architecture-agnostic strategy that
jointly decides ${when}$ to refresh (via an attention-aware drift test on the
most-attended token) and ${where}$ to refresh (via a depth-aware schedule that
recomputes from a chosen layer onward while reusing shallow-layer caches and
off-window MASK caches). Unlike fixed-period schemes, Elastic-Cache performs
adaptive, layer-aware cache updates for diffusion LLMs, reducing redundant
computation and accelerating decoding with negligible loss in generation
quality. Experiments on LLaDA-Instruct, LLaDA-1.5, and LLaDA-V across
mathematical reasoning and code generation tasks demonstrate consistent
speedups: $8.7\times$ on GSM8K (256 tokens), $45.1\times$ on longer sequences,
and $4.8\times$ on HumanEval, while consistently maintaining higher accuracy
than the baseline. Our method achieves significantly higher throughput
($6.8\times$ on GSM8K) than existing confidence-based approaches while
preserving generation quality, enabling practical deployment of diffusion LLMs.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [225] [Do Joint Language-Audio Embeddings Encode Perceptual Timbre Semantics?](https://arxiv.org/abs/2510.14249)
*Qixin Deng,Bryan Pardo,Thrasyvoulos N Pappas*

Main category: cs.SD

TL;DR: 本文评估了三种语言-音频联合嵌入模型（MS-CLAP、LAION-CLAP、MuQ-MuLan）在捕捉音色感知维度方面的能力，发现LAION-CLAP在乐器声音和音频效果上均最一致地与人类感知的音色语义对齐。


<details>
  <summary>Details</summary>
Motivation: 尽管现有联合语言-音频嵌入模型在对齐文本与音频方面表现良好，但其是否符合人类对音色（如亮度、粗糙度、温暖感）的感知仍不清楚，需系统评估。

Method: 通过实验评估MS-CLAP、LAION-CLAP和MuQ-MuLan三种模型在乐器声和音频效果上对人类音色感知维度的建模能力，并与人类感知数据进行对比分析。

Result: LAION-CLAP在捕捉人类感知的音色语义方面表现最稳定且优于其他两种模型，尤其在跨声音类型任务中表现出更强的一致性。

Conclusion: LAION-CLAP是当前最能反映人类音色感知的联合语言-音频嵌入模型，为未来基于感知的音频-语言应用提供了有力支持。

Abstract: Understanding and modeling the relationship between language and sound is
critical for applications such as music information retrieval,text-guided music
generation, and audio captioning. Central to these tasks is the use of joint
language-audio embedding spaces, which map textual descriptions and auditory
content into a shared embedding space. While multimodal embedding models such
as MS-CLAP, LAION-CLAP, and MuQ-MuLan have shown strong performance in aligning
language and audio, their correspondence to human perception of timbre, a
multifaceted attribute encompassing qualities such as brightness, roughness,
and warmth, remains underexplored. In this paper, we evaluate the above three
joint language-audio embedding models on their ability to capture perceptual
dimensions of timbre. Our findings show that LAION-CLAP consistently provides
the most reliable alignment with human-perceived timbre semantics across both
instrumental sounds and audio effects.

</details>


### [226] [Beat Detection as Object Detection](https://arxiv.org/abs/2510.14391)
*Jaehoon Ahn,Moon-Ryul Jung*

Main category: cs.SD

TL;DR: 将节拍和下拍检测任务重新定义为时序“对象”检测问题，采用改进的FCOS检测器实现有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 现有模型输出帧级激活，难以直接得到清晰的节拍位置；通过对象检测框架可更好建模节拍的时序结构。

Method: 借鉴计算机视觉中的FCOS检测器，将其主干网络替换为WaveBeat的时域特征提取器，并引入特征金字塔网络（FPN）捕捉多尺度时序模式，输出带有置信度的重叠节拍区间，再通过非极大值抑制（NMS）筛选最终预测。

Result: 在标准音乐数据集上达到具有竞争力的结果，表明对象检测方法能有效建模音乐节拍。

Conclusion: 将节拍跟踪视为对象检测任务是可行且有效的，NMS可替代传统DBN后处理，流程更简洁、启发性更少。

Abstract: Recent beat and downbeat tracking models (e.g., RNNs, TCNs, Transformers)
output frame-level activations. We propose reframing this task as object
detection, where beats and downbeats are modeled as temporal "objects."
Adapting the FCOS detector from computer vision to 1D audio, we replace its
original backbone with WaveBeat's temporal feature extractor and add a Feature
Pyramid Network to capture multi-scale temporal patterns. The model predicts
overlapping beat/downbeat intervals with confidence scores, followed by
non-maximum suppression (NMS) to select final predictions. This NMS step serves
a similar role to DBNs in traditional trackers, but is simpler and less
heuristic. Evaluated on standard music datasets, our approach achieves
competitive results, showing that object detection techniques can effectively
model musical beats with minimal adaptation.

</details>


### [227] [Big Data Approaches to Bovine Bioacoustics: A FAIR-Compliant Dataset and Scalable ML Framework for Precision Livestock Welfare](https://arxiv.org/abs/2510.14443)
*Mayuri Kate,Suresh Neethirajan*

Main category: cs.SD

TL;DR: 本文介绍了一个大规模、生态真实的牛类发声数据集及配套处理框架，推动基于生物声学的精准畜牧养殖。


<details>
  <summary>Details</summary>
Motivation: 解决生物声学数据在精准畜牧中因计算复杂性和生态有效性挑战而未被充分利用的问题。

Method: 在三个商业奶牛场使用多麦克风阵列采集569个标注片段，覆盖48种行为类别，并通过领域知情增强扩展至2900个样本；构建分布式处理框架，集成iZotope RX去噪、音视频同步和24种声学特征工程。

Result: 初步基准测试显示出在发情检测、痛苦分类和母性交流方面具有明显的类别级声学模式，数据集具备真实养殖环境的声学特征，适合实地部署。

Conclusion: 该工作为动物中心的人工智能提供了基础，通过标准化管道和元数据共享，推动可重复研究，支持联合国可持续发展目标9，实现智能、福利优化的畜牧业系统。

Abstract: The convergence of IoT sensing, edge computing, and machine learning is
transforming precision livestock farming. Yet bioacoustic data streams remain
underused because of computational complexity and ecological validity
challenges. We present one of the most comprehensive bovine vocalization
datasets to date, with 569 curated clips covering 48 behavioral classes,
recorded across three commercial dairy farms using multiple microphone arrays
and expanded to 2900 samples through domain informed augmentation. This FAIR
compliant resource addresses major Big Data challenges - volume (90 hours of
recordings, 65.6 GB), variety (multi farm and multi zone acoustics), velocity
(real time processing), and veracity (noise robust feature extraction). Our
distributed processing framework integrates advanced denoising using iZotope
RX, multimodal synchronization through audio and video alignment, and
standardized feature engineering with 24 acoustic descriptors generated from
Praat, librosa, and openSMILE. Preliminary benchmarks reveal distinct class
level acoustic patterns for estrus detection, distress classification, and
maternal communication. The datasets ecological realism, reflecting authentic
barn acoustics rather than controlled settings, ensures readiness for field
deployment. This work establishes a foundation for animal centered AI, where
bioacoustic data enable continuous and non invasive welfare assessment at
industrial scale. By releasing standardized pipelines and detailed metadata, we
promote reproducible research that connects Big Data analytics, sustainable
agriculture, and precision livestock management. The framework supports UN SDG
9, showing how data science can turn traditional farming into intelligent,
welfare optimized systems that meet global food needs while upholding ethical
animal care.

</details>


### [228] [AudioEval: Automatic Dual-Perspective and Multi-Dimensional Evaluation of Text-to-Audio-Generation](https://arxiv.org/abs/2510.14570)
*Hui Wang,Jinghua Zhao,Cheng Liu,Yuhang Jia,Haoqin Sun,Jiaming Zhou,Yong Qin*

Main category: cs.SD

TL;DR: 提出AudioEval，首个大规模文本到音频（TTA）评估数据集，及基于此的多模态评分模型Qwen-DisQA，可有效预测人类感知质量评分。


<details>
  <summary>Details</summary>
Motivation: 现有TTA生成质量评估依赖昂贵且有限的人类评分，客观指标难以全面反映感知质量，缺乏统一评估标准。

Method: 构建包含4200个音频样本和12.6万评分的AudioEval数据集，涵盖24种系统和五个感知维度；基于此训练多模态模型Qwen-DisQA，联合处理文本提示和生成音频以预测评分。

Result: Qwen-DisQA在预测人类类似质量评分方面表现有效，具备高可靠性与可扩展性；AudioEval为专家与非专家共同标注，具多样性与高质量。

Conclusion: AudioEval填补了TTA评估数据的空白，Qwen-DisQA为自动化、细粒度的音频生成质量评估提供了有效解决方案，推动TTA技术发展。

Abstract: Text-to-audio (TTA) is rapidly advancing, with broad potential in virtual
reality, accessibility, and creative media. However, evaluating TTA quality
remains difficult: human ratings are costly and limited, while existing
objective metrics capture only partial aspects of perceptual quality. To
address this gap, we introduce AudioEval, the first large-scale TTA evaluation
dataset, containing 4,200 audio samples from 24 systems with 126,000 ratings
across five perceptual dimensions, annotated by both experts and non-experts.
Based on this resource, we propose Qwen-DisQA, a multimodal scoring model that
jointly processes text prompts and generated audio to predict human-like
quality ratings. Experiments show its effectiveness in providing reliable and
scalable evaluation. The dataset will be made publicly available to accelerate
future research.

</details>


### [229] [SpeechLLM-as-Judges: Towards General and Interpretable Speech Quality Evaluation](https://arxiv.org/abs/2510.14664)
*Hui Wang,Jinghua Zhao,Yifan Yang,Shujie Liu,Junyang Chen,Yanzhe Zhang,Shiwan Zhao,Jinyu Li,Jiaming Zhou,Haoqin Sun,Yan Lu,Yong Qin*

Main category: cs.SD

TL;DR: 提出SpeechLLM-as-Judges新范式，利用大语言模型进行结构化、可解释的语音质量评估，并发布大规模数据集SpeechEval和模型SQ-LLM。


<details>
  <summary>Details</summary>
Motivation: 现有语音质量评估方法依赖标量评分或二元判断，缺乏可解释性和跨任务、跨语言的泛化能力。

Method: 构建包含32,207个多语言语音片段和128,754个标注的SpeechEval数据集，训练具备思维链推理和奖励优化的语音质量感知大模型SQ-LLM。

Result: SQ-LLM在多种任务和语言下均表现出色，验证了LLM用于结构化语音评估的有效性。

Conclusion: SpeechLLM-as-Judges范式有望推动可解释、通用的语音质量评估发展。

Abstract: Generative speech technologies are progressing rapidly, but evaluating the
perceptual quality of synthetic speech remains a core challenge. Existing
methods typically rely on scalar scores or binary decisions, which lack
interpretability and generalization across tasks and languages. We present
SpeechLLM-as-Judges, a new paradigm for enabling large language models (LLMs)
to conduct structured and explanation-based speech quality evaluation. To
support this direction, we introduce SpeechEval, a large-scale dataset
containing 32,207 multilingual speech clips and 128,754 annotations spanning
four tasks: quality assessment, pairwise comparison, improvement suggestion,
and deepfake detection. Based on this resource, we develop SQ-LLM, a
speech-quality-aware LLM trained with chain-of-thought reasoning and reward
optimization to improve capability. Experimental results show that SQ-LLM
delivers strong performance across tasks and languages, revealing the potential
of this paradigm for advancing speech quality evaluation. Relevant resources
will be open-sourced.

</details>


### [230] [TASLA: Text-Aligned Speech Tokens with Multiple Layer-Aggregation](https://arxiv.org/abs/2510.14934)
*Ming-Hao Hsu,Liang-Hsuan Tseng,Hung-yi Lee,Zhizheng Wu*

Main category: cs.SD

TL;DR: TASLA是一种文本对齐的语音分词框架，通过多层动态注意力和有限标量量化，在低帧率下有效保留语音韵律和音质。


<details>
  <summary>Details</summary>
Motivation: 现有文本对齐语音分词方法（如TASTE）在低帧率下难以保留语音的声学细节，尤其是在压缩特征时容易丢失韵律信息，本文旨在解决这一音质与语言模型兼容性之间的权衡问题。

Method: 提出TASLA框架，包含两个关键组件：多层动态注意力（MLDA），允许每个文本位置自适应地融合冻结语音编码器的浅层和深层特征；有限标量量化（FSQ），实现每维度离散化并优化训练稳定性。

Result: 在约2.62 Hz的低帧率下，TASLA在LibriSpeech、EXPRESSO和Voxceleb等多个数据集上均优于TASTE，显著提升韵律表现并实现具竞争力的重建质量；动态层混合与频谱通量相关，解释了其在高压缩下仍能保留韵律的原因。

Conclusion: TASLA通过多层特征自适应融合和高效量化策略，有效解决了文本对齐语音分词中音质与效率的矛盾，为低帧率语音合成提供了更优的分词方案。

Abstract: We propose Text-Aligned Speech Tokens with Multiple Layer-Aggregation
(TASLA), which is a text-aligned speech tokenization framework that aims to
address the problem that under a low-frame-rate and text-aligned regime,
single-source speech tokens may lose acoustic details during reconstruction. On
the other hand, this paper further explains how different encoder layers
collaborate to capture comprehensive acoustic features for tokenization.
Previous work, TASTE, proposed the text-aligned speech tokenization framework,
which is a LM-friendly architecture, but struggles to capture acoustic details.
We address this trade-off with two components: Multi-Layer Dynamic Attention
(MLDA), which lets each text position adaptively mix shallow/deep features from
a frozen speech encoder, and Finite Scalar Quantization (FSQ), a simple
per-dimension discretization with smooth optimization. At about 2.62 Hz
(tokens/s), TASLA consistently improves prosody and achieves competitive
quality over TASTE on in-domain (LibriSpeech) and OOD (EXPRESSO, Voxceleb)
sets. We further demonstrate that dynamic layer mixing is correlated with
spectral flux and explains why MLDA preserves prosody under a low frame rate
with extreme feature compression.

</details>

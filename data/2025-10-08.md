<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 74]
- [cs.CL](#cs.CL) [Total: 93]
- [cs.SD](#cs.SD) [Total: 14]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Attention-Enhanced Prototypical Learning for Few-Shot Infrastructure Defect Segmentation](https://arxiv.org/abs/2510.05266)
*Christina Thrainer,Md Meftahul Ferdaus,Mahdi Abdelguerfi,Christian Guetl,Steven Sloan,Kendall N. Niles,Ken Pathak*

Main category: cs.CV

TL;DR: 提出了一种用于涵洞和下水道缺陷少样本语义分割的增强特征金字塔网络（E-FPN）框架，结合原型学习和注意力机制，在小样本条件下实现高效准确的缺陷识别。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法需要大量标注数据，难以快速适应新的缺陷类别，而在基础设施检测中获取标注数据昂贵且耗时，因此需要一种能在少量样本下有效学习新缺陷类型的模型。

Method: 提出E-FPN框架，包含三个关键部分：（1）采用InceptionSepConv和深度可分离卷积的自适应编码器，实现高效的多尺度特征提取；（2）结合掩码平均池化的原型学习，从小样本支持集中生成强代表性原型；（3）引入全局自注意力、局部自注意力和交叉注意力机制，增强特征表示能力。

Result: 在基础设施检测数据集上实验表明，该方法在8类5样本训练配置下，2类测试中达到82.55%的F1分数和72.26%的mIoU；其中自注意力机制贡献最大，相较基线提升2.57% F1分数和2.9% mIoU。

Conclusion: 所提出的E-FPN框架能有效应对基础设施检测中样本稀缺的问题，可快速学习新缺陷类型，有助于实现更高效、经济的关键基础设施维护方案。

Abstract: Few-shot semantic segmentation is vital for deep learning-based
infrastructure inspection applications, where labeled training examples are
scarce and expensive. Although existing deep learning frameworks perform well,
the need for extensive labeled datasets and the inability to learn new defect
categories with little data are problematic. We present our Enhanced Feature
Pyramid Network (E-FPN) framework for few-shot semantic segmentation of culvert
and sewer defect categories using a prototypical learning framework. Our
approach has three main contributions: (1) adaptive E-FPN encoder using
InceptionSepConv blocks and depth-wise separable convolutions for efficient
multi-scale feature extraction; (2) prototypical learning with masked average
pooling for powerful prototype generation from small support examples; and (3)
attention-based feature representation through global self-attention, local
self-attention and cross-attention. Comprehensive experimentation on
challenging infrastructure inspection datasets illustrates that the method
achieves excellent few-shot performance, with the best configuration being
8-way 5-shot training configuration at 82.55% F1-score and 72.26% mIoU in 2-way
classification testing. The self-attention method had the most significant
performance improvements, providing 2.57% F1-score and 2.9% mIoU gain over
baselines. Our framework addresses the critical need to rapidly respond to new
defect types in infrastructure inspection systems with limited new training
data that lead to more efficient and economical maintenance plans for critical
infrastructure systems.

</details>


### [2] [SkinMap: Weighted Full-Body Skin Segmentation for Robust Remote Photoplethysmography](https://arxiv.org/abs/2510.05296)
*Zahra Maleki,Amirhossein Akbari,Amirhossein Binesh,Babak Khalaj*

Main category: cs.CV

TL;DR: 提出一种新的皮肤分割技术，用于提升远程光电容积描记法（rPPG）在复杂条件下的信号提取质量，具有更强的运动鲁棒性和对多样皮肤色调的高检测精度。


<details>
  <summary>Details</summary>
Motivation: 传统rPPG技术对光照和运动敏感，且易受非皮肤区域干扰，需要更鲁棒的皮肤区域分割方法以提升信号质量和适用性。

Method: 提出一种优先提取全身皮肤区域的新型皮肤分割技术，排除嘴、眼、头发等干扰区域，并在公开数据集和新构建的SYNC-rPPG数据集上进行评估。

Result: 该方法在说话、头部转动等挑战性条件下仍能准确捕获心跳信号，保持较低的平均绝对误差（MAE），优于其他现有方法，且对多种肤色均表现高检测精度。

Conclusion: 所提方法提升了rPPG技术在真实环境中的鲁棒性和普适性，具有广泛应用于远程健康监测等场景的潜力。

Abstract: Remote photoplethysmography (rPPG) is an innovative method for monitoring
heart rate and vital signs by using a simple camera to record a person, as long
as any part of their skin is visible. This low-cost, contactless approach helps
in remote patient monitoring, emotion analysis, smart vehicle utilization, and
more. Over the years, various techniques have been proposed to improve the
accuracy of this technology, especially given its sensitivity to lighting and
movement. In the unsupervised pipeline, it is necessary to first select skin
regions from the video to extract the rPPG signal from the skin color changes.
We introduce a novel skin segmentation technique that prioritizes skin regions
to enhance the quality of the extracted signal. It can detect areas of skin all
over the body, making it more resistant to movement, while removing areas such
as the mouth, eyes, and hair that may cause interference. Our model is
evaluated on publicly available datasets, and we also present a new dataset,
called SYNC-rPPG, to better represent real-world conditions. The results
indicate that our model demonstrates a prior ability to capture heartbeats in
challenging conditions, such as talking and head rotation, and maintain the
mean absolute error (MAE) between predicted and actual heart rates, while other
methods fail to do so. In addition, we demonstrate high accuracy in detecting a
diverse range of skin tones, making this technique a promising option for
real-world applications.

</details>


### [3] [DeepAf: One-Shot Spatiospectral Auto-Focus Model for Digital Pathology](https://arxiv.org/abs/2510.05315)
*Yousef Yeganeh,Maximilian Frantzen,Michael Lee,Kun-Hsing Yu,Nassir Navab,Azade Farshad*

Main category: cs.CV

TL;DR: 提出了一种结合空间和光谱特征的新型自动对焦框架DeepAf，可在单次成像下实现快速、准确、跨实验室泛化的显微聚焦，显著降低数字病理学的成本与时间开销。


<details>
  <summary>Details</summary>
Motivation: 全玻片成像扫描仪成本高昂，现有低成本自动显微方案存在对焦不一致、耗时长或泛化能力差等问题，亟需一种高效、准确且普适的自动对焦解决方案。

Method: 提出DeepAf，一种融合空间与光谱特征的混合深度学习架构，通过单张图像回归最佳对焦距离，并动态调整显微镜控制参数，实现快速精准对焦。

Result: 相比基于焦栈的方法对焦时间减少80%，对焦精度达0.18μm，跨实验室错误率仅0.72%，90%预测在景深范围内；在536个脑组织样本中，4倍放大下癌症分类AUC达0.90。

Conclusion: DeepAf实现了高效、准确且具良好泛化的自动对焦，结合常规显微镜可构建低成本实时数字病理系统，显著提升资源受限环境下的病理诊断可及性。

Abstract: While Whole Slide Imaging (WSI) scanners remain the gold standard for
digitizing pathology samples, their high cost limits accessibility in many
healthcare settings. Other low-cost solutions also face critical limitations:
automated microscopes struggle with consistent focus across varying tissue
morphology, traditional auto-focus methods require time-consuming focal stacks,
and existing deep-learning approaches either need multiple input images or lack
generalization capability across tissue types and staining protocols. We
introduce a novel automated microscopic system powered by DeepAf, a novel
auto-focus framework that uniquely combines spatial and spectral features
through a hybrid architecture for single-shot focus prediction. The proposed
network automatically regresses the distance to the optimal focal point using
the extracted spatiospectral features and adjusts the control parameters for
optimal image outcomes. Our system transforms conventional microscopes into
efficient slide scanners, reducing focusing time by 80% compared to stack-based
methods while achieving focus accuracy of 0.18 {\mu}m on the same-lab samples,
matching the performance of dual-image methods (0.19 {\mu}m) with half the
input requirements. DeepAf demonstrates robust cross-lab generalization with
only 0.72% false focus predictions and 90% of predictions within the depth of
field. Through an extensive clinical study of 536 brain tissue samples, our
system achieves 0.90 AUC in cancer classification at 4x magnification, a
significant achievement at lower magnification than typical 20x WSI scans. This
results in a comprehensive hardware-software design enabling accessible,
real-time digital pathology in resource-constrained settings while maintaining
diagnostic accuracy.

</details>


### [4] [Fine-Tuned CNN-Based Approach for Multi-Class Mango Leaf Disease Detection](https://arxiv.org/abs/2510.05326)
*Jalal Ahmmed,Faruk Ahmed,Rashedul Hasan Shohan,Md. Mahabub Rana,Mahdi Hasan*

Main category: cs.CV

TL;DR: 该研究采用五种预训练卷积神经网络对八类芒果叶片病害进行多分类识别，DenseNet201在微调后表现最佳，准确率达到99.33%。


<details>
  <summary>Details</summary>
Motivation: 芒果是南亚重要经济作物，但叶部病害严重影响其产量与品质，亟需高效、准确的病害识别方法以支持智能农业应用。

Method: 采用迁移学习策略，对DenseNet201、InceptionV3、ResNet152V2、SeResNet152和Xception五种模型进行微调，基于标准指标（如准确率、精确率、召回率、F1分数和混淆矩阵）评估其在八类芒果叶病识别中的性能。

Result: DenseNet201表现最优，准确率达99.33%，在识别切叶象甲和细菌性溃疡方面表现突出；ResNet152V2和SeResNet152也表现良好，而InceptionV3和Xception在视觉相似病害（如煤污病和白粉病）上表现较差。训练与验证曲线显示高性能模型收敛稳定。

Conclusion: 微调后的迁移学习模型，特别是DenseNet201，能够实现精确且可靠的多类别芒果叶病检测，具备在智能农业中应用的潜力。

Abstract: Mango is an important fruit crop in South Asia, but its cultivation is
frequently hampered by leaf diseases that greatly impact yield and quality.
This research examines the performance of five pre-trained convolutional neural
networks, DenseNet201, InceptionV3, ResNet152V2, SeResNet152, and Xception, for
multi-class identification of mango leaf diseases across eight classes using a
transfer learning strategy with fine-tuning. The models were assessed through
standard evaluation metrics, such as accuracy, precision, recall, F1-score, and
confusion matrices. Among the architectures tested, DenseNet201 delivered the
best results, achieving 99.33% accuracy with consistently strong metrics for
individual classes, particularly excelling in identifying Cutting Weevil and
Bacterial Canker. Moreover, ResNet152V2 and SeResNet152 provided strong
outcomes, whereas InceptionV3 and Xception exhibited lower performance in
visually similar categories like Sooty Mould and Powdery Mildew. The training
and validation plots demonstrated stable convergence for the highest-performing
models. The capability of fine-tuned transfer learning models, for precise and
dependable multi-class mango leaf disease detection in intelligent agricultural
applications.

</details>


### [5] [Mitigating Diffusion Model Hallucinations with Dynamic Guidance](https://arxiv.org/abs/2510.05356)
*Kostas Triaridis,Alexandros Graikos,Aggelina Chatziagapi,Grigorios G. Chrysos,Dimitris Samaras*

Main category: cs.CV

TL;DR: 提出动态引导方法，生成时选择性锐化得分函数以减少扩散模型的幻觉问题，同时保留有效的语义变化。


<details>
  <summary>Details</summary>
Motivation: 扩散模型常产生结构不一致的幻觉样本，源于数据分布模式间的过度平滑，但完全消除插值会牺牲生成多样性，因此需要更精细的解决方案。

Method: 引入动态引导（Dynamic Guidance），仅在预定义的易产生伪影方向上选择性锐化得分函数，抑制幻觉同时保留有意义的语义插值。

Result: 在受控和自然图像数据集上显著减少幻觉，生成质量明显优于基线方法。

Conclusion: 动态引导是首个在生成时针对性解决扩散模型幻觉的方法，兼顾生成真实性与多样性。

Abstract: Diffusion models, despite their impressive demos, often produce hallucinatory
samples with structural inconsistencies that lie outside of the support of the
true data distribution. Such hallucinations can be attributed to excessive
smoothing between modes of the data distribution. However, semantic
interpolations are often desirable and can lead to generation diversity, thus
we believe a more nuanced solution is required. In this work, we introduce
Dynamic Guidance, which tackles this issue. Dynamic Guidance mitigates
hallucinations by selectively sharpening the score function only along the
pre-determined directions known to cause artifacts, while preserving valid
semantic variations. To our knowledge, this is the first approach that
addresses hallucinations at generation time rather than through post-hoc
filtering. Dynamic Guidance substantially reduces hallucinations on both
controlled and natural image datasets, significantly outperforming baselines.

</details>


### [6] [LightCache: Memory-Efficient, Training-Free Acceleration for Video Generation](https://arxiv.org/abs/2510.05367)
*Yang Xiao,Gen Li,Kaiyuan Deng,Yushu Wu,Zheng Zhan,Yanzhi Wang,Xiaolong Ma,Bo Hui*

Main category: cs.CV

TL;DR: 提出三种阶段特定的策略来减少基于缓存加速方法中的内存消耗，在不显著影响生成质量的前提下实现了更快的推理速度和更低的内存占用。


<details>
  <summary>Details</summary>
Motivation: 现有的基于缓存的加速方法在视频生成扩散模型推理过程中会导致显著的内存增长，尤其是在去噪和解码阶段，限制了训练免费加速技术的应用。

Method: 将推理过程分解为编码、去噪和解码三个阶段，分析各阶段特性，提出异步缓存交换、特征分块和切片解码三种策略以降低内存消耗，并确保引入的时间开销低于加速收益。

Result: 相比基线方法，该方法在保持生成质量基本不变的情况下，显著降低了内存使用，并提高了推理速度。

Conclusion: 通过阶段特定的内存优化策略，有效解决了训练免费加速中内存激增的问题，为扩散模型的高效视频生成提供了实用解决方案。

Abstract: Training-free acceleration has emerged as an advanced research area in video
generation based on diffusion models. The redundancy of latents in diffusion
model inference provides a natural entry point for acceleration. In this paper,
we decompose the inference process into the encoding, denoising, and decoding
stages, and observe that cache-based acceleration methods often lead to
substantial memory surges in the latter two stages. To address this problem, we
analyze the characteristics of inference across different stages and propose
stage-specific strategies for reducing memory consumption: 1) Asynchronous
Cache Swapping. 2) Feature chunk. 3) Slicing latents to decode. At the same
time, we ensure that the time overhead introduced by these three strategies
remains lower than the acceleration gains themselves. Compared with the
baseline, our approach achieves faster inference speed and lower memory usage,
while maintaining quality degradation within an acceptable range. The Code is
available at https://github.com/NKUShaw/LightCache .

</details>


### [7] [See the past: Time-Reversed Scene Reconstruction from Thermal Traces Using Visual Language Models](https://arxiv.org/abs/2510.05408)
*Kebin Contreras,Luis Toscano-Palomino,Mauro Dalla Mura,Jorge Bacca*

Main category: cs.CV

TL;DR: 提出了一种基于RGB-热成像配对图像的时间反向重建框架，利用视觉-语言模型与约束扩散过程，重建数秒至120秒前的场景状态。


<details>
  <summary>Details</summary>
Motivation: 通过热成像中残留的人体热迹推断近期活动，在法医和场景分析中有重要应用价值，而传统RGB相机无法捕捉此类信息。

Method: 结合两个视觉-语言模型（VLMs）与约束扩散过程：一个VLM生成场景描述，另一个指导图像重建，确保语义与结构一致性，利用配对的RGB和热图像进行时间反向重建。

Result: 在三个受控场景中验证，可重建最多120秒前的合理场景帧，证明了从热痕迹进行时间反向成像的可行性。

Conclusion: 该方法为从热残差中恢复过去场景提供了新途径，是实现热感知时间反向成像的初步但重要的进展。

Abstract: Recovering the past from present observations is an intriguing challenge with
potential applications in forensics and scene analysis. Thermal imaging,
operating in the infrared range, provides access to otherwise invisible
information. Since humans are typically warmer (37 C -98.6 F) than their
surroundings, interactions such as sitting, touching, or leaning leave residual
heat traces. These fading imprints serve as passive temporal codes, allowing
for the inference of recent events that exceed the capabilities of RGB cameras.
This work proposes a time-reversed reconstruction framework that uses paired
RGB and thermal images to recover scene states from a few seconds earlier. The
proposed approach couples Visual-Language Models (VLMs) with a constrained
diffusion process, where one VLM generates scene descriptions and another
guides image reconstruction, ensuring semantic and structural consistency. The
method is evaluated in three controlled scenarios, demonstrating the
feasibility of reconstructing plausible past frames up to 120 seconds earlier,
providing a first step toward time-reversed imaging from thermal traces.

</details>


### [8] [Personalizing Retrieval using Joint Embeddings or "the Return of Fluffy"](https://arxiv.org/abs/2510.05411)
*Bruno Korbar,Andrew Zisserman*

Main category: cs.CV

TL;DR: 提出一种名为pi-map的可训练映射网络，将局部图像嵌入转换为文本标记，结合自然语言查询实现基于CLIP的图像检索，显著提升个性化检索性能。


<details>
  <summary>Details</summary>
Motivation: 实现结合图像中特定物体实例与自然语言描述的复合查询图像检索，例如基于图像中的特定对象及其动作或位置进行检索。

Method: 设计一个映射网络pi-map，将对象实例的局部图像嵌入转换为文本标记，与文本查询结合后输入冻结的CLIP文本和图像编码器进行检索。该映射仅需对每个对象实例进行一次训练。

Result: 在两个评估个性化检索的基准上，该方法超越了现有技术，达到新的最优性能。

Conclusion: 通过可训练的映射网络将图像嵌入转换为兼容CLIP的文本标记，能有效支持基于实例和文本描述的复合查询图像检索，且训练高效、性能优越。

Abstract: The goal of this paper is to be able to retrieve images using a compound
query that combines object instance information from an image, with a natural
text description of what that object is doing or where it is. For example, to
retrieve an image of "Fluffy the unicorn (specified by an image) on someone's
head". To achieve this we design a mapping network that can "translate" from a
local image embedding (of the object instance) to a text token, such that the
combination of the token and a natural language query is suitable for CLIP
style text encoding, and image retrieval. Generating a text token in this
manner involves a simple training procedure, that only needs to be performed
once for each object instance. We show that our approach of using a trainable
mapping network, termed pi-map, together with frozen CLIP text and image
encoders, improves the state of the art on two benchmarks designed to assess
personalized retrieval.

</details>


### [9] [ArchitectHead: Continuous Level of Detail Control for 3D Gaussian Head Avatars](https://arxiv.org/abs/2510.05488)
*Peizhi Yan,Rabab Ward,Qiang Tang,Shan Du*

Main category: cs.CV

TL;DR: 提出ArchitectHead，首个支持连续调节细节层级（LOD）的3D高斯点云头像框架，通过UV特征场实现高效、动态的LOD控制。


<details>
  <summary>Details</summary>
Motivation: 现有3D Gaussian Splatting头像缺乏对细节层级（LOD）的灵活调控，难以在渲染效率与视觉质量之间动态平衡。

Method: 在2D UV特征空间中参数化高斯点，构建多级可学习特征图组成的UV特征场，并通过轻量神经网络解码为3D高斯属性，通过动态重采样实现LOD控制。

Result: 在最高LOD下实现SOTA质量，在最低LOD下仅用6.2%的高斯点，质量适度下降但渲染速度近乎翻倍。

Conclusion: ArchitectHead首次实现了无需重训练的连续LOD控制，在多种重演任务中兼顾高效性与高质量。

Abstract: 3D Gaussian Splatting (3DGS) has enabled photorealistic and real-time
rendering of 3D head avatars. Existing 3DGS-based avatars typically rely on
tens of thousands of 3D Gaussian points (Gaussians), with the number of
Gaussians fixed after training. However, many practical applications require
adjustable levels of detail (LOD) to balance rendering efficiency and visual
quality. In this work, we propose "ArchitectHead", the first framework for
creating 3D Gaussian head avatars that support continuous control over LOD. Our
key idea is to parameterize the Gaussians in a 2D UV feature space and propose
a UV feature field composed of multi-level learnable feature maps to encode
their latent features. A lightweight neural network-based decoder then
transforms these latent features into 3D Gaussian attributes for rendering.
ArchitectHead controls the number of Gaussians by dynamically resampling
feature maps from the UV feature field at the desired resolutions. This method
enables efficient and continuous control of LOD without retraining.
Experimental results show that ArchitectHead achieves state-of-the-art (SOTA)
quality in self and cross-identity reenactment tasks at the highest LOD, while
maintaining near SOTA performance at lower LODs. At the lowest LOD, our method
uses only 6.2\% of the Gaussians while the quality degrades moderately (L1 Loss
+7.9\%, PSNR --0.97\%, SSIM --0.6\%, LPIPS Loss +24.1\%), and the rendering
speed nearly doubles.

</details>


### [10] [Human Action Recognition from Point Clouds over Time](https://arxiv.org/abs/2510.05506)
*James Dickens*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D点云序列的人体动作识别新方法，结合点云分割、追踪与体部分割，利用点基技术和稀疏卷积网络，在NTU RGB-D 120数据集上实现了89.3%的准确率，优于现有点云动作识别方法。


<details>
  <summary>Details</summary>
Motivation: 随着深度传感器和激光雷达的普及，利用密集3D数据进行动作识别成为一个新方向。传统方法主要依赖骨骼数据或视频，本文旨在探索基于完整3D点云的动作识别，提升识别性能并拓展应用可能。

Method: 提出一个包含人体点云分割、个体追踪和体部分割的处理流程，支持来自深度传感器和单目深度估计的点云数据；核心是一个结合点基方法与应用于体素化点云序列的稀疏卷积网络的新骨干网络，并引入表面法向量、颜色、红外强度和体部分割标签等辅助特征以提升识别精度。

Result: 在NTU RGB-D 120数据集上验证了方法的有效性，结果表明该方法与现有的骨骼动作识别算法性能相当；在融合传感器深度与估计深度的集成设置下，跨被试设置下的识别准确率达到89.3%，优于此前的点云动作识别方法。

Conclusion: 本文验证了直接使用3D点云进行动作识别的可行性与优势，所提出的框架在不依赖骨骼估计的情况下实现了高性能，为未来基于多模态3D数据的动作识别提供了新思路。

Abstract: Recent research into human action recognition (HAR) has focused predominantly
on skeletal action recognition and video-based methods. With the increasing
availability of consumer-grade depth sensors and Lidar instruments, there is a
growing opportunity to leverage dense 3D data for action recognition, to
develop a third way. This paper presents a novel approach for recognizing
actions from 3D videos by introducing a pipeline that segments human point
clouds from the background of a scene, tracks individuals over time, and
performs body part segmentation. The method supports point clouds from both
depth sensors and monocular depth estimation. At the core of the proposed HAR
framework is a novel backbone for 3D action recognition, which combines
point-based techniques with sparse convolutional networks applied to
voxel-mapped point cloud sequences. Experiments incorporate auxiliary point
features including surface normals, color, infrared intensity, and body part
parsing labels, to enhance recognition accuracy. Evaluation on the NTU RGB- D
120 dataset demonstrates that the method is competitive with existing skeletal
action recognition algorithms. Moreover, combining both sensor-based and
estimated depth inputs in an ensemble setup, this approach achieves 89.3%
accuracy when different human subjects are considered for training and testing,
outperforming previous point cloud action recognition methods.

</details>


### [11] [Be Tangential to Manifold: Discovering Riemannian Metric for Diffusion Models](https://arxiv.org/abs/2510.05509)
*Shinnosuke Saito,Takashi Matsubara*

Main category: cs.CV

TL;DR: 提出一种基于黎曼度量的噪声空间新方法，使扩散模型在数据流形上进行更自然的插值。


<details>
  <summary>Details</summary>
Motivation: 扩散模型缺乏显式的低维潜在空间，限制了对数据流形的感知分析与操作，现有插值方法未充分遵循数据流形，导致过渡不自然。

Method: 受分数函数雅可比刻画局部数据流形切空间的启发，提出在噪声空间上定义一种新的黎曼度量，使噪声空间中的测地线保持在或平行于数据流形。

Result: 在图像插值实验中，该方法相比基于密度和朴素基线方法，生成了感知上更自然、更保真的过渡结果。

Conclusion: 所提黎曼度量能有效利用扩散模型学习到的数据流形，提升插值的视觉质量和语义连贯性。

Abstract: Diffusion models are powerful deep generative models (DGMs) that generate
high-fidelity, diverse content. However, unlike classical DGMs, they lack an
explicit, tractable low-dimensional latent space that parameterizes the data
manifold. This absence limits manifold-aware analysis and operations, such as
interpolation and editing. Existing interpolation methods for diffusion models
typically follow paths through high-density regions, which are not necessarily
aligned with the data manifold and can yield perceptually unnatural
transitions. To exploit the data manifold learned by diffusion models, we
propose a novel Riemannian metric on the noise space, inspired by recent
findings that the Jacobian of the score function captures the tangent spaces to
the local data manifold. This metric encourages geodesics in the noise space to
stay within or run parallel to the learned data manifold. Experiments on image
interpolation show that our metric produces perceptually more natural and
faithful transitions than existing density-based and naive baselines.

</details>


### [12] [Teamwork: Collaborative Diffusion with Low-rank Coordination and Adaptation](https://arxiv.org/abs/2510.05532)
*Sam Sartor,Pieter Peers*

Main category: cs.CV

TL;DR: 本文提出了一种名为Teamwork的灵活高效统一方法，通过协调多个预训练扩散模型实例（即“队友”）来实现输入输出通道的扩展，并适应新任务，无需修改原始模型结构。


<details>
  <summary>Details</summary>
Motivation: 现有的通道扩展方法通常针对特定应用，难以适配不同扩散模型或新任务。需要一种通用、灵活的方法来统一解决生成和逆向图形任务中的通道扩展问题。

Method: Teamwork利用多个预训练扩散模型实例协同工作，引入一种新颖的低秩适应（LoRA）变体，联合实现模型适配与实例间协调，并支持队友的动态激活与关闭。

Result: 在图像修复、单张图像SVBRDF估计、本征分解、神经着色和本征图像合成等多种任务上验证了Teamwork的有效性与灵活性，表现出良好的性能和扩展能力。

Conclusion: Teamwork提供了一种无需修改原模型结构的通用通道扩展方案，具有良好的任务适应性、灵活性和效率，适用于多种生成与逆向图形应用。

Abstract: Large pretrained diffusion models can provide strong priors beneficial for
many graphics applications. However, generative applications such as neural
rendering and inverse methods such as SVBRDF estimation and intrinsic image
decomposition require additional input or output channels. Current solutions
for channel expansion are often application specific and these solutions can be
difficult to adapt to different diffusion models or new tasks. This paper
introduces Teamwork: a flexible and efficient unified solution for jointly
increasing the number of input and output channels as well as adapting a
pretrained diffusion model to new tasks. Teamwork achieves channel expansion
without altering the pretrained diffusion model architecture by coordinating
and adapting multiple instances of the base diffusion model (\ie, teammates).
We employ a novel variation of Low Rank-Adaptation (LoRA) to jointly address
both adaptation and coordination between the different teammates. Furthermore
Teamwork supports dynamic (de)activation of teammates. We demonstrate the
flexibility and efficiency of Teamwork on a variety of generative and inverse
graphics tasks such as inpainting, single image SVBRDF estimation, intrinsic
decomposition, neural shading, and intrinsic image synthesis.

</details>


### [13] [Seeing the Big Picture: Evaluating Multimodal LLMs' Ability to Interpret and Grade Handwritten Student Work](https://arxiv.org/abs/2510.05538)
*Owen Henkel,Bill Roberts,Doug Jaffe,Laurence Holt*

Main category: cs.CV

TL;DR: 多模态大语言模型（MLLMs）在识别和评估手写数学作业方面接近人类水平，但在理解小学生数学图解等开放性任务上仍有困难，依赖视觉描述可显著提升表现。


<details>
  <summary>Details</summary>
Motivation: 探索MLLMs在中小学手写数学作业评分与反馈中的潜力，减轻教师负担并深入理解学生的学习过程。

Method: 进行了两项实验：实验A评估MLLMs对具有明确答案的手写算术题的评分能力；实验B评估其对学生数学图解的评分能力，并比较直接分析图像与基于人工描述输入的表现。

Result: 实验A中MLLMs达到95%准确率（k=0.90），接近人类水平；实验B中直接分析图解表现差（k=0.20），但借助人工描述后一致性显著提升至k=0.47，达到人类间评分一致性水平。

Conclusion: MLLMs能较好‘看见’算术步骤，但难以理解开放式学生图解，当前在教育应用中仍需结合人类视觉描述以提升评估准确性。

Abstract: Recent advances in multimodal large language models (MLLMs) raise the
question of their potential for grading, analyzing, and offering feedback on
handwritten student classwork. This capability would be particularly beneficial
in elementary and middle-school mathematics education, where most work remains
handwritten, because seeing students' full working of a problem provides
valuable insights into their learning processes, but is extremely
time-consuming to grade. We present two experiments investigating MLLM
performance on handwritten student mathematics classwork. Experiment A examines
288 handwritten responses from Ghanaian middle school students solving
arithmetic problems with objective answers. In this context, models achieved
near-human accuracy (95%, k = 0.90) but exhibited occasional errors that human
educators would be unlikely to make. Experiment B evaluates 150 mathematical
illustrations from American elementary students, where the drawings are the
answer to the question. These tasks lack single objective answers and require
sophisticated visual interpretation as well as pedagogical judgment in order to
analyze and evaluate them. We attempted to separate MLLMs' visual capabilities
from their pedagogical abilities by first asking them to grade the student
illustrations directly, and then by augmenting the image with a detailed human
description of the illustration. We found that when the models had to analyze
the student illustrations directly, they struggled, achieving only k = 0.20
with ground truth scores, but when given human descriptions, their agreement
levels improved dramatically to k = 0.47, which was in line with human-to-human
agreement levels. This gap suggests MLLMs can "see" and interpret arithmetic
work relatively well, but still struggle to "see" student mathematical
illustrations.

</details>


### [14] [Midway Network: Learning Representations for Recognition and Motion from Latent Dynamics](https://arxiv.org/abs/2510.05558)
*Christopher Hoang,Mengye Ren*

Main category: cs.CV

TL;DR: Midway Network是一种新的自监督学习架构，首次从自然视频中同时学习物体识别和运动理解的强表示，通过扩展潜在动态建模，在语义分割和光流任务上优于先前方法。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法通常只关注物体识别或运动理解其中一个任务，而两者在感知中相辅相成，因此需要一种能同时学习两者的统一框架。

Method: 提出Midway Network，引入中层自上而下的路径推断帧间运动潜变量，结合密集前向预测目标和层次化结构，以应对自然视频中复杂多物体场景。

Result: 在两个大规模自然视频数据集上预训练后，Midway Network在语义分割和光流任务上均优于之前的自监督方法，并通过前向特征扰动分析显示其能捕捉高层对应关系。

Conclusion: Midway Network成功将潜在动态建模扩展到视觉表示学习，实现了物体识别与运动理解的统一自监督学习框架。

Abstract: Object recognition and motion understanding are key components of perception
that complement each other. While self-supervised learning methods have shown
promise in their ability to learn from unlabeled data, they have primarily
focused on obtaining rich representations for either recognition or motion
rather than both in tandem. On the other hand, latent dynamics modeling has
been used in decision making to learn latent representations of observations
and their transformations over time for control and planning tasks. In this
work, we present Midway Network, a new self-supervised learning architecture
that is the first to learn strong visual representations for both object
recognition and motion understanding solely from natural videos, by extending
latent dynamics modeling to this domain. Midway Network leverages a midway
top-down path to infer motion latents between video frames, as well as a dense
forward prediction objective and hierarchical structure to tackle the complex,
multi-object scenes of natural videos. We demonstrate that after pretraining on
two large-scale natural video datasets, Midway Network achieves strong
performance on both semantic segmentation and optical flow tasks relative to
prior self-supervised learning methods. We also show that Midway Network's
learned dynamics can capture high-level correspondence via a novel analysis
method based on forward feature perturbation.

</details>


### [15] [HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video](https://arxiv.org/abs/2510.05560)
*Hongchi Xia,Chih-Hao Lin,Hao-Yu Hsu,Quentin Leboutet,Katelyn Gao,Michael Paulitsch,Benjamin Ummenhofer,Shenlong Wang*

Main category: cs.CV

TL;DR: HoloScene 是一个新型的交互式3D重建框架，能够同时满足几何完整性、物理合理性和逼真渲染等要求，生成高质量的可交互数字孪生环境。


<details>
  <summary>Details</summary>
Motivation: 现有3D重建和场景理解方法在几何完整性、对象交互性、物理合理性或逼真渲染等方面常存在不足，难以满足虚拟现实、游戏和机器人等领域的高要求。

Method: HoloScene 采用包含几何、外观和物理属性以及层次与对象间关系的交互式场景图表示，将重建建模为融合观测数据、物理约束和生成先验的基于能量的优化问题，并通过采样探索与梯度优化相结合的混合方法高效求解。

Result: 在多个基准数据集上的评估表明，HoloScene 在几何完整性、物理稳定性和新视角渲染质量方面优于现有方法，并成功应用于交互式游戏和实时数字孪生操作。

Conclusion: HoloScene 实现了高保真、物理合理且可交互的虚拟环境重建，具有广泛的应用前景和实际有效性。

Abstract: Digitizing the physical world into accurate simulation-ready virtual
environments offers significant opportunities in a variety of fields such as
augmented and virtual reality, gaming, and robotics. However, current 3D
reconstruction and scene-understanding methods commonly fall short in one or
more critical aspects, such as geometry completeness, object interactivity,
physical plausibility, photorealistic rendering, or realistic physical
properties for reliable dynamic simulation. To address these limitations, we
introduce HoloScene, a novel interactive 3D reconstruction framework that
simultaneously achieves these requirements. HoloScene leverages a comprehensive
interactive scene-graph representation, encoding object geometry, appearance,
and physical properties alongside hierarchical and inter-object relationships.
Reconstruction is formulated as an energy-based optimization problem,
integrating observational data, physical constraints, and generative priors
into a unified, coherent objective. Optimization is efficiently performed via a
hybrid approach combining sampling-based exploration with gradient-based
refinement. The resulting digital twins exhibit complete and precise geometry,
physical stability, and realistic rendering from novel viewpoints. Evaluations
conducted on multiple benchmark datasets demonstrate superior performance,
while practical use-cases in interactive gaming and real-time digital-twin
manipulation illustrate HoloScene's broad applicability and effectiveness.
Project page: https://xiahongchi.github.io/HoloScene.

</details>


### [16] [CalibCLIP: Contextual Calibration of Dominant Semantics for Text-Driven Image Retrieval](https://arxiv.org/abs/2510.05586)
*Bin Kang,Bin Chen,Junjie Wang,Yulin Li,Junzhi Zhao,Zhuotao Tian*

Main category: cs.CV

TL;DR: 提出了一种无需训练的校准方法CalibCLIP，通过在视觉和文本空间中抑制主导token和增强判别性概念，提升文本驱动图像检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型中，少数低贡献token可能过度主导全局语义，抑制判别性特征，影响检索效果。

Method: 在视觉空间中设计对比视觉增强器（CVE），解耦视觉特征并动态抑制主导token；在文本空间中引入判别概念校准器（DCC），区分并优化通用与判别性概念表示。

Result: 在七个基准上进行了广泛实验，涵盖三类图像检索任务，均取得一致性能提升。

Conclusion: CalibCLIP有效缓解了token压制问题，增强了模型判别能力，显著提升了文本到图像检索的表现。

Abstract: Existing Visual Language Models (VLMs) suffer structural limitations where a
few low contribution tokens may excessively capture global semantics,
dominating the information aggregation process and suppressing the
discriminative features in text-driven image retrieval tasks. To address this,
we introduce \textbf{CalibCLIP}, a training-free method designed to calibrate
the suppressive effect of dominant tokens. Specifically, in the visual space,
we propose the Contrastive Visual Enhancer (CVE), which decouples visual
features into target and low information regions. Subsequently, it identifies
dominant tokens and dynamically suppresses their representations.In the textual
space, we introduce the Discriminative Concept Calibrator (DCC), which aims to
differentiate between general and discriminative concepts within the text
query. By mitigating the challenges posed by generic concepts and improving the
representations of discriminative concepts, DCC strengthens the differentiation
among similar samples. Finally, extensive experiments demonstrate consistent
improvements across seven benchmarks spanning three image retrieval tasks,
underscoring the effectiveness of CalibCLIP. Code is available at:
https://github.com/kangbin98/CalibCLIP

</details>


### [17] [Improving Chain-of-Thought Efficiency for Autoregressive Image Generation](https://arxiv.org/abs/2510.05593)
*Zeqi Gu,Markos Georgopoulos,Xiaoliang Dai,Marjan Ghazvininejad,Chu Wang,Felix Juefei-Xu,Kunpeng Li,Yujun Shi,Zecheng He,Zijian He,Jiawei Zhou,Abe Davis,Jialiang Wang*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级优化框架ShortCoTI，用于生成更简洁的思维链（CoT）推理序列，以提高图像生成效率，同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有的基于思维链推理的多模态图像生成方法容易引入冗余信息（称为视觉过思考），增加计算成本并可能导致与原始提示矛盾的细节。

Method: 提出ShortCoTI框架，在强化学习中引入自适应奖励机制，鼓励生成更简洁的CoT提示，奖励的尺度根据每个任务的估计难度动态调整。

Result: 在多个基准（T2I-CompBench, GenEval）上，CoT推理长度减少了54%，图像质量保持或略有提升；定性分析显示冗长解释和重复修正被消除，生成的提示简洁且语义丰富。

Conclusion: ShortCoTI在不损害图像保真度和视觉吸引力的前提下，显著提高了生成过程的计算效率。

Abstract: Autoregressive multimodal large language models have recently gained
popularity for image generation, driven by advances in foundation models. To
enhance alignment and detail, newer approaches employ chain-of-thought (CoT)
reasoning, expanding user inputs into elaborated prompts prior to image
synthesis. However, this strategy can introduce unnecessary redundancy -- a
phenomenon we call visual overthinking -- which increases computational costs
and can introduce details that contradict the original prompt. In this work, we
explore how to generate more concise CoT sequences for more efficient image
generation. We introduce ShortCoTI, a lightweight optimization framework that
encourages more concise CoT while preserving output image quality. ShortCoTI
rewards more concise prompts with an adaptive function that scales according to
an estimated difficulty for each task. Incorporating this reward into a
reinforcement learning paradigm reduces prompt reasoning length by 54% while
maintaining or slightly improving quality metrics across multiple benchmarks
(T2I-CompBench, GenEval). Qualitative analysis shows that our method eliminates
verbose explanations and repetitive refinements, producing reasoning prompts
that are both concise and semantically rich. As a result, ShortCoTI improves
computational efficiency without compromising the fidelity or visual appeal of
generated images.

</details>


### [18] [HOI-R1: Exploring the Potential of Multimodal Large Language Models for Human-Object Interaction Detection](https://arxiv.org/abs/2510.05609)
*Junwen Chen,Peilin Xiong,Keiji Yanai*

Main category: cs.CV

TL;DR: 本文提出HOI-R1，首次探索仅使用语言模型（MLLM）结合强化学习进行人-物交互检测（HOID），无需额外检测模块，通过纯文本推理实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有HOID方法依赖视觉-语言模型（VLMs）的先验知识，且需复杂架构与训练策略；而多模态大语言模型（MLLMs）在HOID任务中的推理能力尚未被充分挖掘。

Method: 受强化学习训练MLLM的启发，提出HOI-R1，设计了HOI推理过程和专门的HOID奖励函数，完全基于文本进行人-物交互检测，无需物体检测器等额外模块。

Result: 在HICO-DET数据集上的实验表明，HOI-R1的准确率是基线方法的两倍，并展现出强大的泛化能力。

Conclusion: 纯语言模型在HOID任务上具有巨大潜力，HOI-R1提供了一种更简洁、高效的替代方案，无需复杂的多模块融合框架。

Abstract: Recent Human-object interaction detection (HOID) methods highly require prior
knowledge from VLMs to enhance the interaction recognition capabilities. The
training strategies and model architectures for connecting the knowledge from
VLMs to the HOI instance representations from the object detector are
challenging, and the whole framework is complex for further development or
application. On the other hand, the inherent reasoning abilities of MLLMs on
human-object interaction detection are under-explored. Inspired by the recent
success of training MLLMs with reinforcement learning (RL) methods, we propose
HOI-R1 and first explore the potential of the language model on the HOID task
without any additional detection modules. We introduce an HOI reasoning process
and HOID reward functions to solve the HOID task by pure text. The results on
the HICO-DET dataset show that HOI-R1 achieves 2x the accuracy of the baseline
with great generalization ability. The source code is available at
https://github.com/cjw2021/HOI-R1.

</details>


### [19] [Efficient Conditional Generation on Scale-based Visual Autoregressive Models](https://arxiv.org/abs/2510.05610)
*Jiaqi Liu,Tao Huang,Chang Xu*

Main category: cs.CV

TL;DR: 提出了一种高效的即插即用框架ECM，通过轻量控制模块和分布式架构实现对自回归图像生成的高效可控性，显著提升了训练和推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归模型在复杂空间条件生成任务中依赖微调，训练成本高，亟需一种高效且无需微调的控制方法。

Method: 设计了Efficient Control Model（ECM），包括上下文感知注意力层、共享门控前馈网络（FFN）以及早期为中心的采样策略，并结合推理阶段的温度调度机制。

Result: 在基于尺度的自回归模型上实验表明，ECM在图像生成的保真度和多样性控制方面优于现有基线方法，同时显著降低了训练和推理成本。

Conclusion: ECM提供了一种高效、灵活的条件控制方案，适用于复杂的自回归图像生成任务，具备良好的实用性和扩展性。

Abstract: Recent advances in autoregressive (AR) models have demonstrated their
potential to rival diffusion models in image synthesis. However, for complex
spatially-conditioned generation, current AR approaches rely on fine-tuning the
pre-trained model, leading to significant training costs. In this paper, we
propose the Efficient Control Model (ECM), a plug-and-play framework featuring
a lightweight control module that introduces control signals via a distributed
architecture. This architecture consists of context-aware attention layers that
refine conditional features using real-time generated tokens, and a shared
gated feed-forward network (FFN) designed to maximize the utilization of its
limited capacity and ensure coherent control feature learning. Furthermore,
recognizing the critical role of early-stage generation in determining semantic
structure, we introduce an early-centric sampling strategy that prioritizes
learning early control sequences. This approach reduces computational cost by
lowering the number of training tokens per iteration, while a complementary
temperature scheduling during inference compensates for the resulting
insufficient training of late-stage tokens. Extensive experiments on
scale-based AR models validate that our method achieves high-fidelity and
diverse control over image generation, surpassing existing baselines while
significantly improving both training and inference efficiency.

</details>


### [20] [PointNSP: Autoregressive 3D Point Cloud Generation with Next-Scale Level-of-Detail Prediction](https://arxiv.org/abs/2510.05613)
*Ziqiao Meng,Qichao Wang,Zhiyang Dou,Zixing Song,Zhipeng Zhou,Irwin King,Peilin Zhao*

Main category: cs.CV

TL;DR: 提出了一种名为PointNSP的自回归点云生成框架，采用由粗到细的多尺度生成方式，首次在生成质量上达到并超越扩散模型，同时在效率和可扩展性上表现优异。


<details>
  <summary>Details</summary>
Motivation: 自回归模型因强制引入点序而导致难以建模点云的全局结构，性能落后于扩散模型；本文旨在克服序列偏差，提升生成质量与全局一致性。

Method: 基于细节层次（LOD）思想，设计了由粗到细的生成框架PointNSP，通过下一级尺度预测（next-scale prediction）在低分辨率保持全局结构，并逐步细化几何细节，避免固定点序问题。

Result: 在ShapeNet上实现了自回归方法中的最先进生成质量，超越多个强扩散模型基线，且在参数量、训练和推理效率上更优；在生成8192个点的密集点云时优势更明显。

Conclusion: PointNSP成功将自回归方法的性能提升至新高度，兼顾全局结构与细节生成，具备高效率和良好可扩展性，为自回归点云生成提供了新范式。

Abstract: Autoregressive point cloud generation has long lagged behind diffusion-based
approaches in quality. The performance gap stems from the fact that
autoregressive models impose an artificial ordering on inherently unordered
point sets, forcing shape generation to proceed as a sequence of local
predictions. This sequential bias emphasizes short-range continuity but
undermines the model's capacity to capture long-range dependencies, hindering
its ability to enforce global structural properties such as symmetry,
consistent topology, and large-scale geometric regularities. Inspired by the
level-of-detail (LOD) principle in shape modeling, we propose PointNSP, a
coarse-to-fine generative framework that preserves global shape structure at
low resolutions and progressively refines fine-grained geometry at higher
scales through a next-scale prediction paradigm. This multi-scale factorization
aligns the autoregressive objective with the permutation-invariant nature of
point sets, enabling rich intra-scale interactions while avoiding brittle fixed
orderings. Experiments on ShapeNet show that PointNSP establishes
state-of-the-art (SOTA) generation quality for the first time within the
autoregressive paradigm. In addition, it surpasses strong diffusion-based
baselines in parameter, training, and inference efficiency. Finally, in dense
generation with 8,192 points, PointNSP's advantages become even more
pronounced, underscoring its scalability potential.

</details>


### [21] [TFM Dataset: A Novel Multi-task Dataset and Integrated Pipeline for Automated Tear Film Break-Up Segmentation](https://arxiv.org/abs/2510.05615)
*Guangrong Wan,Jun liu,Tang tang,Lianghao Shi,Wenjun Luo,TingTing Xu*

Main category: cs.CV

TL;DR: 本文提出了首个用于多任务泪膜分析的TFM数据集，并设计了高效的TF-Net模型和集成实时分析管道TF-Collab，实现了泪膜破裂区域的自动分割与临床参数提取，推动了干眼症诊断的自动化研究。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏标注数据集和集成解决方案，泪膜破裂（TFBU）的自动分割具有挑战性。本文旨在构建一个全面的数据集并开发高效的自动化分析方法，以支持干眼症的临床诊断。

Method: 提出了TFM数据集，包含15个高分辨率视频（共6,247帧），标注了帧级分类、Placido环检测和像素级TFBU分割三个任务；设计了基于MobileOne-mini骨干网络和增强特征金字塔的轻量分割模型TF-Net；并构建了协同利用三项任务模型的集成实时分析管道TF-Collab。

Result: TF-Net在TFM分割子集上表现出良好的精度与效率平衡，适于实时应用；TF-Collab通过串联帧分类、瞳孔定位与TFBU分割实现了全流程自动化分析，实验验证了其有效性。

Conclusion: 所提出的TFM数据集、TF-Net模型与TF-Collab管道为泪膜自动分析提供了可靠基础，显著推动了眼表疾病诊断的自动化与临床适用性。

Abstract: Tear film break-up (TFBU) analysis is critical for diagnosing dry eye
syndrome, but automated TFBU segmentation remains challenging due to the lack
of annotated datasets and integrated solutions. This paper introduces the Tear
Film Multi-task (TFM) Dataset, the first comprehensive dataset for multi-task
tear film analysis, comprising 15 high-resolution videos (totaling 6,247
frames) annotated with three vision tasks: frame-level classification ('clear',
'closed', 'broken', 'blur'), Placido Ring detection, and pixel-wise TFBU area
segmentation. Leveraging this dataset, we first propose TF-Net, a novel and
efficient baseline segmentation model. TF-Net incorporates a MobileOne-mini
backbone with re-parameterization techniques and an enhanced feature pyramid
network to achieve a favorable balance between accuracy and computational
efficiency for real-time clinical applications. We further establish benchmark
performance on the TFM segmentation subset by comparing TF-Net against several
state-of-the-art medical image segmentation models. Furthermore, we design
TF-Collab, a novel integrated real-time pipeline that synergistically leverages
models trained on all three tasks of the TFM dataset. By sequentially
orchestrating frame classification for BUT determination, pupil region
localization for input standardization, and TFBU segmentation, TF-Collab fully
automates the analysis. Experimental results demonstrate the effectiveness of
the proposed TF-Net and TF-Collab, providing a foundation for future research
in ocular surface diagnostics. Our code and the TFM datasets are available at
https://github.com/glory-wan/TF-Net

</details>


### [22] [InstaGeo: Compute-Efficient Geospatial Machine Learning from Data to Deployment](https://arxiv.org/abs/2510.05617)
*Ibrahim Salihu Yusuf,Iffanice Houndayi,Rym Oualha,Mohamed Aziz Cherif,Kobby Panford-Quainoo,Arnu Pretorius*

Main category: cs.CV

TL;DR: InstaGeo是一个开源的端到端框架，通过自动化数据处理、任务特定模型蒸馏和无缝部署，将遥感影像分析流程简化，显著减小模型体积并提升效率，支持快速构建高效的地理空间AI应用。


<details>
  <summary>Details</summary>
Motivation: 现有的地理空间基础模型缺乏处理原始卫星影像的自动化数据管道，且微调后的模型体积大、部署困难，限制了其在环境与人道主义应用中的广泛使用。

Method: InstaGeo集成了三项核心技术：（1）自动化数据整理，将原始影像转化为模型可用数据集；（2）任务特定的知识蒸馏，生成轻量化、高效计算的模型；（3）一键部署为交互式网络地图应用。

Result: 蒸馏后模型体积最多缩小8倍，计算量和碳排放显著降低，精度损失极小（mIoU变化在±1.8 pp内）。在新构建的更大作物分割数据集上达到60.65% mIoU，比先前基线提高12个百分点。从原始数据到部署可在一天内完成。

Conclusion: InstaGeo通过整合数据准备、模型压缩与部署，推动地理空间AI向注重数据质量和实际应用创新的方向发展，使研究级模型转化为实用、低碳的大规模地球观测工具。

Abstract: Open-access multispectral imagery from missions like Landsat 8-9 and
Sentinel-2 has fueled the development of geospatial foundation models (GFMs)
for humanitarian and environmental applications. Yet, their deployment remains
limited by (i) the absence of automated geospatial data pipelines and (ii) the
large size of fine-tuned models. Existing GFMs lack workflows for processing
raw satellite imagery, and downstream adaptations often retain the full
complexity of the original encoder.
  We present InstaGeo, an open-source, end-to-end framework that addresses
these challenges by integrating: (1) automated data curation to transform raw
imagery into model-ready datasets; (2) task-specific model distillation to
derive compact, compute-efficient models; and (3) seamless deployment as
interactive web-map applications. Using InstaGeo, we reproduced datasets from
three published studies and trained models with marginal mIoU differences of
-0.73 pp for flood mapping, -0.20 pp for crop segmentation, and +1.79 pp for
desert locust prediction. The distilled models are up to 8x smaller than
standard fine-tuned counterparts, reducing FLOPs and CO2 emissions with minimal
accuracy loss.
  Leveraging InstaGeo's streamlined data pipeline, we also curated a larger
crop segmentation dataset, achieving a state-of-the-art mIoU of 60.65%, a 12 pp
improvement over prior baselines. Moreover, InstaGeo enables users to progress
from raw data to model deployment within a single working day.
  By unifying data preparation, model compression, and deployment, InstaGeo
transforms research-grade GFMs into practical, low-carbon tools for real-time,
large-scale Earth observation. This approach shifts geospatial AI toward data
quality and application-driven innovation. Source code, datasets, and model
checkpoints are available at:
https://github.com/instadeepai/InstaGeo-E2E-Geospatial-ML.git

</details>


### [23] [Beyond Spectral Peaks: Interpreting the Cues Behind Synthetic Image Detection](https://arxiv.org/abs/2510.05633)
*Sara Mandelli,Diego Vila-Portela,David Vázquez-Padín,Paolo Bestagini,Fernando Pérez-González*

Main category: cs.CV

TL;DR: 本文系统研究了现有基于深度学习的生成图像检测器是否真正依赖频域中的周期性峰值特征，并提出了一种去除频谱峰值的方法以及一个仅依赖峰值的线性检测器作为可解释基线。结果表明大多数检测器并不根本依赖这些峰值，挑战了领域内的普遍假设。


<details>
  <summary>Details</summary>
Motivation: 尽管频域中的周期性峰值被认为是生成图像的重要特征，但当前检测器多为黑箱模型，其是否真正依赖这些特征尚不明确，影响了模型的可解释性和可信度。

Method: 提出一种去除图像中频谱峰值的策略，评估该操作对多种检测器的影响；同时设计一个仅基于频域峰值的简单线性检测器，作为可解释的基准方法。

Result: 实验发现大多数先进检测器在去除频谱峰值后性能下降有限，表明它们并不主要依赖这些特征；而提出的线性检测器能有效利用峰值进行检测。

Conclusion: 当前多数检测器并非基于频域峰值进行判断，挑战了现有认知；研究推动了更透明、可靠取证工具的发展。

Abstract: Over the years, the forensics community has proposed several deep
learning-based detectors to mitigate the risks of generative AI. Recently,
frequency-domain artifacts (particularly periodic peaks in the magnitude
spectrum), have received significant attention, as they have been often
considered a strong indicator of synthetic image generation. However,
state-of-the-art detectors are typically used as black-boxes, and it still
remains unclear whether they truly rely on these peaks. This limits their
interpretability and trust. In this work, we conduct a systematic study to
address this question. We propose a strategy to remove spectral peaks from
images and analyze the impact of this operation on several detectors. In
addition, we introduce a simple linear detector that relies exclusively on
frequency peaks, providing a fully interpretable baseline free from the
confounding influence of deep learning. Our findings reveal that most detectors
are not fundamentally dependent on spectral peaks, challenging a widespread
assumption in the field and paving the way for more transparent and reliable
forensic tools.

</details>


### [24] [Combined Hyperbolic and Euclidean Soft Triple Loss Beyond the Single Space Deep Metric Learning](https://arxiv.org/abs/2510.05643)
*Shozo Saeki,Minoru Kawahara,Hirohisa Aman*

Main category: cs.CV

TL;DR: 提出了一种结合双曲空间和欧几里得空间的代理损失函数CHEST，用于提升深度度量学习的准确性和稳定性，并在多个基准数据集上实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 双曲空间适合表示复杂结构（如树结构），但现有基于代理的监督损失难以直接应用于双曲空间；同时，代理损失在大规模数据上训练效率高，因此需要设计一种适用于双曲空间的新型代理损失方法。

Method: 提出CHEST损失函数，结合双曲空间和欧几里得空间的代理损失，并引入基于双曲层次聚类的正则化项；通过联合优化两个空间的表示来提升学习效果。

Result: 在四个基准数据集上验证了CHEST的有效性，显著提升了深度度量学习的性能，达到新的最先进水平。

Conclusion: 结合双曲与欧几里得空间的代理损失能够有效提升深度度量学习的准确性和训练稳定性，为未来在双曲空间中设计监督损失提供了可行方案。

Abstract: Deep metric learning (DML) aims to learn a neural network mapping data to an
embedding space, which can represent semantic similarity between data points.
Hyperbolic space is attractive for DML since it can represent richer
structures, such as tree structures. DML in hyperbolic space is based on
pair-based loss or unsupervised regularization loss. On the other hand,
supervised proxy-based losses in hyperbolic space have not been reported yet
due to some issues in applying proxy-based losses in a hyperbolic space.
However, proxy-based losses are attractive for large-scale datasets since they
have less training complexity. To address these, this paper proposes the
Combined Hyperbolic and Euclidean Soft Triple (CHEST) loss. CHEST loss is
composed of the proxy-based losses in hyperbolic and Euclidean spaces and the
regularization loss based on hyperbolic hierarchical clustering. We find that
the combination of hyperbolic and Euclidean spaces improves DML accuracy and
learning stability for both spaces. Finally, we evaluate the CHEST loss on four
benchmark datasets, achieving a new state-of-the-art performance.

</details>


### [25] [Ocular-Induced Abnormal Head Posture: Diagnosis and Missing Data Imputation](https://arxiv.org/abs/2510.05649)
*Saja Al-Dabet,Sherzod Turaev,Nazar Zaki,Arif O. Khan,Luai Eldweik*

Main category: cs.CV

TL;DR: 本研究提出了两种深度学习框架，用于解决眼源性异常头位（AHP）的自动诊断和缺失数据处理问题，实现了高精度诊断与数据填补。


<details>
  <summary>Details</summary>
Motivation: 早期诊断AHP可减少并发症，但当前临床评估主观且常受限于不完整的病历资料，因此需要更客观、鲁棒的自动化方法。

Method: 提出AHP-CADNet多层级注意力融合框架，结合眼部特征、头部姿态与临床变量进行可解释性预测；并设计基于课程学习的缺失数据填补框架，利用结构化变量与非结构化临床文本提升数据恢复能力。

Result: 在PoseGaze-AHP数据集上，AHP-CADNet分类准确率达96.9%-99.0%，回归任务MAE为0.103-0.199，R²超过0.93；填补框架使用PubMedBERT准确率达93.46%-99.78%，且临床依赖建模显著提升效果（p<0.001）。

Conclusion: 两种框架在自动化诊断和处理缺失数据方面均表现出色，具有良好的临床应用潜力。

Abstract: Ocular-induced abnormal head posture (AHP) is a compensatory mechanism that
arises from ocular misalignment conditions, such as strabismus, enabling
patients to reduce diplopia and preserve binocular vision. Early diagnosis
minimizes morbidity and secondary complications such as facial asymmetry;
however, current clinical assessments remain largely subjective and are further
complicated by incomplete medical records. This study addresses both challenges
through two complementary deep learning frameworks. First, AHP-CADNet is a
multi-level attention fusion framework for automated diagnosis that integrates
ocular landmarks, head pose features, and structured clinical attributes to
generate interpretable predictions. Second, a curriculum learning-based
imputation framework is designed to mitigate missing data by progressively
leveraging structured variables and unstructured clinical notes to enhance
diagnostic robustness under realistic data conditions. Evaluation on the
PoseGaze-AHP dataset demonstrates robust diagnostic performance. AHP-CADNet
achieves 96.9-99.0 percent accuracy across classification tasks and low
prediction errors for continuous variables, with MAE ranging from 0.103 to
0.199 and R2 exceeding 0.93. The imputation framework maintains high accuracy
across all clinical variables (93.46-99.78 percent with PubMedBERT), with
clinical dependency modeling yielding significant improvements (p < 0.001).
These findings confirm the effectiveness of both frameworks for automated
diagnosis and recovery from missing data in clinical settings.

</details>


### [26] [EduVerse: A User-Defined Multi-Agent Simulation Space for Education Scenario](https://arxiv.org/abs/2510.05650)
*Yiping Ma,Shiyu Hu,Buyuan Zhu,Yipei Wang,Yaxuan Kang,Shiqing Liu,Kang Hao Cheong*

Main category: cs.CV

TL;DR: EduVerse是首个支持环境、智能体和会话定制的多智能体虚拟课堂模拟系统，采用CIE架构实现认知、交互与长期演化的逼真建模，支持真实用户介入，并在中学语文课堂中验证了其教学对齐性、群体互动和跨会话演化能力。


<details>
  <summary>Details</summary>
Motivation: 现有教育AI系统多局限于短期或单智能体场景，难以复现真实课堂中的开放认知、动态社交、情感因素和长期发展。EduVerse旨在构建一个可定制、可复现且融合人类参与的多智能体模拟平台，以系统研究课堂复杂性。

Method: 提出EduVerse，基于Cognition-Interaction-Evolution（CIE）三层架构设计多智能体模拟空间，支持智能体行为、环境和会话的自定义，并通过人机协同接口允许真实用户加入。在中学语文课堂中开展多会话实验，覆盖三种文本类型和多种环境设置。

Result: （1）教学对齐性：模拟课堂的IRF互动比率为0.28–0.64，接近真实课堂的0.37–0.49；（2）群体互动：网络密度为0.27–0.40，约三分之一同伴连接被激活，任务表现显示个体差异与教学稳定性平衡；（3）跨会话演化：正向转变率R+平均提升11.7%，揭示认知、情感与行为的长期发展轨迹。

Conclusion: EduVerse实现了真实感、可复现性与可解释性的平衡，为教育AI提供了一个可扩展的研究平台，未来将开源以促进跨学科合作。

Abstract: Reproducing cognitive development, group interaction, and long-term evolution
in virtual classrooms remains a core challenge for educational AI, as real
classrooms integrate open-ended cognition, dynamic social interaction,
affective factors, and multi-session development rarely captured together.
Existing approaches mostly focus on short-term or single-agent settings,
limiting systematic study of classroom complexity and cross-task reuse. We
present EduVerse, the first user-defined multi-agent simulation space that
supports environment, agent, and session customization. A distinctive
human-in-the-loop interface further allows real users to join the space. Built
on a layered CIE (Cognition-Interaction-Evolution) architecture, EduVerse
ensures individual consistency, authentic interaction, and longitudinal
adaptation in cognition, emotion, and behavior-reproducing realistic classroom
dynamics with seamless human-agent integration. We validate EduVerse in
middle-school Chinese classes across three text genres, environments, and
multiple sessions. Results show: (1) Instructional alignment: simulated IRF
rates (0.28-0.64) closely match real classrooms (0.37-0.49), indicating
pedagogical realism; (2) Group interaction and role differentiation: network
density (0.27-0.40) with about one-third of peer links realized, while
human-agent tasks indicate a balance between individual variability and
instructional stability; (3) Cross-session evolution: the positive transition
rate R+ increase by 11.7% on average, capturing longitudinal shifts in
behavior, emotion, and cognition and revealing structured learning
trajectories. Overall, EduVerse balances realism, reproducibility, and
interpretability, providing a scalable platform for educational AI. The system
will be open-sourced to foster cross-disciplinary research.

</details>


### [27] [SD-MVSum: Script-Driven Multimodal Video Summarization Method and Datasets](https://arxiv.org/abs/2510.05652)
*Manolis Mylonas,Charalampia Zerva,Evlampios Apostolidis,Vasileios Mezaris*

Main category: cs.CV

TL;DR: 本文提出了一种新的脚本驱动的多模态视频摘要方法SD-MVSum，结合视频的视觉和语音内容，并引入加权跨模态注意力机制以提升与用户脚本最相关部分的摘要效果。


<details>
  <summary>Details</summary>
Motivation: 现有脚本驱动的视频摘要方法主要关注视觉内容，忽略语音信息，限制了摘要的相关性。本文旨在通过融合视觉和语音模态来提升摘要质量。

Method: 提出SD-MVSum方法，使用加权跨模态注意力机制建模脚本与视频、脚本与转录文本之间的关系，利用语义相似性突出视频中最相关片段。同时扩展两个大规模数据集（S-VideoXum, MrHiSum）以支持多模态脚本驱动摘要研究。

Result: 实验表明，SD-MVSum在脚本驱动和通用视频摘要任务中均优于现有SOTA方法，在新扩展的数据集上表现出色。

Conclusion: 结合脚本与多模态信息（视觉+语音）并通过加权跨模态注意力建模，能有效提升视频摘要的相关性和质量，扩展的数据集为后续研究提供了支持。

Abstract: In this work, we extend a recent method for script-driven video
summarization, originally considering just the visual content of the video, to
take into account the relevance of the user-provided script also with the
video's spoken content. In the proposed method, SD-MVSum, the dependence
between each considered pair of data modalities, i.e., script-video and
script-transcript, is modeled using a new weighted cross-modal attention
mechanism. This explicitly exploits the semantic similarity between the paired
modalities in order to promote the parts of the full-length video with the
highest relevance to the user-provided script. Furthermore, we extend two
large-scale datasets for video summarization (S-VideoXum, MrHiSum), to make
them suitable for training and evaluation of script-driven multimodal video
summarization methods. Experimental comparisons document the competitiveness of
our SD-MVSum method against other SOTA approaches for script-driven and generic
video summarization. Our new method and extended datasets are available at:
https://github.com/IDT-ITI/SD-MVSum.

</details>


### [28] [A Hierarchical Geometry-guided Transformer for Histological Subtyping of Primary Liver Cancer](https://arxiv.org/abs/2510.05657)
*Anwen Lu,Mingxin Liu,Yiping Jiao,Hongyi Gong,Geyang Xu,Jun Chen,Jun Xu*

Main category: cs.CV

TL;DR: 提出ARGUS模型，通过整合宏观-中观-微观层级信息与细胞几何特征，实现肝癌组织学亚型的精准分类，达到当前最优性能。


<details>
  <summary>Details</summary>
Motivation: 肝细胞癌（HCC）和肝内胆管癌（ICC）组织形态复杂，现有方法未能充分利用全切片图像（WSI）中的多层次特征进行有效亚型分类，限制了病理表征理解与诊断性能。

Method: 提出ARGUS模型：1）构建微几何特征刻画细胞核间的几何结构；2）设计多层次视野（FoVs）对齐模块捕捉WSI中的宏观与中观层次信息；3）采用几何先验引导的融合策略，整合微几何与FoVs特征进行联合表征。

Result: 在公共和私有数据集上实验表明，ARGUS在肝癌组织学亚型分类任务中达到当前最先进（SOTA）性能，显著优于现有方法。

Conclusion: ARGUS能有效捕捉肝脏肿瘤微环境中的多层次特征，提升肝癌亚型的精准识别能力，具有良好的临床诊断应用前景。

Abstract: Primary liver malignancies are widely recognized as the most heterogeneous
and prognostically diverse cancers of the digestive system. Among these,
hepatocellular carcinoma (HCC) and intrahepatic cholangiocarcinoma (ICC) emerge
as the two principal histological subtypes, demonstrating significantly greater
complexity in tissue morphology and cellular architecture than other common
tumors. The intricate representation of features in Whole Slide Images (WSIs)
encompasses abundant crucial information for liver cancer histological
subtyping, regarding hierarchical pyramid structure, tumor microenvironment
(TME), and geometric representation. However, recent approaches have not
adequately exploited these indispensable effective descriptors, resulting in a
limited understanding of histological representation and suboptimal subtyping
performance. To mitigate these limitations, ARGUS is proposed to advance
histological subtyping in liver cancer by capturing the macro-meso-micro
hierarchical information within the TME. Specifically, we first construct a
micro-geometry feature to represent fine-grained cell-level pattern via a
geometric structure across nuclei, thereby providing a more refined and precise
perspective for delineating pathological images. Then, a Hierarchical
Field-of-Views (FoVs) Alignment module is designed to model macro- and
meso-level hierarchical interactions inherent in WSIs. Finally, the augmented
micro-geometry and FoVs features are fused into a joint representation via
present Geometry Prior Guided Fusion strategy for modeling holistic phenotype
interactions. Extensive experiments on public and private cohorts demonstrate
that our ARGUS achieves state-of-the-art (SOTA) performance in histological
subtyping of liver cancer, which provide an effective diagnostic tool for
primary liver malignancies in clinical practice.

</details>


### [29] [Teleportraits: Training-Free People Insertion into Any Scene](https://arxiv.org/abs/2510.05660)
*Jialu Gao,K J Joseph,Fernando De La Torre*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的统一管道，利用预训练的文本到图像扩散模型，实现将参考图像中的人物真实地插入到背景场景中，首次实现了无需训练的真实人物插入，并在多种复合场景图像中实现了最先进的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的人物插入方法通常将位置姿态确定和个性化生成视为独立问题，且依赖训练。本文旨在探索预训练扩散模型的内在能力，实现无需训练的高质量、场景感知的人物插入。

Method: 结合图像反转技术与无分类器引导，在预训练扩散模型中实现场景感知的全局编辑；提出掩码引导的自注意力机制，保持人物身份、衣着和身体特征，仅需一张参考图即可完成个性化。

Result: 在无需训练的情况下，实现了真实感强、身份保持良好的人物插入效果，在多种复杂背景场景中达到最先进水平。

Conclusion: 扩散模型本身就具备在复杂场景中合理放置人物的知识，通过适当的机制设计，无需训练即可实现高质量的人体插入与个性化，为图像编辑提供了高效、实用的新途径。

Abstract: The task of realistically inserting a human from a reference image into a
background scene is highly challenging, requiring the model to (1) determine
the correct location and poses of the person and (2) perform high-quality
personalization conditioned on the background. Previous approaches often treat
them as separate problems, overlooking their interconnections, and typically
rely on training to achieve high performance. In this work, we introduce a
unified training-free pipeline that leverages pre-trained text-to-image
diffusion models. We show that diffusion models inherently possess the
knowledge to place people in complex scenes without requiring task-specific
training. By combining inversion techniques with classifier-free guidance, our
method achieves affordance-aware global editing, seamlessly inserting people
into scenes. Furthermore, our proposed mask-guided self-attention mechanism
ensures high-quality personalization, preserving the subject's identity,
clothing, and body features from just a single reference image. To the best of
our knowledge, we are the first to perform realistic human insertions into
scenes in a training-free manner and achieve state-of-the-art results in
diverse composite scene images with excellent identity preservation in
backgrounds and subjects.

</details>


### [30] [When and How to Cut Classical Concerts? A Multimodal Automated Video Editing Approach](https://arxiv.org/abs/2510.05661)
*Daniel Gonzálbez-Biosca,Josep Cabacas-Maso,Carles Ventura,Ismael Benito-Altamirano*

Main category: cs.CV

TL;DR: 本文提出了一种新的多模态架构，用于多摄像头古典音乐演奏会视频的自动编辑，通过融合音频、视觉和时间特征，在“何时剪辑”和“如何剪辑”两个任务上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动化视频剪辑在计算机视觉和多媒体领域研究较少，尤其是在与视频生成和场景理解相比时。本文旨在解决多摄像头音乐演奏会视频剪辑的挑战，推动该领域的进展。

Method: 将剪辑问题分解为“何时剪辑”和“如何剪辑”两个子任务。“何时剪辑”采用结合对数梅尔谱图、可选图像嵌入和标量时间特征的轻量级卷积-Transformer架构；“如何剪辑”则使用CLIP编码器替代传统ResNet骨干网络，并限制干扰镜头来自同一场音乐会。数据集通过伪标签方法自动生成镜头片段。

Result: 所提模型在检测剪辑点方面优于先前基线，并在视觉镜头选择上表现出竞争力，推动了多模态自动视频编辑的最先进水平。

Conclusion: 本文验证了多模态深度学习在专业视频编辑任务中的有效性，尤其在音乐演奏会场景中实现了更精准的剪辑决策。

Abstract: Automated video editing remains an underexplored task in the computer vision
and multimedia domains, especially when contrasted with the growing interest in
video generation and scene understanding. In this work, we address the specific
challenge of editing multicamera recordings of classical music concerts by
decomposing the problem into two key sub-tasks: when to cut and how to cut.
Building on recent literature, we propose a novel multimodal architecture for
the temporal segmentation task (when to cut), which integrates log-mel
spectrograms from the audio signals, plus an optional image embedding, and
scalar temporal features through a lightweight convolutional-transformer
pipeline. For the spatial selection task (how to cut), we improve the
literature by updating from old backbones, e.g. ResNet, with a CLIP-based
encoder and constraining distractor selection to segments from the same
concert. Our dataset was constructed following a pseudo-labeling approach, in
which raw video data was automatically clustered into coherent shot segments.
We show that our models outperformed previous baselines in detecting cut points
and provide competitive visual shot selection, advancing the state of the art
in multimodal automated video editing.

</details>


### [31] [Development and Validation of a Low-Cost Imaging System for Seedling Germination Kinetics through Time-Cumulative Analysis](https://arxiv.org/abs/2510.05668)
*M. Torrente,A. Follador,A. Calcante,P. Casati,R. Oberti*

Main category: cs.CV

TL;DR: 本研究利用低成本图像监测系统和创新的时序图像分析流程，评估了立枯丝核菌（R. solani）对生菜种子萌发和早期生长的影响，实现了在复杂生长条件下对重叠幼苗的准确识别与活力评估。


<details>
  <summary>Details</summary>
Motivation: 传统图像分析方法在幼苗重叠或密集生长时难以准确分割和计数，限制了植物表型分析的精度。本研究旨在开发一种鲁棒的图像分析方法，以非破坏性方式精确监测病原菌对种子萌发和早期发育的影响。

Method: 部署多台相机连续拍摄感染组与对照组生菜种子的萌发过程；开发了一种结合形态学与空间特征的图像分析流程，创新性地引入时序信息整合，利用前期发育状态辅助当前帧中幼苗的识别与分割，提升在复杂条件下的分析准确性。

Result: R. solani 显著降低了种子萌发率和幼苗早期活力；所提方法在幼苗计数和活力评估中表现出高精度，决定系数达0.98，均方根误差为1.12，尤其在后期重叠严重阶段显著优于传统分割技术。

Conclusion: 结合低成本成像设备与基于时序整合的先进图像分析方法，可实现对植物萌发过程的非破坏性、可扩展且高精度的表型监测，为植物病理学和功能基因组学研究提供了有力工具。

Abstract: The study investigates the effects of R. solani inoculation on the
germination and early development of Lactuca sativa L. seeds using a low-cost,
image-based monitoring system. Multiple cameras were deployed to continuously
capture images of the germination process in both infected and control groups.
The objective was to assess the impact of the pathogen by analyzing germination
dynamics and growth over time. To achieve this, a novel image analysis pipeline
was developed. The algorithm integrates both morphological and spatial features
to identify and quantify individual seedlings, even under complex conditions
where traditional image analyses fails. A key innovation of the method lies in
its temporal integration: each analysis step considers not only the current
status but also their developmental across prior time points. This approach
enables robust discrimination of individual seedlings, especially when
overlapping leaves significantly hinder object separation. The method
demonstrated high accuracy in seedling counting and vigor assessment, even in
challenging scenarios characterized by dense and intertwined growth. Results
confirm that R. solani infection significantly reduces germination rates and
early seedling vigor. The study also validates the feasibility of combining
low-cost imaging hardware with advanced computational tools to obtain
phenotyping data in a non-destructive and scalable manner. The temporal
integration enabled accurate quantification of germinated seeds and precise
determination of seedling emergence timing. This approach proved particularly
effective in later stages of the experiment, where conventional segmentation
techniques failed due to overlapping or intertwined seedlings, making accurate
counting. The method achieved a coefficient of determination of 0.98 and a root
mean square error (RMSE) of 1.12, demonstrating its robustness and reliability.

</details>


### [32] [Context Matters: Learning Global Semantics for Visual Reasoning and Comprehension](https://arxiv.org/abs/2510.05674)
*Jike Zhong,Yuxiang Lai,Xiaofeng Yang,Konstantinos Psounis*

Main category: cs.CV

TL;DR: 提出一种基于对象级别的视觉建模方法，通过语义接地的目标缩小视觉模型与语言模型在推理和上下文学习方面的差距。


<details>
  <summary>Details</summary>
Motivation: 当前视觉变换器（ViT）训练方案缺乏语义和上下文引导，导致其在推理和上下文学习方面落后于语言模型。本文旨在通过设计语义基础目标来弥合这一差距。

Method: 将视觉中的“对象”视为语言中“词”的等价物，采用掩码图像建模（MIM）框架，对视觉对象而非随机 patches 应用掩码，从而促使模型学习视觉元素间的全局上下文和语义。

Result: 定性和定量评估表明，仅通过对象级表示即可帮助学习真实世界分布，避免了像素平均的捷径；在视觉问答任务（VQA、GQA、ScienceQA）中结合多模态大语言模型（MLLM）进一步验证了该方法在推理和上下文理解上的显著提升。

Conclusion: 对象级编码能有效提升视觉模型的语义理解和推理能力，为构建更强的视觉编码器和分词器提供了可行方向。

Abstract: Recent advances in language modeling have witnessed the rise of highly
desirable emergent capabilities, such as reasoning and in-context learning.
However, vision models have yet to exhibit comparable progress in these areas.
In this paper, we argue that this gap could stem from the lack of semantic and
contextual guidance in current vision transformer (ViT) training schemes, and
such a gap can be narrowed through the design of a semantic-grounded objective.
Specifically, we notice that individual words in natural language are
inherently semantic, and modeling directly on word tokens naturally learns a
realistic distribution. In contrast, ViTs rely on spatial patchification, which
inevitably lacks semantic information. To bridge this gap, we propose to
directly model "object" as the visual equivalence of "word," pushing the model
to learn the global context and semantics among visual elements. We investigate
our hypotheses via masked image modeling (MIM), a framework where our approach
can be readily tested by applying masks to visual objects rather than random
patches. Considerable evidence from qualitative and quantitative evaluations
reveals a key finding: object-level representation alone helps to learn a
real-world distribution, whereas pixel-averaging shortcuts are often learned
without it. Moreover, further evaluations with multimodal LLMs (MLLM) on visual
question answering (VQA, GQA, ScienceQA) tasks demonstrate the strong reasoning
and contextual understanding gained with this simple objective. We hope our
study highlights the effectiveness of object-level encoding and provides a
plausible direction for developing stronger vision encoders and tokenizers.
Code and model will be publicly released. Keywords: Semantic Visual Tokenizer,
Vision Reasoning, In-context Learning, Multimodal Reasoning

</details>


### [33] [AgeBooth: Controllable Facial Aging and Rejuvenation via Diffusion Models](https://arxiv.org/abs/2510.05715)
*Shihao Zhu,Bohan Cao,Ziheng Ouyang,Zhen Li,Peng-Tao Jiang,Qibin Hou*

Main category: cs.CV

TL;DR: 提出AgeBooth，一种无需大量跨年龄成对数据的年龄特异性微调方法，通过年龄条件提示混合和年龄特异性LoRA融合策略，实现基于单张参考图像的高质量、身份一致的跨年龄人脸生成。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在保持身份一致性的同时难以精确控制年龄，且微调通常依赖昂贵的跨年龄成对图像数据。

Method: 提出AgeBooth，结合年龄条件提示混合和基于SVDMix的年龄特异性LoRA融合策略，在adapter-based身份个性化模型上进行微调。

Result: 实验表明，AgeBooth在年龄控制精度和生成图像视觉质量上优于现有的编辑类最先进方法，能从单张参考图像生成真实且身份一致的多年龄人脸图像。

Conclusion: AgeBooth有效提升了身份个性化模型的年龄控制能力，减少了对大规模标注数据的依赖，适用于高质量的年龄演化图像生成。

Abstract: Recent diffusion model research focuses on generating identity-consistent
images from a reference photo, but they struggle to accurately control age
while preserving identity, and fine-tuning such models often requires costly
paired images across ages. In this paper, we propose AgeBooth, a novel
age-specific finetuning approach that can effectively enhance the age control
capability of adapterbased identity personalization models without the need for
expensive age-varied datasets. To reduce dependence on a large amount of
age-labeled data, we exploit the linear nature of aging by introducing
age-conditioned prompt blending and an age-specific LoRA fusion strategy that
leverages SVDMix, a matrix fusion technique. These techniques enable
high-quality generation of intermediate-age portraits. Our AgeBooth produces
realistic and identity-consistent face images across different ages from a
single reference image. Experiments show that AgeBooth achieves superior age
control and visual quality compared to previous state-of-the-art editing-based
methods.

</details>


### [34] [Data Factory with Minimal Human Effort Using VLMs](https://arxiv.org/abs/2510.05722)
*Jiaojiao Ye,Jiaxing Zhong,Qian Xie,Yuzhou Zhou,Niki Trigoni,Andrew Markham*

Main category: cs.CV

TL;DR: 提出了一种无需训练的新型数据增强管道，结合预训练的ControlNet和视觉-语言模型，实现高质量、多样化的合成图像与像素级标签生成，显著提升单样本语义分割性能。


<details>
  <summary>Details</summary>
Motivation: 传统数据增强方法在操纵高阶语义属性（如材质和纹理）方面存在困难，而现有基于扩散模型的方法要么计算成本高，要么性能不足，因此需要一种高效且高性能的自动化数据生成方法。

Method: 提出一种无需训练的 pipeline，集成预训练的 ControlNet 和视觉-语言模型（VLMs），引入多路提示生成器、掩码生成器和高质量图像筛选模块，实现文本或图像引导下的图像生成与像素级标签配对。

Result: 在 PASCAL-5i 和 COCO-20i 数据集上，该方法在单样本语义分割任务中表现优异，性能优于当前同类方法。

Conclusion: 该方法有效解决了扩散模型在数据增强中计算成本高和性能受限的问题，实现了高质量、多样化且带有精确标注的图像生成，显著提升了下游分割任务的表现。

Abstract: Generating enough and diverse data through augmentation offers an efficient
solution to the time-consuming and labour-intensive process of collecting and
annotating pixel-wise images. Traditional data augmentation techniques often
face challenges in manipulating high-level semantic attributes, such as
materials and textures. In contrast, diffusion models offer a robust
alternative, by effectively utilizing text-to-image or image-to-image
transformation. However, existing diffusion-based methods are either
computationally expensive or compromise on performance. To address this issue,
we introduce a novel training-free pipeline that integrates pretrained
ControlNet and Vision-Language Models (VLMs) to generate synthetic images
paired with pixel-level labels. This approach eliminates the need for manual
annotations and significantly improves downstream tasks. To improve the
fidelity and diversity, we add a Multi-way Prompt Generator, Mask Generator and
High-quality Image Selection module. Our results on PASCAL-5i and COCO-20i
present promising performance and outperform concurrent work for one-shot
semantic segmentation.

</details>


### [35] [Redefining Generalization in Visual Domains: A Two-Axis Framework for Fake Image Detection with FusionDetect](https://arxiv.org/abs/2510.05740)
*Amirtaha Amanzadi,Zahra Dehghanian,Hamid Beigy,Hamid R. Rabiee*

Main category: cs.CV

TL;DR: 提出OmniGen Benchmark和FusionDetect方法，用于提升合成图像检测在跨生成器和跨视觉域上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有合成图像检测研究多关注跨生成器泛化，忽视跨视觉域泛化，需构建更全面的评估体系与检测方法。

Method: 提出FusionDetect，融合CLIP与DINOv2两种冻结基础模型的特征，构建能自适应生成器内容与设计变化的统一特征空间。

Result: 在OmniGen上准确率提升4.48%，在现有基准上平均比最佳竞品准确率高3.87%、精确率高6.13%，并对常见图像扰动表现出强鲁棒性。

Conclusion: FusionDetect结合新提出的OmniGen基准，为通用AI图像检测提供了新的高性能检测器、评估平台与研究框架。

Abstract: The rapid development of generative models has made it increasingly crucial
to develop detectors that can reliably detect synthetic images. Although most
of the work has now focused on cross-generator generalization, we argue that
this viewpoint is too limited. Detecting synthetic images involves another
equally important challenge: generalization across visual domains. To bridge
this gap,we present the OmniGen Benchmark. This comprehensive evaluation
dataset incorporates 12 state-of-the-art generators, providing a more realistic
way of evaluating detector performance under realistic conditions. In addition,
we introduce a new method, FusionDetect, aimed at addressing both vectors of
generalization. FusionDetect draws on the benefits of two frozen foundation
models: CLIP & Dinov2. By deriving features from both complementary models,we
develop a cohesive feature space that naturally adapts to changes in both
thecontent and design of the generator. Our extensive experiments demonstrate
that FusionDetect delivers not only a new state-of-the-art, which is 3.87% more
accurate than its closest competitor and 6.13% more precise on average on
established benchmarks, but also achieves a 4.48% increase in accuracy on
OmniGen,along with exceptional robustness to common image perturbations. We
introduce not only a top-performing detector, but also a new benchmark and
framework for furthering universal AI image detection. The code and dataset are
available at http://github.com/amir-aman/FusionDetect

</details>


### [36] [ALISE: Annotation-Free LiDAR Instance Segmentation for Autonomous Driving](https://arxiv.org/abs/2510.05752)
*Yongxuan Lyu,Guangfeng Jiang,Hongsi Liu,Jun Liu*

Main category: cs.CV

TL;DR: 提出了一种完全无需标注的LiDAR实例分割框架ALISE，通过视觉基础模型和时空投票机制生成高质量伪标签，在无监督3D实例分割中达到新SOTA，甚至超越部分有监督方法。


<details>
  <summary>Details</summary>
Motivation: 手动标注户外LiDAR点云实例分割数据成本极高，现有方法仍依赖一定程度的人工标注，因此需要一种完全无需标注的解决方案。

Method: 利用文本和图像引导的视觉基础模型（VFMs）生成初始伪标签，通过结合2D和3D语义的时空投票模块优化标签，并引入基于2D先验的损失和基于原型的对比损失以增强特征学习。

Result: 在无监督3D实例分割任务上达到新的最先进性能，mAP达到50.95%，超过使用真实2D边界框监督的MWSIS方法2.53%。

Conclusion: ALISE实现了无需任何人工标注的高质量LiDAR实例分割，通过伪标签优化和多模态语义监督显著提升了无监督性能，展现出取代有监督方法的潜力。

Abstract: The manual annotation of outdoor LiDAR point clouds for instance segmentation
is extremely costly and time-consuming. Current methods attempt to reduce this
burden but still rely on some form of human labeling. To completely eliminate
this dependency, we introduce ALISE, a novel framework that performs LiDAR
instance segmentation without any annotations. The central challenge is to
generate high-quality pseudo-labels in a fully unsupervised manner. Our
approach starts by employing Vision Foundation Models (VFMs), guided by text
and images, to produce initial pseudo-labels. We then refine these labels
through a dedicated spatio-temporal voting module, which combines 2D and 3D
semantics for both offline and online optimization. To achieve superior feature
learning, we further introduce two forms of semantic supervision: a set of 2D
prior-based losses that inject visual knowledge into the 3D network, and a
novel prototype-based contrastive loss that builds a discriminative feature
space by exploiting 3D semantic consistency. This comprehensive design results
in significant performance gains, establishing a new state-of-the-art for
unsupervised 3D instance segmentation. Remarkably, our approach even
outperforms MWSIS, a method that operates with supervision from ground-truth
(GT) 2D bounding boxes by a margin of 2.53% in mAP (50.95% vs. 48.42%).

</details>


### [37] [OneVision: An End-to-End Generative Framework for Multi-view E-commerce Vision Search](https://arxiv.org/abs/2510.05759)
*Zexin Zheng,Huangyu Dai,Lingtao Mao,Xinyu Sun,Zihan Liang,Ben Chen,Yuqing Ding,Chenyi Lei,Wenwu Ou,Han Li,Kun Gai*

Main category: cs.CV

TL;DR: 提出了一种端到端的生成式框架OneVision，通过视觉对齐的残差量化编码和多阶段语义对齐机制，统一检索与个性化，提升推理效率和在线性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于多阶段级联架构的视觉搜索在查询与商品表示之间存在多视角表征差异，导致用户体验与转化难以同时优化。

Method: 提出OneVision框架，基于VRQ（视觉对齐残差量化编码）对齐不同视角下的对象表示，并采用多阶段语义对齐融合用户个性化信息。

Result: 离线评估中性能媲美在线MCA，推理效率提升21%；A/B测试中CTR提升2.15%，CVR提升2.27%，订单量提升3.12%。

Conclusion: 以语义ID为核心的生成式架构可有效统一检索与个性化，简化服务流程并提升整体效果。

Abstract: Traditional vision search, similar to search and recommendation systems,
follows the multi-stage cascading architecture (MCA) paradigm to balance
efficiency and conversion. Specifically, the query image undergoes feature
extraction, recall, pre-ranking, and ranking stages, ultimately presenting the
user with semantically similar products that meet their preferences. This
multi-view representation discrepancy of the same object in the query and the
optimization objective collide across these stages, making it difficult to
achieve Pareto optimality in both user experience and conversion. In this
paper, an end-to-end generative framework, OneVision, is proposed to address
these problems. OneVision builds on VRQ, a vision-aligned residual quantization
encoding, which can align the vastly different representations of an object
across multiple viewpoints while preserving the distinctive features of each
product as much as possible. Then a multi-stage semantic alignment scheme is
adopted to maintain strong visual similarity priors while effectively
incorporating user-specific information for personalized preference generation.
In offline evaluations, OneVision performs on par with online MCA, while
improving inference efficiency by 21% through dynamic pruning. In A/B tests, it
achieves significant online improvements: +2.15% item CTR, +2.27% CVR, and
+3.12% order volume. These results demonstrate that a semantic ID centric,
generative architecture can unify retrieval and personalization while
simplifying the serving pathway.

</details>


### [38] [A Novel Technique for Robust Training of Deep Networks With Multisource Weak Labeled Remote Sensing Data](https://arxiv.org/abs/2510.05760)
*Gianmarco Perantoni,Lorenzo Bruzzone*

Main category: cs.CV

TL;DR: 提出一种利用多源标签数据（包括可靠和不可靠标签）训练深度网络的方法，通过嵌入迁移矩阵在梯度层面加权不同来源的标签，提升遥感图像场景分类性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络需要大量高质量标注数据，但遥感图像中高可靠性标签获取成本高且数量有限，而存在大量低质量但易获取的标注数据，需有效利用这些弱标签源。

Method: 结合少量高可靠性标签数据与多个弱标签数据源构建多源标注数据集，利用描述各数据源错误统计特性的转移矩阵，在训练过程中对不同来源的标签进行加权，实现梯度层面的样本加权优化。

Result: 在多个数据集上的实验表明，该方法能有效利用不可靠标签数据，提升模型性能，具有良好的鲁棒性。

Conclusion: 该方法能有效融合多源异质标签数据，通过建模标签错误统计特性，在遥感图像场景分类中显著提升深度网络的训练效果。

Abstract: Deep learning has gained broad interest in remote sensing image scene
classification thanks to the effectiveness of deep neural networks in
extracting the semantics from complex data. However, deep networks require
large amounts of training samples to obtain good generalization capabilities
and are sensitive to errors in the training labels. This is a problem in remote
sensing since highly reliable labels can be obtained at high costs and in
limited amount. However, many sources of less reliable labeled data are
available, e.g., obsolete digital maps. In order to train deep networks with
larger datasets, we propose both the combination of single or multiple weak
sources of labeled data with a small but reliable dataset to generate
multisource labeled datasets and a novel training strategy where the
reliability of each source is taken in consideration. This is done by
exploiting the transition matrices describing the statistics of the errors of
each source. The transition matrices are embedded into the labels and used
during the training process to weigh each label according to the related
source. The proposed method acts as a weighting scheme at gradient level, where
each instance contributes with different weights to the optimization of
different classes. The effectiveness of the proposed method is validated by
experiments on different datasets. The results proved the robustness and
capability of leveraging on unreliable source of labels of the proposed method.

</details>


### [39] [Mysteries of the Deep: Role of Intermediate Representations in Out of Distribution Detection](https://arxiv.org/abs/2510.05782)
*I. M. De la Jara,C. Rodriguez-Opazo,D. Teney,D. Ranasinghe,E. Abbasnejad*

Main category: cs.CV

TL;DR: 本文提出利用预训练模型中间层的多样化表示进行无需训练的OOD检测，通过熵准则自动选择最具互补性的层，显著提升了远端和近端OOD检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的OOD检测方法通常只使用预训练模型的最后一层表示，忽略了中间层可能包含的丰富且多样的分布偏移信号，因此限制了检测性能。

Method: 提出一种基于熵的自动层选择准则，利用残差连接带来的中间层表示多样性，在无需训练且无OOD数据的情况下，选择最具互补信息的中间层进行融合以增强OOD检测。

Result: 在多种模型架构和训练目标下，该方法在远端OOD检测上准确率提升高达10%，近端OOD检测上超过7%，优于现有的训练自由方法。

Conclusion: 中间层包含有价值的OOD信号，合理利用可显著提升检测效果，为OOD检测提供了新方向，并揭示了不同训练目标和架构对置信度方法的影响。

Abstract: Out-of-distribution (OOD) detection is essential for reliably deploying
machine learning models in the wild. Yet, most methods treat large pre-trained
models as monolithic encoders and rely solely on their final-layer
representations for detection. We challenge this wisdom. We reveal the
\textit{intermediate layers} of pre-trained models, shaped by residual
connections that subtly transform input projections, \textit{can} encode
\textit{surprisingly rich and diverse signals} for detecting distributional
shifts. Importantly, to exploit latent representation diversity across layers,
we introduce an entropy-based criterion to \textit{automatically} identify
layers offering the most complementary information in a training-free setting
-- \textit{without access to OOD data}. We show that selectively incorporating
these intermediate representations can increase the accuracy of OOD detection
by up to \textbf{$10\%$} in far-OOD and over \textbf{$7\%$} in near-OOD
benchmarks compared to state-of-the-art training-free methods across various
model architectures and training objectives. Our findings reveal a new avenue
for OOD detection research and uncover the impact of various training
objectives and model architectures on confidence-based OOD detection methods.

</details>


### [40] [Rasterized Steered Mixture of Experts for Efficient 2D Image Regression](https://arxiv.org/abs/2510.05814)
*Yi-Hsin Li,Thomas Sikora,Sebastian Knorr,Mårten Sjöström*

Main category: cs.CV

TL;DR: 提出了一种基于光栅化的优化策略，结合Steered Mixture of Experts的边缘感知机制与光栅化高斯核渲染的高效性，显著提升二维图像回归的计算效率，同时保持稀疏性和重建质量。


<details>
  <summary>Details</summary>
Motivation: Steered Mixture of Experts在图像重建等任务中表现优异，但计算成本过高，限制了实际应用，因此需要一种更高效的优化方法。

Method: 引入基于光栅化的优化策略，用光栅化公式替代全局迭代优化，结合Steered Mixture of Experts的边缘感知门控机制，实现快速参数更新和内存高效表示。

Result: 该方法显著加快了参数更新速度，提升了内存效率，并支持原生超分辨率和图像去噪等标准光栅化方法难以实现的应用。

Conclusion: 该框架在保持重建质量的同时，实现了计算效率与重建保真度之间的新平衡，适用于多种二维图像处理任务。

Abstract: The Steered Mixture of Experts regression framework has demonstrated strong
performance in image reconstruction, compression, denoising, and
super-resolution. However, its high computational cost limits practical
applications. This work introduces a rasterization-based optimization strategy
that combines the efficiency of rasterized Gaussian kernel rendering with the
edge-aware gating mechanism of the Steered Mixture of Experts. The proposed
method is designed to accelerate two-dimensional image regression while
maintaining the model's inherent sparsity and reconstruction quality. By
replacing global iterative optimization with a rasterized formulation, the
method achieves significantly faster parameter updates and more
memory-efficient model representations. In addition, the proposed framework
supports applications such as native super-resolution and image denoising,
which are not directly achievable with standard rasterized Gaussian kernel
approaches. The combination of fast rasterized optimization with the edge-aware
structure of the Steered Mixture of Experts provides a new balance between
computational efficiency and reconstruction fidelity for two-dimensional image
processing tasks.

</details>


### [41] [Deformable Image Registration for Self-supervised Cardiac Phase Detection in Multi-View Multi-Disease Cardiac Magnetic Resonance Images](https://arxiv.org/abs/2510.05819)
*Sven Koehler,Sarah Kaye Mueller,Jonathan Kiekenap,Gerald Greil,Tarique Hussain,Samir Sarikouch,Florian André,Norbert Frey,Sandy Engelhardt*

Main category: cs.CV

TL;DR: 提出一种自监督深度学习方法，通过变形配准和1D运动描述符实现短轴和四腔长轴心脏磁共振视频中五个关键帧的精确检测，显著优于基于容积的传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有自动检测心脏磁共振关键帧的方法仅依赖左心室容积曲线，难以深入反映心肌运动，且个体心跳周期差异大，限制了时间对比和亚相位分析。

Method: 从图像中计算密集变形配准场，生成1D运动描述符来表征心脏整体收缩与舒张模式，并结合简单规则检测多个关键帧；采用自监督深度学习框架，训练和评估基于多中心、多病种公开数据集。

Result: 在ED和ES检测上，相比容积法cFD指标提升30%-51%（SAX）和11%-47%（4CH）；平均cFD低于1.31帧（SAX）和1.73帧（LAX），并可检测三个额外关键帧。

Conclusion: 该方法能实现跨患者、跨周期的心脏动态时间对齐分析，支持更精细的心脏功能评估，且具有良好的泛化性和临床适用性。

Abstract: Cardiovascular magnetic resonance (CMR) is the gold standard for assessing
cardiac function, but individual cardiac cycles complicate automatic temporal
comparison or sub-phase analysis. Accurate cardiac keyframe detection can
eliminate this problem. However, automatic methods solely derive end-systole
(ES) and end-diastole (ED) frames from left ventricular volume curves, which do
not provide a deeper insight into myocardial motion. We propose a
self-supervised deep learning method detecting five keyframes in short-axis
(SAX) and four-chamber long-axis (4CH) cine CMR. Initially, dense deformable
registration fields are derived from the images and used to compute a 1D motion
descriptor, which provides valuable insights into global cardiac contraction
and relaxation patterns. From these characteristic curves, keyframes are
determined using a simple set of rules. The method was independently evaluated
for both views using three public, multicentre, multidisease datasets. M&Ms-2
(n=360) dataset was used for training and evaluation, and M&Ms (n=345) and ACDC
(n=100) datasets for repeatability control. Furthermore, generalisability to
patients with rare congenital heart defects was tested using the German
Competence Network (GCN) dataset. Our self-supervised approach achieved
improved detection accuracy by 30% - 51% for SAX and 11% - 47% for 4CH in ED
and ES, as measured by cyclic frame difference (cFD), compared with the
volume-based approach. We can detect ED and ES, as well as three additional
keyframes throughout the cardiac cycle with a mean cFD below 1.31 frames for
SAX and 1.73 for LAX. Our approach enables temporally aligned inter- and
intra-patient analysis of cardiac dynamics, irrespective of cycle or phase
lengths. GitHub repository:
https://github.com/Cardio-AI/cmr-multi-view-phase-detection.git

</details>


### [42] [Flow4Agent: Long-form Video Understanding via Motion Prior from Optical Flow](https://arxiv.org/abs/2510.05836)
*Ruyang Liu,Shangkun Sun,Haoran Tang,Ge Li,Wei Gao*

Main category: cs.CV

TL;DR: 提出Flow4Agent，利用光流运动先验优化多模态大模型在长视频理解中的表现，通过时间粒度优化和运动标记剪枝减少时空冗余。


<details>
  <summary>Details</summary>
Motivation: 长视频理解因时空冗余和多模态大模型上下文长度限制而困难，现有方法依赖语义先验（如CLIP），缺乏对运动信息的有效利用。

Method: 提出Flow4Agent框架，包含时间粒度优化（TGO）和运动标记剪枝（MTP）：TGO结合粗略光流和语义先验分层筛选关键帧，MTP利用细粒度光流剪除帧内冗余标记。

Result: 在多个长视频理解基准上超越现有方法，尤其在小时级任务中表现突出，Video-MME达64.7%，MLVU达71.4%，LongVideoBench达60.4%。

Conclusion: 引入光流运动先验可有效提升长视频理解性能，Flow4Agent为MLLM处理长视频提供了高效且可扩展的解决方案。

Abstract: Long-form video understanding has always been a challenging problem due to
the significant redundancy in both temporal and spatial contents. This
challenge is further exacerbated by the limited context length of Multimodal
Large Language Models (MLLMs). To address this issue, many previous works have
attempted to extract key video information, where the "key" is typically
semantic-aware and heavily dependent on the CLIP model as prior. In this paper,
we propose Flow4Agent, a novel framework that pioneeringly incorporates motion
priors from optical flow to facilitate LLM-based long video understanding.
Flow4Agent mitigates the redundancy in long videos at both temporal and spatial
levels through two core modules: Temporal Granularity Optimization (TGO)
adaptively refines framelevel hierarchies, which first leverages coarse flow
priors to group similar visual contents and then applies semantic priors to
filter out highly irrelevant scene information. Motion Token Pruning (MTP)
further refines the intra-frame visual representations, pruning high-redundancy
video tokens using fine-grained optical flow information. Extensive experiments
demonstrate that our Flow4Agent outperforms existing methods across a wide
range of video MLLM benchmarks, especially for hour-level video understanding
tasks, achieving 64.7% on Video-MME, 71.4% on MLVU and 60.4% on LongVideoBench.

</details>


### [43] [acia-workflows: Automated Single-cell Imaging Analysis for Scalable and Deep Learning-based Live-cell Imaging Analysis Workflows](https://arxiv.org/abs/2510.05886)
*Johannes Seiffarth,Keitaro Kasahara,Michelle Bund,Benita Lückel,Richard D. Paul,Mathias Pesch,Lennart Witting,Michael Bott,Dietrich Kohlheyer,Katharina Nöh*

Main category: cs.CV

TL;DR: 提出了一个名为acia-workflows的开源平台，集成了深度学习驱动的细胞分割与追踪工具，通过模块化、可复现的Jupyter Notebook工作流，支持高通量活细胞成像数据的自动化分析。


<details>
  <summary>Details</summary>
Motivation: 高通量活细胞成像产生大量数据，传统分析方法难以处理，现有深度学习方法缺乏易用、可复现的工作流支持，限制了其在生物学研究中的广泛应用。

Method: 构建了一个包含三部分的平台：(1) 支持多种深度学习模型的Python库acia；(2) 将分析流程、依赖、文档和可视化整合到Jupyter Notebook中的工作流；(3) 提供多个真实应用场景的示例工作流。

Result: 发布了超过十个开源应用工作流，支持从生长速率比较到单细胞动态响应的高分辨率定量分析，并已在微流控活细胞成像实验中成功应用。

Conclusion: acia-workflows平台通过集成深度学习与可复现计算环境，显著降低了活细胞成像数据分析的门槛，推动了其在生命科学研究中的常规化应用。

Abstract: Live-cell imaging (LCI) technology enables the detailed spatio-temporal
characterization of living cells at the single-cell level, which is critical
for advancing research in the life sciences, from biomedical applications to
bioprocessing. High-throughput setups with tens to hundreds of parallel cell
cultivations offer the potential for robust and reproducible insights. However,
these insights are obscured by the large amount of LCI data recorded per
experiment. Recent advances in state-of-the-art deep learning methods for cell
segmentation and tracking now enable the automated analysis of such large data
volumes, offering unprecedented opportunities to systematically study
single-cell dynamics. The next key challenge lies in integrating these powerful
tools into accessible, flexible, and user-friendly workflows that support
routine application in biological research. In this work, we present
acia-workflows, a platform that combines three key components: (1) the
Automated live-Cell Imaging Analysis (acia) Python library, which supports the
modular design of image analysis pipelines offering eight deep learning
segmentation and tracking approaches; (2) workflows that assemble the image
analysis pipeline, its software dependencies, documentation, and visualizations
into a single Jupyter Notebook, leading to accessible, reproducible and
scalable analysis workflows; and (3) a collection of application workflows
showcasing the analysis and customization capabilities in real-world
applications. Specifically, we present three workflows to investigate various
types of microfluidic LCI experiments ranging from growth rate comparisons to
precise, minute-resolution quantitative analyses of individual dynamic cells
responses to changing oxygen conditions. Our collection of more than ten
application workflows is open source and publicly available at
https://github.com/JuBiotech/acia-workflows.

</details>


### [44] [BioAutoML-NAS: An End-to-End AutoML Framework for Multimodal Insect Classification via Neural Architecture Search on Large-Scale Biodiversity Data](https://arxiv.org/abs/2510.05888)
*Arefin Ittesafun Abian,Debopom Sutradhar,Md Rafi Ur Rashid,Reem E. Mohamed,Md Rafiqul Islam,Asif Karim,Kheng Cher Yeo,Sami Azam*

Main category: cs.CV

TL;DR: 提出了一种基于多模态数据的自动化神经架构搜索模型BioAutoML-NAS，用于高效准确的昆虫分类，在大规模数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 昆虫分类对农业管理和生态研究至关重要，但由于昆虫特征复杂、类别不平衡和数据规模大，现有方法仍面临挑战，因此需要一种高效、自动化的多模态分类模型。

Method: 提出BioAutoML-NAS，结合图像与元数据进行多模态融合，采用神经架构搜索（NAS）自动学习图像分支的最优结构，通过堆叠多个细胞提取图像特征，并使用交替双层优化策略联合更新网络权重与架构参数，利用零操作剪枝冗余连接以提升效率。

Result: 在BIOSCAN-5M数据集上达到96.81%准确率、97.46%精度、96.81%召回率和97.05% F1分数，优于现有方法约8%-16%；在Insects-1M数据集上取得93.25%准确率和93.22% F1分数，验证了其有效性与泛化能力。

Conclusion: BioAutoML-NAS能有效融合视觉与生物元数据，实现高效、稀疏且性能优越的昆虫分类，为可持续农业提供了可靠的自动化工具。

Abstract: Insect classification is important for agricultural management and ecological
research, as it directly affects crop health and production. However, this task
remains challenging due to the complex characteristics of insects, class
imbalance, and large-scale datasets. To address these issues, we propose
BioAutoML-NAS, the first BioAutoML model using multimodal data, including
images, and metadata, which applies neural architecture search (NAS) for images
to automatically learn the best operations for each connection within each
cell. Multiple cells are stacked to form the full network, each extracting
detailed image feature representations. A multimodal fusion module combines
image embeddings with metadata, allowing the model to use both visual and
categorical biological information to classify insects. An alternating bi-level
optimization training strategy jointly updates network weights and architecture
parameters, while zero operations remove less important connections, producing
sparse, efficient, and high-performing architectures. Extensive evaluation on
the BIOSCAN-5M dataset demonstrates that BioAutoML-NAS achieves 96.81%
accuracy, 97.46% precision, 96.81% recall, and a 97.05% F1 score, outperforming
state-of-the-art transfer learning, transformer, AutoML, and NAS methods by
approximately 16%, 10%, and 8% respectively. Further validation on the
Insects-1M dataset obtains 93.25% accuracy, 93.71% precision, 92.74% recall,
and a 93.22% F1 score. These results demonstrate that BioAutoML-NAS provides
accurate, confident insect classification that supports modern sustainable
farming.

</details>


### [45] [$\bf{D^3}$QE: Learning Discrete Distribution Discrepancy-aware Quantization Error for Autoregressive-Generated Image Detection](https://arxiv.org/abs/2510.05891)
*Yanran Zhang,Bingyao Yu,Yu Zheng,Wenzhao Zheng,Yueqi Duan,Lei Chen,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: 提出利用离散分布差异感知的量化误差（D³QE）方法，用于检测自回归生成图像，通过融合动态码本频率统计与语义特征，在多种视觉AR模型上实现高精度和强泛化性的检测。


<details>
  <summary>Details</summary>
Motivation: 视觉自回归模型在图像生成方面表现出色，但其基于离散标记预测的机制带来了新的伪造图像检测挑战，需探索其特有的向量量化表示中的差异。

Method: 提出D³QE方法，设计离散分布差异感知的Transformer架构，将动态码本频率统计信息融入注意力机制，并融合语义特征与量化误差潜在表示。

Result: 在涵盖7个主流视觉AR模型的ARForensics数据集上验证了方法有效性，D³QE展现出优越的检测准确率、跨模型泛化能力及对真实世界扰动的鲁棒性。

Conclusion: D³QE能有效捕捉AR生成图像在码本分布上的固有偏差，为检测新一代自回归图像提供了新思路。

Abstract: The emergence of visual autoregressive (AR) models has revolutionized image
generation while presenting new challenges for synthetic image detection.
Unlike previous GAN or diffusion-based methods, AR models generate images
through discrete token prediction, exhibiting both marked improvements in image
synthesis quality and unique characteristics in their vector-quantized
representations. In this paper, we propose to leverage Discrete Distribution
Discrepancy-aware Quantization Error (D$^3$QE) for autoregressive-generated
image detection that exploits the distinctive patterns and the frequency
distribution bias of the codebook existing in real and fake images. We
introduce a discrete distribution discrepancy-aware transformer that integrates
dynamic codebook frequency statistics into its attention mechanism, fusing
semantic features and quantization error latent. To evaluate our method, we
construct a comprehensive dataset termed ARForensics covering 7 mainstream
visual AR models. Experiments demonstrate superior detection accuracy and
strong generalization of D$^3$QE across different AR models, with robustness to
real-world perturbations. Code is available at
\href{https://github.com/Zhangyr2022/D3QE}{https://github.com/Zhangyr2022/D3QE}.

</details>


### [46] [Efficient Universal Models for Medical Image Segmentation via Weakly Supervised In-Context Learning](https://arxiv.org/abs/2510.05899)
*Jiesi Hu,Yanwu Yang,Zhiyu Ye,Jinyan Zhou,Jianfeng Cao,Hanyang Peng,Ting Ma*

Main category: cs.CV

TL;DR: 提出了一种弱监督的上下文学习方法（WS-ICL），利用弱标注（如边界框或点）替代密集标签，显著降低医学图像分割中的标注成本，同时保持与常规ICL模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像分割通用模型（如交互式模型和上下文学习模型）依赖大量精细标注，标注成本高。为了减少标注负担，需要一种能利用弱标注信息的新方法。

Method: 提出弱监督上下文学习（WS-ICL），使用弱提示（如边界框或点）构建上下文，避免对像素级掩码和重复用户提示的依赖，并在三个基准数据集上进行评估。

Result: WS-ICL在性能上与传统的ICL模型相当，但标注成本显著降低，并在交互式设置下也表现出很强的竞争力。

Conclusion: WS-ICL是一种高效且统一的医学图像分割通用模型新范式，为降低标注成本提供了可行路径。

Abstract: Universal models for medical image segmentation, such as interactive and
in-context learning (ICL) models, offer strong generalization but require
extensive annotations. Interactive models need repeated user prompts for each
image, while ICL relies on dense, pixel-level labels. To address this, we
propose Weakly Supervised In-Context Learning (WS-ICL), a new ICL paradigm that
leverages weak prompts (e.g., bounding boxes or points) instead of dense labels
for context. This approach significantly reduces annotation effort by
eliminating the need for fine-grained masks and repeated user prompting for all
images. We evaluated the proposed WS-ICL model on three held-out benchmarks.
Experimental results demonstrate that WS-ICL achieves performance comparable to
regular ICL models at a significantly lower annotation cost. In addition,
WS-ICL is highly competitive even under the interactive paradigm. These
findings establish WS-ICL as a promising step toward more efficient and unified
universal models for medical image segmentation. Our code and model are
publicly available at https://github.com/jiesihu/Weak-ICL.

</details>


### [47] [Kaputt: A Large-Scale Dataset for Visual Defect Detection](https://arxiv.org/abs/2510.05903)
*Sebastian Höfer,Dorian Henning,Artemij Amiranashvili,Douglas Morrison,Mariliza Tzes,Ingmar Posner,Marc Matvienko,Alessandro Rennola,Anton Milan*

Main category: cs.CV

TL;DR: 提出一个用于物流场景缺陷检测的大规模数据集，相较于现有数据集（如MVTec-AD）在规模和多样性上大幅提升，验证了现有异常检测方法在此新场景下的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有工业异常检测数据集主要针对制造场景，受限于物体类别和姿态控制，已趋于饱和；而零售物流中的异常检测面临更大挑战，需应对物体姿态和外观的高度多样性和变化性。

Method: 构建了一个包含超过23万张图像、2.9万个缺陷样本和4.8万种不同物体的新数据集，并对多种最先进的异常检测方法进行了广泛评估。

Result: 当前最先进的方法在该数据集上的AUROC得分不超过56.96%，显著低于其在MVTec-AD等数据集上的表现，表明该任务更具挑战性。

Conclusion: 该数据集为零售物流中的异常检测设立了新基准，推动未来研究关注复杂姿态和外观变化下的缺陷检测问题。

Abstract: We present a novel large-scale dataset for defect detection in a logistics
setting. Recent work on industrial anomaly detection has primarily focused on
manufacturing scenarios with highly controlled poses and a limited number of
object categories. Existing benchmarks like MVTec-AD [6] and VisA [33] have
reached saturation, with state-of-the-art methods achieving up to 99.9% AUROC
scores. In contrast to manufacturing, anomaly detection in retail logistics
faces new challenges, particularly in the diversity and variability of object
pose and appearance. Leading anomaly detection methods fall short when applied
to this new setting. To bridge this gap, we introduce a new benchmark that
overcomes the current limitations of existing datasets. With over 230,000
images (and more than 29,000 defective instances), it is 40 times larger than
MVTec-AD and contains more than 48,000 distinct objects. To validate the
difficulty of the problem, we conduct an extensive evaluation of multiple
state-of-the-art anomaly detection methods, demonstrating that they do not
surpass 56.96% AUROC on our dataset. Further qualitative analysis confirms that
existing methods struggle to leverage normal samples under heavy pose and
appearance variation. With our large-scale dataset, we set a new benchmark and
encourage future research towards solving this challenging problem in retail
logistics anomaly detection. The dataset is available for download under
https://www.kaputt-dataset.com.

</details>


### [48] [Shaken or Stirred? An Analysis of MetaFormer's Token Mixing for Medical Imaging](https://arxiv.org/abs/2510.05971)
*Ron Keuth,Paul Kaftan,Mattias P. Heinrich*

Main category: cs.CV

TL;DR: 本文首次对医疗影像中的Token Mixer进行了全面研究，系统评估了Pooling、卷积和注意力机制在MetaFormer架构下的表现。结果表明，对于分类任务，低复杂度的Mixer（如分组卷积或池化）已足够；而对于分割任务，卷积类Mixer的局部归纳偏置至关重要，分组卷积为最优选择。


<details>
  <summary>Details</summary>
Motivation: 尽管MetaFormer架构在自然图像中被广泛研究，但在医学影像中的应用仍较少，且缺乏对不同Token Mixer的系统比较，可能忽略了更适合医疗数据的设计。

Method: 在MetaFormer框架下，系统分析了基于池化、卷积和注意力的Token Mixer在图像分类和语义分割任务中的表现，涵盖八个多模态医学影像数据集，并研究了从自然图像预训练权重迁移至新Mixer的有效性。

Result: 分类任务中，低复杂度的Token Mixer（如分组卷积、池化）性能足够且预训练权重仍有效；分割任务中，卷积类Mixer的局部归纳偏置关键，分组卷积在降低计算和参数量的同时保持性能，优于标准卷积。

Conclusion: MetaFormer在医学影像中同样适用，任务类型决定Token Mixer的选择：分类任务可用简单Mixer，分割任务则需保留卷积的局部结构建模能力，分组卷积为高效且有效的首选设计。

Abstract: The generalization of the Transformer architecture via MetaFormer has
reshaped our understanding of its success in computer vision. By replacing
self-attention with simpler token mixers, MetaFormer provides strong baselines
for vision tasks. However, while extensively studied on natural image datasets,
its use in medical imaging remains scarce, and existing works rarely compare
different token mixers, potentially overlooking more suitable designs choices.
In this work, we present the first comprehensive study of token mixers for
medical imaging. We systematically analyze pooling-, convolution-, and
attention-based token mixers within the MetaFormer architecture on image
classification (global prediction task) and semantic segmentation (dense
prediction task). Our evaluation spans eight datasets covering diverse
modalities and common challenges in the medical domain. Given the prevalence of
pretraining from natural images to mitigate medical data scarcity, we also
examine transferring pretrained weights to new token mixers. Our results show
that, for classification, low-complexity token mixers (e.g. grouped convolution
or pooling) are sufficient, aligning with findings on natural images.
Pretrained weights remain useful despite the domain gap introduced by the new
token mixer. For segmentation, we find that the local inductive bias of
convolutional token mixers is essential. Grouped convolutions emerge as the
preferred choice, as they reduce runtime and parameter count compared to
standard convolutions, while the MetaFormer's channel-MLPs already provide the
necessary cross-channel interactions. Our code is available on GitHub.

</details>


### [49] [Diffusion Models for Low-Light Image Enhancement: A Multi-Perspective Taxonomy and Performance Analysis](https://arxiv.org/abs/2510.05976)
*Eashan Adhikarla,Yixin Liu,Brian D. Davison*

Main category: cs.CV

TL;DR: 本文综述了基于扩散模型的低光照图像增强（LLIE）技术，提出了一个涵盖六类方法的多视角分类体系，并对现有方法进行了全面性能比较与实际部署挑战分析，探讨了未来研究方向如基础模型的应用。


<details>
  <summary>Details</summary>
Motivation: 由于低光照条件下视觉退化会影响下游任务性能，在监控、自动驾驶和医学成像等安全关键应用中，LLIE至关重要。扩散模型虽展现出潜力，但仍需系统性评估与分类以指导未来研究。

Method: 提出一种结合模型机制与条件信号的混合视角，构建六类多视角分类法（内在分解、光谱与潜在、加速、引导、多模态与自主），并对扩散模型与其他先进方法（如GAN和Transformer）进行深入对比分析。

Result: 全面评估了扩散模型在LLIE中的性能表现、推理效率、泛化能力及失败模式，揭示了当前基准不一致问题，并分析了实际部署中的内存、能耗等限制因素。

Conclusion: 扩散模型在LLIE中具有巨大潜力，未来研究应关注新型条件机制、实时适应性以及基础模型的融合，以推动该领域的进一步发展。

Abstract: Low-light image enhancement (LLIE) is vital for safety-critical applications
such as surveillance, autonomous navigation, and medical imaging, where
visibility degradation can impair downstream task performance. Recently,
diffusion models have emerged as a promising generative paradigm for LLIE due
to their capacity to model complex image distributions via iterative denoising.
This survey provides an up-to-date critical analysis of diffusion models for
LLIE, distinctively featuring an in-depth comparative performance evaluation
against Generative Adversarial Network and Transformer-based state-of-the-art
methods, a thorough examination of practical deployment challenges, and a
forward-looking perspective on the role of emerging paradigms like foundation
models. We propose a multi-perspective taxonomy encompassing six categories:
Intrinsic Decomposition, Spectral & Latent, Accelerated, Guided, Multimodal,
and Autonomous; that map enhancement methods across physical priors,
conditioning schemes, and computational efficiency. Our taxonomy is grounded in
a hybrid view of both the model mechanism and the conditioning signals. We
evaluate qualitative failure modes, benchmark inconsistencies, and trade-offs
between interpretability, generalization, and inference efficiency. We also
discuss real-world deployment constraints (e.g., memory, energy use) and
ethical considerations. This survey aims to guide the next generation of
diffusion-based LLIE research by highlighting trends and surfacing open
research questions, including novel conditioning, real-time adaptation, and the
potential of foundation models.

</details>


### [50] [A Dynamic Mode Decomposition Approach to Morphological Component Analysis](https://arxiv.org/abs/2510.05977)
*Owen T. Huber,Raghu G. Raj,Tianyu Chen,Zacharie I. Idriss*

Main category: cs.CV

TL;DR: 提出一种基于动态模态分解特征值聚类的自适应视频表示方法，用于分离视频中结构上不同的成分，并应用于去噪和信号增强。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地分离视频中不同结构形态的成分，克服传统方法依赖预定义字典的局限性。

Method: 提出动态形态成分分析（DMCA），通过动态模态分解特征值的聚类学习数据驱动的MCA字典，扩展了传统的形态成分分析算法。

Result: 在Adobe 240fps视频数据集上验证了DMCA在去噪任务中的有效性，并成功应用于提升微弱目标信噪比以及分离ISAR图像中的自行车与风杂波。

Conclusion: DMCA是一种有效的数据驱动方法，能够自适应地分离复杂场景中的不同动态成分，具有在视频处理和雷达图像分析中的应用潜力。

Abstract: This paper introduces a novel methodology of adapting the representation of
videos based on the dynamics of their scene content variation. In particular,
we demonstrate how the clustering of dynamic mode decomposition eigenvalues can
be leveraged to learn an adaptive video representation for separating
structurally distinct morphologies of a video. We extend the morphological
component analysis (MCA) algorithm, which uses multiple predefined incoherent
dictionaries and a sparsity prior to separate distinct sources in signals, by
introducing our novel eigenspace clustering technique to obtain data-driven MCA
dictionaries, which we call dynamic morphological component analysis (DMCA).
After deriving our novel algorithm, we offer a motivational example of DMCA
applied to a still image, then demonstrate DMCA's effectiveness in denoising
applications on videos from the Adobe 240fps dataset. Afterwards, we provide an
example of DMCA enhancing the signal-to-noise ratio of a faint target summed
with a sea state, and conclude the paper by applying DMCA to separate a bicycle
from wind clutter in inverse synthetic aperture radar images.

</details>


### [51] [Diffusion-Based Image Editing for Breaking Robust Watermarks](https://arxiv.org/abs/2510.05978)
*Yunyi Ni,Finn Carter,Ze Niu,Emily Davis,Bo Zhang*

Main category: cs.CV

TL;DR: 本文研究发现，基于扩散模型的图像生成与编辑技术能有效破坏传统鲁棒隐形水印，提出一种针对水印信号的引导扩散攻击，可几乎完全消除水印且保持图像视觉质量。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型在图像生成和编辑中的强大能力兴起，传统设计用于抵御常规扰动的鲁棒水印面临新威胁，亟需研究其安全性漏洞。

Method: 提出一种引导扩散攻击方法，在图像再生过程中显式针对水印信号进行干扰；理论证明随着扩散变换加深，水印与图像间的互信息趋于消失，导致解码失败。

Result: 在StegaStamp、TrustMark和VINE等多个先进水印方案上实验显示，攻击后水印恢复率接近为零，同时再生图像保持高视觉保真度。

Conclusion: 当前鲁棒水印技术在生成模型攻击下面临根本性脆弱性，需在生成式AI时代发展新的水印策略。

Abstract: Robust invisible watermarking aims to embed hidden information into images
such that the watermark can survive various image manipulations. However, the
rise of powerful diffusion-based image generation and editing techniques poses
a new threat to these watermarking schemes. In this paper, we present a
theoretical study and method demonstrating that diffusion models can
effectively break robust image watermarks that were designed to resist
conventional perturbations. We show that a diffusion-driven ``image
regeneration'' process can erase embedded watermarks while preserving
perceptual image content. We further introduce a novel guided diffusion attack
that explicitly targets the watermark signal during generation, significantly
degrading watermark detectability. Theoretically, we prove that as an image
undergoes sufficient diffusion-based transformation, the mutual information
between the watermarked image and the embedded watermark payload vanishes,
resulting in decoding failure. Experimentally, we evaluate our approach on
multiple state-of-the-art watermarking schemes (including the deep
learning-based methods StegaStamp, TrustMark, and VINE) and demonstrate
near-zero watermark recovery rates after attack, while maintaining high visual
fidelity of the regenerated images. Our findings highlight a fundamental
vulnerability in current robust watermarking techniques against generative
model-based attacks, underscoring the need for new watermarking strategies in
the era of generative AI.

</details>


### [52] [Detection and Measurement of Hailstones with Multimodal Large Language Models](https://arxiv.org/abs/2510.06008)
*Moritz Alker,David C. Schedl,Andreas Stöckl*

Main category: cs.CV

TL;DR: 利用预训练的多模态大语言模型，从社交媒体和新闻图像中检测和测量冰雹尺寸，结果显示无需微调的现成模型即可实现平均绝对误差1.12cm的测量精度，尤其通过两阶段提示策略提升了可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统冰雹监测依赖专用传感器，覆盖密度有限；而社交媒体图像来源广泛、时空密度高，因此探索利用现成多模态大模型从图像中自动提取冰雹尺寸信息，以补充传统观测手段。

Method: 收集了2022年1月至2024年9月奥地利474张冰雹事件的众包图像，冰雹直径范围为2-11cm；采用四种基于预训练多模态大语言模型的方法，比较单阶段与双阶段提示策略（后者利用图像中参照物如人手提供尺寸线索）来估计冰雹直径。

Result: 最优模型的平均绝对误差为1.12cm；双阶段提示策略在大多数模型中提升了测量可靠性；表明无需微调的现成模型已具备从图像中估算冰雹尺寸的能力。

Conclusion: 预训练多模态大语言模型可有效从社交媒体图像中提取冰雹尺寸信息，补充传统传感器观测，实现更快、更详细的极端天气评估；未来结合自动化实时图像采集将使该方法可直接应用于实际冰雹事件监测。

Abstract: This study examines the use of social media and news images to detect and
measure hailstones, utilizing pre-trained multimodal large language models. The
dataset for this study comprises 474 crowdsourced images of hailstones from
documented hail events in Austria, which occurred between January 2022 and
September 2024. These hailstones have maximum diameters ranging from 2 to 11cm.
We estimate the hail diameters and compare four different models utilizing
one-stage and two-stage prompting strategies. The latter utilizes additional
size cues from reference objects, such as human hands, within the image. Our
results show that pretrained models already have the potential to measure
hailstone diameters from images with an average mean absolute error of 1.12cm
for the best model. In comparison to a single-stage prompt, two-stage prompting
improves the reliability of most models. Our study suggests that these
off-the-shelf models, even without fine-tuning, can complement traditional hail
sensors by extracting meaningful and spatially dense information from social
media imagery, enabling faster and more detailed assessments of severe weather
events. The automated real-time image harvesting from social media and other
sources remains an open task, but it will make our approach directly applicable
to future hail events.

</details>


### [53] [Continual Learning for Image Captioning through Improved Image-Text Alignment](https://arxiv.org/abs/2510.06009)
*Bertram Taetz,Gal Bordelius*

Main category: cs.CV

TL;DR: 提出了一种用于连续图像描述的多损失框架，通过基于提示的持续学习和对比对齐来缓解灾难性遗忘并提高语义对齐性。


<details>
  <summary>Details</summary>
Motivation: 在持续学习场景中，图像描述面临灾难性遗忘和视觉概念与语言随时间对齐困难的问题，需要更有效的框架来保持模型的学习能力。

Method: 基于预训练的ViT-GPT-2主干，结合标准交叉熵损失与三种新损失：基于提示的余弦相似性损失、CLIP风格的图像-描述对齐损失和语言引导的对比损失（三元组损失），实现语义引导和任务间区分。

Result: 该方法在不增加推理开销和无需提示生成描述的情况下，有效缓解了灾难性遗忘，并在语义对齐方面优于现有最先进方法。

Conclusion: 所提出的多损失框架能够有效支持持续图像描述任务中的知识保留与语义一致性，具有实际应用潜力。

Abstract: Generating accurate and coherent image captions in a continual learning
setting remains a major challenge due to catastrophic forgetting and the
difficulty of aligning evolving visual concepts with language over time. In
this work, we propose a novel multi-loss framework for continual image
captioning that integrates semantic guidance through prompt-based continual
learning and contrastive alignment. Built upon a pretrained ViT-GPT-2 backbone,
our approach combines standard cross-entropy loss with three additional
components: (1) a prompt-based cosine similarity loss that aligns image
embeddings with synthetically constructed prompts encoding objects, attributes,
and actions; (2) a CLIP-style loss that promotes alignment between image
embeddings and target caption embedding; and (3) a language-guided contrastive
loss that employs a triplet loss to enhance class-level discriminability
between tasks. Notably, our approach introduces no additional overhead at
inference time and requires no prompts during caption generation. We find that
this approach mitigates catastrophic forgetting, while achieving better
semantic caption alignment compared to state-of-the-art methods. The code can
be found via the following link https://github.com/
Gepardius/Taetz_Bordelius_Continual_ImageCaptioning.

</details>


### [54] [Emergent AI Surveillance: Overlearned Person Re-Identification and Its Mitigation in Law Enforcement Context](https://arxiv.org/abs/2510.06026)
*An Thi Nguyen,Radina Stoykova,Eric Arazo*

Main category: cs.CV

TL;DR: 研究表明，通用实例搜索模型在过度学习后可能意外获得识别特定个体的能力，引发隐私和数据保护担忧；通过索引排除和混淆损失可缓解该问题，但存在漏洞，需制定相应技术标准与监管政策。


<details>
  <summary>Details</summary>
Motivation: 探讨通用实例搜索模型在无意识下发展出识别人物的能力及其带来的隐私风险，并寻求有效的技术缓解措施与监管框架。

Method: 评估两种技术防护手段——指数排除和混淆损失——对抑制模型人物再识别能力的效果，并测试其在部分人物图像下的鲁棒性。

Result: 结合两种方法可将人物再识别准确率降至2%以下，同时保留82%的非人物对象检索性能，但发现部分人物图像可能绕过防护。

Conclusion: 需要建立明确的技术标准和监管机制，以防止看似无害的AI应用发展出意外的身份识别能力，保障个人隐私与数据安全。

Abstract: Generic instance search models can dramatically reduce the manual effort
required to analyze vast surveillance footage during criminal investigations by
retrieving specific objects of interest to law enforcement. However, our
research reveals an unintended emergent capability: through overlearning, these
models can single out specific individuals even when trained on datasets
without human subjects. This capability raises concerns regarding
identification and profiling of individuals based on their personal data, while
there is currently no clear standard on how de-identification can be achieved.
We evaluate two technical safeguards to curtail a model's person
re-identification capacity: index exclusion and confusion loss. Our experiments
demonstrate that combining these approaches can reduce person re-identification
accuracy to below 2% while maintaining 82% of retrieval performance for
non-person objects. However, we identify critical vulnerabilities in these
mitigations, including potential circumvention using partial person images.
These findings highlight urgent regulatory questions at the intersection of AI
governance and data protection: How should we classify and regulate systems
with emergent identification capabilities? And what technical standards should
be required to prevent identification capabilities from developing in seemingly
benign applications?

</details>


### [55] [Universal Neural Architecture Space: Covering ConvNets, Transformers and Everything in Between](https://arxiv.org/abs/2510.06035)
*Ondřej Týbl,Lukáš Neumann*

Main category: cs.CV

TL;DR: 提出通用神经架构空间UniNAS，统一卷积网络、Transformer及其混合架构，支持新架构发现与现有架构分析，并通过新搜索算法找到优于现有手工设计的架构。


<details>
  <summary>Details</summary>
Motivation: 现有的神经架构搜索空间通常局限于特定类型的网络结构，缺乏统一性和灵活性，难以探索卷积网络、Transformer及其混合架构的完整设计空间。

Method: 构建一个统一的图基神经架构搜索空间UniNAS，涵盖卷积网络、Transformer和混合结构，并提出新的搜索算法来有效遍历该空间，同时提供标准化训练与评估工具包以提升可复现性。

Result: 在相同训练设置下，发现的架构性能优于最先进的手工设计模型，验证了UniNAS空间的有效性和潜力。

Conclusion: UniNAS为系统化探索多样化神经架构提供了统一框架，推动NAS研究向更通用、可比较和可复现的方向发展。

Abstract: We introduce Universal Neural Architecture Space (UniNAS), a generic search
space for neural architecture search (NAS) which unifies convolutional
networks, transformers, and their hybrid architectures under a single, flexible
framework. Our approach enables discovery of novel architectures as well as
analyzing existing architectures in a common framework. We also propose a new
search algorithm that allows traversing the proposed search space, and
demonstrate that the space contains interesting architectures, which, when
using identical training setup, outperform state-of-the-art hand-crafted
architectures. Finally, a unified toolkit including a standardized training and
evaluation protocol is introduced to foster reproducibility and enable fair
comparison in NAS research. Overall, this work opens a pathway towards
systematically exploring the full spectrum of neural architectures with a
unified graph-based NAS perspective.

</details>


### [56] [VideoMiner: Iteratively Grounding Key Frames of Hour-Long Videos via Tree-based Group Relative Policy Optimization](https://arxiv.org/abs/2510.06040)
*Xinye Cao,Hongcan Guo,Jiawen Qian,Guoshun Nan,Chao Wang,Yuqi Pan,Tianhao Hou,Xiaojuan Wang,Yutong Gao*

Main category: cs.CV

TL;DR: 提出VideoMiner和T-GRPO方法，通过层次化树结构和基于树的强化学习策略优化，实现对长视频的有效理解与关键帧精确定位。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长视频时难以避免冗余信息干扰，且无法动态适应复杂层次结构以准确识别关键帧，本文旨在解决这两个挑战。

Method: 提出VideoMiner框架，通过迭代分割、描述和聚类构建长视频的层次化树结构，并引入T-GRPO（基于树的分组相对策略优化）强化学习方法，结合时空信息与问题导向探索关键帧。

Result: 在所有长视频理解任务中均取得优越性能，T-GRPO能自发激励模型生成推理链，树生长辅助机制动态调整扩展深度，提升准确率与效率。

Conclusion: VideoMiner与T-GRPO有效解决了长视频中冗余信息干扰和关键帧动态定位问题，为多模态大模型处理长视频提供了高效且可解释的框架。

Abstract: Understanding hour-long videos with multi-modal large language models
(MM-LLMs) enriches the landscape of human-centered AI applications. However,
for end-to-end video understanding with LLMs, uniformly sampling video frames
results in LLMs being overwhelmed by a vast amount of irrelevant information as
video length increases. Existing hierarchical key frame extraction methods
improve the accuracy of video understanding but still face two critical
challenges. 1) How can the interference of extensive redundant information in
long videos be mitigated? 2) How can a model dynamically adapt to complex
hierarchical structures while accurately identifying key frames? To address
these issues, we propose VideoMiner, which iteratively segments, captions, and
clusters long videos, forming a hierarchical tree structure. The proposed
VideoMiner progresses from long videos to events to frames while preserving
temporal coherence, effectively addressing the first challenge. To precisely
locate key frames, we introduce T-GRPO, a tree-based group relative policy
optimization in reinforcement learning method that guides the exploration of
the VideoMiner. The proposed T-GRPO is specifically designed for tree
structures, integrating spatiotemporal information at the event level while
being guided by the question, thus solving the second challenge. We achieve
superior performance in all long-video understanding tasks and uncover several
interesting insights. Our proposed T-GRPO surprisingly incentivizes the model
to spontaneously generate a reasoning chain. Additionally, the designed tree
growth auxin dynamically adjusts the expansion depth, obtaining accuracy and
efficiency gains. The code is publicly available at
https://github.com/caoxinye/VideoMiner.

</details>


### [57] [GLVD: Guided Learned Vertex Descent](https://arxiv.org/abs/2510.06046)
*Pol Caselles Rico,Francesc Moreno Noguer*

Main category: cs.CV

TL;DR: 提出了一种名为GLVD的混合方法，通过结合每顶点神经场优化和动态预测的3D关键点全局结构引导，实现了高效且高质量的少样本图像3D人脸重建。


<details>
  <summary>Details</summary>
Motivation: 现有3D人脸建模方法受限于固定的形状先验，基于优化的方法虽然质量高但计算开销大。因此，需要一种兼具高表达能力和高效率的方法。

Method: 扩展了Learned Vertex Descent（LVD），引入每顶点神经场优化，并结合动态预测的3D关键点提供全局结构引导；采用相对空间编码，迭代优化网格顶点，无需密集3D监督。

Result: 在单视图设置下达到最先进性能，在多视图场景中也具有强竞争力，同时显著降低了推理时间。

Conclusion: GLVD在保持计算效率的同时，实现了高质量、可表达且自适应的3D人脸几何重建，优于现有方法。

Abstract: Existing 3D face modeling methods usually depend on 3D Morphable Models,
which inherently constrain the representation capacity to fixed shape priors.
Optimization-based approaches offer high-quality reconstructions but tend to be
computationally expensive. In this work, we introduce GLVD, a hybrid method for
3D face reconstruction from few-shot images that extends Learned Vertex Descent
(LVD) by integrating per-vertex neural field optimization with global
structural guidance from dynamically predicted 3D keypoints. By incorporating
relative spatial encoding, GLVD iteratively refines mesh vertices without
requiring dense 3D supervision. This enables expressive and adaptable geometry
reconstruction while maintaining computational efficiency. GLVD achieves
state-of-the-art performance in single-view settings and remains highly
competitive in multi-view scenarios, all while substantially reducing inference
time.

</details>


### [58] [Medical Vision Language Models as Policies for Robotic Surgery](https://arxiv.org/abs/2510.06064)
*Akshay Muppidi,Martin Radfar*

Main category: cs.CV

TL;DR: 提出了一种结合医疗领域特定视觉语言模型MedFlamingo与PPO的新方法，显著提升了基于视觉的机器人腹腔镜手术任务的性能和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 视觉PPO在腹腔镜手术任务中面临高维视觉输入、稀疏奖励和难以从原始视觉数据提取任务相关特征的挑战，需引入领域知识提升性能。

Method: 将MedFlamingo与PPO结合，利用MedFlamingo在每集开始时处理任务观察和指令，生成高层规划token，融合医学专业知识与实时视觉反馈。

Result: 在LapGym五个手术环境中，MedFlamingo PPO任务成功率均超过70%，相比基线提升66.67%至1114.29%，且收敛更快。

Conclusion: 引入医疗领域特定知识可显著提升机器人手术中的策略学习效果，验证了专业视觉语言模型在手术决策中的价值。

Abstract: Vision-based Proximal Policy Optimization (PPO) struggles with visual
observation-based robotic laparoscopic surgical tasks due to the
high-dimensional nature of visual input, the sparsity of rewards in surgical
environments, and the difficulty of extracting task-relevant features from raw
visual data. We introduce a simple approach integrating MedFlamingo, a medical
domain-specific Vision-Language Model, with PPO. Our method is evaluated on
five diverse laparoscopic surgery task environments in LapGym, using only
endoscopic visual observations. MedFlamingo PPO outperforms and converges
faster compared to both standard vision-based PPO and OpenFlamingo PPO
baselines, achieving task success rates exceeding 70% across all environments,
with improvements ranging from 66.67% to 1114.29% compared to baseline. By
processing task observations and instructions once per episode to generate
high-level planning tokens, our method efficiently combines medical expertise
with real-time visual feedback. Our results highlight the value of specialized
medical knowledge in robotic surgical planning and decision-making.

</details>


### [59] [Reasoning under Vision: Understanding Visual-Spatial Cognition in Vision-Language Models for CAPTCHA](https://arxiv.org/abs/2510.06067)
*Python Song,Luke Tenyi Chang,Yun-Yun Tsai,Penghui Li,Junfeng Yang*

Main category: cs.CV

TL;DR: 本文提出CAPTCHA-X，首个结合推理的真实世界验证码基准，揭示了当前视觉语言模型（VLMs）在空间推理任务中的局限性，并通过引入逐步推理框架显著提升验证码求解准确率至83.9%。


<details>
  <summary>Details</summary>
Motivation: 验证码作为衡量视觉语言模型空间推理能力的现实任务，当前模型表现不佳，需系统评估并提升其推理能力。

Method: 构建包含七类验证码的CAPTCHA-X基准，提供逐步动作解和标注；设计五项面向推理的评估指标；提出一种基于代理的VLM框架，强制模型进行逐步推理。

Result: 当前商业VLM在验证码任务上准确率仅为21.9%，而引入逐步推理后准确率提升至83.9%，在五类高难度验证码上达到SOTA性能。

Conclusion: 逐步推理对提升VLM在复杂空间任务中的表现至关重要，CAPTCHA-X为未来视觉推理研究提供了有效基准。

Abstract: CAPTCHA, originally designed to distinguish humans from robots, has evolved
into a real-world benchmark for assessing the spatial reasoning capabilities of
vision-language models. In this work, we first show that step-by-step reasoning
is crucial for vision-language models (VLMs) to solve CAPTCHAs, which represent
high-difficulty spatial reasoning tasks, and that current commercial
vision-language models still struggle with such reasoning. In particular, we
observe that most commercial VLMs (e.g., Gemini, Claude, GPT, etc.) fail to
effectively solve CAPTCHAs and thus achieve low accuracy (around 21.9 percent).
However, our findings indicate that requiring the model to perform step-by-step
reasoning before generating the final coordinates can significantly enhance its
solving accuracy, underscoring the severity of the gap. To systematically study
this issue, we introduce CAPTCHA-X, the first real-world CAPTCHA benchmark with
reasoning, covering seven categories of CAPTCHAs (such as Gobang, hCaptcha,
etc.) with step-by-step action solutions and grounding annotations. We further
define five reasoning-oriented metrics that enable a comprehensive evaluation
of models reasoning capabilities. To validate the effectiveness of reasoning,
we also propose a general agentic VLM-based framework that incorporates the
models inherent reasoning abilities. Our method achieves state-of-the-art
performance across five high-difficulty CAPTCHA types, with an average solving
accuracy of 83.9 percent, substantially surpassing existing baselines. These
results reveal the limitations of current models and highlight the importance
of reasoning in advancing visual-spatial challenges in the future.

</details>


### [60] [There is More to Attention: Statistical Filtering Enhances Explanations in Vision Transformers](https://arxiv.org/abs/2510.06070)
*Meghna P Ayyar,Jenny Benois-Pineau,Akka Zemmari*

Main category: cs.CV

TL;DR: 提出一种结合注意力图和统计滤波的方法，生成更清晰、更符合人类感知的视觉Transformer解释，优于或媲美现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision Transformer解释方法多依赖注意力权重，导致噪声大、解释性差；而许多为CNN设计的解释方法难以迁移到ViT。需要一种更有效、忠实且人类可理解的解释方式。

Method: 将注意力图与一种用于CNN的统计滤波方法结合，去除噪声或无信息的模式，并进一步提出类别特定变体以生成判别性解释。

Result: 在多个数据集上，该方法生成的解释图更清晰、更可读，优于或与现有最先进方法相当；使用扰动实验和人类眼动数据验证了其忠实性和与人类感知的一致性。

Conclusion: 经统计滤波的注意力图是生成Vision Transformer可解释结果的有效途径，兼顾效率、忠实性和人类可解释性。

Abstract: Explainable AI (XAI) has become increasingly important with the rise of large
transformer models, yet many explanation methods designed for CNNs transfer
poorly to Vision Transformers (ViTs). Existing ViT explanations often rely on
attention weights, which tend to yield noisy maps as they capture
token-to-token interactions within each layer.While attribution methods
incorporating MLP blocks have been proposed, we argue that attention remains a
valuable and interpretable signal when properly filtered. We propose a method
that combines attention maps with a statistical filtering, initially proposed
for CNNs, to remove noisy or uninformative patterns and produce more faithful
explanations. We further extend our approach with a class-specific variant that
yields discriminative explanations. Evaluation against popular state-of-the-art
methods demonstrates that our approach produces sharper and more interpretable
maps. In addition to perturbation-based faithfulness metrics, we incorporate
human gaze data to assess alignment with human perception, arguing that human
interpretability remains essential for XAI. Across multiple datasets, our
approach consistently outperforms or is comparable to the SOTA methods while
remaining efficient and human plausible.

</details>


### [61] [When Thinking Drifts: Evidential Grounding for Robust Video Reasoning](https://arxiv.org/abs/2510.06077)
*Mi Luo,Zihui Xue,Alex Dimakis,Kristen Grauman*

Main category: cs.CV

TL;DR: 本文研究了链式思维（CoT）在视频推理中的局限性，提出“视觉思维漂移”概念，并引入基于视觉证据奖励（VER）的强化学习框架以提升多步视频推理的准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管链式思维（CoT）在文本推理中效果显著，但在视频理解中却常导致性能下降。作者旨在揭示CoT在视频推理中的根本问题，并提出一种更可靠、基于视觉证据的推理机制。

Method: 通过贝叶斯视角分析CoT导致的“视觉思维漂移”现象，提出视觉证据奖励（VER）框架，利用强化学习鼓励模型生成可验证地基于视觉证据的推理轨迹，并在多个视频理解任务中进行验证。

Result: 在10个多样化视频理解基准上的实验表明，Video-VER一致取得最优性能，有效抑制了推理过程中的幻觉与偏差。

Conclusion: 视频推理需避免脱离视觉证据的语言推理漂移，VER框架推动多模态模型在‘思考前回答’的同时实现‘边看边思考’，实现更稳固的视觉基础推理。

Abstract: Video reasoning, the task of enabling machines to infer from dynamic visual
content through multi-step logic, is crucial for advanced AI. While the
Chain-of-Thought (CoT) mechanism has enhanced reasoning in text-based tasks,
its application to video understanding remains underexplored. This paper
presents a systematic analysis revealing that CoT often degrades performance in
video reasoning, generating verbose but misleading internal monologues, and
leading to hallucinated visual details and overridden correct intuitions - a
phenomenon we term "visual thinking drift". We explain this drift through a
Bayesian lens, positing that CoT traces often diverge from actual visual
evidence, instead amplifying internal biases or language priors, causing models
to storytell rather than engage in grounded reasoning. To counteract this, we
introduce Visual Evidence Reward (VER), a novel reinforcement learning
framework that explicitly rewards the generation of reasoning traces that are
verifiably grounded in visual evidence. Comprehensive evaluation across 10
diverse video understanding benchmarks demonstrates that our Video-VER
consistently achieves top performance. Our work sheds light on the distinct
challenges of video-centric reasoning and encourages the development of AI that
robustly grounds its inferences in visual evidence - for large multimodal
models that not only "think before answering", but also "see while thinking".

</details>


### [62] [A public cardiac CT dataset featuring the left atrial appendage](https://arxiv.org/abs/2510.06090)
*Bjoern Hansen,Jonas Pedersen,Klaus F. Kofoed,Oscar Camara,Rasmus R. Paulsen,Kristine Soerensen*

Main category: cs.CV

TL;DR: 本文提出了首个开源的、解剖结构一致的高分辨率左心耳（LAA）、冠状动脉（CA）和肺静脉（PV）分割数据集，并基于ImageCAS的1000例心脏CT血管造影图像提供精细化标注，旨在促进LAA形态学研究。


<details>
  <summary>Details</summary>
Motivation: 尽管现有分割框架（如TotalSegmentator）取得成功，但LAA、CA和PV的精准分割在医学影像中仍具挑战性，亟需高质量公开数据集支持相关研究。

Method: 使用专为高分辨率LAA分割设计的先进框架，在含专家标注的大规模私有数据集上训练模型后迁移至ImageCAS数据；优化原始CA标注并精炼TS生成的PV分割结果，同时标注数据中存在的常见缺陷。

Result: 发布了包含1000例CCTA扫描的精细化分割数据集，涵盖LAA、CA、PV及全心标签，并提供存在诸如步进伪影、视野外LAA等问题的扫描列表。

Conclusion: 该数据集为心脏结构特别是LAA的形态分析提供了可靠资源，有望推动相关算法发展与临床研究。

Abstract: Despite the success of advanced segmentation frameworks such as
TotalSegmentator (TS), accurate segmentations of the left atrial appendage
(LAA), coronary arteries (CAs), and pulmonary veins (PVs) remain a significant
challenge in medical imaging. In this work, we present the first open-source,
anatomically coherent dataset of curated, high-resolution segmentations for
these structures, supplemented with whole-heart labels produced by TS on the
publicly available ImageCAS dataset consisting of 1000 cardiac computed
tomography angiography (CCTA) scans. One purpose of the data set is to foster
novel approaches to the analysis of LAA morphology.
  LAA segmentations on ImageCAS were generated using a state-of-the-art
segmentation framework developed specifically for high resolution LAA
segmentation. We trained the network on a large private dataset with manual
annotations provided by medical readers guided by a trained cardiologist and
transferred the model to ImageCAS data. CA labels were improved from the
original ImageCAS annotations, while PV segmentations were refined from TS
outputs. In addition, we provide a list of scans from ImageCAS that contains
common data flaws such as step artefacts, LAAs extending beyond the scanner's
field of view, and other types of data defects.

</details>


### [63] [Compact Multi-level-prior Tensor Representation for Hyperspectral Image Super-resolution](https://arxiv.org/abs/2510.06098)
*Yinjian Wang,Wei Li,Yuanyuan Gui,Gemine Vivone*

Main category: cs.CV

TL;DR: 提出了一种新的基于张量的高光谱图像超分辨率融合模型，通过解耦光谱低秩性和空间先验，并利用非凸模式混洗张量相关全变差有效整合多级先验，实现了更优的融合效果。


<details>
  <summary>Details</summary>
Motivation: 现有张量方法难以同时有效整合多级先验且模型复杂，导致先验权衡和优化困难，本文旨在构建一个紧凑且高效融合多级先验的模型。

Method: 采用块分解将高分辨率图像分解为光谱子空间和空间映射；构造空间张量以编码高阶低秩和光滑性先验，并提出非凸模式混洗张量相关全变差进行联合建模；基于线性化ADMM设计高效优化算法。

Result: 在多个数据集上实验表明所提方法在融合效果上优于现有方法，且算法具有理论收敛性保证。

Conclusion: 所提模型能有效融合多级先验，提升高光谱图像超分辨率质量，同时保持模型紧凑性和优化效率。

Abstract: Fusing a hyperspectral image with a multispectral image acquired over the
same scene, \textit{i.e.}, hyperspectral image super-resolution, has become a
popular computational way to access the latent high-spatial-spectral-resolution
image. To date, a variety of fusion methods have been proposed, among which the
tensor-based ones have testified that multiple priors, such as multidimensional
low-rankness and spatial total variation at multiple levels, effectively drive
the fusion process. However, existing tensor-based models can only effectively
leverage one or two priors at one or two levels, since simultaneously
incorporating multi-level priors inevitably increases model complexity. This
introduces challenges in both balancing the weights of different priors and
optimizing multi-block structures. Concerning this, we present a novel
hyperspectral super-resolution model compactly characterizing these multi-level
priors of hyperspectral images within the tensor framework. Firstly, the
proposed model decouples the spectral low-rankness and spatial priors by
casting the latent high-spatial-spectral-resolution image into spectral
subspace and spatial maps via block term decomposition. Secondly, these spatial
maps are stacked as the spatial tensor encoding the high-order spatial
low-rankness and smoothness priors, which are co-modeled via the proposed
non-convex mode-shuffled tensor correlated total variation. Finally, we draw
inspiration from the linearized alternating direction method of multipliers to
design an efficient algorithm to optimize the resulting model, theoretically
proving its Karush-Kuhn-Tucker convergence under mild conditions. Experiments
on multiple datasets demonstrate the effectiveness of the proposed algorithm.
The code implementation will be available from https://github.com/WongYinJ.

</details>


### [64] [Multimodal Feature Prototype Learning for Interpretable and Discriminative Cancer Survival Prediction](https://arxiv.org/abs/2510.06113)
*Shuo Jiang,Zhuwen Chen,Liaoman Xu,Yanming Zhu,Changmiao Wang,Jiong Zhang,Feiwei Qin,Yifei Chen,Zhu Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的基于原型的多模态框架FeatProto，通过整合病理全切片图像的全局与局部特征及基因组数据，提升了癌症生存预测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有生存分析模型难以解释，且传统原型学习方法忽视肿瘤整体背景，缺乏与基因组数据的语义对齐，限制了其在临床中的应用。

Method: 提出FeatProto框架，构建统一的特征原型空间；采用指数原型更新策略（EMA ProtoUp）保持跨模态稳定性，并设计分层原型匹配机制以捕捉全局、局部和队列级信息。

Result: 在四个公开癌症数据集上实验表明，该方法在生存预测准确性和可解释性方面优于当前最先进的单模态和多模态方法。

Conclusion: FeatProto通过改进原型学习方法，实现了更精准、可追溯的癌症生存预测，为医学领域的多模态分析提供了新思路。

Abstract: Survival analysis plays a vital role in making clinical decisions. However,
the models currently in use are often difficult to interpret, which reduces
their usefulness in clinical settings. Prototype learning presents a potential
solution, yet traditional methods focus on local similarities and static
matching, neglecting the broader tumor context and lacking strong semantic
alignment with genomic data. To overcome these issues, we introduce an
innovative prototype-based multimodal framework, FeatProto, aimed at enhancing
cancer survival prediction by addressing significant limitations in current
prototype learning methodologies within pathology. Our framework establishes a
unified feature prototype space that integrates both global and local features
of whole slide images (WSI) with genomic profiles. This integration facilitates
traceable and interpretable decision-making processes. Our approach includes
three main innovations: (1) A robust phenotype representation that merges
critical patches with global context, harmonized with genomic data to minimize
local bias. (2) An Exponential Prototype Update Strategy (EMA ProtoUp) that
sustains stable cross-modal associations and employs a wandering mechanism to
adapt prototypes flexibly to tumor heterogeneity. (3) A hierarchical prototype
matching scheme designed to capture global centrality, local typicality, and
cohort-level trends, thereby refining prototype inference. Comprehensive
evaluations on four publicly available cancer datasets indicate that our method
surpasses current leading unimodal and multimodal survival prediction
techniques in both accuracy and interoperability, providing a new perspective
on prototype learning for critical medical applications. Our source code is
available at https://github.com/JSLiam94/FeatProto.

</details>


### [65] [Towards Data-Efficient Medical Imaging: A Generative and Semi-Supervised Framework](https://arxiv.org/abs/2510.06123)
*Mosong Ma,Tania Stathaki,Michalis Lazarou*

Main category: cs.CV

TL;DR: SSGNet 是一种结合类别特异性生成建模与半监督伪标签的统一框架，用于增强医学图像分类与分割性能，有效缓解标注数据稀缺与不平衡的问题。


<details>
  <summary>Details</summary>
Motivation: 医学图像分析中深度学习常受限于标注数据稀缺且类别不平衡，需要有效方法提升模型性能。

Method: SSGNet 结合 StyleGAN3 生成类别特定图像以扩充训练数据，并通过迭代式半监督伪标签优化标注，可嵌入现有模型以增强性能。

Result: 在多个医学影像基准上，分类与分割性能均取得一致提升，FID 分析表明生成图像质量高。

Conclusion: SSGNet 是一种实用且有效的策略，可缓解标注瓶颈，提升医学图像分析的鲁棒性。

Abstract: Deep learning in medical imaging is often limited by scarce and imbalanced
annotated data. We present SSGNet, a unified framework that combines class
specific generative modeling with iterative semisupervised pseudo labeling to
enhance both classification and segmentation. Rather than functioning as a
standalone model, SSGNet augments existing baselines by expanding training data
with StyleGAN3 generated images and refining labels through iterative pseudo
labeling. Experiments across multiple medical imaging benchmarks demonstrate
consistent gains in classification and segmentation performance, while Frechet
Inception Distance analysis confirms the high quality of generated samples.
These results highlight SSGNet as a practical strategy to mitigate annotation
bottlenecks and improve robustness in medical image analysis.

</details>


### [66] [Discrete Diffusion Models with MLLMs for Unified Medical Multimodal Generation](https://arxiv.org/abs/2510.06131)
*Jiawei Mao,Yuhan Wang,Lifeng Chen,Can Zhao,Yucheng Tang,Dong Yang,Liangqiong Qu,Daguang Xu,Yuyin Zhou*

Main category: cs.CV

TL;DR: MeDiM是首个跨模态无特定组件的医疗离散扩散模型，统一处理医学图像与文本生成，实现高质量的图像-报告联合生成。


<details>
  <summary>Details</summary>
Motivation: 现有生成式医疗模型受限于模态孤立，难以融合影像、病理和临床文本等多模态数据，阻碍了医学基础模型的发展。

Method: 提出MeDiM，基于离散扩散框架，使用多模态大语言模型（MLLM）作为扩散主干，去除因果注意力掩码以实现双向上下文，并注入连续时间步嵌入以增强扩散感知，从而在共享概率空间中统一视觉与语言表示。

Result: 在MIMIC-CXR上FID为16.60，PathGen上为24.19；报告生成METEOR分别为0.2650和0.2580；联合生成图像-报告对使下游任务BLEU-1提升6.43%，BLEU-3提升31.58%，METEOR提升4.80%。

Conclusion: MeDiM支持连贯且临床合理的多模态生成，推动医学基础模型在跨模态学习与推理中的发展。

Abstract: Recent advances in generative medical models are constrained by
modality-specific scenarios that hinder the integration of complementary
evidence from imaging, pathology, and clinical notes. This fragmentation limits
their evolution into foundation models that can learn and reason across the
full spectrum of biomedical data. We propose MeDiM, the first medical discrete
diffusion model that learns shared distributions across modalities without
modality-specific components. MeDiM unifies multiple generative tasks:
translating between images and text, and jointly producing image-report pairs
across domains in response to prompts. Built on a discrete diffusion framework,
MeDiM bridges vision and language representations through a shared
probabilistic space. To enable unified and flexible medical generation, we
employ a multimodal large language model (MLLM) as the diffusion backbone,
leveraging its prior knowledge and cross-modal reasoning. Two key designs are
introduced: (1) removing the causal attention mask for bidirectional context,
and (2) injecting continuous timestep embeddings for diffusion awareness.
Experiments demonstrate high-fidelity medical generation (FID 16.60 on
MIMIC-CXR and FID 24.19 on PathGen) and accurate report generation (METEOR
0.2650 and 0.2580). Jointly generated image-report pairs further enhance
downstream performance (plus6.43 percent BLEU-1, plus18.57 percent BLEU-2,
plus31.58 percent BLEU-3, plus4.80 percent METEOR), showing that MeDiM supports
coherent and clinically grounded multimodal outputs.

</details>


### [67] [Deforming Videos to Masks: Flow Matching for Referring Video Segmentation](https://arxiv.org/abs/2510.06139)
*Zanyi Wang,Dengyang Jiang,Liuzhuozheng Li,Sizhe Dang,Chengzu Li,Harry Yang,Guang Dai,Mengmeng Wang,Jingdong Wang*

Main category: cs.CV

TL;DR: 本文提出了FlowRVS，一种将指代表情视频对象分割（RVOS）重构为条件连续流问题的新框架，通过语言引导的视频表征到目标掩码的直接变形，实现了一阶段生成式分割，在多个基准上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RVOS方法通常采用“先定位后分割”的级联 pipeline，导致语义信息损失和时序不一致，难以有效对齐语言与视频像素。因此，需要一种更直接、端到端的方法来克服信息瓶颈并增强跨模态与时间的一致性。

Method: 提出FlowRVS，将RVOS视为一个条件连续流问题，利用预训练的文本到视频（T2V）模型，学习从视频整体表征到目标掩码的语言引导直接变形过程，实现一阶段生成式分割，避免了传统方法中从噪声生成掩码或直接预测掩码的方式。

Result: FlowRVS在多个主流RVOS基准上取得新的最先进性能：在MeViS上达到51.1的J&F分数（比之前SOTA提升1.6），在零样本设置下的Ref-DAVIS17上达到73.3（提升2.7），显示出建模连续变形过程的有效性。

Conclusion: 将RVOS建模为语言引导的连续变形过程是一种高效且有潜力的范式，FlowRVS通过一阶段生成式框架实现了更好的语义对齐与时序一致性，推动了视频理解任务的发展。

Abstract: Referring Video Object Segmentation (RVOS) requires segmenting specific
objects in a video guided by a natural language description. The core challenge
of RVOS is to anchor abstract linguistic concepts onto a specific set of pixels
and continuously segment them through the complex dynamics of a video. Faced
with this difficulty, prior work has often decomposed the task into a pragmatic
`locate-then-segment' pipeline. However, this cascaded design creates an
information bottleneck by simplifying semantics into coarse geometric prompts
(e.g, point), and struggles to maintain temporal consistency as the segmenting
process is often decoupled from the initial language grounding. To overcome
these fundamental limitations, we propose FlowRVS, a novel framework that
reconceptualizes RVOS as a conditional continuous flow problem. This allows us
to harness the inherent strengths of pretrained T2V models, fine-grained pixel
control, text-video semantic alignment, and temporal coherence. Instead of
conventional generating from noise to mask or directly predicting mask, we
reformulate the task by learning a direct, language-guided deformation from a
video's holistic representation to its target mask. Our one-stage, generative
approach achieves new state-of-the-art results across all major RVOS
benchmarks. Specifically, achieving a $\mathcal{J}\&\mathcal{F}$ of 51.1 in
MeViS (+1.6 over prior SOTA) and 73.3 in the zero shot Ref-DAVIS17 (+2.7),
demonstrating the significant potential of modeling video understanding tasks
as continuous deformation processes.

</details>


### [68] [Bimanual 3D Hand Motion and Articulation Forecasting in Everyday Images](https://arxiv.org/abs/2510.06145)
*Aditya Prakash,David Forsyth,Saurabh Gupta*

Main category: cs.CV

TL;DR: 提出一种通过扩散模型从单张图像预测双手3D手部运动与关节状态的方法，利用生成的4D手部运动数据进行训练，在多样场景下显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据集中缺乏多场景下的3D手部标注，难以支持复杂日常场景中的双手运动预测，因此需要构建高质量的4D手部运动数据并设计有效的预测模型。

Method: 设计了一个基于扩散模型的标注流程，将2D手关键点序列提升为4D手部运动；采用扩散损失训练预测模型，以应对手部运动的多模态分布特性。

Result: 在6个数据集上实验表明，使用生成数据训练的模型性能提升14%，提升模块比基线好42%，预测模型增益达16.4%，在零样本泛化任务中表现尤为突出。

Conclusion: 所提方法能有效生成多样化的训练数据并准确预测真实日常场景中的双手3D运动，显著提升模型泛化能力与预测精度。

Abstract: We tackle the problem of forecasting bimanual 3D hand motion & articulation
from a single image in everyday settings. To address the lack of 3D hand
annotations in diverse settings, we design an annotation pipeline consisting of
a diffusion model to lift 2D hand keypoint sequences to 4D hand motion. For the
forecasting model, we adopt a diffusion loss to account for the multimodality
in hand motion distribution. Extensive experiments across 6 datasets show the
benefits of training on diverse data with imputed labels (14% improvement) and
effectiveness of our lifting (42% better) & forecasting (16.4% gain) models,
over the best baselines, especially in zero-shot generalization to everyday
images.

</details>


### [69] [ShapeGen4D: Towards High Quality 4D Shape Generation from Videos](https://arxiv.org/abs/2510.06208)
*Jiraphon Yenphraphai,Ashkan Mirzaei,Jianqi Chen,Jiaxu Zou,Sergey Tulyakov,Raymond A. Yeh,Peter Wonka,Chaoyang Wang*

Main category: cs.CV

TL;DR: 提出了一种端到端的视频到4D形状生成框架，利用预训练3D模型实现高质量、时间一致的动态3D形状生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以从单个视频中准确恢复时间变化的3D几何和视图一致的外观，且常存在时间不一致和拓扑变化处理困难的问题。

Method: 基于大规模预训练3D模型，引入三个关键组件：时序注意力机制、时间感知的点采样与4D潜在锚定、跨帧噪声共享，以实现端到端动态3D表示生成。

Result: 方法在真实视频上实现了更鲁棒、感知质量更高的4D生成结果，能准确捕捉非刚性运动、体积变化和拓扑变换，并减少失败模式。

Conclusion: 该框架有效提升了视频条件下的4D形状生成质量，无需逐帧优化即可实现时间一致性与高保真重建。

Abstract: Video-conditioned 4D shape generation aims to recover time-varying 3D
geometry and view-consistent appearance directly from an input video. In this
work, we introduce a native video-to-4D shape generation framework that
synthesizes a single dynamic 3D representation end-to-end from the video. Our
framework introduces three key components based on large-scale pre-trained 3D
models: (i) a temporal attention that conditions generation on all frames while
producing a time-indexed dynamic representation; (ii) a time-aware point
sampling and 4D latent anchoring that promote temporally consistent geometry
and texture; and (iii) noise sharing across frames to enhance temporal
stability. Our method accurately captures non-rigid motion, volume changes, and
even topological transitions without per-frame optimization. Across diverse
in-the-wild videos, our method improves robustness and perceptual fidelity and
reduces failure modes compared with the baselines.

</details>


### [70] [Drive&Gen: Co-Evaluating End-to-End Driving and Video Generation Models](https://arxiv.org/abs/2510.06209)
*Jiahao Wang,Zhenpei Yang,Yijing Bai,Yingwei Li,Yuliang Zou,Bo Sun,Abhijit Kundu,Jose Lezama,Luna Yue Huang,Zehao Zhu,Jyh-Jing Hwang,Dragomir Anguelov,Mingxing Tan,Chiyu Max Jiang*

Main category: cs.CV

TL;DR: 本文提出一种结合端到端驾驶模型与生成式世界模型（Drive&Gen）的新方法，利用可控视频生成技术评估生成视频的真实性和驾驶模型的泛化能力，并证明合成数据可有效提升自动驾驶模型在分布外场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型虽能生成逼真驾驶视频，但其条件一致性及对端到端驾驶模型评估的有效性尚不明确；同时，端到端模型在非分布场景下的泛化能力受限于数据，需更深入理解其偏差。因此，需构建可评估生成视频真实性的方法，并提升驾驶模型的泛化能力。

Method: 提出Drive&Gen框架，结合端到端驾驶模型与生成式世界模型；设计基于驾驶模型响应的统计指标评估生成视频的现实性；利用生成模型的可控性进行针对性实验，分析影响驾驶模型性能的分布差距；使用生成的合成数据增强训练以提升模型泛化能力。

Result: 实验表明，所提出的统计指标能有效评估生成视频的现实性与条件一致性；通过可控生成实验揭示了影响端到端驾驶模型性能的关键分布差距；使用合成数据训练显著提升了模型在非分布场景下的表现，且效果接近使用真实数据增强的结果。

Conclusion: 生成式世界模型不仅能作为可控虚拟测试环境，还可与端到端驾驶模型协同，用于评估生成质量、分析模型偏差，并通过合成数据有效提升自动驾驶系统的泛化能力和部署灵活性。

Abstract: Recent advances in generative models have sparked exciting new possibilities
in the field of autonomous vehicles. Specifically, video generation models are
now being explored as controllable virtual testing environments.
Simultaneously, end-to-end (E2E) driving models have emerged as a streamlined
alternative to conventional modular autonomous driving systems, gaining
popularity for their simplicity and scalability. However, the application of
these techniques to simulation and planning raises important questions. First,
while video generation models can generate increasingly realistic videos, can
these videos faithfully adhere to the specified conditions and be realistic
enough for E2E autonomous planner evaluation? Second, given that data is
crucial for understanding and controlling E2E planners, how can we gain deeper
insights into their biases and improve their ability to generalize to
out-of-distribution scenarios? In this work, we bridge the gap between the
driving models and generative world models (Drive&Gen) to address these
questions. We propose novel statistical measures leveraging E2E drivers to
evaluate the realism of generated videos. By exploiting the controllability of
the video generation model, we conduct targeted experiments to investigate
distribution gaps affecting E2E planner performance. Finally, we show that
synthetic data produced by the video generation model offers a cost-effective
alternative to real-world data collection. This synthetic data effectively
improves E2E model generalization beyond existing Operational Design Domains,
facilitating the expansion of autonomous vehicle services into new operational
contexts.

</details>


### [71] [Fine-grained Defocus Blur Control for Generative Image Models](https://arxiv.org/abs/2510.06215)
*Ayush Shrivastava,Connelly Barnes,Xuaner Zhang,Lingzhi Zhang,Andrew Owens,Sohrab Amirghodsi,Eli Shechtman*

Main category: cs.CV

TL;DR: 提出了一种利用EXIF相机元数据（如光圈、对焦距离）控制镜头模糊的新型文本到图像扩散模型，通过模拟物理成像过程实现精细的景深控制。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型难以精确整合细粒度的相机参数（如光圈、对焦距离），导致无法生成可控的镜头模糊效果；而真实图像常附带EXIF元数据，利用这些信息可提升生成图像的真实感和可控性。

Method: 提出一个分阶段框架：1）生成全清晰图像；2）估计单目深度；3）用新型对焦距离Transformer预测合理对焦距离；4）结合可微分镜头模糊模型生成虚化图像；整个流程可微，支持端到端训练且无需显式标注。

Result: 模型能根据EXIF数据和内容自动生成合理的景深效果，在推理时支持用户交互式调整模糊程度，保持场景内容不变，实现了比现有方法更精细的控制。

Conclusion: 该方法成功将相机元数据融入扩散模型，实现了物理合理的可控虚化效果，为图像生成提供了更高精度的用户控制能力。

Abstract: Current text-to-image diffusion models excel at generating diverse,
high-quality images, yet they struggle to incorporate fine-grained camera
metadata such as precise aperture settings. In this work, we introduce a novel
text-to-image diffusion framework that leverages camera metadata, or EXIF data,
which is often embedded in image files, with an emphasis on generating
controllable lens blur. Our method mimics the physical image formation process
by first generating an all-in-focus image, estimating its monocular depth,
predicting a plausible focus distance with a novel focus distance transformer,
and then forming a defocused image with an existing differentiable lens blur
model. Gradients flow backwards through this whole process, allowing us to
learn without explicit supervision to generate defocus effects based on content
elements and the provided EXIF data. At inference time, this enables precise
interactive user control over defocus effects while preserving scene contents,
which is not achievable with existing diffusion models. Experimental results
demonstrate that our model enables superior fine-grained control without
altering the depicted scene.

</details>


### [72] [Dropping the D: RGB-D SLAM Without the Depth Sensor](https://arxiv.org/abs/2510.06216)
*Mert Kiray,Alican Karaomer,Benjamin Busam*

Main category: cs.CV

TL;DR: DropD-SLAM是一个实时单目SLAM系统，利用预训练视觉模块替代深度传感器，达到RGB-D级别的精度。


<details>
  <summary>Details</summary>
Motivation: 在不依赖主动深度传感器的情况下实现高精度、实时的度量级SLAM，降低系统复杂性和成本。

Method: 采用三个预训练模型：单目度量深度估计器、学习型关键点检测器和实例分割网络；通过膨胀实例掩码抑制动态物体，将静态关键点赋予预测深度并反投影为3D特征，输入标准RGB-D SLAM后端进行跟踪与建图。

Result: 在TUM RGB-D基准上，静态序列平均ATE为7.4厘米，动态序列为1.8厘米，性能媲美或超越现有RGB-D方法，单GPU上运行速度达22 FPS。

Conclusion: 现代预训练视觉模型可作为可靠的实时度量尺度来源，替代主动深度传感器，推动更简单、低成本SLAM系统的发展。

Abstract: We present DropD-SLAM, a real-time monocular SLAM system that achieves
RGB-D-level accuracy without relying on depth sensors. The system replaces
active depth input with three pretrained vision modules: a monocular metric
depth estimator, a learned keypoint detector, and an instance segmentation
network. Dynamic objects are suppressed using dilated instance masks, while
static keypoints are assigned predicted depth values and backprojected into 3D
to form metrically scaled features. These are processed by an unmodified RGB-D
SLAM back end for tracking and mapping. On the TUM RGB-D benchmark, DropD-SLAM
attains 7.4 cm mean ATE on static sequences and 1.8 cm on dynamic sequences,
matching or surpassing state-of-the-art RGB-D methods while operating at 22 FPS
on a single GPU. These results suggest that modern pretrained vision models can
replace active depth sensors as reliable, real-time sources of metric scale,
marking a step toward simpler and more cost-effective SLAM systems.

</details>


### [73] [EgoNight: Towards Egocentric Vision Understanding at Night with a Challenging Benchmark](https://arxiv.org/abs/2510.06218)
*Deheng Zhang,Yuqian Fu,Runyi Yang,Yang Miao,Tianwen Qian,Xu Zheng,Guolei Sun,Ajad Chhatkuli,Xuanjing Huang,Yu-Gang Jiang,Luc Van Gool,Danda Pani Paudel*

Main category: cs.CV

TL;DR: EgoNight是首个针对夜间自我中心视觉的综合基准，核心任务为视觉问答（VQA），揭示了现有模型在低光照条件下性能显著下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有自我中心视觉基准大多关注白天场景，忽视了实际应用中不可避免的低光照条件，缺乏对夜间视觉理解的有效评估。

Method: 构建了视觉与时间对齐的日夜配对视频，结合Blender合成数据和真实世界录制；提出日增广夜间自动标注引擎，并通过大量人工验证精炼标签。

Result: EgoNight-VQA包含90段视频中的3658个问答对，涵盖12种问答类型，揭示了现有大规模多模态模型从白天到夜间的显著性能下降。同时引入两个辅助任务：日夜对应检索与夜间深度估计。

Conclusion: EgoNight为推动应用驱动的自我中心视觉研究提供了坚实基础，特别是在跨光照条件泛化方面，并将促进更具鲁棒性的模型发展。

Abstract: Most existing benchmarks for egocentric vision understanding focus primarily
on daytime scenarios, overlooking the low-light conditions that are inevitable
in real-world applications. To investigate this gap, we present EgoNight, the
first comprehensive benchmark for nighttime egocentric vision, with visual
question answering (VQA) as the core task. A key feature of EgoNight is the
introduction of day-night aligned videos, which enhance night annotation
quality using the daytime data and reveal clear performance gaps between
lighting conditions. To achieve this, we collect both synthetic videos rendered
by Blender and real-world recordings, ensuring that scenes and actions are
visually and temporally aligned. Leveraging these paired videos, we construct
EgoNight-VQA, supported by a novel day-augmented night auto-labeling engine and
refinement through extensive human verification. Each QA pair is double-checked
by annotators for reliability. In total, EgoNight-VQA contains 3658 QA pairs
across 90 videos, spanning 12 diverse QA types, with more than 300 hours of
human work. Evaluations of state-of-the-art multimodal large language models
(MLLMs) reveal substantial performance drops when transferring from day to
night, underscoring the challenges of reasoning under low-light conditions.
Beyond VQA, EgoNight also introduces two auxiliary tasks, day-night
correspondence retrieval and egocentric depth estimation at night, that further
explore the boundaries of existing models. We believe EgoNight-VQA provides a
strong foundation for advancing application-driven egocentric vision research
and for developing models that generalize across illumination domains. All the
data and code will be made available upon acceptance.

</details>


### [74] [Human3R: Everyone Everywhere All at Once](https://arxiv.org/abs/2510.06219)
*Yue Chen,Xingyu Chen,Yuxuan Xue,Anpei Chen,Yuliang Xiu,Gerard Pons-Moll*

Main category: cs.CV

TL;DR: Human3R是一种统一的前馈框架，用于从单目视频中实时、高效地进行在线4D人物-场景重建，能够在单次前向传递中同时恢复多人物、3D场景和相机轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有的多阶段管道方法依赖于迭代优化和多个前置任务（如检测、深度估计和SLAM），导致效率低且复杂。作者希望提出一种更高效、统一的方法，避免这些依赖并提升实时性与性能。

Method: 基于CUT3R模型，引入参数高效的视觉提示调优（visual prompt tuning），保留其时空先验，直接输出多个SMPL-X人体模型，并联合重建3D场景与相机轨迹，实现端到端的单阶段训练与推理。

Result: 仅在单GPU上训练一天后，Human3R在多个任务上达到最优或具有竞争力的表现，包括全局人体运动估计、局部人体网格恢复、视频深度估计和相机位姿估计，推理速度达15FPS，内存占用仅8GB。

Conclusion: Human3R实现了高效、统一的4D人-景重建，消除了对复杂预处理和迭代优化的依赖，为下游应用提供了简洁而强大的基线模型。

Abstract: We present Human3R, a unified, feed-forward framework for online 4D
human-scene reconstruction, in the world frame, from casually captured
monocular videos. Unlike previous approaches that rely on multi-stage
pipelines, iterative contact-aware refinement between humans and scenes, and
heavy dependencies, e.g., human detection, depth estimation, and SLAM
pre-processing, Human3R jointly recovers global multi-person SMPL-X bodies
("everyone"), dense 3D scene ("everywhere"), and camera trajectories in a
single forward pass ("all-at-once"). Our method builds upon the 4D online
reconstruction model CUT3R, and uses parameter-efficient visual prompt tuning,
to strive to preserve CUT3R's rich spatiotemporal priors, while enabling direct
readout of multiple SMPL-X bodies. Human3R is a unified model that eliminates
heavy dependencies and iterative refinement. After being trained on the
relatively small-scale synthetic dataset BEDLAM for just one day on one GPU, it
achieves superior performance with remarkable efficiency: it reconstructs
multiple humans in a one-shot manner, along with 3D scenes, in one stage, at
real-time speed (15 FPS) with a low memory footprint (8 GB). Extensive
experiments demonstrate that Human3R delivers state-of-the-art or competitive
performance across tasks, including global human motion estimation, local human
mesh recovery, video depth estimation, and camera pose estimation, with a
single unified model. We hope that Human3R will serve as a simple yet strong
baseline, be easily extended for downstream applications.Code available in
https://fanegg.github.io/Human3R

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [75] [Collaborative and Proactive Management of Task-Oriented Conversations](https://arxiv.org/abs/2510.05110)
*Arezoo Saedi,Afsaneh Fatemi,Mohammad Ali Nematbakhsh,Sophie Rosset,Anne Vilnat*

Main category: cs.CL

TL;DR: 本文提出了一种基于信息状态的对话管理模型，通过结合大型语言模型和中间信息构建，实现任务导向型对话系统中的有效目标感知规划，在MultiWOZ数据集上取得了优于以往方法的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的任务导向对话系统在目标感知规划方面不足，尽管大语言模型在自然语言处理任务中表现优异，但缺乏有效的规划机制影响任务完成效果。

Method: 采用信息状态方法进行对话管理，定义预设槽位和文本部分信息组件来建模用户偏好，识别关键情境并构建相应的信息组件，形成有限的信息状态；设计对话动作表示状态转移及操作过程，并构建更新策略；利用大语言模型的上下文学习实现模型，并基于槽位和文本部分生成数据库查询及实体排序。

Result: 在仅包含一个领域的MultiWOZ完整测试对话上评估，该模型在告知率（inform）和任务成功率（success）方面达到最高水平，并优于先前方法。

Conclusion: 所提出的基于信息状态和中间信息构建的对话管理模型有效提升了任务导向对话系统的规划能力和任务完成性能。

Abstract: Task oriented dialogue systems (TOD) complete particular tasks based on user
preferences across natural language interactions. Considering the impressive
performance of large language models (LLMs) in natural language processing
(NLP) tasks, most of the latest TODs are centered on LLMs. While proactive
planning is crucial for task completion, many existing TODs overlook effective
goal-aware planning. This paper creates a model for managing task-oriented
conversations, conceptualized centered on the information state approach to
dialogue management. The created model incorporated constructive intermediate
information in planning. Initially, predefined slots and text part
informational components are created to model user preferences. Investigating
intermediate information, critical circumstances are identified. Informational
components corresponding to these circumstances are created. Possible
configurations for these informational components lead to limited information
states. Then, dialogue moves, which indicate movement between these information
states and the procedures that must be performed in the movements, are created.
Eventually, the update strategy is constructed. The created model is
implemented leveraging in-context learning of LLMs. In this model, database
queries are created centered on indicated predefined slots and the order of
retrieved entities is indicated centered on text part. This mechanism enables
passing the whole corresponding entities to the preferences in the order of
congruency. Evaluations exploiting the complete test conversations of MultiWOZ,
with no more than a domain in a conversation, illustrate maximal inform and
success, and improvement compared with previous methods.

</details>


### [76] [Trainable Reference-Based Evaluation Metric for Identifying Quality of English-Gujarati Machine Translation System](https://arxiv.org/abs/2510.05113)
*Nisheeth Joshi,Pragya Katyayan,Palak Arora*

Main category: cs.CL

TL;DR: 本文提出了一种基于监督学习的、针对古吉拉特语的基于参考的机器翻译评估指标，并通过多层神经网络模型实现了比现有指标更高的人类相关性。


<details>
  <summary>Details</summary>
Motivation: 现有的机器翻译评估方法在处理印度语言时效果不佳，因此需要为古吉拉特语开发更有效的评估指标。

Method: 提出了两种基于25个特征的监督学习模型，分别使用6层和10层隐藏层、训练500个周期的神经网络来训练评估指标。

Result: 在包含七个机器翻译系统共1000个输出的数据集上测试，该指标与人工评分的相关性优于其他现有指标。

Conclusion: 所提出的监督学习方法在古吉拉特语MT评估中表现优越，适用于印度语言的翻译质量评估。

Abstract: Machine Translation (MT) Evaluation is an integral part of the MT development
life cycle. Without analyzing the outputs of MT engines, it is impossible to
evaluate the performance of an MT system. Through experiments, it has been
identified that what works for English and other European languages does not
work well with Indian languages. Thus, In this paper, we have introduced a
reference-based MT evaluation metric for Gujarati which is based on supervised
learning. We have trained two versions of the metric which uses 25 features for
training. Among the two models, one model is trained using 6 hidden layers with
500 epochs while the other model is trained using 10 hidden layers with 500
epochs. To test the performance of the metric, we collected 1000 MT outputs of
seven MT systems. These MT engine outputs were compared with 1 human reference
translation. While comparing the developed metrics with other available
metrics, it was found that the metrics produced better human correlations.

</details>


### [77] [Hallucination is Inevitable for LLMs with the Open World Assumption](https://arxiv.org/abs/2510.05116)
*Bowen Xu*

Main category: cs.CL

TL;DR: 本文将大语言模型的“幻觉”问题重新定义为泛化问题的表现，指出在开放世界假设下幻觉不可避免，应被视为需容忍并与人类智能兼容的结构性特征，而非单纯工程缺陷。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型表现出强大语言能力，但其生成的幻觉问题在工程和理论层面仍缺乏对通用人工智能（AGI）背景下的完整性解释。

Method: 通过引入封闭世界与开放世界的假设对比，构建幻觉分类框架，分析其可纠正性与不可避免性。

Result: 提出在开放世界条件下，幻觉是模型泛化的结构性产物，部分类型无法完全消除。

Conclusion: 应重新理解幻觉为一种需管理与兼容的系统性特征，而非单纯需消除的错误，以推动通往AGI的稳健智能系统设计。

Abstract: Large Language Models (LLMs) exhibit impressive linguistic competence but
also produce inaccurate or fabricated outputs, often called ``hallucinations''.
Engineering approaches usually regard hallucination as a defect to be
minimized, while formal analyses have argued for its theoretical inevitability.
Yet both perspectives remain incomplete when considering the conditions
required for artificial general intelligence (AGI). This paper reframes
``hallucination'' as a manifestation of the generalization problem. Under the
Closed World assumption, where training and test distributions are consistent,
hallucinations may be mitigated. Under the Open World assumption, however,
where the environment is unbounded, hallucinations become inevitable. This
paper further develops a classification of hallucination, distinguishing cases
that may be corrected from those that appear unavoidable under open-world
conditions. On this basis, it suggests that ``hallucination'' should be
approached not merely as an engineering defect but as a structural feature to
be tolerated and made compatible with human intelligence.

</details>


### [78] [Towards Structured Knowledge: Advancing Triple Extraction from Regional Trade Agreements using Large Language Models](https://arxiv.org/abs/2510.05121)
*Durgesh Nandini,Rebekka Koch,Mirco Schoenfeld*

Main category: cs.CL

TL;DR: 本研究探讨了大语言模型（LLM）在经济学领域中从自然语言文本中提取主谓宾三元组的有效性，特别应用于区域贸易协定文本，使用Llama 3.1模型进行零样本、单样本和少样本提示实验。


<details>
  <summary>Details</summary>
Motivation: 旨在利用大语言模型自动构建经济领域的结构化知识图谱，特别是从复杂的法律贸易协议文本中提取有用信息，提升知识获取效率。

Method: 采用Llama 3.1模型，通过零样本、单样本和少样本学习方式，结合正例与负例提示，从非结构化的区域贸易协定文本中提取Subject-Predicate-Object三元组，并通过定量与定性指标评估效果。

Result: 模型能够在不同提示设置下有效提取贸易相关三元组，少样本设置结合正负例提示表现较优，但仍面临歧义、复杂句式和领域术语等挑战。

Conclusion: 大语言模型在经济文本知识提取中具有潜力，提示工程对性能影响显著，未来可优化模型微调与领域适应以提升实用性。

Abstract: This study investigates the effectiveness of Large Language Models (LLMs) for
the extraction of structured knowledge in the form of Subject-Predicate-Object
triples. We apply the setup for the domain of Economics application. The
findings can be applied to a wide range of scenarios, including the creation of
economic trade knowledge graphs from natural language legal trade agreement
texts. As a use case, we apply the model to regional trade agreement texts to
extract trade-related information triples. In particular, we explore the
zero-shot, one-shot and few-shot prompting techniques, incorporating positive
and negative examples, and evaluate their performance based on quantitative and
qualitative metrics. Specifically, we used Llama 3.1 model to process the
unstructured regional trade agreement texts and extract triples. We discuss key
insights, challenges, and potential future directions, emphasizing the
significance of language models in economic applications.

</details>


### [79] [CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support Conversation](https://arxiv.org/abs/2510.05122)
*Jie Zhu,Yuanchen Zhou,Shuo Jiang,Junhui Li,Lifan Guo,Feng Chen,Chi Zhang,Fang Kong*

Main category: cs.CL

TL;DR: 提出CARE框架，通过强化原始训练集的推理能力，在不依赖大规模合成数据的情况下提升情感支持对话中回应的逻辑性和支持性。


<details>
  <summary>Details</summary>
Motivation: 现有情感支持对话研究多集中于数据增强和合成语料构建，忽视了有效情感支持背后的深层认知推理过程。

Method: 提出CARE框架，利用原始ESC训练集引导模型生成逻辑一致且具支持性的回应，并结合强化学习进一步优化推理过程。

Result: 实验结果表明，CARE显著提升了回应的逻辑性和支持质量。

Conclusion: CARE有助于构建更具共情能力、认知稳健且类人的情感支持系统。

Abstract: Emotional Support Conversation (ESC) plays a vital role in alleviating
psychological stress and providing emotional value through dialogue. While
recent studies have largely focused on data augmentation and synthetic corpus
construction, they often overlook the deeper cognitive reasoning processes that
underpin effective emotional support. To address this gap, we propose
\textbf{CARE}, a novel framework that strengthens reasoning in ESC without
relying on large-scale synthetic data. CARE leverages the original ESC training
set to guide models in generating logically coherent and supportive responses,
thereby explicitly enhancing cognitive reasoning. Building on this foundation,
we further employ reinforcement learning to refine and reinforce the reasoning
process. Experimental results demonstrate that CARE significantly improves both
the logical soundness and supportive quality of responses, advancing the
development of empathetic, cognitively robust, and human-like emotional support
systems.

</details>


### [80] [MADS: Multi-Agent Dialogue Simulation for Diverse Persuasion Data Generation](https://arxiv.org/abs/2510.05124)
*Mingjin Li,Yu Liu,Huayi Liu,Xiang Ye,Chao Jiang,Hongguang Zhang*

Main category: cs.CL

TL;DR: MADS是一个通过多智能体自博弈生成多轮说服性对话的可扩展框架，利用三个协同智能体实现低成本训练数据生成，显著提升小规模大模型的说服能力，并在真实营销场景中将自然流量转化率提高22.4%。


<details>
  <summary>Details</summary>
Motivation: 为解决行业中缺乏用户数据、冷启动评估困难和提示效率低下等挑战，需一种无需人工标注即可生成高质量说服性对话数据的方法。

Method: 提出MADS框架，包含模拟不同角色行为的用户智能体、执行任务导向说服策略的对话智能体以及评估和优化对话结果的优化智能体，通过智能体自博弈生成对话，并结合用户态度链（CoA）建模与专用大模型说服力评估进行验证。

Result: 在真实营销应用中，MADS显著提升了小规模大模型的说服性能，使自然流量转化率从1.83%提高到2.24%，增幅达22.4%。

Conclusion: MADS能够高效生成高质量说服性对话数据，有效解决数据稀缺和评估难题，具备显著的实用性和商业价值。

Abstract: We propose MADS (Multi-Agent Dialogue Simulation), a scalable framework for
generating persuasive multi-turn dialogues via agent self-play. MADS employs
three coordinated agents: User Agents simulating diverse persona-driven
behaviors, a Dialog Agent executing task-oriented persuasion strategies and an
Optimization Agent evaluating and refining dialogue outcomes. We further
validate its effectiveness through users' Chain-of-Attitude (CoA) modeling and
dedicated LLMs' persuasion assessment. This approach enables low-cost
generation of training data without human annotation, addressing key industry
challenges such as lack of user data, cold-start evaluation difficulties, and
prompt inefficiency. Applied to a real-world marketing scenario, MADS
significantly improved the persuasion capacity of small LLMs, increasing the
organic traffic conversion rate by 22.4\% (from 1.83\% to 2.24\%) ,
demonstrating clear business value.

</details>


### [81] [Catalog-Native LLM: Speaking Item-ID Dialect with Less Entanglement for Recommendation](https://arxiv.org/abs/2510.05125)
*Reza Shirkavand,Xiaokai Wei,Chen Wang,Zheng Hui,Heng Huang,Michelle Gong*

Main category: cs.CL

TL;DR: 本文提出了IDIOMoE模型，将物品交互历史视为语言空间中的一种原生方言，通过文本专家和物品专家的混合结构，有效融合协同过滤信号与大语言模型的语义理解能力，实现高性能推荐并保持对文本的理解。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统需要结合协同过滤的高效预测能力和大语言模型的语义表达与推理能力，以满足用户对自然语言查询和可解释性的更高期望。然而，协同信号语义不透明，而大语言模型难以仅从文本输入中捕捉隐式用户偏好，因此亟需一种统一且有效的融合方法。

Method: 提出IDIOMoE模型，将预训练大语言模型中每个块的前馈网络拆分为文本专家和物品专家，并通过token类型门控机制实现协同信号与文本信号的分离处理，将物品交互历史视为语言空间中的一个原生方言进行建模。

Result: IDIOMoE在多个公开和私有数据集上均展现出强大的推荐性能，同时保持了预训练语言模型的文本理解能力，避免了两种模态之间的破坏性干扰。

Conclusion: 通过将协同过滤信号纳入语言建模框架，IDIOMoE实现了推荐效果与语言理解的有机结合，为构建统一、高效且可解释的现代推荐系统提供了可行路径。

Abstract: While collaborative filtering delivers predictive accuracy and efficiency,
and Large Language Models (LLMs) enable expressive and generalizable reasoning,
modern recommendation systems must bring these strengths together. Growing user
expectations, such as natural-language queries and transparent explanations,
further highlight the need for a unified approach. However, doing so is
nontrivial. Collaborative signals are often token-efficient but semantically
opaque, while LLMs are semantically rich but struggle to model implicit user
preferences when trained only on textual inputs. This paper introduces Item-ID
+ Oral-language Mixture-of-Experts Language Model (IDIOMoE), which treats item
interaction histories as a native dialect within the language space, enabling
collaborative signals to be understood in the same way as natural language. By
splitting the Feed Forward Network of each block of a pretrained LLM into a
separate text expert and an item expert with token-type gating, our method
avoids destructive interference between text and catalog modalities. IDIOMoE
demonstrates strong recommendation performance across both public and
proprietary datasets, while preserving the text understanding of the pretrained
model.

</details>


### [82] [Improving Metacognition and Uncertainty Communication in Language Models](https://arxiv.org/abs/2510.05126)
*Mark Steyvers,Catarina Belem,Padhraic Smyth*

Main category: cs.CL

TL;DR: 通过监督微调可以提升大语言模型在不同任务和领域中表达不确定性信息的能力，尤其是多任务微调能显著提高模型在校准性和辨别力上的跨领域表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在决策场景中日益普及，但其输出缺乏对不确定性的准确表达，导致用户可能误信错误答案。尽管模型内部存在不确定性信号，其显式表达往往校准不良且难以区分正误回答。研究旨在探索微调是否能改善模型不确定性表达，并检验其泛化能力。

Method: 在涵盖常识、数学和开放问答的数据集上，对两类大语言模型进行监督微调，评估两种元认知任务：单题置信度估计和成对置信度比较，并测试在医学、法律等未见领域的泛化性能。

Result: 微调显著提升了模型的校准性（置信度与准确率的一致性）和辨别力（正确回答的置信度更高），且准确性未受影响。但效果具有任务特异性：单题训练不提升成对任务表现，反之亦然。多任务微调则带来更广泛的增益，尤其在跨域评估中表现更优。

Conclusion: 大语言模型的不确定性表达能力可通过训练改善并具备泛化性，但不同元认知技能之间不会自然迁移，需通过多任务训练协同发展。

Abstract: Large language models (LLMs) are increasingly used in decision-making
contexts, but when they present answers without signaling low confidence, users
may unknowingly act on erroneous outputs. While prior work shows that LLMs
maintain internal uncertainty signals, their explicit verbalized confidence is
typically miscalibrated and poorly discriminates between correct and incorrect
answers. Across two types of LLMs, we investigate whether supervised finetuning
can improve models' ability to communicate uncertainty and whether such
improvements generalize across tasks and domains. We finetune the LLMs on
datasets spanning general knowledge, mathematics, and open-ended trivia, and
evaluate two metacognitive tasks: (1) single-question confidence estimation,
where the model assigns a numeric certainty to its answer, and (2) pairwise
confidence comparison, where the model selects which of two answers it is more
likely to have correct. We assess generalization to unseen domains, including
medical and legal reasoning. Results show that finetuning improves calibration
(alignment between stated confidence and accuracy) and discrimination (higher
confidence for correct vs. incorrect responses) within and across domains,
while leaving accuracy unchanged. However, improvements are task-specific:
training on single-question calibration does not transfer to pairwise
comparison, and vice versa. In contrast, multitask finetuning on both forms of
metacognition yields broader gains, producing lower calibration error and
stronger discrimination in out-of-domain evaluations. These results show that
while uncertainty communication in LLMs is trainable and generalizable,
different metacognitive skills do not naturally reinforce one another and must
be developed together through multitask training.

</details>


### [83] [Advancing Automated Spatio-Semantic Analysis in Picture Description Using Language Models](https://arxiv.org/abs/2510.05128)
*Si-Ioi Ng,Pranav S. Ambadi,Kimberly D. Mueller,Julie Liss,Visar Berisha*

Main category: cs.CL

TL;DR: 提出了一种基于BERT的管道模型，用于自动提取和排序Cookie Theft图片描述中的内容信息单元（CIU），有效捕捉视觉叙述路径，支持认知障碍评估。


<details>
  <summary>Details</summary>
Motivation: 现有自动化评估认知语言障碍的方法通常忽略说话者描述的视觉叙事路径，且依赖人工标记或词典映射的语义空间特征分析耗时费力，亟需一种高效、自动化的解决方案。

Method: 采用BERT模型，结合二元交叉熵和成对排序损失进行微调，构建端到端管道用于CIU的自动提取与顺序预测，并通过5折交叉验证评估性能。

Result: 在CIU检测上达到93%中位精确率和96%中位召回率，序列错误率为24%；提取特征与真实标注具有强皮尔逊相关性，优于词典基线方法，且在ANCOVA分析中表现接近人工标注特征。

Conclusion: 该管道能有效表征视觉叙述路径，可用于认知障碍的自动化评估，相关模型与实现已开源。

Abstract: Current methods for automated assessment of cognitive-linguistic impairment
via picture description often neglect the visual narrative path - the sequence
and locations of elements a speaker described in the picture. Analyses of
spatio-semantic features capture this path using content information units
(CIUs), but manual tagging or dictionary-based mapping is labor-intensive. This
study proposes a BERT-based pipeline, fine tuned with binary cross-entropy and
pairwise ranking loss, for automated CIU extraction and ordering from the
Cookie Theft picture description. Evaluated by 5-fold cross-validation, it
achieves 93% median precision, 96% median recall in CIU detection, and 24%
sequence error rates. The proposed method extracts features that exhibit strong
Pearson correlations with ground truth, surpassing the dictionary-based
baseline in external validation. These features also perform comparably to
those derived from manual annotations in evaluating group differences via
ANCOVA. The pipeline is shown to effectively characterize visual narrative
paths for cognitive impairment assessment, with the implementation and models
open-sourced to public.

</details>


### [84] [Automated Alignment of Math Items to Content Standards in Large-Scale Assessments Using Language Models](https://arxiv.org/abs/2510.05129)
*Qingshu Xu,Hong Jiao,Tianyi Zhou,Ming Li,Nan Zhang,Sydney Peters,Yanbin Fu*

Main category: cs.CL

TL;DR: 该研究评估了三种自动化方法在将测试题目与四个领域和十九个技能标签对齐方面的性能，发现基于BERT的模型（如DeBERTa-v3-base和RoBERTa-large）表现最佳，优于传统机器学习和集成学习方法。


<details>
  <summary>Details</summary>
Motivation: 确保测试题目与内容标准的准确对齐对大规模评估中的分数解释至关重要，自动化对齐方法可提高效率和一致性。

Method: 采用三种方法：基于嵌入的经典机器学习模型（结合降维分析）、八种BERT及其变体模型的微调、以及集成学习（多数投票和堆叠）。

Result: DeBERTa-v3-base在领域对齐中达到0.950的加权F1分数，RoBERTa-large在技能对齐中达到0.869的F1分数；集成模型未超越最佳语言模型；降维提升了线性分类器性能但不及语言模型。

Conclusion: 基于Transformer的语言模型在自动化题目对齐任务中表现最优，是实现高效精准对齐的可行方案。

Abstract: Accurate alignment of items to content standards is critical for valid score
interpretation in large-scale assessments. This study evaluates three automated
paradigms for aligning items with four domain and nineteen skill labels. First,
we extracted embeddings and trained multiple classical supervised machine
learning models, and further investigated the impact of dimensionality
reduction on model performance. Second, we fine-tuned eight BERT model and its
variants for both domain and skill alignment. Third, we explored ensemble
learning with majority voting and stacking with multiple meta-models. The
DeBERTa-v3-base achieved the highest weighted-average F1 score of 0.950 for
domain alignment while the RoBERTa-large yielded the highest F1 score of 0.869
for skill alignment. Ensemble models did not surpass the best-performing
language models. Dimension reduction enhanced linear classifiers based on
embeddings but did not perform better than language models. This study
demonstrated different methods in automated item alignment to content
standards.}

</details>


### [85] [Submodular Context Partitioning and Compression for In-Context Learning-short paper](https://arxiv.org/abs/2510.05130)
*Shaoyi Zheng,Canyu Zhang,Tianyi Zhou,Shengjie Wang*

Main category: cs.CL

TL;DR: 提出Sub-CP框架，通过子模函数控制上下文块的多样性，提升大模型中上下文学习的效率与性能。


<details>
  <summary>Details</summary>
Motivation: 现有上下文学习方法在处理长上下文时因分块策略导致信息冗余或表征不足，性能受限。

Method: 提出Sub-CP，一种基于子模目标的块感知上下文选择框架，支持从全局多样到局部连贯的灵活选择策略，并允许预计算。

Result: 在多种任务和数据集上实验表明，Sub-CP在不同规模模型上均一致提升性能。

Conclusion: Sub-CP通过细粒度控制语义结构，有效缓解了上下文分块带来的问题，增强了上下文学习的效果。

Abstract: In-context learning (ICL) enables efficient few-shot learning in large
language models (LLMs) without training, but suffers from the quadratic input
complexity of transformers, limiting the maximum number of exemplars. While
various efficient ICL approaches partition the context into blocks to process
(e.g., ensembling, compression, cross-attention), they often ignore the
information redundancy or under-representation caused by different partition
strategies, leading to suboptimal performance. To tackle this problem, we
propose Sub-CP, a block-aware context selection framework that leverages
submodular objectives to control block diversity. Sub-CP supports a flexible
spectrum of selection strategies, allowing each block to range from globally
diverse to locally coherent. This allows fine-grained control over semantic
structure while enabling precomputation. Extensive experiments across diverse
tasks on multiple datasets show that Sub-CP consistently improves performance
across model scales.

</details>


### [86] [Rationale-Augmented Retrieval with Constrained LLM Re-Ranking for Task Discovery](https://arxiv.org/abs/2510.05131)
*Bowen Wei*

Main category: cs.CL

TL;DR: 提出了一种结合轻量级容错词汇检索、基于嵌入的向量相似性和受限大语言模型重排序的混合语义搜索系统，以解决Head Start项目中因术语复杂性和搜索局限性导致的任务查找困难。


<details>
  <summary>Details</summary>
Motivation: 新员工或轮岗员工在Head Start项目的GoEngage平台上难以找到合适的任务模块，主要由于领域术语、系统专有名称以及传统词汇搜索对拼写错误和词序变化的处理能力有限。

Method: 设计并实现一个混合语义搜索系统，结合容错词汇检索、向量相似性匹配和大语言模型重排序，并利用现有任务库和知识库基础设施，通过智能缓存、短列表生成和优雅降级机制提升效率与鲁棒性。

Result: 提供了包含资源需求、分阶段实施策略、离线评估协议（Hit@K, Precision@K, Recall@K, MRR）和在线测量方法（查询成功率、零结果率、停留时间代理指标）的完整框架。

Conclusion: 该系统在保持低误报率、可演化性和经济高效性的前提下，显著提升Head Start平台上的任务查找效率和用户体验。

Abstract: Head Start programs utilizing GoEngage face significant challenges when new
or rotating staff attempt to locate appropriate Tasks (modules) on the platform
homepage. These difficulties arise from domain-specific jargon (e.g., IFPA,
DRDP), system-specific nomenclature (e.g., Application Pool), and the inherent
limitations of lexical search in handling typos and varied word ordering. We
propose a pragmatic hybrid semantic search system that synergistically combines
lightweight typo-tolerant lexical retrieval, embedding-based vector similarity,
and constrained large language model (LLM) re-ranking. Our approach leverages
the organization's existing Task Repository and Knowledge Base infrastructure
while ensuring trustworthiness through low false-positive rates, evolvability
to accommodate terminological changes, and economic efficiency via intelligent
caching, shortlist generation, and graceful degradation mechanisms. We provide
a comprehensive framework detailing required resources, a phased implementation
strategy with concrete milestones, an offline evaluation protocol utilizing
curated test cases (Hit@K, Precision@K, Recall@K, MRR), and an online
measurement methodology incorporating query success metrics, zero-result rates,
and dwell-time proxies.

</details>


### [87] [Training Large Language Models To Reason In Parallel With Global Forking Tokens](https://arxiv.org/abs/2510.05132)
*Sheng Jia,Xiao Wang,Shiva Prasad Kasiviswanathan*

Main category: cs.CL

TL;DR: 提出了一种基于集合的监督微调方法（SSFT），通过引入全局损失函数来保持多样且准确的推理路径，显著提升LLMs在推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法在扩展并行测试时计算难以兼顾推理路径的多样性与准确性，尤其是在复杂问题中，触发多样化正确推理的分叉token通常位于采样树深层，导致多样性与准确性之间权衡恶化。

Method: 将并行推理视为一组下一个token预测问题，利用自监督的二分匹配，在监督微调（SFT）中引入基于集合的全局损失，使全局分叉token与独特推理轨迹对齐。

Result: 实验表明，与传统SFT相比，SSFT能有效保持多种推理模式，产生突现的全局分叉token，并在多个推理基准上显著提升Pass@1和Cons@k指标。

Conclusion: SSFT通过结构化的集合学习机制，解决了推理过程中多样性与准确性冲突的问题，为提升LLM推理能力提供了新思路。

Abstract: Although LLMs have demonstrated improved performance by scaling parallel
test-time compute, doing so relies on generating reasoning paths that are both
diverse and accurate. For challenging problems, the forking tokens that trigger
diverse yet correct reasoning modes are typically deep in the sampling tree.
Consequently, common strategies to encourage diversity, such as temperature
scaling, encounter a worsened trade-off between diversity and accuracy.
Motivated by this challenge, we treat parallel reasoning as a
set-of-next-token-prediction problem, and incorporate a set-based global loss
into Supervised Fine-Tuning (SFT) using self-supervised bipartite matching
between our global forking tokens and unique reasoning traces. We observe that,
while naive fine-tuning with multiple reasoning traces collapses these unique
reasoning modes, our proposed method, Set Supervised Fine-Tuning (SSFT),
preserves these modes and produces emergent global forking tokens. Experiments
on multiple reasoning benchmarks show that our SSFT consistently outperforms
SFT under both Pass@1 and Cons@k metrics.

</details>


### [88] [Characterizing Model Behavior Under Synthetic Data Training: An Empirical Study Across Scales and Mixing Ratios](https://arxiv.org/abs/2510.05133)
*Y. Du,G. Wu,G. Tang,W. Wang,Q. Fan*

Main category: cs.CL

TL;DR: 该研究系统地探讨了在NLP训练中合成数据比例对模型性能的影响，发现最多20%的合成数据可保持性能稳定，超过30%后性能迅速下降，且大模型对合成数据更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管合成数据在现代NLP训练中广泛应用，但其比例对模型行为的影响尚缺乏系统理解，尤其是不同模型规模下的表现变化。

Method: 使用Pythia模型系列（410M-12B参数）在五个不同任务上进行控制实验，评估1到3轮训练后，合成数据比例从0%到50%对模型性能、校准性和输出特性的影响。

Result: 模型在合成数据占比不超过20%时表现稳定，超过30%后性能加速下降；大模型（6.9B-12B）比小模型更稳健；校准性退化早于准确率下降；推理任务比检索任务更易受合成数据影响。当前最佳实践（如STaR、Self-Instruct）使用的高外部数据比例处于安全范围内。

Conclusion: 研究为不同模型规模和任务类型下的合成数据使用提供了实用指导，强调控制合成数据比例以避免性能退化，并建议利用校准性作为早期预警指标。

Abstract: Synthetic data generated by large language models has become integral to
modern NLP training pipelines, from bootstrapping reasoning capabilities to
augmenting instruction-following datasets. While recent work demonstrates
successful applications maintaining high external data ratios, systematic
understanding of how synthetic data proportion affects model behavior across
different scales remains limited. This paper presents a controlled empirical
study examining model performance, calibration, and output characteristics when
trained on varying synthetic-to-external data ratios. Using the Pythia model
suite (410M-12B parameters) across five diverse tasks, we evaluate models after
one to three training iterations with synthetic data proportions ranging from
0-50\%. Our key findings include: models maintain stable performance with up to
20\% synthetic data, but degradation accelerates beyond 30\%; larger models
(6.9B-12B) show greater robustness to synthetic data than smaller models
(410M-1.4B); calibration degradation precedes accuracy loss, providing an early
warning signal; and task characteristics matter, with reasoning tasks degrading
faster than retrieval tasks under synthetic data training. Importantly, we find
that current best practices, such as those employed in STaR and Self-Instruct
systems that maintain greater than 80\% external data, operate well within safe
regimes identified by our experiments. We provide practical guidance for
practitioners on synthetic data budgets based on model scale and task
requirements, alongside detailed comparison with concurrent work including
Shumailov et al.'s model collapse findings.

</details>


### [89] [Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech](https://arxiv.org/abs/2510.05799)
*Rikuto Kotoge,Yuichi Sasaki*

Main category: cs.CL

TL;DR: 提出了一种无需配对数据的语音合成偏好优化方法TKTO，通过细粒度的词元级对齐显著提升日语TTS的准确性和发音正确率。


<details>
  <summary>Details</summary>
Motivation: 现有语音合成偏好优化方法依赖成对的优劣样本且局限于语句级别，缺少细粒度的词元级优化能力，难以实现精确的发音对齐。

Method: 提出TKTO方法，无需配对数据，直接在词元级别进行优化，自动产生细粒度对齐信号，提升训练效率和发音准确性。

Result: 在日语TTS任务中，TKTO将准确性提升39%，CER降低54%，并对目标词元自动赋予高达12.8倍的强化奖励。

Conclusion: TKTO通过消除配对数据需求和实现词元级优化，显著提升了语音合成的性能，尤其在复杂语言如日语中表现突出。

Abstract: Aligning text-to-speech (TTS) system outputs with human feedback through
preference optimization has been shown to effectively improve the robustness
and naturalness of language model-based TTS models. Current approaches
primarily require paired desirable and undesirable samples at the utterance
level. However, such pairs are often limited in TTS output data, and
utterance-level formulation prevents fine-grained token-level optimization
needed for accurate pronunciation alignment. In this study, we propose TKTO
that eliminates the need for paired data, enabling a more data-efficient
training paradigm, and directly targets token-level units, automatically
providing fine-grained alignment signals without token-level annotations. TKTO
improves the challenging Japanese TTS accuracy by 39% and reduces CER by 54%,
automatically assigning 12.8 times stronger reward to targeted tokens.

</details>


### [90] [Curiosity-Driven LLM-as-a-judge for Personalized Creative Judgment](https://arxiv.org/abs/2510.05135)
*Vanya Bannihatti Kumar,Divyanshu Goyal,Akhil Eppa,Neel Bhandari*

Main category: cs.CL

TL;DR: 提出一种基于好奇心驱动的个性化LLM评价方法，用于评估创造性写作，在TTCW基准上优于传统监督微调方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在主观创造性评估任务上表现不佳，难以捕捉个体差异和主观判断的一致性。

Method: 采用好奇心驱动的LLM-as-a-judge框架，个性化建模每个个体的创造性判断，基于TTCW基准进行训练与评估。

Result: 在不同规模模型上均优于监督微调基线，在Pearson相关系数、Cohen's kappa和F1等指标上取得更好表现。

Conclusion: 该方法能有效学习个体化创造性判断，特别适用于标注者间主观差异较大的创造性评估任务。

Abstract: Modern large language models (LLMs) excel at objective tasks such as
evaluating mathematical reasoning and factual accuracy, yet they falter when
faced with the nuanced, subjective nature of assessing creativity. In this
work, we propose a novel curiosity-driven LLM-as-a-judge for evaluating
creative writing which is personlized to each individual's creative judgments.
We use the Torrance Test of Creative Thinking(TTCW) benchmark introduced in
Chakrabarty et al. (2024), which has stories annotated by expert humans across
various subjective dimensions like Originality, to test our hypothesis. We show
that our method enables models across various sizes, to learn the nuanced
creative judgments of different individuals, by showing improvements over
baseline supervised finetuning(SFT) method across various evaluation metrics
like Pearson correlation, Cohen's and F1 values. Our method is especially
useful in subjective evaluations where not all the annotators agree with each
other.

</details>


### [91] [Linguistic Characteristics of AI-Generated Text: A Survey](https://arxiv.org/abs/2510.05136)
*Luka Terčon,Kaja Dobrovoljc*

Main category: cs.CL

TL;DR: 本文综述了现有针对AI生成文本的语言学特征研究，系统归纳了当前研究在语言层次、模型类型、文本体裁、语言种类和提示方式等方面的发现与趋势，指出AI生成文本倾向于更正式、非个性化，词汇多样性较低且重复性较高，同时强调当前研究过度依赖英语和GPT系列模型，提示敏感性研究不足。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在各领域的广泛应用，亟需系统总结AI生成文本的语言学特征，以深化对生成文本与人类文本差异的理解，并推动跨语言、跨模型的深入研究。

Method: 通过分类梳理现有研究，从语言描述层次、涉及模型、分析语体、语言类型及提示方法等多个维度进行综合分析，归纳当前研究趋势与主要发现。

Result: 发现AI生成文本更正式、非人格化，名词、限定词和介词更多，形容词和副词较少；词汇多样性低、词汇量小、重复性强；研究主要集中于英语和GPT系列模型，提示敏感性问题普遍被忽视。

Conclusion: 当前研究存在语言和模型覆盖不足、提示设计单一等问题，未来需加强跨语言、跨模型及多提示条件下的系统性研究。

Abstract: Large language models (LLMs) are solidifying their position in the modern
world as effective tools for the automatic generation of text. Their use is
quickly becoming commonplace in fields such as education, healthcare, and
scientific research. There is a growing need to study the linguistic features
present in AI-generated text, as the increasing presence of such texts has
profound implications in various disciplines such as corpus linguistics,
computational linguistics, and natural language processing. Many observations
have already been made, however a broader synthesis of the findings made so far
is required to provide a better understanding of the topic. The present survey
paper aims to provide such a synthesis of extant research. We categorize the
existing works along several dimensions, including the levels of linguistic
description, the models included, the genres analyzed, the languages analyzed,
and the approach to prompting. Additionally, the same scheme is used to present
the findings made so far and expose the current trends followed by researchers.
Among the most-often reported findings is the observation that AI-generated
text is more likely to contain a more formal and impersonal style, signaled by
the increased presence of nouns, determiners, and adpositions and the lower
reliance on adjectives and adverbs. AI-generated text is also more likely to
feature a lower lexical diversity, a smaller vocabulary size, and repetitive
text. Current research, however, remains heavily concentrated on English data
and mostly on text generated by the GPT model family, highlighting the need for
broader cross-linguistic and cross-model investigation. In most cases authors
also fail to address the issue of prompt sensitivity, leaving much room for
future studies that employ multiple prompt wordings in the text generation
phase.

</details>


### [92] [Demystifying deep search: a holistic evaluation with hint-free multi-hop questions and factorised metrics](https://arxiv.org/abs/2510.05137)
*Maojia Song,Renhang Liu,Xinyu Wang,Yong Jiang,Pengjun Xie,Fei Huang,Soujanya Poria,Jingren Zhou*

Main category: cs.CL

TL;DR: 提出WebDetective，一个无提示泄漏的多跳问答基准和可追溯的评估框架，揭示现有RAG和网络代理在自主发现推理路径上的根本缺陷，并提出EvidenceLoop改进方案。


<details>
  <summary>Details</summary>
Motivation: 现有RAG和网络代理评估存在推理路径泄漏和单一通过率评估的问题，难以真实衡量模型的自主推理能力。

Method: 构建无提示多跳问题基准WebDetective，配合可控Wikipedia沙箱实现行为可追溯；提出细粒度评估框架，分离搜索充分性、知识利用和拒绝行为；评估25种SOTA模型并设计EvidenceLoop代理工作流以改进缺陷。

Result: 发现当前模型普遍存在知识利用不足和缺乏适当拒绝行为的问题，揭示其擅长执行既定推理路径但难以自主发现路径；EvidenceLoop通过验证循环和证据追踪提升了搜索与综合能力。

Conclusion: WebDetective能有效诊断推理系统的根本缺陷，推动构建真正自主的推理系统而非仅遵循模式的代理。

Abstract: RAG (Retrieval-Augmented Generation) systems and web agents are increasingly
evaluated on multi-hop deep search tasks, yet current practice suffers from two
major limitations. First, most benchmarks leak the reasoning path in the
question text, allowing models to follow surface cues rather than discover
reasoning chains autonomously. Second, evaluation is typically reduced to a
single pass rate, which collapses diverse behaviours into one score and
obscures whether failures stem from inadequate search, poor knowledge use, or
inappropriate refusal. To address these issues, we present WebDetective, a
benchmark of hint-free multi-hop questions paired with a controlled Wikipedia
sandbox that ensures full traceability of model actions, and a holistic
evaluation framework that separates search sufficiency, knowledge utilisation,
and refusal behaviour. Our evaluation of 25 state-of-the-art models reveals
systematic weaknesses across all architectures: models struggle with knowledge
utilisation despite having sufficient evidence and demonstrate near-absent
appropriate refusal when evidence is lacking. These patterns expose a
fundamental gap: today's systems excel at executing given reasoning paths but
fail when required to discover them. We develop an agentic workflow,
EvidenceLoop, that explicitly targets the challenges our benchmark identifies,
incorporating verification loops and systematic evidence tracking that improve
both search and synthesis capabilities. This baseline demonstrates that
WebDetective's diagnostic framework can guide concrete architectural
improvements, establishing our benchmark as a critical tool for developing
genuinely autonomous reasoning systems rather than pattern-following agents.

</details>


### [93] [LiRA: A Multi-Agent Framework for Reliable and Readable Literature Review Generation](https://arxiv.org/abs/2510.05138)
*Gregory Hok Tjoan Go,Khang Ly,Anders Søgaard,Amin Tabatabaei,Maarten de Rijke,Xinyi Chen*

Main category: cs.CL

TL;DR: 提出了一种名为LiRA的多智能体协作框架，用于自动生成高质量、连贯且可读性强的科学文献综述，无需领域特定调优即可在写作质量和引用准确性上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 科学出版物快速增长使得文献综述难以保持全面和及时，现有自动化方法多集中于检索与筛选，而写作阶段尤其在可读性和事实准确性方面仍缺乏探索。

Method: 设计了一个模仿人类文献综述过程的多智能体系统LiRA，包含内容提纲、段落撰写、编辑和评审等专业化智能体，通过协作生成完整的综述文章。

Result: 在SciReviewGen和ScienceDirect私有数据集上，LiRA在写作质量和引用准确性上优于AutoSurvey和MASS-Survey等基线方法，并与人工撰写综述保持较高相似度；同时验证了其在真实检索场景下的鲁棒性和对评审模型变化的稳定性。

Conclusion: 研究表明，基于代理的LLM工作流在无需领域微调的情况下，仍能显著提升自动化学术写作的可靠性与可用性，为自动化文献综述提供了有效新路径。

Abstract: The rapid growth of scientific publications has made it increasingly
difficult to keep literature reviews comprehensive and up-to-date. Though prior
work has focused on automating retrieval and screening, the writing phase of
systematic reviews remains largely under-explored, especially with regard to
readability and factual accuracy. To address this, we present LiRA (Literature
Review Agents), a multi-agent collaborative workflow which emulates the human
literature review process. LiRA utilizes specialized agents for content
outlining, subsection writing, editing, and reviewing, producing cohesive and
comprehensive review articles. Evaluated on SciReviewGen and a proprietary
ScienceDirect dataset, LiRA outperforms current baselines such as AutoSurvey
and MASS-Survey in writing and citation quality, while maintaining competitive
similarity to human-written reviews. We further evaluate LiRA in real-world
scenarios using document retrieval and assess its robustness to reviewer model
variation. Our findings highlight the potential of agentic LLM workflows, even
without domain-specific tuning, to improve the reliability and usability of
automated scientific writing.

</details>


### [94] [NLD-LLM: A systematic framework for evaluating small language transformer models on natural language description](https://arxiv.org/abs/2510.05139)
*Hamed Jelodar,Mohammad Meymani,Parisa Hamedi,Tochukwu Emmanuel Nwankwo,Samita Bai,Roozbeh Razavi-Far,Ali A. Ghorbani*

Main category: cs.CL

TL;DR: 提出NLD-LLM框架，系统评估大语言模型在生成源代码描述任务中的表现，强调提示工程对小模型性能的显著提升作用。


<details>
  <summary>Details</summary>
Motivation: 自然语言描述（NLD）任务需要从自然语言输入生成结构化输出，现有模型在代码描述生成上的表现缺乏系统性评估。

Method: 构建NLD-LLM框架，整合多种Transformer模型（如Qwen、LLaMA等），采用标准化提示设计与迭代优化策略，并结合语义与结构指标进行评估。

Result: 实验表明提示工程显著提升模型表现，精心设计的提示可使小型模型达到与大型模型相当的性能。

Conclusion: 提示设计对NLD任务至关重要，NLD-LLM为评估代码描述生成提供了系统、公平的基准框架。

Abstract: Natural Language Description (NLD) is a Natural Language Processing (NLP)
task that requires models to generate structured and meaningful outputs from
natural language inputs. In this work, we propose NLD-LLM, a systematic NLP
framework to evaluate the performance of language models to generate accurate
and concise source code descriptions. This framework incorporates a diverse set
of transformer models, including Qwen, DeepSeek, Phi, LLaMA, and Mistral,
spanning various sizes, architectures, and training approaches. Central to
NLD-LLM is a comprehensive prompt design strategy that includes standardized
formatting, clear task guidance, and NLD prompting, ensuring fair and
consistent evaluation. Additionally, we apply an iterative refinement process
to improve output's quality and assess the model's adaptability. Using semantic
and structural metrics, our analysis demonstrates that prompt engineering
significantly impacts the effectiveness of the model such that smaller models
often performing competitively when supported by well-crafted prompts.

</details>


### [95] [To model human linguistic prediction, make LLMs less superhuman](https://arxiv.org/abs/2510.05141)
*Byung-Doh Oh,Tal Linzen*

Main category: cs.CL

TL;DR: 尽管大语言模型（LLM）在预测下一个词方面表现出色，但其预测人类阅读行为的能力却在下降，原因在于LLM在长期和短期记忆方面远超人类，导致其成为“超人类”语言理解模型。本文主张构建具有类人记忆能力的模型，并提出实现路径及所需的人类实验数据。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在语言建模任务上的进步，人们希望将其用作人类语言认知的计算模型。然而，LLM预测人类阅读反应的能力反而下降，这限制了其作为认知模型的有效性，因此需要探究其原因并提出改进方向。

Method: 本文通过分析当前LLM与人类在语言预测中的表现差异，识别出LLM‘超人类’特性的两个关键因素：更强的长期记忆（对事实和训练样本的记忆）和更好的短期记忆（对上下文的记忆），并提出构建更具人类认知特征的记忆受限模型的可能路径。

Result: 研究发现，LLM的高预测准确率导致其低估人类阅读难度，从而无法准确模拟人类阅读行为；其‘超人类’特性主要来自记忆能力的非人属性。

Conclusion: 为使LLM成为更有效的认知模型，应开发具有类人记忆限制的模型，并收集更充分的人类行为数据以支持此类研究。

Abstract: When people listen to or read a sentence, they actively make predictions
about upcoming words: words that are less predictable are generally read more
slowly than predictable ones. The success of large language models (LLMs),
which, like humans, make predictions about upcoming words, has motivated
exploring the use of these models as cognitive models of human linguistic
prediction. Surprisingly, in the last few years, as language models have become
better at predicting the next word, their ability to predict human reading
behavior has declined. This is because LLMs are able to predict upcoming words
much better than people can, leading them to predict lower processing
difficulty in reading than observed in human experiments; in other words,
mainstream LLMs are 'superhuman' as models of language comprehension. In this
position paper, we argue that LLMs' superhumanness is primarily driven by two
factors: compared to humans, LLMs have much stronger long-term memory for facts
and training examples, and they have much better short-term memory for previous
words in the text. We advocate for creating models that have human-like
long-term and short-term memory, and outline some possible directions for
achieving this goal. Finally, we argue that currently available human data is
insufficient to measure progress towards this goal, and outline human
experiments that can address this gap.

</details>


### [96] [Reliable End-to-End Material Information Extraction from the Literature with Source-Tracked Multi-Stage Large Language Models](https://arxiv.org/abs/2510.05142)
*Xin Wang,Anshu Raj,Matthew Luebbe,Haiming Wen,Shuozhi Xu,Kun Lu*

Main category: cs.CL

TL;DR: 提出了一种基于大语言模型的多阶段信息抽取 pipeline，可从实验性材料文献中提取涵盖成分、工艺、微观结构和性能的47个特征，显著提高了抽取准确性和完整性。


<details>
  <summary>Details</summary>
Motivation: 现有的材料信息抽取方法通常局限于少量特征，且未充分捕捉成分-工艺-微观结构-性能之间的综合关系，导致难以构建全面的材料数据库。

Method: 构建了一个多阶段信息抽取流程，结合迭代抽取与溯源机制，利用大语言模型从非结构化文献中提取材料的多维度特征，并在特征级和元组级进行评估。

Result: 在特征级和元组级的F1得分均达到约0.96；相比单次抽取，微观结构类别的F1得分分别提升了10.0%（特征级）和13.7%（元组级），遗漏材料数从49降至13（396个材料中），漏检率从12.4%降至3.3%，且无虚报。

Conclusion: 该方法实现了高精度、低遗漏、零误报的材料信息抽取，适用于大规模文献挖掘，所生成的数据集可为机器学习和材料信息学提供可靠输入，且模块化设计可推广至多种材料体系。

Abstract: Data-driven materials discovery requires large-scale experimental datasets,
yet most of the information remains trapped in unstructured literature.
Existing extraction efforts often focus on a limited set of features and have
not addressed the integrated composition-processing-microstructure-property
relationships essential for understanding materials behavior, thereby posing
challenges for building comprehensive databases. To address this gap, we
propose a multi-stage information extraction pipeline powered by large language
models, which captures 47 features spanning composition, processing,
microstructure, and properties exclusively from experimentally reported
materials. The pipeline integrates iterative extraction with source tracking to
enhance both accuracy and reliability. Evaluations at the feature level
(independent attributes) and tuple level (interdependent features) yielded F1
scores around 0.96. Compared with single-pass extraction without source
tracking, our approach improved F1 scores of microstructure category by 10.0%
(feature level) and 13.7% (tuple level), and reduced missed materials from 49
to 13 out of 396 materials in 100 articles on precipitate-containing
multi-principal element alloys (miss rate reduced from 12.4% to 3.3%). The
pipeline enables scalable and efficient literature mining, producing databases
with high precision, minimal omissions, and zero false positives. These
datasets provide trustworthy inputs for machine learning and materials
informatics, while the modular design generalizes to diverse material classes,
enabling comprehensive materials information extraction.

</details>


### [97] [SynCED-EnDe 2025: A Synthetic and Curated English - German Dataset for Critical Error Detection in Machine Translation](https://arxiv.org/abs/2510.05144)
*Muskaan Chopra,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.CL

TL;DR: 提出并发布了SynCED-EnDe，一个大规模、标注平衡、来源多样的英德关键错误检测数据集，支持细粒度错误分析，显著提升现有模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有WMT21英德CED数据集存在规模小、标签不平衡、领域覆盖有限和时效性差等问题，限制了机器翻译关键错误检测的发展。

Method: 构建了一个包含1000个金标和8000个银标句对的新数据集SynCED-EnDe，涵盖多样来源（如StackExchange、GOV.UK），引入错误子类、触发标志和细粒度辅助标注（明显性、严重性等），并公开发布数据与工具。

Result: 基于XLM-R等编码器的基准实验表明，相较于WMT21，使用SynCED-EnDe可因标签平衡和标注精细化带来显著性能提升。

Conclusion: SynCED-EnDe是一个高质量、可扩展的社区资源，有望推动机器翻译在信息检索、对话系统及可穿戴AI等新兴场景中的安全部署。

Abstract: Critical Error Detection (CED) in machine translation aims to determine
whether a translation is safe to use or contains unacceptable deviations in
meaning. While the WMT21 English-German CED dataset provided the first
benchmark, it is limited in scale, label balance, domain coverage, and temporal
freshness. We present SynCED-EnDe, a new resource consisting of 1,000
gold-labeled and 8,000 silver-labeled sentence pairs, balanced 50/50 between
error and non-error cases. SynCED-EnDe draws from diverse 2024-2025 sources
(StackExchange, GOV.UK) and introduces explicit error subclasses, structured
trigger flags, and fine-grained auxiliary judgments (obviousness, severity,
localization complexity, contextual dependency, adequacy deviation). These
enrichments enable systematic analyses of error risk and intricacy beyond
binary detection. The dataset is permanently hosted on GitHub and Hugging Face,
accompanied by documentation, annotation guidelines, and baseline scripts.
Benchmark experiments with XLM-R and related encoders show substantial
performance gains over WMT21 due to balanced labels and refined annotations. We
envision SynCED-EnDe as a community resource to advance safe deployment of MT
in information retrieval and conversational assistants, particularly in
emerging contexts such as wearable AI devices.

</details>


### [98] [Every Step Counts: Decoding Trajectories as Authorship Fingerprints of dLLMs](https://arxiv.org/abs/2510.05148)
*Qi Li,Runpeng Yu,Haiquan Lu,Xinchao Wang*

Main category: cs.CL

TL;DR: 本文提出了一种基于离散扩散大语言模型（dLLMs）解码机制的模型归属方法，通过提取解码过程中的结构信息实现对不同模型或同一模型不同检查点的有效区分。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多样化的归属场景下表现受限，特别是难以区分不同模型或同一模型的不同检查点；作者希望利用dLLMs独特的双向解码机制中蕴含的结构信号进行更有效的模型归属。

Method: 提出“有向解码图”（DDM）来捕捉解码步骤间的结构关系，避免直接使用每步置信度导致的信息冗余；并进一步提出“高斯轨迹归属”（GTA），通过对每个解码位置拟合单元级高斯分布，以轨迹在各模型分布下的似然得分进行归属判断。

Result: 实验表明，所提DDM和GTA方法在多种设定下均显著优于基线方法，能够有效利用解码轨迹的结构信息，在模型归属任务中取得优异性能。

Conclusion: dLLMs的解码机制不仅提升推理效率与任务表现，还可作为模型归属的强大工具；通过合理提取与利用解码结构信息，能实现精准的生成轨迹溯源。

Abstract: Discrete Diffusion Large Language Models (dLLMs) have recently emerged as a
competitive paradigm for non-autoregressive language modeling. Their
distinctive decoding mechanism enables faster inference speed and strong
performance in code generation and mathematical tasks. In this work, we show
that the decoding mechanism of dLLMs not only enhances model utility but also
can be used as a powerful tool for model attribution. A key challenge in this
problem lies in the diversity of attribution scenarios, including
distinguishing between different models as well as between different
checkpoints or backups of the same model. To ensure broad applicability, we
identify two fundamental problems: what information to extract from the
decoding trajectory, and how to utilize it effectively. We first observe that
relying directly on per-step model confidence yields poor performance. This is
mainly due to the bidirectional decoding nature of dLLMs: each newly decoded
token influences the confidence of other decoded tokens, making model
confidence highly redundant and washing out structural signal regarding
decoding order or dependencies. To overcome this, we propose a novel
information extraction scheme called the Directed Decoding Map (DDM), which
captures structural relationships between decoding steps and better reveals
model-specific behaviors. Furthermore, to make full use of the extracted
structural information during attribution, we propose Gaussian-Trajectory
Attribution (GTA), where we fit a cell-wise Gaussian distribution at each
decoding position for each target model, and define the likelihood of a
trajectory as the attribution score: if a trajectory exhibits higher
log-likelihood under the distribution of a specific model, it is more likely to
have been generated by that model. Extensive experiments under different
settings validate the utility of our methods.

</details>


### [99] [Chronological Thinking in Full-Duplex Spoken Dialogue Language Models](https://arxiv.org/abs/2510.05150)
*Donghang Wu,Haoyang Zhang,Chen Chen,Tianyu Zhang,Fei Tian,Xuerui Yang,Gang Yu,Hexin Liu,Nana Hou,Yuchen Hu,Eng Siong Chng*

Main category: cs.CL

TL;DR: 提出了一种名为Chronological Thinking的实时对话思考机制，用于全双工对话系统，在不增加延迟的情况下提升响应质量。


<details>
  <summary>Details</summary>
Motivation: 现有全双工对话系统在听用户说话时处于空闲状态，重复预测静音标记，不符合人类在对话中持续轻量思考的模式，因此需要一种更拟人化的实时思考机制。

Method: 提出Chronological Thinking机制，采用严格因果的增量推理方式，在用户说话过程中利用听音窗口进行摊销式思考，不进行前瞻，用户停止后立即响应。

Result: 实验表明，该方法在客观指标和人工评价中均显著提升响应质量，并能有效应对对话动态，在全双工交互指标上表现优异。

Conclusion: Chronological Thinking为全双工对话系统提供了一种高效、低延迟的实时思考范式，更贴近人类对话行为，提升了对话质量与自然性。

Abstract: Recent advances in spoken dialogue language models (SDLMs) reflect growing
interest in shifting from turn-based to full-duplex systems, where the models
continuously perceive user speech streams while generating responses. This
simultaneous listening and speaking design enables real-time interaction and
the agent can handle dynamic conversational behaviors like user barge-in.
However, during the listening phase, existing systems keep the agent idle by
repeatedly predicting the silence token, which departs from human behavior: we
usually engage in lightweight thinking during conversation rather than
remaining absent-minded. Inspired by this, we propose Chronological Thinking, a
on-the-fly conversational thinking mechanism that aims to improve response
quality in full-duplex SDLMs. Specifically, chronological thinking presents a
paradigm shift from conventional LLM thinking approaches, such as
Chain-of-Thought, purpose-built for streaming acoustic input. (1) Strictly
causal: the agent reasons incrementally while listening, updating internal
hypotheses only from past audio with no lookahead. (2) No additional latency:
reasoning is amortized during the listening window; once the user stops
speaking, the agent halts thinking and begins speaking without further delay.
Experiments demonstrate the effectiveness of chronological thinking through
both objective metrics and human evaluations show consistent improvements in
response quality. Furthermore, chronological thinking robustly handles
conversational dynamics and attains competitive performance on full-duplex
interaction metrics.

</details>


### [100] [Exploring Large Language Models for Financial Applications: Techniques, Performance, and Challenges with FinMA](https://arxiv.org/abs/2510.05151)
*Prudence Djagba,Abdelkader Y. Saley*

Main category: cs.CL

TL;DR: 该研究评估了在PIXIU框架下构建的领域适应型大语言模型FinMA在金融NLP任务中的表现，发现其在情感分析和分类任务中表现良好，但在数值推理、实体识别和摘要生成方面存在挑战。


<details>
  <summary>Details</summary>
Motivation: 金融应用对准确性、可靠性和领域适应性要求极高，因此需要深入理解如何有效设计和评估金融领域的大语言模型，以支持金融决策。

Method: 研究分析了FinMA的模型架构，使用金融指令调优（FIT）数据集进行指令微调，并在FLARE基准下进行评估。

Result: FinMA在情感分析和分类任务中表现良好，但在数值推理、命名实体识别和文本摘要等任务中表现较弱。

Conclusion: 该研究揭示了金融领域大语言模型的优势与局限，为未来模型的设计与评估提供了方向，有助于提升其在金融决策中的实用性。

Abstract: This research explores the strengths and weaknesses of domain-adapted Large
Language Models (LLMs) in the context of financial natural language processing
(NLP). The analysis centers on FinMA, a model created within the PIXIU
framework, which is evaluated for its performance in specialized financial
tasks. Recognizing the critical demands of accuracy, reliability, and domain
adaptation in financial applications, this study examines FinMA's model
architecture, its instruction tuning process utilizing the Financial
Instruction Tuning (FIT) dataset, and its evaluation under the FLARE benchmark.
Findings indicate that FinMA performs well in sentiment analysis and
classification, but faces notable challenges in tasks involving numerical
reasoning, entity recognition, and summarization. This work aims to advance the
understanding of how financial LLMs can be effectively designed and evaluated
to assist in finance-related decision-making processes.

</details>


### [101] [A Single Character can Make or Break Your LLM Evals](https://arxiv.org/abs/2510.05152)
*Jingtong Su,Jianyu Zhang,Karen Ullrich,Léon Bottou,Mark Ibrahim*

Main category: cs.CL

TL;DR: 提示中用于分隔上下文示例的分隔符选择虽看似微小，却显著影响大语言模型（LLM）的性能表现，不同分隔符可导致MMLU得分差异高达±23%，甚至改变模型排名。


<details>
  <summary>Details</summary>
Motivation: 研究当前LLM评估中常使用示例引导模型输出，但示例格式（尤其是分隔符）的影响被忽视，作者旨在探究这一选择对模型性能的潜在影响。

Method: 在多个主流模型家族（如Llama、Qwen、Gemma）上测试不同分隔符（如逗号、换行、分号、#等）对MMLU等任务性能的影响，并通过注意力机制分析其作用机制，最后尝试在提示中显式说明分隔符以提高鲁棒性。

Result: 发现分隔符选择对模型性能影响显著，性能波动可达±23%；某些分隔符能引导注意力聚焦关键输入词元；显式指定分隔符可提升模型鲁棒性。

Conclusion: 当前LLM对提示中分隔符的选择极为敏感，这种脆弱性普遍存在且不随模型规模增大而改善；建议在实际应用和评估中谨慎选择并显式声明分隔符以提升可靠性。

Abstract: Common Large Language model (LLM) evaluations rely on demonstration examples
to steer models' responses to the desired style. While the number of examples
used has been studied and standardized, the choice of how to format examples is
less investigated. In evaluation protocols and real world usage, users face the
choice how to separate in-context examples: use a comma? new line? semi-colon?
hashtag? etc.? Surprisingly, we find this seemingly minor choice can
dramatically alter model response quality. Across leading model families
(Llama, Qwen, Gemma), performance on MMLU for example can vary by $\pm 23\%$
depending on the choice of delimiter. In fact, one can manipulate model
rankings to put any model in the lead by only modifying the single character
separating examples. We find LLMs' brittleness pervades topics, model families,
and doesn't improve with scale. By probing attention head scores, we find that
good-performing delimiters steer attention towards key tokens in the input.
Finally, we explore methods to improve LLMs' robustness to the choice of
delimiter. We find specifying the selected delimiter in the prompt boosts
robustness and offer practical recommendations for the best-performing
delimiters to select.

</details>


### [102] [Can AI Truly Represent Your Voice in Deliberations? A Comprehensive Study of Large-Scale Opinion Aggregation with LLMs](https://arxiv.org/abs/2510.05154)
*Shenzhe Zhu,Shu Yang,Michiel A. Bakker,Alex Pentland,Jiaxin Pei*

Main category: cs.CL

TL;DR: 本文提出了DeliberationBank，一个大规模、基于人类标注的数据集，用于评估公共审议文本的摘要质量，并提出了DeliberationJudge模型，以更高效、更贴近人类判断的方式评估摘要的代表性、中立性等维度，揭示了现有LLM在少数观点表达上的不足。


<details>
  <summary>Details</summary>
Motivation: 大规模公共审议产生大量自由文本，需生成公正、代表性的摘要用于政策制定，但现有LLM摘要模型存在忽视少数观点、顺序偏差等问题，且当前依赖LLM作为评估工具与人类判断对齐性差，亟需更可靠的大规模评估方法。

Method: 构建DeliberationBank数据集，包含3000名参与者对10个议题的意见文本和4500名参与者在四个维度（代表性、信息性、中立性、政策认可）上的摘要评分；基于此训练DeliberationJudge——一个微调的DeBERTa模型，用于自动化评估摘要质量，并对比多种LLM裁判的表现。

Result: DeliberationJudge在效率和与人类判断的一致性上优于多种LLM裁判；通过该工具评估18种LLM，发现其普遍存在对少数观点的代表性不足问题。

Conclusion: DeliberationBank和DeliberationJudge为审议摘要提供了可扩展且可靠的评估框架，有助于提升AI在政策制定中生成更公平、更具代表性的摘要能力。

Abstract: Large-scale public deliberations generate thousands of free-form
contributions that must be synthesized into representative and neutral
summaries for policy use. While LLMs have been shown as a promising tool to
generate summaries for large-scale deliberations, they also risk
underrepresenting minority perspectives and exhibiting bias with respect to the
input order, raising fairness concerns in high-stakes contexts. Studying and
fixing these issues requires a comprehensive evaluation at a large scale, yet
current practice often relies on LLMs as judges, which show weak alignment with
human judgments. To address this, we present DeliberationBank, a large-scale
human-grounded dataset with (1) opinion data spanning ten deliberation
questions created by 3,000 participants and (2) summary judgment data annotated
by 4,500 participants across four dimensions (representativeness,
informativeness, neutrality, policy approval). Using these datasets, we train
DeliberationJudge, a fine-tuned DeBERTa model that can rate deliberation
summaries from individual perspectives. DeliberationJudge is more efficient and
more aligned with human judgements compared to a wide range of LLM judges. With
DeliberationJudge, we evaluate 18 LLMs and reveal persistent weaknesses in
deliberation summarization, especially underrepresentation of minority
positions. Our framework provides a scalable and reliable way to evaluate
deliberation summarization, helping ensure AI systems are more representative
and equitable for policymaking.

</details>


### [103] [A novel hallucination classification framework](https://arxiv.org/abs/2510.05189)
*Maksym Zavhorodnii,Dmytro Dehtiarov,Anna Konovalenko*

Main category: cs.CL

TL;DR: 提出一种基于提示工程和无监督学习的轻量级框架，可有效检测大语言模型中的幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在推理过程中可能生成幻觉（即虚假信息），影响其可靠性，亟需自动检测方法。

Method: 通过提示工程系统性地复现多种幻觉类型，构建专门数据集，并利用嵌入模型将其映射到向量空间，采用降维和无监督学习分析幻觉与真实响应的分布差异。

Result: 定量分析显示，幻觉的语义空间偏离程度与其信息失真严重性呈正相关，即使简单分类器也能有效区分幻觉与正确输出。

Conclusion: 该方法为单一LLM内部的幻觉检测提供了理论和实证支持，是一种高效且轻量的模型可靠性提升框架。

Abstract: This work introduces a novel methodology for the automatic detection of
hallucinations generated during large language model (LLM) inference. The
proposed approach is based on a systematic taxonomy and controlled reproduction
of diverse hallucination types through prompt engineering. A dedicated
hallucination dataset is subsequently mapped into a vector space using an
embedding model and analyzed with unsupervised learning techniques in a
reduced-dimensional representation of hallucinations with veridical responses.
Quantitative evaluation of inter-centroid distances reveals a consistent
correlation between the severity of informational distortion in hallucinations
and their spatial divergence from the cluster of correct outputs. These
findings provide theoretical and empirical evidence that even simple
classification algorithms can reliably distinguish hallucinations from accurate
responses within a single LLM, thereby offering a lightweight yet effective
framework for improving model reliability.

</details>


### [104] [Let it Calm: Exploratory Annealed Decoding for Verifiable Reinforcement Learning](https://arxiv.org/abs/2510.05251)
*Chenghao Yang,Lin Gui,Chenxiao Yang,Victor Veitch,Lizhu Zhang,Zhuokai Zhao*

Main category: cs.CL

TL;DR: 提出了一种名为探索性退火解码（EAD）的新方法，在强化学习中通过动态调整采样温度，前高后低，提升大语言模型推理能力，显著提高样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有固定温度采样的探索策略难以在样本质量和训练稳定性之间取得平衡，需要一种更有效的探索机制以提升大语言模型在强化学习中的推理性能。

Method: 提出探索性退火解码（EAD），在序列生成初期使用高温度促进探索，随后逐渐降低温度以利用模型当前策略，聚焦于高质量样本生成，从而实现‘开头探索，结尾利用’的动态策略。

Result: EAD在多种强化学习与可验证奖励（RLVR）算法和不同模型规模下均优于固定温度采样，显著提升样本效率和训练稳定性。

Conclusion: 将探索策略与序列生成的自然动态相匹配，是一种提升大语言模型推理能力的高效且稳健的方法，EAD为RLVR提供了一种轻量、即插即用的改进方案。

Abstract: Reinforcement learning with verifiable rewards (RLVR) is a powerful paradigm
for enhancing the reasoning capabilities of large language models (LLMs), yet
its success hinges on effective exploration. An ideal exploration strategy must
navigate two fundamental challenges: it must preserve sample quality while also
ensuring training stability. While standard fixed-temperature sampling is
simple, it struggles to balance these competing demands, as high temperatures
degrade sample quality and low temperatures limit discovery. In this work, we
propose a simpler and more effective strategy, Exploratory Annealed Decoding
(EAD), grounded in the insight that exploration is most impactful on early
tokens which define a sequence's semantic direction. EAD implements an
intuitive **explore-at-the-beginning, exploit-at-the-end** strategy by
annealing the sampling temperature from high to low during generation. This
dynamic schedule encourages meaningful, high-level diversity at the start, then
gradually lowers the temperature to preserve sample quality and keep the
sampling distribution close to the target policy, which is essential for stable
training. We demonstrate that EAD is a lightweight, plug-and-play method that
significantly improves sample efficiency, consistently outperforming
fixed-temperature sampling across various RLVR algorithms and model sizes. Our
work suggests that aligning exploration with the natural dynamics of sequential
generation offers a robust path to improving LLM reasoning.

</details>


### [105] [Camellia: Benchmarking Cultural Biases in LLMs for Asian Languages](https://arxiv.org/abs/2510.05291)
*Tarek Naous,Anagha Savit,Carlos Rafael Catalan,Geyang Guo,Jaehyeok Lee,Kyungdon Lee,Lheane Marie Dizon,Mengyu Ye,Neel Kothari,Sahajpreet Singh,Sarah Masud,Tanish Patwa,Trung Thanh Tran,Zohaib Khan,Alan Ritter,JinYeong Bak,Keisuke Sakaguchi,Tanmoy Chakraborty,Yuki Arase,Wei Xu*

Main category: cs.CL

TL;DR: 本文介绍了Camellia，一个用于衡量九种亚洲语言中以实体为中心的文化偏见的基准。通过该基准测试，研究发现当前多语言大模型在处理亚洲语言时普遍存在文化适应困难、情感关联偏差和实体抽取性能差距等问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型多语言能力的提升，其在处理非西方语言时是否表现出文化偏见尚不明确。由于缺乏多语言评测基准，难以系统评估模型在亚洲语言中的文化公平性。因此，亟需一个覆盖多种亚洲文化的基准来量化此类偏见。

Method: 构建了Camellia基准，包含19,530个手动标注为亚洲或西方文化关联的实体，以及2,173个来自社交媒体的真实掩码上下文。在九种亚洲语言上，对四类多语言大模型家族进行评估，任务涵盖文化语境适应、情感关联和实体抽取问答等。

Result: 实验表明，所有模型在亚洲语言的文化适应上均表现不佳；不同模型因训练数据来源差异而表现出不同的文化偏见模式；在情感关联和实体抽取任务中存在显著的文化间性能差距。

Conclusion: 当前多语言大模型在处理亚洲语言时存在显著的文化偏见与理解局限，亟需改进训练数据覆盖与文化感知能力以提升跨文化公平性。

Abstract: As Large Language Models (LLMs) gain stronger multilingual capabilities,
their ability to handle culturally diverse entities becomes crucial. Prior work
has shown that LLMs often favor Western-associated entities in Arabic, raising
concerns about cultural fairness. Due to the lack of multilingual benchmarks,
it remains unclear if such biases also manifest in different non-Western
languages. In this paper, we introduce Camellia, a benchmark for measuring
entity-centric cultural biases in nine Asian languages spanning six distinct
Asian cultures. Camellia includes 19,530 entities manually annotated for
association with the specific Asian or Western culture, as well as 2,173
naturally occurring masked contexts for entities derived from social media
posts. Using Camellia, we evaluate cultural biases in four recent multilingual
LLM families across various tasks such as cultural context adaptation,
sentiment association, and entity extractive QA. Our analyses show a struggle
by LLMs at cultural adaptation in all Asian languages, with performance
differing across models developed in regions with varying access to
culturally-relevant data. We further observe that different LLM families hold
their distinct biases, differing in how they associate cultures with particular
sentiments. Lastly, we find that LLMs struggle with context understanding in
Asian languages, creating performance gaps between cultures in entity
extraction.

</details>


### [106] [RAG Makes Guardrails Unsafe? Investigating Robustness of Guardrails under RAG-style Contexts](https://arxiv.org/abs/2510.05310)
*Yining She,Daniel W. Peterson,Marianne Menglin Liu,Vikas Upadhyay,Mohammad Hossein Chaghazardi,Eunsuk Kang,Dan Roth*

Main category: cs.CL

TL;DR: 研究表明，基于大语言模型（LLM）的外部防护模型在面对上下文中插入的无害信息时表现出明显的判断不稳定性，揭示了现有防护机制在上下文鲁棒性方面的缺陷。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，确保其安全性至关重要。当前流行的基于LLM的防护模型本身也依赖于LLM，因而可能受数据分布变化影响，特别是在检索增强生成（RAG）等场景中，其鲁棒性尚不清楚。

Method: 以检索增强生成（RAG）为案例，系统评估了3个Llama Guard模型和2个GPT-oss模型在面对上下文中插入良性文档时的表现，分析了检索文档、用户查询和模型生成响应各部分对防护判断的影响，并测试了两种缓解策略。

Result: 实验发现，向防护模型上下文中插入良性文档会导致输入和输出防护判断分别在约11%和8%的情况下发生改变，表明其可靠性下降；所测试的两种缓解方法仅带来轻微改善。

Conclusion: 当前基于LLM的防护模型存在上下文鲁棒性缺陷，需在训练和评估中考虑检索内容与查询组合带来的影响，以提升实际应用中的安全性。

Abstract: With the increasing adoption of large language models (LLMs), ensuring the
safety of LLM systems has become a pressing concern. External LLM-based
guardrail models have emerged as a popular solution to screen unsafe inputs and
outputs, but they are themselves fine-tuned or prompt-engineered LLMs that are
vulnerable to data distribution shifts. In this paper, taking Retrieval
Augmentation Generation (RAG) as a case study, we investigated how robust
LLM-based guardrails are against additional information embedded in the
context. Through a systematic evaluation of 3 Llama Guards and 2 GPT-oss
models, we confirmed that inserting benign documents into the guardrail context
alters the judgments of input and output guardrails in around 11% and 8% of
cases, making them unreliable. We separately analyzed the effect of each
component in the augmented context: retrieved documents, user query, and
LLM-generated response. The two mitigation methods we tested only bring minor
improvements. These results expose a context-robustness gap in current
guardrails and motivate training and evaluation protocols that are robust to
retrieval and query composition.

</details>


### [107] [WeatherArchive-Bench: Benchmarking Retrieval-Augmented Reasoning for Historical Weather Archives](https://arxiv.org/abs/2510.05336)
*Yongan Yu,Xianda Du,Qingchen Hu,Jiahao Liang,Jingwei Ni,Dan Qiang,Kaiyu Huang,Grant McKenzie,Renee Sieber,Fengran Mo*

Main category: cs.CL

TL;DR: 本文提出了WeatherArchive-Bench，首个用于评估基于历史天气档案的检索增强生成（RAG）系统的基准，包含检索和评估两项任务，揭示了现有密集检索模型和大语言模型在处理历史术语及社会脆弱性与韧性概念上的局限性。


<details>
  <summary>Details</summary>
Motivation: 历史档案记录了社会对极端天气事件的经验与响应，提供了气象数据中缺乏的社会脆弱性和韧性的定性信息。然而，这些档案规模庞大、数字化质量差且语言古老，难以转化为气候研究可用的结构化知识。为促进对这类档案的有效利用，需要一个专门的评估基准。

Method: 构建WeatherArchive-Bench基准，包括两个任务：WeatherArchive-Retrieval（从百万级历史新闻片段中检索相关段落）和WeatherArchive-Assessment（利用大语言模型分类极端天气叙事中的社会脆弱性和韧性指标）。通过稀疏、密集和重排序检索器以及多种大语言模型进行广泛实验。

Result: 实验表明，密集检索器在处理历史术语时表现不佳，而大语言模型常误解脆弱性和韧性概念，暴露出当前RAG系统在理解复杂社会指标方面的关键缺陷。

Conclusion: 研究揭示了现有模型在处理历史气候档案时的局限，为构建更鲁棒的面向气候研究的RAG系统提供了重要启示，所构建的数据集和评估框架已公开。

Abstract: Historical archives on weather events are collections of enduring primary
source records that offer rich, untapped narratives of how societies have
experienced and responded to extreme weather events. These qualitative accounts
provide insights into societal vulnerability and resilience that are largely
absent from meteorological records, making them valuable for climate scientists
to understand societal responses. However, their vast scale, noisy digitized
quality, and archaic language make it difficult to transform them into
structured knowledge for climate research. To address this challenge, we
introduce WeatherArchive-Bench, the first benchmark for evaluating
retrieval-augmented generation (RAG) systems on historical weather archives.
WeatherArchive-Bench comprises two tasks: WeatherArchive-Retrieval, which
measures a system's ability to locate historically relevant passages from over
one million archival news segments, and WeatherArchive-Assessment, which
evaluates whether Large Language Models (LLMs) can classify societal
vulnerability and resilience indicators from extreme weather narratives.
Extensive experiments across sparse, dense, and re-ranking retrievers, as well
as a diverse set of LLMs, reveal that dense retrievers often fail on historical
terminology, while LLMs frequently misinterpret vulnerability and resilience
concepts. These findings highlight key limitations in reasoning about complex
societal indicators and provide insights for designing more robust
climate-focused RAG systems from archival contexts. The constructed dataset and
evaluation framework are publicly available at
https://anonymous.4open.science/r/WeatherArchive-Bench/.

</details>


### [108] [Residualized Similarity for Faithfully Explainable Authorship Verification](https://arxiv.org/abs/2510.05362)
*Peter Zeng,Pegah Alipoormolabashi,Jihu Mun,Gourab Dey,Nikita Soni,Niranjan Balasubramanian,Owen Rambow,H. Schwartz*

Main category: cs.CL

TL;DR: 提出了一种名为残差化相似性（RS）的新方法，通过结合可解释特征与神经网络来提升作者验证系统的性能，同时保持预测的可解释性和保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的作者身份验证系统虽然精度高，但缺乏可解释性，尤其在需要为现实决策提供依据时，模型的预测必须能够通过可追溯到原文的可解释特征进行解释。

Method: 将作者验证视为相似性任务，使用可解释系统初步预测文档相似性，再用神经网络预测该相似性的残差（即误差），从而补充和提升可解释系统的性能。

Result: 在四个数据集上的实验表明，该方法能达到最先进的作者验证模型的性能水平，并且能够展示预测结果的可解释性和保真度。

Conclusion: RS方法成功地在不牺牲可解释性的前提下提升了基于可解释特征的作者验证系统的性能，使得模型预测既准确又可追溯到原始文本。

Abstract: Responsible use of Authorship Verification (AV) systems not only requires
high accuracy but also interpretable solutions. More importantly, for systems
to be used to make decisions with real-world consequences requires the model's
prediction to be explainable using interpretable features that can be traced to
the original texts. Neural methods achieve high accuracies, but their
representations lack direct interpretability. Furthermore, LLM predictions
cannot be explained faithfully -- if there is an explanation given for a
prediction, it doesn't represent the reasoning process behind the model's
prediction. In this paper, we introduce Residualized Similarity (RS), a novel
method that supplements systems using interpretable features with a neural
network to improve their performance while maintaining interpretability.
Authorship verification is fundamentally a similarity task, where the goal is
to measure how alike two documents are. The key idea is to use the neural
network to predict a similarity residual, i.e. the error in the similarity
predicted by the interpretable system. Our evaluation across four datasets
shows that not only can we match the performance of state-of-the-art authorship
verification models, but we can show how and to what degree the final
prediction is faithful and interpretable.

</details>


### [109] [The End of Transformers? On Challenging Attention and the Rise of Sub-Quadratic Architectures](https://arxiv.org/abs/2510.05364)
*Alexander M. Fichtl,Jeremias Bohn,Josefin Kelber,Edoardo Mosca,Georg Groh*

Main category: cs.CL

TL;DR: 本文综述了近年来为克服Transformer中注意力机制的二次复杂度瓶颈而提出的各种方法，包括亚二次注意力变体、循环神经网络、状态空间模型和混合架构，并对其计算与内存复杂度、基准结果及根本局限性进行了批判性分析。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在序列处理任务中占据主导地位，但其注意力机制的二次复杂度在上下文长度增加时成为显著瓶颈，因此需要探索更高效的替代方案。

Method: 本文系统性地回顾并比较了多种旨在降低注意力计算复杂度的方法，涵盖亚二次注意力机制、RNN、状态空间模型以及混合架构，从计算与内存开销、性能表现和理论局限性角度进行分析。

Result: 多种新兴方法在长上下文任务中展现出与Transformer相当甚至更优的效率和性能，显示出挑战纯注意力架构主导地位的潜力。

Conclusion: 尽管Transformer仍占主导，但新兴架构在效率和扩展性方面进步显著，未来纯注意力模型的统治地位可能受到挑战。

Abstract: Transformers have dominated sequence processing tasks for the past seven
years -- most notably language modeling. However, the inherent quadratic
complexity of their attention mechanism remains a significant bottleneck as
context length increases. This paper surveys recent efforts to overcome this
bottleneck, including advances in (sub-quadratic) attention variants, recurrent
neural networks, state space models, and hybrid architectures. We critically
analyze these approaches in terms of compute and memory complexity, benchmark
results, and fundamental limitations to assess whether the dominance of
pure-attention transformers may soon be challenged.

</details>


### [110] [Context Length Alone Hurts LLM Performance Despite Perfect Retrieval](https://arxiv.org/abs/2510.05381)
*Yufeng Du,Minyang Tian,Srikanth Ronanki,Subendhu Rongali,Sravan Bodapati,Aram Galstyan,Azton Wells,Roy Schwartz,Eliu A Huerta,Hao Peng*

Main category: cs.CL

TL;DR: 即使大语言模型能够完美检索相关信息，输入长度本身仍会导致性能显著下降，表明长上下文处理存在与检索质量无关的固有局限。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在长上下文任务中性能未能随上下文长度扩展而提升的原因，挑战‘只要检索完美性能就应保持’的假设。

Method: 在数学、问答和编程任务上，对5个开源和闭源大模型进行系统实验，控制检索质量（如屏蔽无关内容、前置相关信息），观察不同输入长度下的性能变化。

Result: 即使模型能完美检索相关 tokens，输入长度增加仍导致性能下降13.9%–85%；即使无关 token 被替换或屏蔽，或相关证据置于问题前，性能仍下降。

Conclusion: 输入长度本身会影响模型表现，揭示了大模型长上下文处理的新瓶颈；提出一种模型无关的缓解策略：通过提示模型先复述检索到的证据，再解决问题，可提升性能。

Abstract: Large language models (LLMs) often fail to scale their performance on
long-context tasks performance in line with the context lengths they support.
This gap is commonly attributed to retrieval failures -- the models' inability
to identify relevant information in the long inputs. Accordingly, recent
efforts often focus on evaluating and improving LLMs' retrieval performance: if
retrieval is perfect, a model should, in principle, perform just as well on a
long input as it does on a short one -- or should it? This paper presents
findings that the answer to this question may be negative. Our systematic
experiments across 5 open- and closed-source LLMs on math, question answering,
and coding tasks reveal that, even when models can perfectly retrieve all
relevant information, their performance still degrades substantially
(13.9%--85%) as input length increases but remains well within the models'
claimed lengths. This failure occurs even when the irrelevant tokens are
replaced with minimally distracting whitespace, and, more surprisingly, when
they are all masked and the models are forced to attend only to the relevant
tokens. A similar performance drop is observed when all relevant evidence is
placed immediately before the question. Our findings reveal a
previously-unrealized limitation: the sheer length of the input alone can hurt
LLM performance, independent of retrieval quality and without any distraction.
They motivate our simple, model-agnostic mitigation strategy that transforms a
long-context task into a short-context one by prompting the model to recite the
retrieved evidence before attempting to solve the problem. On RULER, we observe
a consistent improvement of GPT-4o up to 4% on an already strong baseline.

</details>


### [111] [Cross-Lingual Mental Health Ontologies for Indian Languages: Bridging Patient Expression and Clinical Understanding through Explainable AI and Human-in-the-Loop Validation](https://arxiv.org/abs/2510.05387)
*Ananth Kandala,Ratna Kandala,Akshata Kishore Moharir,Niva Manchanda,Sunaina Singh*

Main category: cs.CL

TL;DR: 提出了一种基于图方法的跨语言患者压力表达框架（CL-PDE），用于构建包含印度多种语言和文化表达的跨语言心理健康本体，以弥补现有临床自然语言处理在文化与语言多样性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有心理健康资源多以英语或西方文化为中心，难以准确表达印度多语言、多文化背景下患者的心理困扰，导致临床自然语言处理在印度语境下的表征不足。

Method: 采用基于图的方法构建跨语言患者压力表达（CL-PDE）框架，通过捕捉文化嵌入的压力表达，实现多语言间的对齐，并与临床术语建立链接。

Result: 构建出能反映印度多种语言和文化背景下心理困扰表达的跨语言本体，提升自然语言处理系统对本地化表达的理解能力。

Conclusion: CL-PDE框架有助于创建更具文化包容性和以患者为中心的心理健康AI工具，改善多语言环境下的心理健康沟通与服务。

Abstract: Mental health communication in India is linguistically fragmented, culturally
diverse, and often underrepresented in clinical NLP. Current health ontologies
and mental health resources are dominated by diagnostic frameworks centered on
English or Western culture, leaving a gap in representing patient distress
expressions in Indian languages. We propose cross-linguistic graphs of patient
stress expressions (CL-PDE), a framework for building cross-lingual mental
health ontologies through graph-based methods that capture culturally embedded
expressions of distress, align them across languages, and link them with
clinical terminology. Our approach addresses critical gaps in healthcare
communication by grounding AI systems in culturally valid representations,
allowing more inclusive and patient-centric NLP tools for mental health care in
multilingual contexts.

</details>


### [112] [Aligning Language Models with Clinical Expertise: DPO for Heart Failure Nursing Documentation in Critical Care](https://arxiv.org/abs/2510.05410)
*Junyi Fan,Li Sun,Negin Ashrafi,Kamiar Alaei,Maryam Pishgar*

Main category: cs.CL

TL;DR: 本研究使用直接偏好优化（DPO）方法微调Mistral-7B语言模型，基于MIMIC-III数据库中的8,838条心力衰竭护理记录和21,210对专家验证的偏好数据，显著提升了重症监护病房护理文档的质量。


<details>
  <summary>Details</summary>
Motivation: 重症监护病房的护理文档常存在术语不一致、表述不规范和缺乏标准化的问题，尤其在心力衰竭护理中更为突出，亟需一种能提升文档质量且符合临床专家标准的隐私保护AI辅助方法。

Method: 采用直接偏好优化（DPO）方法，在本地部署的Mistral-7B语言模型上进行训练，使用来自MIMIC-III数据库的心力衰竭护理记录及由GPT输出、模型生成和原始记录构成的专家验证偏好对数据。

Result: 在BLEU、ROUGE、BERTScore、困惑度及专家定性评估中，DPO均显著提升文档质量：BLEU提升84%（0.173至0.318），BERTScore提高7.6%（0.828至0.891），专家评分在准确性、完整性、逻辑一致性、可读性和结构清晰性上分别提升14.4、14.5、14.1、11.1和6.0分。

Conclusion: DPO能有效将轻量级临床语言模型与专家标准对齐，支持在电子病历系统中实现保护隐私的AI辅助文档生成，减轻临床文书负担并提升ICU患者安全。

Abstract: Nursing documentation in intensive care units (ICUs) provides essential
clinical intelligence but often suffers from inconsistent terminology, informal
styles, and lack of standardization, challenges that are particularly critical
in heart failure care. This study applies Direct Preference Optimization (DPO)
to adapt Mistral-7B, a locally deployable language model, using 8,838 heart
failure nursing notes from the MIMIC-III database and 21,210 preference pairs
derived from expert-verified GPT outputs, model generations, and original
notes. Evaluation across BLEU, ROUGE, BERTScore, Perplexity, and expert
qualitative assessments demonstrates that DPO markedly enhances documentation
quality. Specifically, BLEU increased by 84% (0.173 to 0.318), BERTScore
improved by 7.6% (0.828 to 0.891), and expert ratings rose across accuracy
(+14.4 points), completeness (+14.5 points), logical consistency (+14.1
points), readability (+11.1 points), and structural clarity (+6.0 points).
These results indicate that DPO can align lightweight clinical language models
with expert standards, supporting privacy-preserving, AI-assisted documentation
within electronic health record systems to reduce administrative burden and
improve ICU patient safety.

</details>


### [113] [A Lightweight Large Language Model-Based Multi-Agent System for 2D Frame Structural Analysis](https://arxiv.org/abs/2510.05414)
*Ziheng Geng,Jiachen Liu,Ran Cao,Lu Cheng,Haifeng Wang,Minghui Cheng*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型的多智能体系统，用于自动化二维框架的有限元建模，显著提升了结构工程中的自动化水平。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在多个工程领域已展现出强大的自动化潜力，但在需要几何建模、复杂推理和专业知识的结构工程有限元建模中应用仍不足，本文旨在填补这一空白。

Method: 构建一个基于Llama-3.3 70B Instruct模型的多智能体系统，将结构分析分解为多个子任务，由专门的智能体分别负责问题分析、几何生成、代码翻译、模型验证和加载条件应用。

Result: 在20个基准问题上的实验表明，该系统在多数情况下准确率超过80%，且在10次重复试验中表现稳定，性能优于Gemini-2.5 Pro和ChatGPT-4o模型。

Conclusion: 该多智能体系统有效实现了二维框架有限元建模的自动化，展示了大语言模型在结构工程中的巨大潜力。

Abstract: Large language models (LLMs) have recently been used to empower autonomous
agents in engineering, significantly improving automation and efficiency in
labor-intensive workflows. However, their potential remains underexplored in
structural engineering, particularly for finite element modeling tasks
requiring geometric modeling, complex reasoning, and domain knowledge. To
bridge this gap, this paper develops a LLM-based multi-agent system to automate
finite element modeling of 2D frames. The system decomposes structural analysis
into subtasks, each managed by a specialized agent powered by the lightweight
Llama-3.3 70B Instruct model. The workflow begins with a Problem Analysis
Agent, which extracts geometry, boundary, and material parameters from the user
input. Next, a Geometry Agent incrementally derives node coordinates and
element connectivity by applying expert-defined rules. These structured outputs
are converted into executable OpenSeesPy code by a Translation Agent and
refined by a Model Validation Agent through consistency checks. Then, a Load
Agent applies load conditions into the assembled structural model. Experimental
evaluations on 20 benchmark problems demonstrate that the system achieves
accuracy over 80% in most cases across 10 repeated trials, outperforming
Gemini-2.5 Pro and ChatGPT-4o models.

</details>


### [114] [Self-Filtered Distillation with LLMs-generated Trust Indicators for Reliable Patent Classification](https://arxiv.org/abs/2510.05431)
*Yoo Yongmin,Zhang Xu,Cao Longbing*

Main category: cs.CL

TL;DR: 提出Self-Filtered Distillation框架，通过三个无监督信任度指标过滤和加权LLM生成的专利分类推理路径，提升模型准确性、稳定性和可解释性。


<details>
  <summary>Details</summary>
Motivation: LLM生成的推理常含逻辑错误和标签不一致，直接用作监督信号会引入噪声，影响训练稳定性，尤其在专利分类等专业领域更需可靠推理监督。

Method: 提出Self-Filtered Distillation框架，利用自一致性、类别蕴涵对齐和LLM共识评分三个无监督信任指标，构建统一信任得分，对LLM生成的推理进行加权或过滤，实现推理感知的监督学习。

Result: 在USPTO-2M数据集上，该方法优于基于标签学习和传统蒸馏方法，在分类准确率、训练稳定性和解释性方面均有提升。

Conclusion: 通过信任度加权而非直接监督使用LLM推理，可有效提升专利分类性能，为专业领域中的推理增强学习提供了可靠范式。

Abstract: Large language models (LLMs) increasingly generate natural language
rationales to enhance interpretability, but these often contain logical errors,
label mismatches, and domain-specific misalignments. Directly using such
rationales as supervision risks propagating noise and undermining training
stability. To address this challenge, we introduce Self-Filtered Distillation,
a framework specifically tailored for patent classification, which treats
LLM-generated rationales as trust signals rather than ground-truth supervision.
The framework employs selective distillation guided by three unsupervised trust
metrics: (1) Self-Consistency, which measures the stability of LLM-generated
rationales across multiple generations; (2) Class Entailment Alignment, which
assesses semantic coherence with patent-specific class definitions; and (3) LLM
Agreement Scoring, which validates rationale-label plausibility. These metrics
are integrated into a unified trust score that primarily weights training
samples while optionally filtering out extremely low-trust cases, enabling
reasoning-aware supervision. Experiments on the USPTO-2M dataset, a widely used
benchmark for patent classification, show that our method outperforms
label-based learning and conventional distillation in accuracy, stability, and
interpretability, establishing a reliable paradigm for leveraging
reasoning-aware trust indicators in patent analytics.

</details>


### [115] [SimulatorArena: Are User Simulators Reliable Proxies for Multi-Turn Evaluation of AI Assistants?](https://arxiv.org/abs/2510.05444)
*Yao Dou,Michel Galley,Baolin Peng,Chris Kedzie,Weixin Cai,Alan Ritter,Chris Quirk,Wei Xu,Jianfeng Gao*

Main category: cs.CL

TL;DR: SimulatorArena是一个新基准，用于评估LLM模拟用户在数学辅导和文档创建任务中作为真实用户的可靠替代，实验表明基于用户画像的模拟器与人类判断高度一致，可作为高效、可扩展的人类评估替代方案。


<details>
  <summary>Details</summary>
Motivation: 由于人类评估成本高、耗时且难以复现，亟需可靠的自动化方法评估LLM在多轮对话中的表现，当前缺乏评估模拟用户可靠性的基准和系统研究。

Method: 构建包含909段标注的人类-LLM对话数据集SimulatorArena，涵盖数学辅导和文档创建两个任务，通过消息行为匹配度和助手评分一致性评估不同模拟器方法，并引入用户画像信息提升模拟效果。

Result: 基于用户画像的模拟器在两项任务上与人类判断的Spearman相关系数ρ达到0.7，显著优于其他方法；使用最优模拟器对18个主流LLM助手（包括GPT-5、Claude 4.1 Opus、Gemini 2.5 Pro）进行了基准测试。

Conclusion: SimulatorArena验证了条件化用户画像的模拟器可有效替代人类进行LLM评估，提供了实用且可扩展的自动化评估方案，推动了交互式LLM应用的可靠评测发展。

Abstract: Large language models (LLMs) are increasingly used in interactive
applications, and human evaluation remains the gold standard for assessing
their performance in multi-turn conversations. Since human studies are costly,
time-consuming, and hard to reproduce, recent work explores using LLMs to
simulate users for automatic assistant evaluation. However, there is no
benchmark or systematic study to evaluate whether these simulated users are
reliable stand-ins for real users. To address this, we introduce
SimulatorArena, a benchmark of 909 annotated human-LLM conversations on two
interactive tasks -- math tutoring and document creation. SimulatorArena
evaluates simulators based on how closely their messages match human behavior
and how well their assistant ratings align with human judgments. Experiments on
various simulator methods show that simulators conditioned on user profiles,
capturing traits like background and message styles, align closely with human
judgments. They reach Spearman's $\rho$ of 0.7 on both tasks, providing a
practical, scalable alternative to human evaluation. Using the best simulator
for each task, we benchmark 18 assistants, including the latest LLMs such as
GPT-5, Claude 4.1 Opus, and Gemini 2.5 Pro.

</details>


### [116] [AgentRouter: A Knowledge-Graph-Guided LLM Router for Collaborative Multi-Agent Question Answering](https://arxiv.org/abs/2510.05445)
*Zheyuan Zhang,Kaiwen Shi,Zhengqing Yuan,Zehong Wang,Tianyi Ma,Keerthiram Murugesan,Vincent Galassi,Chuxu Zhang,Yanfang Ye*

Main category: cs.CL

TL;DR: 提出 tAgentRouter 框架，将多代理问答建模为知识图谱引导的路由问题，利用异构图神经网络实现基于上下文感知的智能代理路由，提升问答性能。


<details>
  <summary>Details</summary>
Motivation: 不同代理和大模型在问答任务中各有优势，但现有代理路由方法多关注成本效率，忽略了任务中的细粒度上下文和关系结构，亟需一种能自适应选择最优代理配置的机制。

Method: 将问答实例转化为包含问题、上下文实体和代理的知识图，使用异构图神经网络（GNN）在图上传播信息，并基于实证性能信号训练模型生成任务感知的代理路由分布；结合软监督和加权聚合输出。

Result: 在多个基准和大模型主干上，tAgentRouter 一致优于单代理和集成基线方法，展现出更强的泛化能力和鲁棒性。

Conclusion: 基于知识图谱监督的多代理路由能有效捕捉代理间的互补性，为复杂问答任务提供了一种高效、自适应的协作框架。

Abstract: Large language models (LLMs) and agent-based frameworks have advanced
rapidly, enabling diverse applications. Yet, with the proliferation of models
and agentic strategies, practitioners face substantial uncertainty in selecting
the best configuration for a downstream task. Prior studies show that different
agents and backbones exhibit complementary strengths, and that larger models
are not always superior, underscoring the need for adaptive routing mechanisms.
Existing approaches to agent routing, however, often emphasize cost efficiency
while overlooking the fine-grained contextual and relational structure inherent
in QA tasks. In this paper, we propose tAgentRouter, a framework that
formulates multi-agent QA as a knowledge-graph-guided routing problem
supervised by empirical performance signals. Specifically, we convert QA
instance into a knowledge graph that jointly encodes queries, contextual
entities, and agents, and then train a heterogeneous graph neural network (GNN)
to propagate information across node types and produce task-aware routing
distributions over agents. By leveraging soft supervision and weighted
aggregation of agent outputs, AgentRouter learns principled collaboration
schemes that capture the complementary strengths of diverse agents. Extensive
experiments demonstrate that our framework consistently outperforms
single-agent and ensemble baselines, while generalizing across benchmarks and
LLM backbones. These results highlight the effectiveness and robustness of
graph-supervised multi-agent routing for question answering.

</details>


### [117] [SocialNLI: A Dialogue-Centric Social Inference Dataset](https://arxiv.org/abs/2510.05458)
*Akhil Deo,Kate Sanders,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 本文介绍了SoNLI，这是首个专注于对话中复杂社交细微差别的社会对话推理数据集，旨在评估和提升大语言模型在理解讽刺和反语等社交现象方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在理解对话中的复杂社交现象（如讽刺和反语）方面表现不佳，这限制了其作为智能助手的社交能力。因此，需要一个专门的数据集来评估和改进模型的社交推理能力。

Method: 作者构建了一个名为SocialNLI（SoNLI）的数据集，包含精心挑选的对话转录文本，这些文本聚焦于复杂的社交细微差别，并配以推断、相应的可能性评分和人工撰写的解释。通过多步反事实推理，评估大语言模型和推理模型的心智理论能力。

Result: SoNLI 数据集为评估模型在理解复杂社交现象方面的能力提供了一个新的基准。实验结果表明，当前的大语言模型在处理讽刺和反语等社交现象时仍存在明显不足。

Conclusion: SoNLI 数据集有助于识别当前模型在社交推理方面的弱点，并为未来的研究提供了方向，以提升模型在真实社交场景中的表现。

Abstract: Making theory-of-mind inferences from human dialogue is a strong indicator of
a model's underlying social abilities, which are fundamental for adept AI
assistants. However, large language and reasoning models struggle to understand
sophisticated social phenomena in transcript data, such as sarcasm and irony.
To assess the weaknesses of current models and to identify their solutions, we
introduce SocialNLI (SoNLI) -- the first social dialogue inference dataset.
SoNLI consists of a collection of dialogue transcripts hand-picked to center
complex social nuances like irony and sarcasm, paired with inferences,
corresponding likelihood scores, and human-written explanations. We explore
social inference analysis as a facet of theory-of-mind, and evaluate LLM and
reasoning model theory-of-mind ability through multi-step counterfactual
reasoning.

</details>


### [118] [TensorBLEU: Vectorized GPU-based BLEU Score Implementation for Per-Sentence In-Training Evaluation](https://arxiv.org/abs/2510.05485)
*Adam Filipek*

Main category: cs.CL

TL;DR: 本文提出了TensorBLEU，一种专为GPU加速设计的BLEU指标实现，可在训练过程中高效地对token ID进行逐句计算，显著提升了自然语言处理模型评估的速度。


<details>
  <summary>Details</summary>
Motivation: 现有的自然语言处理模型规模日益庞大，但其评估工具常成为计算瓶颈，特别是在强化学习中的训练过程中需要高效处理GPU上的token ID批次。因此，亟需一种高效的评估方法来加速研究进程。

Method: 提出了一种全新的BLEU度量实现方法TensorBLEU，该方法完全向量化以支持PyTorch中的GPU加速，并使用torch.unique构建紧凑的n-gram字典，从而避免传统哈希向量化带来的高内存消耗。

Result: 与标准CPU库NLTK相比，TensorBLEU在消费级GPU（如NVIDIA T4）上实现了超过13倍的速度提升，在数据中心级硬件（如NVIDIA A100）上更是超过了40倍的加速效果。

Conclusion: TensorBLEU将原本显著的评估瓶颈转变为训练循环中可忽略的部分，为基于强化学习的模型微调等领域的研究提供了强有力的加速工具。

Abstract: Modern natural language processing models have achieved unprecedented scale,
yet the tools for their evaluation often remain a computational bottleneck,
limiting the pace of research. This is particularly acute for in-training
evaluation metrics, such as per-sentence reward signals in Reinforcement
Learning, which must operate efficiently on batches of token IDs directly on
the GPU. In this paper, we introduce TensorBLEU, a novel implementation of the
BLEU metric designed from the ground up for this specific use case. Our
approach is fully vectorized for GPU-accelerated, per-sentence computation
within PyTorch and introduces a memory-efficient counting mechanism. By
creating a compact, batch-specific dictionary of n-grams using
\texttt{torch.unique}, our method avoids the prohibitive memory costs of
traditional hashing-based vectorization, making it practical for
large-vocabulary models. We benchmark TensorBLEU against NLTK, the standard
library for token-ID-based BLEU calculation on the CPU. Experiments show that
TensorBLEU provides speedups of over 13x on consumer-grade GPUs (NVIDIA T4) and
exceeding 40x on data-center-class hardware (NVIDIA A100). This performance
transforms a significant bottleneck into a negligible part of the training
loop. By clearly defining its role as a "Token-ID BLEU" for development
purposes and open-sourcing our implementation, we provide a powerful tool for
accelerating research in areas like RL-based model fine-tuning.

</details>


### [119] [Language Model as Planner and Formalizer under Constraints](https://arxiv.org/abs/2510.05486)
*Cassie Huang,Stuti Mohan,Ziyi Yang,Stefanie Tellex,Li Zhang*

Main category: cs.CL

TL;DR: 本文通过在现有规划基准中引入精细标注的自然语言约束，揭示了当前大语言模型在复杂和受约束环境下的规划能力被高估的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM规划研究依赖于简单通用的环境设定，可能导致规划能力被高估，并引发实际应用中的安全性问题。

Method: 构建包含四类形式化定义约束的精细标注数据，增强现有规划基准，并在4种先进推理LLM、3种形式语言、5种方法和4个数据集上进行评估。

Result: 引入约束后，模型性能普遍下降一半以上，且在问题复杂性和词汇变化上的鲁棒性显著下降。

Conclusion: 精细的环境约束能更真实地评估LLM的规划能力，凸显了当前方法在复杂现实场景中应用的局限性。

Abstract: LLMs have been widely used in planning, either as planners to generate action
sequences end-to-end, or as formalizers to represent the planning domain and
problem in a formal language that can derive plans deterministically. However,
both lines of work rely on standard benchmarks that only include generic and
simplistic environmental specifications, leading to potential overestimation of
the planning ability of LLMs and safety concerns in downstream tasks. We bridge
this gap by augmenting widely used planning benchmarks with manually annotated,
fine-grained, and rich natural language constraints spanning four formally
defined categories. Over 4 state-of-the-art reasoning LLMs, 3 formal languages,
5 methods, and 4 datasets, we show that the introduction of constraints not
only consistently halves performance, but also significantly challenges
robustness to problem complexity and lexical shift.

</details>


### [120] [LANTERN: Scalable Distillation of Large Language Models for Job-Person Fit and Explanation](https://arxiv.org/abs/2510.05490)
*Zhoutong Fu,Yihan Cao,Yi-Lin Chen,Aman Lunia,Liming Dong,Neha Saraf,Ruijie Jiang,Yun Dai,Qingquan Song,Tan Wang,Guoyao Li,Derek Koh,Haichao Wei,Zhipeng Wang,Aman Gupta,Chengming Jiang,Jianqiang Shen,Liangjie Hong,Wenjing Zhang*

Main category: cs.CL

TL;DR: LANTERN 是一种专为岗位匹配任务设计的大型语言模型知识蒸馏框架，通过多目标建模和多层次蒸馏提升效果与效率。


<details>
  <summary>Details</summary>
Motivation: 直接应用开源或微调的大型语言模型在岗位匹配和解释任务中难以产生高质量、可操作的反馈，且模型体积大导致推理延迟高，难以满足在线应用场景的需求。

Method: 提出 LANTERN 框架，包含用于分类的编码器模型和用于生成解释的解码器模型，采用多层级知识蒸馏（数据级和logit级）从强教师模型向下游模型传递知识，并结合后训练技术和提示工程优化模型适配。

Result: 实验表明，LANTERN 显著提升了岗位匹配与解释任务的指标表现，在线评估显示申请率提升 0.24%，合格申请率提升 0.28%。

Conclusion: LANTERN 能有效解决领域特定任务中大模型部署的效率与输出质量问题，适用于需要结构化输出和低延迟的工业级应用场景。

Abstract: Large language models (LLMs) have achieved strong performance across a wide
range of natural language processing tasks. However, deploying LLMs at scale
for domain specific applications, such as job-person fit and explanation in job
seeking platforms, introduces distinct challenges. At LinkedIn, the job person
fit task requires analyzing a candidate's public profile against job
requirements to produce both a fit assessment and a detailed explanation.
Directly applying open source or finetuned LLMs to this task often fails to
yield high quality, actionable feedback due to the complexity of the domain and
the need for structured outputs. Moreover, the large size of these models leads
to high inference latency and limits scalability, making them unsuitable for
online use. To address these challenges, we introduce LANTERN, a novel LLM
knowledge distillation framework tailored specifically for job person fit
tasks. LANTERN involves modeling over multiple objectives, an encoder model for
classification purpose, and a decoder model for explanation purpose. To better
distill the knowledge from a strong black box teacher model to multiple
downstream models, LANTERN incorporates multi level knowledge distillation that
integrates both data and logit level insights. In addition to introducing the
knowledge distillation framework, we share our insights on post training
techniques and prompt engineering, both of which are crucial for successfully
adapting LLMs to domain specific downstream tasks. Extensive experimental
results demonstrate that LANTERN significantly improves task specific metrics
for both job person fit and explanation. Online evaluations further confirm its
effectiveness, showing measurable gains in job seeker engagement, including a
0.24\% increase in apply rate and a 0.28\% increase in qualified applications.

</details>


### [121] [Prototype-Based Dynamic Steering for Large Language Models](https://arxiv.org/abs/2510.05498)
*Ceyhun Efe Kayan,Li Zhang*

Main category: cs.CL

TL;DR: 提出了一种无需修改指令或微调的动态引导方法PDS，通过构建推理原型来增强大语言模型的推理能力，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有大模型推理增强方法依赖显式指令或静态引导，缺乏自适应性，本文旨在实现无需指令干预的动态推理增强。

Method: 在推理时，通过聚类思维链（CoT）与中性提示下的激活差异，构建‘推理原型’，并利用输入隐藏状态在这些原型上的投影生成实例特定的引导向量。

Result: 在GSM8K、AQuA-RAT和BIG-Bench等任务上，PDS在无需微调或提示工程的情况下持续提升准确率，且在抑制CoT时仍保持增益。

Conclusion: 基于原型的动态引导是一种轻量、有效的推理增强方法，能够强化模型内在的推理机制，为训练时方法提供了可行替代方案。

Abstract: Despite impressive breadth, LLMs still rely on explicit reasoning
instructions or static, one-fits-all steering methods, leaving a gap for
adaptive, instruction-free reasoning amplification. We present Prototype-Based
Dynamic Steering (PDS), a test-time method that amplifies large language model
(LLM) reasoning without adding or altering instructions. We introduce
"reasoning prototypes" by clustering activation differences between
Chain-of-Thought (CoT) and neutral prompts. At inference, an input's hidden
state is projected onto these prototypes to form an instance-specific steering
vector. Evaluated on GSM8K, AQuA-RAT, and BIG-Bench tasks, PDS consistently
improves accuracy without fine-tuning or prompt engineering. Notably, the gains
persist even when CoT is explicitly suppressed to improve cost-efficiency,
indicating that the intervention strengthens latent reasoning processes rather
than inducing a superficial behavioral shift. These results position dynamic,
prototype-guided steering as a lightweight alternative to training-time
approaches for enhancing LLM reasoning.

</details>


### [122] [CAM: A Constructivist View of Agentic Memory for LLM-Based Reading Comprehension](https://arxiv.org/abs/2510.05520)
*Rui Li,Zeyu Zhang,Xiaohe Bo,Zihang Tian,Xu Chen,Quanyu Dai,Zhenhua Dong,Ruiming Tang*

Main category: cs.CL

TL;DR: 本文提出了一种受皮亚杰建构主义理论启发的建构主义代理记忆（CAM），用于增强大语言模型在长文本阅读理解中的记忆能力，通过结构化、灵活适应和动态调整的内存模块，在多项任务中实现了性能与效率的双重提升。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在处理长文档时面临信息过载问题，缺乏系统性的记忆模块设计原则，因此需要一种结构清晰、可扩展的记忆机制来支持自主阅读代理的有效理解。

Method: 借鉴皮亚杰的建构主义理论，提出具备结构化图式、灵活同化和动态顺应三大特性的代理记忆框架，并实现CAM原型系统，采用增量重叠聚类算法构建层次化记忆结构，支持在线批处理集成和基于查询的联想式检索。

Result: CAM在问答、基于查询的摘要和声明验证等长文本理解任务中，相比现有方法在性能和效率方面均表现出优势，能够更高效地激活相关信息以生成上下文响应。

Conclusion: 基于建构主义理论的记忆设计为大语言模型提供了系统性记忆架构的新范式，CAM展示了构建高效、动态、结构化记忆系统的可行性，推动LLM向自主阅读代理迈进。

Abstract: Current Large Language Models (LLMs) are confronted with overwhelming
information volume when comprehending long-form documents. This challenge
raises the imperative of a cohesive memory module, which can elevate vanilla
LLMs into autonomous reading agents. Despite the emergence of some heuristic
approaches, a systematic design principle remains absent. To fill this void, we
draw inspiration from Jean Piaget's Constructivist Theory, illuminating three
traits of the agentic memory -- structured schemata, flexible assimilation, and
dynamic accommodation. This blueprint forges a clear path toward a more robust
and efficient memory system for LLM-based reading comprehension. To this end,
we develop CAM, a prototype implementation of Constructivist Agentic Memory
that simultaneously embodies the structurality, flexibility, and dynamicity. At
its core, CAM is endowed with an incremental overlapping clustering algorithm
for structured memory development, supporting both coherent hierarchical
summarization and online batch integration. During inference, CAM adaptively
explores the memory structure to activate query-relevant information for
contextual response, akin to the human associative process. Compared to
existing approaches, our design demonstrates dual advantages in both
performance and efficiency across diverse long-text reading comprehension
tasks, including question answering, query-based summarization, and claim
verification.

</details>


### [123] [KEO: Knowledge Extraction on OMIn via Knowledge Graphs and RAG for Safety-Critical Aviation Maintenance](https://arxiv.org/abs/2510.05524)
*Kuangshi Ai,Jonathan A. Karr Jr,Meng Jiang,Nitesh V. Chawla,Chaoli Wang*

Main category: cs.CL

TL;DR: KEO是一个基于知识图谱的大语言模型框架，用于安全关键领域的知识提取与推理，相比传统文本分块检索，在全局态势感知和系统级洞察方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 在安全关键场景中，传统检索增强生成（RAG）方法局限于局部信息检索，难以支持全局推理和系统级理解，因此需要一种能整合结构化知识以提升推理能力的框架。

Method: 提出KEO框架，利用OMIn数据集构建问答基准，通过构建结构化知识图谱（KG），并将其集成到检索增强生成（RAG）流程中，实现跨数据集的连贯推理。使用本地部署的大语言模型（如Gemma-3、Phi-4、Mistral-Nemo）进行实验，并采用更强模型（如GPT-4o、Llama-3.3）作为评估裁判。

Result: KEO显著提升了全局态势感知能力，能够揭示数据中的模式和系统级洞察，而传统文本分块RAG在需要局部检索的细粒度任务中仍具优势。

Conclusion: 知识图谱增强的大语言模型在安全敏感、领域特定的问答任务中具有巨大潜力，尤其适用于高风险决策场景中的复杂推理。

Abstract: We present Knowledge Extraction on OMIn (KEO), a domain-specific knowledge
extraction and reasoning framework with large language models (LLMs) in
safety-critical contexts. Using the Operations and Maintenance Intelligence
(OMIn) dataset, we construct a QA benchmark spanning global sensemaking and
actionable maintenance tasks. KEO builds a structured Knowledge Graph (KG) and
integrates it into a retrieval-augmented generation (RAG) pipeline, enabling
more coherent, dataset-wide reasoning than traditional text-chunk RAG. We
evaluate locally deployable LLMs (Gemma-3, Phi-4, Mistral-Nemo) and employ
stronger models (GPT-4o, Llama-3.3) as judges. Experiments show that KEO
markedly improves global sensemaking by revealing patterns and system-level
insights, while text-chunk RAG remains effective for fine-grained procedural
tasks requiring localized retrieval. These findings underscore the promise of
KG-augmented LLMs for secure, domain-specific QA and their potential in
high-stakes reasoning.

</details>


### [124] [H1B-KV: Hybrid One-Bit Caches for Memory-Efficient Large Language Model Inference](https://arxiv.org/abs/2510.05529)
*Harshil Vejendla*

Main category: cs.CL

TL;DR: 提出了一种名为H1B-KV的混合一键值缓存压缩方案，通过1比特键值草图和4比特值量化，大幅减少大语言模型长上下文推理的内存占用，实现70倍压缩并保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型自回归解码过程中需缓存不断增长的键值对，导致长上下文推理成为内存瓶颈；现有压缩方法往往不完整，存在组件未压缩或上下文丢失问题。

Method: 提出H1B-KV，对键向量使用1比特二值草图表示以支持硬件友好的按位注意力计算，同时对值向量采用4比特量化，形成一体化的键值缓存压缩方案，并结合轻量微调以恢复性能。

Result: 在70亿参数模型上实现8k上下文仅需60MB以下缓存内存，压缩达70倍；在困惑度、数学推理（GSM8K）、多任务理解（MMLU）和代码生成（HumanEval）等任务上达到全精度性能，优于KIVI、SparseLLM和Loki等现有方法。

Conclusion: H1B-KV是一种高效且完整的键值缓存压缩方案，显著提升内存受限环境下大模型的部署能力，兼顾性能与压缩率。

Abstract: Autoregressive decoding in large language models (LLMs) requires caching a
growing list of past key-value (KV) pairs, making long-context inference a
memory-bound problem. While recent methods have explored quantizing the cache,
evicting tokens, or using binary sketches for keys (e.g., Loki), these
approaches often provide an incomplete solution by leaving one component (like
values) uncompressed or by discarding context information. This paper
introduces the Hybrid One-Bit KV Cache (H1B-KV), a comprehensive compression
scheme that radically reduces memory usage without sacrificing context. H1B-KV
represents each key vector using a 1-bit binary sketch, enabling
hardware-friendly bitwise attention, and further compresses value vectors using
4-bit quantization. This holistic, hybrid approach allows a 7-billion parameter
LLM to handle an 8k-token context with under 60 MB of cache memory - a 70x
reduction. We demonstrate that after a lightweight finetuning, H1B-KV matches
full-precision performance not only on perplexity benchmarks but also on
complex downstream tasks like mathematical reasoning (GSM8K), multi-task
understanding (MMLU), and code generation (HumanEval). Our results show H1B-KV
significantly outperforms leading quantization (KIVI), token eviction
(SparseLLM), and key-only sketching (Loki) methods in quality-per-byte,
establishing it as a robust solution for deploying LLMs in memory-constrained
environments.

</details>


### [125] [On the Role of Difficult Prompts in Self-Play Preference Optimization](https://arxiv.org/abs/2510.05534)
*Yao Xiao,Jung-jae Kim,Roy Ka-wei Lee,Lidong Bing*

Main category: cs.CL

TL;DR: 研究发现，在自博弈偏好优化中，困难提示会显著降低语言模型的优化性能，而选择性地移除部分困难提示可提升整体表现。


<details>
  <summary>Details</summary>
Motivation: 尽管提示在自博弈偏好优化中起核心作用，但其难度对优化效果的影响尚未被充分研究。本文旨在探究不同难度提示如何影响该过程。

Method: 使用采样响应的平均奖励作为提示难度的代理指标，分析困难与简单提示在自博弈偏好优化中的表现差异，并探索模型容量和去噪策略的影响。

Result: 困难提示导致更差的优化性能，且加入困难提示会轻微降低整体表现；模型容量增大时，难易提示的性能差距缩小；选择性移除部分困难提示可提升最终性能。

Conclusion: 提示难度显著影响自博弈偏好优化效果，合理筛选提示可优化训练效果，为实际应用提供重要启示。

Abstract: Self-play preference optimization has emerged as a prominent paradigm for
aligning large language models (LLMs). It typically involves a language model
to generate on-policy responses for prompts and a reward model (RM) to guide
the selection of chosen and rejected responses, which can be further trained
with direct preference optimization (DPO). However, the role of prompts remains
underexplored, despite being a core component in this pipeline. In this work,
we investigate how prompts of varying difficulty influence self-play preference
optimization. We first use the mean reward of $N$ sampled responses of a prompt
as a proxy for its difficulty. We find that difficult prompts exhibit
substantially inferior self-play optimization performance in comparison to easy
prompts for language models. Moreover, incorporating difficult prompts into
training fails to enhance overall performance and, in fact, leads to slight
degradation compared to training on easy prompts alone. We also observe that
the performance gap between difficult and easy prompts closes as the model
capacity increases, suggesting that difficulty interacts with the model
capacity. Building on these findings, we explore strategies to mitigate the
negative effect of difficult prompts on final performance. We demonstrate that
selectively removing an appropriate portion of challenging prompts enhances
overall self-play performance, while also reporting failed attempts and lessons
learned.

</details>


### [126] [Activation-Informed Pareto-Guided Low-Rank Compression for Efficient LLM/VLM](https://arxiv.org/abs/2510.05544)
*Ryan Solgi,Parsa Madinei,Jiayi Tian,Rupak Swaminathan,Jing Liu,Nathan Susanj,Zheng Zhang*

Main category: cs.CL

TL;DR: 提出了一种新的低秩压缩框架PGSVD，通过帕累托引导的奇异值分解实现对大语言模型和视觉语言模型的零样本压缩，在保持更高精度的同时实现推理加速。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）和视觉语言模型（VLM）在部署中面临巨大的内存和计算挑战，现有的压缩方法缺乏理论支持，尤其是对层间激活误差的理论分析存在空白。

Method: 首先通过层激活误差上限网络损失变化，填补理论空白；然后将低秩压缩建模为双目标优化问题，证明单一均匀容差可导出帕累托最优的异构秩分布；基于此提出PGSVD方法，结合帕累托引导的秩选择和交替最小二乘实现零样本压缩。

Result: 在LLM和VLM上应用PGSVD，相比现有方法在相同压缩率下实现了更高的准确性以及更快的推理速度。

Conclusion: PGSVD是一种理论驱动的、激活感知的低秩压缩方法，能够有效平衡模型压缩与性能保持，适用于大规模多模态模型的高效部署。

Abstract: Large language models (LLM) and vision-language models (VLM) have achieved
state-of-the-art performance, but they impose significant memory and computing
challenges in deployment. We present a novel low-rank compression framework to
address this challenge. First, we upper bound the change of network loss via
layer-wise activation-based compression errors, filling a theoretical gap in
the literature. We then formulate low-rank model compression as a bi-objective
optimization and prove that a single uniform tolerance yields surrogate
Pareto-optimal heterogeneous ranks. Based on our theoretical insights, we
propose Pareto-Guided Singular Value Decomposition (PGSVD), a zero-shot
pipeline that improves activation-aware compression via Pareto-guided rank
selection and alternating least-squares implementation. We apply PGSVD to both
LLM and VLM, showing better accuracy at the same compression levels and
inference speedup.

</details>


### [127] [Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for Academic Presentations](https://arxiv.org/abs/2510.05571)
*Chengzhi Liu,Yuzhe Yang,Kaiwen Zhou,Zhen Zhang,Yue Fan,Yannan Xie,Peng Qi,Xin Eric Wang*

Main category: cs.CL

TL;DR: 提出EvoPresent，一个通过虚拟角色实现连贯叙述、审美感知设计和真实演示的自我改进代理框架，并引入PresAesth多任务强化学习模型与EvoPresent Benchmark评估基准，推动学术演示自动化生成。


<details>
  <summary>Details</summary>
Motivation: 现有学术论文推广的自动化方法在叙事连贯性、审美质量和自我调节能力方面存在不足，缺乏有效的评估机制阻碍了优化。因此需要一种可评估且能自我提升的生成框架。

Method: 提出EvoPresent框架，结合虚拟角色生成演示内容；设计PresAesth多任务强化学习模型进行审美评分、缺陷修正和比较反馈；构建EvoPresent Benchmark，包含650篇顶级AI会议论文的多模态数据和2000张幻灯片对，用于系统评估生成质量与审美意识。

Result: 实验表明：高质量反馈对代理自我改进至关重要；自动化生成在视觉设计与内容构建间存在权衡；多任务RL在审美任务中展现出更强泛化能力。

Conclusion: EvoPresent通过整合审美感知与自我优化机制，显著提升学术演示生成的质量与自主进化能力，为科研传播提供了可评估、可迭代的新范式。

Abstract: The promotion of academic papers has become an important means of enhancing
research visibility. However, existing automated methods struggle limited
storytelling, insufficient aesthetic quality, and constrained self-adjustment,
making it difficult to achieve efficient and engaging dissemination. At the
heart of those challenges is a simple principle: \emph{there is no way to
improve it when you cannot evaluate it right}. To address this, we introduce
\textbf{EvoPresent}, a self-improvement agent framework that unifies coherent
narratives, aesthetic-aware designs, and realistic presentation delivery via
virtual characters. Central to EvoPresent is \textbf{PresAesth}, a multi-task
reinforcement learning (RL) aesthetic model that provides reliable aesthetic
scoring, defect adjustment, and comparative feedback, enabling iterative
self-improvement even under limited aesthetic training data. To systematically
evaluate the methods, we introduce \textbf{EvoPresent Benchmark}, a
comprehensive benchmark comprising: \textit{Presentation Generation Quality},
built on 650 top-tier AI conference papers with multimodal resources (slides,
videos and scripts) to assess both content and design; and \textit{Aesthetic
Awareness}, consisting of 2,000 slide pairs with varying aesthetic levels,
supporting joint training and evaluation on scoring, defect adjustment, and
comparison. Our findings highlight that (i) High-quality feedback is essential
for agent self-improvement, while initial capability alone does not guarantee
effective self-correction. (ii) Automated generation pipelines exhibit a
trade-off between visual design and content construction. (iii) Multi-task RL
training shows stronger generalization in aesthetic awareness tasks.

</details>


### [128] [Mission Impossible: Feedback-Guided Dynamic Interactive Planning for Improving Reasoning on LLMs](https://arxiv.org/abs/2510.05577)
*Dong Yan,Gaochen Wu,Bowen Zhou*

Main category: cs.CL

TL;DR: 提出了一种名为反馈引导的动态交互规划（FGDIP）的新框架，通过动态和自适应的信息探索策略，显著提升了大语言模型在开放域多跳推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有语言代理在处理开放域多跳推理任务时，因依赖固定动作序列而难以有效检索大量信息，导致推理能力受限。

Method: FGDIP框架首先识别问题中的关键实体作为推理起点，结合历史错误分析和实时反馈动态生成和优化推理子节点，并融合深度优先搜索与创新的节点生成技术，实现对搜索空间的动态扩展与系统收敛。

Result: 在HotpotQA和StrategyQA数据集上，FGDIP分别取得了54.47%和70.05%的F1分数，超过最佳基线模型5.03%和7.25%。

Conclusion: FGDIP通过动态调整推理策略，有效提升了语言模型在复杂开放域多跳推理任务中的准确性和适应性，展现出较强的通用潜力。

Abstract: Recent advancements in language agents have led to significant improvements
in multi-hop reasoning tasks. However, existing approaches often struggle with
handling open-domain problems, which require massive information retrieval due
to their reliance on a fixed sequence of actions. To address this, we propose
Feedback-Guided Dynamic Interactive Planning (FGDIP), a novel framework
tailored to enhance reasoning in LLMs by utilizing dynamic and adaptive
strategies for information exploration in open-domain multi-hop reasoning
tasks. Our approach begins by identifying key entities relevant to the problem,
which serve as the initial nodes in the reasoning process. From these initial
nodes, we then generate reasoning child nodes with the process being refined
through a combination of historical error analysis and real-time feedback,
which allows the framework to dynamically adjust and optimize its reasoning
strategies. By integrating depth-first search with an innovative node
generation technique, our framework adapts based on both prior error paths and
concurrently generated nodes at the same hierarchical level. This dynamic
strategy effectively expands the search space while ensuring the reasoning
process systematically converges toward accurate solutions. Experimental
results show that FGDIP achieved up to 54.47% F1 score on the HotpotQA dataset
and 70.05% on the StrategyQA dataset, surpassing the best baseline by 5.03% and
7.25% respectively, highlighting its versatility and potential to enhance
language agents in multi-hop reasoning tasks.

</details>


### [129] [A Goal Without a Plan Is Just a Wish: Efficient and Effective Global Planner Training for Long-Horizon Agent Tasks](https://arxiv.org/abs/2510.05608)
*Shuzheng Si,Haozhe Zhao,Kangyang Luo,Gang Chen,Fanchao Qi,Minjia Zhang,Baobao Chang,Maosong Sun*

Main category: cs.CL

TL;DR: 提出EAGLET，一种无需人工干预的高效规划器训练方法，通过两步训练提升代理在长程任务中的全局规划能力，显著降低成本并取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的代理在长时程任务中缺乏全局规划，导致盲目试错和幻觉动作，难以有效完成复杂任务。

Method: 提出一种两阶段训练方法：首先利用同源共识过滤策略从高级LLM生成高质量计划并进行微调冷启动；然后采用基于规则的强化学习，结合执行器能力增益奖励进一步优化规划器。

Result: 在三个长时程代理任务上实验表明，使用EAGLET训练的规划器显著优于现有方法，达到最先进水平，且训练成本降低8倍。

Conclusion: EAGLET提供了一种高效、无需人工标注和额外数据的规划器训练方案，有效增强代理的全局规划能力，适用于不同难度的任务。

Abstract: Agents based on large language models (LLMs) struggle with brainless
trial-and-error and generating hallucinatory actions due to a lack of global
planning in long-horizon tasks. In this paper, we introduce a plan-and-execute
framework and propose EAGLET, an efficient and effective planner training
method to enhance the executor agent's planning abilities without human effort.
Specifically, we train a plug-and-play global planner through a two-step
process: we first synthesize high-quality plans from an advanced LLM using our
proposed homologous consensus filtering strategy, and apply fine-tuning as a
cold start. Moreover, we further improve the planner with a rule-based
reinforcement learning stage using a novel executor capability gain reward,
ensuring it can handle task instructions of varying difficulty. Experiments on
three long-horizon agent tasks show that executor agents equipped with our
planner outperform existing methods, achieving new state-of-the-art
performance. Meanwhile, EAGLET reduces training costs by 8x compared to
RL-based baselines, and it does not require manual effort or extra training
data, offering an efficient and effective solution.

</details>


### [130] [MADIAVE: Multi-Agent Debate for Implicit Attribute Value Extraction](https://arxiv.org/abs/2510.05611)
*Wei-Chieh Huang,Cornelia Caragea*

Main category: cs.CL

TL;DR: 本文提出了一种基于多智能体辩论框架的隐式属性值提取方法，通过多个多模态大语言模型（MLLM）智能体之间的迭代辩论，显著提升了电商场景中多模态数据下隐式属性推断的准确性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 隐式属性值提取对电商产品表示至关重要，但由于多维数据的复杂性和视觉-文本理解之间的鸿沟，现有MLLM在该任务上仍面临挑战。

Method: 提出\textsc{\modelname}框架，采用多个MLLM智能体进行多轮辩论，通过相互验证和更新推断结果，实现隐式AVE任务的迭代优化。

Result: 在ImplicitAVE数据集上的实验表明，即使是少数几轮辩论也能显著提升准确率，尤其对初始性能较差的属性提升明显；不同配置的辩论策略均展现出有效性。

Conclusion: 多智能体辩论策略能有效克服单智能体方法的局限性，为多模态电商中的隐式属性提取提供了可扩展的解决方案。

Abstract: Implicit Attribute Value Extraction (AVE) is essential for accurately
representing products in e-commerce, as it infers lantent attributes from
multimodal data. Despite advances in multimodal large language models (MLLMs),
implicit AVE remains challenging due to the complexity of multidimensional data
and gaps in vision-text understanding. In this work, we introduce
\textsc{\modelname}, a multi-agent debate framework that employs multiple MLLM
agents to iteratively refine inferences. Through a series of debate rounds,
agents verify and update each other's responses, thereby improving inference
performance and robustness. Experiments on the ImplicitAVE dataset demonstrate
that even a few rounds of debate significantly boost accuracy, especially for
attributes with initially low performance. We systematically evaluate various
debate configurations, including identical or different MLLM agents, and
analyze how debate rounds affect convergence dynamics. Our findings highlight
the potential of multi-agent debate strategies to address the limitations of
single-agent approaches and offer a scalable solution for implicit AVE in
multimodal e-commerce.

</details>


### [131] [The African Languages Lab: A Collaborative Approach to Advancing Low-Resource African NLP](https://arxiv.org/abs/2510.05644)
*Sheriff Issaka,Keyi Wang,Yinka Ajibola,Oluwatumininu Samuel-Ipaye,Zhaoyi Zhang,Nicte Aguillon Jimenez,Evans Kofi Agyei,Abraham Lin,Rohan Ramachandran,Sadick Abdul Mumin,Faith Nchifor,Mohammed Shuraim,Lieqi Liu,Erick Rosas Gonzalez,Sylvester Kpei,Jemimah Osei,Carlene Ajeneza,Persis Boateng,Prisca Adwoa Dufie Yeboah,Saadia Gabriel*

Main category: cs.CL

TL;DR: 非洲语言在现代自然语言处理技术中严重被忽视，本文提出非洲语言实验室（All Lab）研究计划，通过系统性的数据收集、模型开发和本地能力建设，构建了涵盖40种语言的大规模多模态数据集，并在多个NLP任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 非洲语言占全球语言近三分之一，但88%被计算语言学严重忽视或完全忽略，亟需系统性支持以弥补NLP技术在该地区的鸿沟。

Method: 建立质量可控的数据收集管道，构建大规模多语言文本与语音数据集；通过微调模型进行实验验证；并实施结构化研究培训项目以培养本地研究人才。

Result: 发布了包含40种非洲语言、190亿词元和12,628小时对齐语音的数据集；在31种语言上平均提升+23.69 ChrF++、+0.33 COMET和+15.34 BLEU；部分语言性能与Google Translate相当。

Conclusion: 系统性的数据建设、模型优化与本地人才培养可有效推动非洲语言NLP发展，为低资源语言的技术进步提供了可持续框架。

Abstract: Despite representing nearly one-third of the world's languages, African
languages remain critically underserved by modern NLP technologies, with 88\%
classified as severely underrepresented or completely ignored in computational
linguistics. We present the African Languages Lab (All Lab), a comprehensive
research initiative that addresses this technological gap through systematic
data collection, model development, and capacity building. Our contributions
include: (1) a quality-controlled data collection pipeline, yielding the
largest validated African multi-modal speech and text dataset spanning 40
languages with 19 billion tokens of monolingual text and 12,628 hours of
aligned speech data; (2) extensive experimental validation demonstrating that
our dataset, combined with fine-tuning, achieves substantial improvements over
baseline models, averaging +23.69 ChrF++, +0.33 COMET, and +15.34 BLEU points
across 31 evaluated languages; and (3) a structured research program that has
successfully mentored fifteen early-career researchers, establishing
sustainable local capacity. Our comparative evaluation against Google Translate
reveals competitive performance in several languages while identifying areas
that require continued development.

</details>


### [132] [Code-Switching In-Context Learning for Cross-Lingual Transfer of Large Language Models](https://arxiv.org/abs/2510.05678)
*Haneul Yoo,Jiho Jin,Kyunghyun Cho,Alice Oh*

Main category: cs.CL

TL;DR: 提出一种名为code-switching in-context learning (CSICL) 的提示方法，通过在示范和指令中从目标语言逐步切换到英语，有效缓解大语言模型在多语言推理中的翻译障碍，提升跨语言性能，尤其在低资源语言中表现显著。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽具多语言能力，但其推理过程依赖英语作为潜在表示，形成翻译障碍，导致非英语语言性能下降。现有跨语言上下文学习方法多使用单语示范，难以克服此问题。因此，需要一种能显式引导模型跨语言推理的新方法。

Method: 提出CSICL方法，在上下文学习中采用代码转换（code-switching）策略，即在示范和指令中从目标语言逐步过渡到英语，作为隐式的语言桥梁，引导模型在英语中进行潜在推理，增强跨语言对齐。

Result: 在4个大模型、6个数据集和10种语言上的实验表明，CSICL在目标语言和未见语言上分别平均提升3.1和1.9个百分点；在低资源设置下，提升达14.7%和5.3%，显著优于现有X-ICL基线。

Conclusion: CSICL通过有控制的代码转换有效缓解翻译障碍，是一种原理清晰且鲁棒的跨语言推理方法，有助于实现更公平、高效的大语言模型多语言系统。

Abstract: While large language models (LLMs) exhibit strong multilingual abilities,
their reliance on English as latent representations creates a translation
barrier, where reasoning implicitly depends on internal translation into
English. When this process fails, performance in non-English languages
deteriorates sharply, limiting the inclusiveness of LLM-based applications.
Existing cross-lingual in-context learning (X-ICL) methods primarily leverage
monolingual demonstrations, often failing to mitigate this barrier and instead
reinforcing it. In this work, we introduce code-switching in-context learning
(CSICL), a simple yet effective prompting strategy that progressively
transitions from a target language to English within demonstrations and
instruction to facilitate their latent reasoning in English. By explicitly
scaffolding the reasoning process through controlled code-switching, CSICL acts
as an implicit linguistic bridge that enhances cross-lingual alignment and
reduces reliance on the translation barrier. We conduct extensive experiments
across 4 LLMs, 6 datasets, and 10 languages, spanning both knowledge-intensive
and reasoning-oriented domains. Our results demonstrate that CSICL consistently
outperforms X-ICL baselines, achieving gains of 3.1%p and 1.9%p in both target
and unseen languages, respectively. The improvement is even more pronounced in
low-resource settings, with gains of 14.7% in target and 5.3% in unseen
languages. These findings establish code-switching as a principled and robust
approach for overcoming the translation barrier during inference, moving LLMs
toward more equitable and effective multilingual systems.

</details>


### [133] [DecEx-RAG: Boosting Agentic Retrieval-Augmented Generation with Decision and Execution Optimization via Process Supervision](https://arxiv.org/abs/2510.05691)
*Yongqi Leng,Yikun Lei,Xikai Liu,Meizhi Zhong,Bojian Xiong,Yurong Zhang,Yan Gao,Yi Wu,Yao Hu,Deyi Xiong*

Main category: cs.CL

TL;DR: DecEx-RAG通过将检索增强生成建模为包含决策与执行的马尔可夫决策过程，并引入高效剪枝策略，显著提升了复杂任务下的自主分解、动态检索与答案生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于结果监督的强化学习在Agentic RAG中面临探索效率低、奖励信号稀疏和全局反馈模糊的问题，需更细粒度的过程监督与优化机制。

Method: 将RAG建模为包含决策与执行的马尔可夫决策过程（MDP），并通过过程级策略优化和高效剪枝策略改进数据扩展效率。

Result: 在六个数据集上平均绝对性能提升6.2%，剪枝策略使数据构建效率提高近6倍。

Conclusion: DecEx-RAG在过程监督的RAG训练中实现了更高效的数据利用和更强的自主推理能力，为复杂任务处理提供了有效解决方案。

Abstract: Agentic Retrieval-Augmented Generation (Agentic RAG) enhances the processing
capability for complex tasks through dynamic retrieval and adaptive workflows.
Recent advances (e.g., Search-R1) have shown that outcome-supervised
reinforcement learning demonstrate strong performance. However, this approach
still suffers from inefficient exploration, sparse reward signals, and
ambiguous global reward feedback. To address these challenges, we propose
DecEx-RAG, which models RAG as a Markov Decision Process (MDP) incorporating
decision-making and execution, while introducing an efficient pruning strategy
to optimize data expansion. Through comprehensive process-level policy
optimization, DecEx-RAG significantly enhances the autonomous task
decomposition, dynamic retrieval, and high-quality answer generation
capabilities of large language models (LLMs). Experiments show that DecEx-RAG
achieves an average absolute performance improvement of $6.2\%$ across six
datasets, significantly outperforming existing baselines. Moreover, the pruning
strategy improves data construction efficiency by nearly $6 \times$, providing
an efficient solution for process-supervised RAG training. The code is
available at https://github.com/sdsxdxl/DecEx-RAG.

</details>


### [134] [Adaptive and Multi-Source Entity Matching for Name Standardization of Astronomical Observation Facilities](https://arxiv.org/abs/2510.05744)
*Liza Fretel,Baptiste Cecconi,Laura Debisschop*

Main category: cs.CL

TL;DR: 本研究提出一种多源映射方法，整合天文观测设施信息，利用NLP技术和大语言模型生成标准化的实体同义词集，支持虚拟天文台数据互操作。


<details>
  <summary>Details</summary>
Motivation: 天文领域存在多个语义资源，实体命名不一致，缺乏统一标准，导致数据整合困难，需构建可互操作、符合FAIR原则的多源映射。

Method: 从八个语义资源中提取实体，利用标签、定义、波段、资助机构等多属性，结合词袋、序列和表面特征等NLP方法计算匹配分数，并使用大语言模型对映射建议进行验证与解释。

Result: 生成了标准化的多源同义词集，每个多义词集合仅保留一个标准标签，映射结果具备可解释性与合理性。

Conclusion: 该方法有效整合多源天文设施数据，支持名称解析服务，并将集成至IVOA词汇表和OntoPortal-Astro平台，推动天文语义互操作。

Abstract: This ongoing work focuses on the development of a methodology for generating
a multi-source mapping of astronomical observation facilities. To compare two
entities, we compute scores with adaptable criteria and Natural Language
Processing (NLP) techniques (Bag-of-Words approaches, sequential approaches,
and surface approaches) to map entities extracted from eight semantic
artifacts, including Wikidata and astronomy-oriented resources. We utilize
every property available, such as labels, definitions, descriptions, external
identifiers, and more domain-specific properties, such as the observation
wavebands, spacecraft launch dates, funding agencies, etc. Finally, we use a
Large Language Model (LLM) to accept or reject a mapping suggestion and provide
a justification, ensuring the plausibility and FAIRness of the validated
synonym pairs. The resulting mapping is composed of multi-source synonym sets
providing only one standardized label per entity. Those mappings will be used
to feed our Name Resolver API and will be integrated into the International
Virtual Observatory Alliance (IVOA) Vocabularies and the OntoPortal-Astro
platform.

</details>


### [135] [Diversity Is All You Need for Contrastive Learning: Spectral Bounds on Gradient Magnitudes](https://arxiv.org/abs/2510.05767)
*Peter Ochieng*

Main category: cs.CL

TL;DR: 提出了一种基于谱分析的非渐近性方法来约束InfoNCE梯度范数，并设计了谱感知批量选择策略，显著提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解和优化对比学习中的梯度行为，特别是InfoNCE损失下的梯度稳定性与收敛速度，需要理论指导的批量采样和预处理方法。

Method: 通过分析对齐性、温度系数和批量谱特性，推导出非渐近的谱界；引入有效秩 $R_{\mathrm{eff}}$ 作为各向异性的代理，设计谱感知批量选择算法（如Greedy-64）和批内白化方法。

Result: 在ImageNet和CIFAR-10上，Greedy-64相比随机采样将达到67.5% top-1准确率的时间减少了15%（相对加速）；批内白化使梯度方差降低 $1.37\times$，符合理论上界。

Conclusion: 谱分析为对比学习提供了理论支持，谱感知的批量构建和白化预处理能有效提升训练效率与梯度稳定性。

Abstract: We derive non-asymptotic spectral bands that bound the squared InfoNCE
gradient norm via alignment, temperature, and batch spectrum, recovering the
\(1/\tau^{2}\) law and closely tracking batch-mean gradients on synthetic data
and ImageNet. Using effective rank \(R_{\mathrm{eff}}\) as an anisotropy proxy,
we design spectrum-aware batch selection, including a fast greedy builder. On
ImageNet-100, Greedy-64 cuts time-to-67.5\% top-1 by 15\% vs.\ random (24\%
vs.\ Pool--P3) at equal accuracy; CIFAR-10 shows similar gains. In-batch
whitening promotes isotropy and reduces 50-step gradient variance by
\(1.37\times\), matching our theoretical upper bound.

</details>


### [136] [InforME: Improving Informativeness of Abstractive Text Summarization With Informative Attention Guided by Named Entity Salience](https://arxiv.org/abs/2510.05769)
*Jianbin Shen,Christy Jie Liang,Junyu Xuan*

Main category: cs.CL

TL;DR: 提出了一种基于最优传输和累积联合熵减少的新方法，以提高抽象文本摘要的信息量，在CNN/Daily Mail和XSum数据集上取得了优于先前方法的结果。


<details>
  <summary>Details</summary>
Motivation: 提高抽象文本摘要的信息量，以更有效地处理大数据时代的长文本数据。

Method: 采用基于最优传输的 informative attention 方法和针对命名实体的累积联合熵减少方法，增强摘要的信息显著性。

Result: 在CNN/Daily Mail数据集上ROUGE得分更高，在XSum上表现具有竞争力，人工评估也显示摘要信息量更优。

Conclusion: 所提方法能有效提升摘要的信息性和质量，具有实际应用潜力。

Abstract: Abstractive text summarization is integral to the Big Data era, which demands
advanced methods to turn voluminous and often long text data into concise but
coherent and informative summaries for efficient human consumption. Despite
significant progress, there is still room for improvement in various aspects.
One such aspect is to improve informativeness. Hence, this paper proposes a
novel learning approach consisting of two methods: an optimal transport-based
informative attention method to improve learning focal information in reference
summaries and an accumulative joint entropy reduction method on named entities
to enhance informative salience. Experiment results show that our approach
achieves better ROUGE scores compared to prior work on CNN/Daily Mail while
having competitive results on XSum. Human evaluation of informativeness also
demonstrates the better performance of our approach over a strong baseline.
Further analysis gives insight into the plausible reasons underlying the
evaluation results.

</details>


### [137] [Mixture of Neuron Experts](https://arxiv.org/abs/2510.05781)
*Runxi Cheng,Yuchen Guan,Yucheng Ding,Qingguo Hu,Yongxian Wei,Chun Yuan,Yelong Shen,Weizhu Chen,Yeyun Gong*

Main category: cs.CL

TL;DR: 本文提出了一种名为Mixture of Neuron Experts (MoNE)的新方法，通过在神经元粒度上进行专家选择，显著提升了MoE模型的参数利用率和推理效率，仅激活50%的参数即可达到传统MoE的性能。


<details>
  <summary>Details</summary>
Motivation: 研究发现MoE层在推理时激活的参数依然高度稀疏，大多数神经元激活值接近零，这启发作者在预训练时仅选择高激活神经元专家以提升效率。

Method: 将专家分解为神经元粒度的MoE，通过在每个专家内部应用简单的top-k选择机制实现神经元级别的专家选择，无需额外路由参数或专家间通信。

Result: MoNE在仅激活50% MoE层参数的情况下，性能与传统MoE相当；在相同激活参数数量下，MoNE持续优于传统MoE。

Conclusion: MoNE是一种提升MoE类模型参数利用率和推理效率的实用方法。

Abstract: In this work, we first explore whether the parameters activated by the MoE
layer remain highly sparse at inference. We perform a sparsification study on
several representative MoE models. For each expert, we rank parameters by the
magnitude of their activations from the gate projection and progressively prune
the activated subset. Pruning up to 60% of parameters within that subset causes
only negligible task-performance degradation; substantial drops occur only
after more than 90% are removed. We further decompose experts into
neuron-granular MoE and visualize their activation values, finding that most
neuron activations are near zero. This observation motivates us to select only
high-activation neuron experts during pretraining. Based on this insight, we
propose Mixture of Neuron Experts (MoNE). MoNE achieves neuron-granular expert
selection by only applying a simple top-k selection within each expert, incurs
negligible latency, and requires no additional routing parameters or
inter-expert communication. Extensive experiments demonstrate that MoNE matches
traditional MoE performance while activating only 50% of the MoE-layer
parameters, and it consistently outperforms traditional MoE when compared at
equal numbers of activated parameters. These results suggest that MoNE is a
practical approach to improving parameter utilization and inference efficiency
in MoE-like models.

</details>


### [138] [EEPO: Exploration-Enhanced Policy Optimization via Sample-Then-Forget](https://arxiv.org/abs/2510.05837)
*Liang Chen,Xueting Han,Qizhou Wang,Bo Han,Jing Bai,Hinrich Schutze,Kam-Fai Wong*

Main category: cs.CL

TL;DR: 本文提出了EEPO（Exploration-Enhanced Policy Optimization）框架，通过两阶段rollout与自适应“遗忘”机制增强大语言模型在强化学习中的探索能力，有效打破过度利用导致的性能瓶颈，在多个推理任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于可验证奖励的强化学习（RLVR）方法容易过度利用，导致策略熵坍缩，探索能力下降，陷入主导行为模式的自强化循环，限制性能提升。

Method: 提出EEPO框架：第一阶段生成部分轨迹后，进行轻量级“遗忘”以暂时抑制已采样响应；第二阶段在此基础上继续生成，迫使模型探索输出空间的新区域。这种“采样-遗忘”机制增强了探索多样性。

Result: 在五个推理基准上，EEPO相较于GRPO取得了显著提升：Qwen2.5-3B平均提升24.3%，Llama3.2-3B-Instruct提升33.0%，Qwen3-8B-Base提升10.4%。

Conclusion: EEPO通过自适应遗忘机制有效平衡了探索与利用，打破了强化学习中主导模式的自强化循环，显著提升了大语言模型在推理任务中的性能。

Abstract: Balancing exploration and exploitation remains a central challenge in
reinforcement learning with verifiable rewards (RLVR) for large language models
(LLMs). Current RLVR methods often overemphasize exploitation, leading to
entropy collapse, diminished exploratory capacity, and ultimately limited
performance gains. Although techniques that increase policy stochasticity can
promote exploration, they frequently fail to escape dominant behavioral modes.
This creates a self-reinforcing loop-repeatedly sampling and rewarding dominant
modes-that further erodes exploration. We introduce Exploration-Enhanced Policy
Optimization (EEPO), a framework that promotes exploration via two-stage
rollouts with adaptive unlearning. In the first stage, the model generates half
of the trajectories; it then undergoes a lightweight unlearning step to
temporarily suppress these sampled responses, forcing the second stage to
explore different regions of the output space. This sample-then-forget
mechanism disrupts the self-reinforcing loop and promotes wider exploration
during rollouts. Across five reasoning benchmarks, EEPO outperforms GRPO,
achieving average relative gains of 24.3% on Qwen2.5-3B, 33.0% on
Llama3.2-3B-Instruct, and 10.4% on Qwen3-8B-Base.

</details>


### [139] [Luth: Efficient French Specialization for Small Language Models and Cross-Lingual Transfer](https://arxiv.org/abs/2510.05846)
*Maxence Lasbordes,Sinoué Gad*

Main category: cs.CL

TL;DR: Luth 是一个专注于法语的小型语言模型家族，通过针对性的后训练和模型融合策略，在多个法语基准上超越同规模开源模型，同时保持原有的英语能力。


<details>
  <summary>Details</summary>
Motivation: 现有大多语言模型在法语上的性能远低于英语，尤其是小型语言模型，且针对法语的高效适配研究有限，因此需要专门优化法语性能的模型。

Method: 通过对高质量法语数据进行针对性的后训练，并采用战略性模型融合方法，提升法语性能同时保留英语能力。

Result: Luth 在多个法语基准上优于同等规模的开源模型，成为法语小型语言模型的新标杆，同时在英语任务上保持竞争力。

Conclusion: Luth 为法语语言模型研究提供了强大的基线，并展示了针对性后训练和模型融合在多语言小型模型中的有效性。

Abstract: The landscape of Large Language Models (LLMs) remains predominantly
English-centric, resulting in a significant performance gap for other major
languages, such as French, especially in the context of Small Language Models
(SLMs). Existing multilingual models demonstrate considerably lower performance
in French compared to English, and research on efficient adaptation methods for
French remains limited. To address this, we introduce \textbf{Luth}, a family
of French-specialized SLMs: through targeted post-training on curated,
high-quality French data, our models outperform all open-source counterparts of
comparable size on multiple French benchmarks while retaining their original
English capabilities. We further show that strategic model merging enhances
performance in both languages, establishing Luth as a new state of the art for
French SLMs and a robust baseline for future French-language research.

</details>


### [140] [DACP: Domain-Adaptive Continual Pre-Training of Large Language Models for Phone Conversation Summarization](https://arxiv.org/abs/2510.05858)
*Xue-Yong Fu,Elena Khasanova,Md Tahmid Rahman Laskar,Harsh Saini,Shashi Bhushan TN*

Main category: cs.CL

TL;DR: 本文探索了使用持续预训练作为自监督方法，来提升大语言模型在对话摘要任务中的性能，尤其适用于噪声较多的真实世界对话转录数据。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在通用文本摘要上表现优异，但在特定领域或与原始训练分布不同的对话数据上表现欠佳。微调虽有效但依赖昂贵且稀缺的标注数据，因此需要一种更可扩展的适应方法。

Method: 采用持续预训练策略，在大规模无标签的商业对话数据上对大语言模型进行进一步预训练，以增强其在对话摘要任务上的能力。同时研究不同数据选择策略的影响。

Result: 实验表明，持续预训练显著提升了模型在领域内和领域外摘要基准上的表现，同时保持了良好的泛化性和鲁棒性。

Conclusion: 持续预训练是一种高效、可扩展的方法，适用于工业场景中面向摘要任务的模型适应，尤其在缺乏标注数据的情况下具有重要应用价值。

Abstract: Large language models (LLMs) have achieved impressive performance in text
summarization, yet their performance often falls short when applied to
specialized domains %or conversational data that differ from their original
pre-training distribution. While fine-tuning can improve summarization quality,
it typically relies on costly and scarce high-quality labeled data. In this
work, we explore continual pre-training as a scalable, self-supervised approach
to adapt LLMs for downstream summarization tasks, particularly in the context
of noisy real-world conversation transcripts. We conduct extensive experiments
using large-scale, unlabeled business conversation data to investigate whether
continual pre-training enhances model capabilities in conversational
summarization. Our results demonstrate that continual pre-training yields
substantial gains in both in-domain and out-of-domain summarization benchmarks,
while maintaining strong generalization and robustness. We also analyze the
effects of data selection strategies, providing practical guidelines for
applying continual pre-training in summarization-focused industrial
applications.

</details>


### [141] [Automated Boilerplate: Prevalence and Quality of Contract Generators in the Context of Swiss Privacy Policies](https://arxiv.org/abs/2510.05860)
*Luka Nenadic,David Rodriguez*

Main category: cs.CL

TL;DR: 本研究通过创建多语言基准数据集，评估2023年瑞士隐私法修订后的合规情况，发现使用自动化合同生成器显著提升中小企业隐私政策的合规性，最高提升达15个百分点。


<details>
  <summary>Details</summary>
Motivation: 中小企业常因资源与专业知识不足而难以应对日益复杂的数字法规，亟需低成本合规解决方案。本文旨在评估自动化合同生成工具在提升隐私政策合规性方面的实际效果。

Method: 构建涵盖瑞士与欧盟隐私法关键合规要求的多语言基准数据集，并利用GPT-5-based方法对大量隐私政策进行合规性评估，分析法规修订影响及生成器使用效果。

Result: 法规修订后整体合规性有所提升；18%的本地网站明确引用了生成器；使用生成器的隐私政策合规率显著更高，最多提升15个百分点。

Conclusion: 自动化合同生成工具能有效提升中小企业法律合规水平；LLM可用于跨语言法律分析；研究支持欧盟法规的“布鲁塞尔效应”，并凸显自动化工具在改善合同质量中的关键作用。

Abstract: It has become increasingly challenging for firms to comply with a plethora of
novel digital regulations. This is especially true for smaller businesses that
often lack both the resources and know-how to draft complex legal documents.
Instead of seeking costly legal advice from attorneys, firms may turn to
cheaper alternative legal service providers such as automated contract
generators. While these services have a long-standing presence, there is little
empirical evidence on their prevalence and output quality.
  We address this gap in the context of a 2023 Swiss privacy law revision. To
enable a systematic evaluation, we create and annotate a multilingual benchmark
dataset that captures key compliance obligations under Swiss and EU privacy
law. Using this dataset, we validate a novel GPT-5-based method for large-scale
compliance assessment of privacy policies, allowing us to measure the impact of
the revision. We observe compliance increases indicating an effect of the
revision. Generators, explicitly referenced by 18% of local websites, are
associated with substantially higher levels of compliance, with increases of up
to 15 percentage points compared to privacy policies without generator use.
These findings contribute to three debates: the potential of LLMs for
cross-lingual legal analysis, the Brussels Effect of EU regulations, and,
crucially, the role of automated tools in improving compliance and contractual
quality.

</details>


### [142] [Revisiting Long-context Modeling from Context Denoising Perspective](https://arxiv.org/abs/2510.05862)
*Zecheng Tang,Baibei Ji,Juntao Li,Lijun Wu,Haijia Gui,Min Zhang*

Main category: cs.CL

TL;DR: 提出一种名为上下文去噪训练（CDT）的方法，通过集成梯度（IG）分数检测和减轻上下文噪声，显著提升长上下文模型对关键信息的关注和预测性能。


<details>
  <summary>Details</summary>
Motivation: 长上下文模型易受无关上下文噪声干扰，影响其对关键信息的注意力和预测能力，需要有效方法识别并减轻噪声影响。

Method: 引入集成梯度（IG）分数作为衡量上下文噪声的指标，并提出上下文去噪训练（CDT）策略，在训练过程中减少噪声干扰，增强模型对关键标记的关注。

Result: 在四种任务和不同长上下文设置下，CDT显著提升模型性能；采用CDT训练的8B开源模型性能（50.92）接近GPT-4o（51.00）。

Conclusion: CDT是一种简单而有效的训练策略，能显著增强长上下文模型对关键信息的注意力和预测能力，具有广泛的应用潜力。

Abstract: Long-context models (LCMs) have demonstrated great potential in processing
long sequences, facilitating many real-world applications. The success of LCMs
can be attributed to their ability to locate implicit critical information
within the context for further prediction. However, recent research reveals
that LCMs are often susceptible to contextual noise, i.e., irrelevant tokens,
that can mislead model attention. In this paper, we conduct a fine-grained
analysis of the context noise and propose an effective metric, the Integrated
Gradient (IG) score, to detect and quantify the noise information within the
context. Our findings reveal that even simple mitigation of detected context
noise can substantially boost the model's attention on critical tokens and
benefit subsequent predictions. Building on this insight, we propose Context
Denoising Training (CDT), a straightforward yet effective training strategy
that improves attention on critical tokens while reinforcing their influence on
model predictions. Extensive experiments across four tasks, under both context
window scaling and long-context alignment settings, demonstrate the superiority
of CDT. Notably, when trained with CDT, an open-source 8B model can achieve
performance (50.92) comparable to GPT-4o (51.00).

</details>


### [143] [Evaluating the Sensitivity of LLMs to Harmful Contents in Long Input](https://arxiv.org/abs/2510.05864)
*Faeze Ghorbanpour,Alexander Fraser*

Main category: cs.CL

TL;DR: 首次系统评估了大语言模型在长上下文场景下对显式与隐式有害内容的敏感性，发现其检测性能在中等有害内容比例时最佳，且受内容位置、显隐性和上下文长度影响显著。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在长上下文应用中的普及，其在安全关键场景下的行为尚不清楚，尤其对有害内容的识别能力缺乏系统研究。

Method: 通过控制有害内容的类型（显式vs.隐式）、位置（开头、中间、结尾）、占比（0.01–0.50）和上下文长度（600–6000 tokens），在LLaMA-3、Qwen-2.5和Mistral等模型上评估其检测性能。

Result: 发现模型性能在有害内容占比0.25时达到峰值，内容过少或过多均使其下降；上下文越长，召回率越低；开头的有害内容更易被检测；显式内容比隐式内容更容易识别。

Conclusion: 揭示了大语言模型在长上下文中处理有害内容的规律，凸显其在安全应用中的潜力与挑战，为改进模型安全机制提供了依据。

Abstract: Large language models (LLMs) increasingly support applications that rely on
extended context, from document processing to retrieval-augmented generation.
While their long-context capabilities are well studied for reasoning and
retrieval, little is known about their behavior in safety-critical scenarios.
We evaluate LLMs' sensitivity to harmful content under extended context,
varying type (explicit vs. implicit), position (beginning, middle, end),
prevalence (0.01-0.50 of the prompt), and context length (600-6000 tokens).
Across harmful content categories such as toxic, offensive, and hate speech,
with LLaMA-3, Qwen-2.5, and Mistral, we observe similar patterns: performance
peaks at moderate harmful prevalence (0.25) but declines when content is very
sparse or dominant; recall decreases with increasing context length; harmful
sentences at the beginning are generally detected more reliably; and explicit
content is more consistently recognized than implicit. These findings provide
the first systematic view of how LLMs prioritize and calibrate harmful content
in long contexts, highlighting both their emerging strengths and the challenges
that remain for safety-critical use.

</details>


### [144] [The fragility of "cultural tendencies" in LLMs](https://arxiv.org/abs/2510.05869)
*Kun Sun,Rong Wang*

Main category: cs.CL

TL;DR: 本文对Lu, Song, 和 Zhang (2025)的研究提出质疑，认为其发现的大语言模型在不同语言提示下表现出的文化倾向性并非稳定特征，而是特定模型和任务设计的脆弱产物。作者通过更广泛的模型和更多测试项的复制实验，发现提示语言对输出影响极小，挑战了原研究中模型具备根深蒂固文化信念的观点。


<details>
  <summary>Details</summary>
Motivation: 回应LSZ研究关于大语言模型具有文化特定倾向的主张，质疑其方法论和解释的合理性，并重新评估其结论的稳健性。

Method: 通过更广泛的LLM集合和更大规模的测试项目进行针对性复制实验，重新检验提示语言对模型输出的影响。

Result: 实验结果表明，提示语言对模型输出的影响微乎其微，所谓的‘文化倾向’并不稳定，且高度依赖于具体模型和任务设计。

Conclusion: 大语言模型在不同语言提示下的行为差异不能被简单解释为文化信念的体现；这些差异更可能是方法论因素导致的偶然现象，而非模型编码了真实的文化认知。

Abstract: In a recent study, Lu, Song, and Zhang (2025) (LSZ) propose that large
language models (LLMs), when prompted in different languages, display
culturally specific tendencies. They report that the two models (i.e., GPT and
ERNIE) respond in more interdependent and holistic ways when prompted in
Chinese, and more independent and analytic ways when prompted in English. LSZ
attribute these differences to deep-seated cultural patterns in the models,
claiming that prompt language alone can induce substantial cultural shifts.
While we acknowledge the empirical patterns they observed, we find their
experiments, methods, and interpretations problematic. In this paper, we
critically re-evaluate the methodology, theoretical framing, and conclusions of
LSZ. We argue that the reported "cultural tendencies" are not stable traits but
fragile artifacts of specific models and task design. To test this, we
conducted targeted replications using a broader set of LLMs and a larger number
of test items. Our results show that prompt language has minimal effect on
outputs, challenging LSZ's claim that these models encode grounded cultural
beliefs.

</details>


### [145] [Prompt reinforcing for long-term planning of large language models](https://arxiv.org/abs/2510.05921)
*Hsien-Chin Lin,Benjamin Matthias Ruppik,Carel van Niekerk,Chia-Hao Shen,Michael Heck,Nurul Lubis,Renato Vukovic,Shutong Feng,Milica Gašić*

Main category: cs.CL

TL;DR: 提出一种受强化学习启发的提示优化框架，通过修改基于大语言模型（LLM）代理的任务指令提示，实现多轮交互中的长期规划，显著提升了文本到SQL和面向任务对话等任务的表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多轮交互中表现不佳，常依赖错误的早期假设且难以持续跟踪用户目标，因此需要一种能支持长期规划的优化方法。

Method: 提出一种基于强化学习思想的提示优化框架，通过生成逐轮反馈并利用经验回放机制重写提示，仅通过调整任务指令提示来实现规划能力。

Result: 在文本到SQL和任务导向对话等多轮任务中实现了显著性能提升，且方法可泛化至不同的LLM代理，并能利用多种LLM作为元提示代理。

Conclusion: 强化学习启发的无需参数调整的提示优化方法在多轮交互任务中具有潜力，值得进一步研究。

Abstract: Large language models (LLMs) have achieved remarkable success in a wide range
of natural language processing tasks and can be adapted through prompting.
However, they remain suboptimal in multi-turn interactions, often relying on
incorrect early assumptions and failing to track user goals over time, which
makes such tasks particularly challenging. Prior works in dialogue systems have
shown that long-term planning is essential for handling interactive tasks. In
this work, we propose a prompt optimisation framework inspired by reinforcement
learning, which enables such planning to take place by only modifying the task
instruction prompt of the LLM-based agent. By generating turn-by-turn feedback
and leveraging experience replay for prompt rewriting, our proposed method
shows significant improvement in multi-turn tasks such as text-to-SQL and
task-oriented dialogue. Moreover, it generalises across different LLM-based
agents and can leverage diverse LLMs as meta-prompting agents. This warrants
future research in reinforcement learning-inspired parameter-free optimisation
methods.

</details>


### [146] [UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG](https://arxiv.org/abs/2510.03663)
*Xiangyu Peng,Cab Qin,Zeyuan Chen,Ran Xu,Caiming Xiong,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: 本文介绍了UniDoc-Bench，首个大规模、真实场景的多模态检索增强生成（MM-RAG）基准，基于7万页真实PDF文档构建，涵盖八种领域，支持文本、表格和图像联合评估。


<details>
  <summary>Details</summary>
Motivation: 现有MM-RAG评估多局限于单一模态或简化设置，缺乏对以文档为中心的真实多模态场景的全面评测，亟需一个统一、现实的基准来推动该领域发展。

Method: 提出UniDoc-Bench构建流程：从真实PDF中提取并关联文本、表格和图像证据，生成1600个多模态问答对，覆盖多种查询类型；20%样本经多标注员验证与专家裁决确保质量；支持四种范式在统一流程下的公平比较。

Result: 实验表明，多模态文本-图像融合RAG系统在性能上持续优于单模态及基于联合多模态嵌入的检索方法，揭示当前多模态嵌入仍不足。

Conclusion: UniDoc-Bench为MM-RAG提供了可靠评测平台，揭示了视觉上下文如何补全文本证据，暴露系统性缺陷，并为构建更鲁棒的多模态RAG系统提供了实践指导。

Abstract: Multimodal retrieval-augmented generation (MM-RAG) is a key approach for
applying large language models (LLMs) and agents to real-world knowledge bases,
yet current evaluations are fragmented, focusing on either text or images in
isolation or on simplified multimodal setups that fail to capture
document-centric multimodal use cases. In this paper, we introduce
UniDoc-Bench, the first large-scale, realistic benchmark for MM-RAG built from
70k real-world PDF pages across eight domains. Our pipeline extracts and links
evidence from text, tables, and figures, then generates 1,600 multimodal QA
pairs spanning factual retrieval, comparison, summarization, and logical
reasoning queries. To ensure reliability, 20% of QA pairs are validated by
multiple annotators and expert adjudication. UniDoc-Bench supports
apples-to-apples comparison across four paradigms: (1) text-only, (2)
image-only, (3) multimodal text-image fusion, and (4) multimodal joint
retrieval -- under a unified protocol with standardized candidate pools,
prompts, and evaluation metrics. Our experiments show that multimodal
text-image fusion RAG systems consistently outperform both unimodal and jointly
multimodal embedding-based retrieval, indicating that neither text nor images
alone are sufficient and that current multimodal embeddings remain inadequate.
Beyond benchmarking, our analysis reveals when and how visual context
complements textual evidence, uncovers systematic failure modes, and offers
actionable guidance for developing more robust MM-RAG pipelines.

</details>


### [147] [Hire Your Anthropologist! Rethinking Culture Benchmarks Through an Anthropological Lens](https://arxiv.org/abs/2510.05931)
*Mai AlKhamissi,Yunze Xiao,Badr AlKhamissi,Mona Diab*

Main category: cs.CL

TL;DR: 本文提出一个四部分框架，用于分析当前文化评估基准在衡量大语言模型文化能力时的局限性，指出其常将文化简化为静态事实，并忽略文化多样性。通过分析20个现有基准，作者识别出六类方法论问题，并基于人类学方法提出改进建议，如引入真实情境、社区参与和情境化评估，以建立更动态、真实的文化评估体系。


<details>
  <summary>Details</summary>
Motivation: 当前的文化评估基准通常将文化简化为静态知识或单一价值观，忽视了文化的动态性与实践性，导致模型评估无法反映真实文化情境。为弥合语言模型评估与人类学对文化的理解之间的差距，亟需重新审视现有评估方法。

Method: 本文构建了一个四维框架（知识、偏好、表现、偏见）来分类和分析文化评估基准如何界定文化；基于该框架对20个现有文化基准进行定性分析；结合人类学方法，提出改进文化评估的设计原则。

Result: 研究发现了六项普遍存在的方法论问题，如将国家等同于文化、忽略文化内部多样性、依赖简化的调查形式等；并展示了现有基准多聚焦于静态文化知识，缺乏对文化实践和情境化表达的考察。

Conclusion: 文化应被视为动态、历史嵌入和实践导向的。本文呼吁采用更符合人类学视角的文化评估方法，通过融入真实叙事、社区参与和情境化测试，提升大语言模型文化评估的深度与真实性。

Abstract: Cultural evaluation of large language models has become increasingly
important, yet current benchmarks often reduce culture to static facts or
homogeneous values. This view conflicts with anthropological accounts that
emphasize culture as dynamic, historically situated, and enacted in practice.
To analyze this gap, we introduce a four-part framework that categorizes how
benchmarks frame culture, such as knowledge, preference, performance, or bias.
Using this lens, we qualitatively examine 20 cultural benchmarks and identify
six recurring methodological issues, including treating countries as cultures,
overlooking within-culture diversity, and relying on oversimplified survey
formats. Drawing on established anthropological methods, we propose concrete
improvements: incorporating real-world narratives and scenarios, involving
cultural communities in design and validation, and evaluating models in context
rather than isolation. Our aim is to guide the development of cultural
benchmarks that go beyond static recall tasks and more accurately capture the
responses of the models to complex cultural situations.

</details>


### [148] [EvalMORAAL: Interpretable Chain-of-Thought and LLM-as-Judge Evaluation for Moral Alignment in Large Language Models](https://arxiv.org/abs/2510.05942)
*Hadi Mohammadi,Anastasia Giachanou,Ayoub Bagheri*

Main category: cs.CL

TL;DR: 提出了一种透明的链式思维框架EvalMORAAL，用于评估20个大语言模型在道德对齐方面的表现，发现模型在西方地区对齐效果较好，但在非西方地区存在显著偏差。


<details>
  <summary>Details</summary>
Motivation: 为了更公平、透明地评估大语言模型在不同文化背景下的道德对齐程度，特别是揭示区域偏差问题。

Method: 结合两种评分方法（对数概率和直接评分）和模型作为裁判的同行评审机制，采用链式思维协议并在世界价值观调查和PEW全球态度调查数据上进行验证。

Result: 顶级模型在世界价值观调查中与人类回答高度一致（Pearson相关系数约0.90），但西方地区（r=0.82）优于非西方地区（r=0.61），存在0.21的差距；同行评审检测到348个冲突，且评审一致性与调查对齐度显著相关。

Conclusion: EvalMORAAL有助于实现文化感知的AI评估，揭示了模型在跨区域应用中的挑战，推动了对文化多样性的关注。

Abstract: We present EvalMORAAL, a transparent chain-of-thought (CoT) framework that
uses two scoring methods (log-probabilities and direct ratings) plus a
model-as-judge peer review to evaluate moral alignment in 20 large language
models. We assess models on the World Values Survey (55 countries, 19 topics)
and the PEW Global Attitudes Survey (39 countries, 8 topics). With EvalMORAAL,
top models align closely with survey responses (Pearson's r approximately 0.90
on WVS). Yet we find a clear regional difference: Western regions average
r=0.82 while non-Western regions average r=0.61 (a 0.21 absolute gap),
indicating consistent regional bias. Our framework adds three parts: (1) two
scoring methods for all models to enable fair comparison, (2) a structured
chain-of-thought protocol with self-consistency checks, and (3) a
model-as-judge peer review that flags 348 conflicts using a data-driven
threshold. Peer agreement relates to survey alignment (WVS r=0.74, PEW r=0.39,
both p<.001), supporting automated quality checks. These results show real
progress toward culture-aware AI while highlighting open challenges for use
across regions.

</details>


### [149] [Probing the Difficulty Perception Mechanism of Large Language Models](https://arxiv.org/abs/2510.05969)
*Sunbowen Lee,Qingyu Yin,Chak Tou Leong,Jialiang Zhang,Yicheng Gong,Xiaoyu Shen*

Main category: cs.CL

TL;DR: 研究发现大语言模型（LLM）的内部表征能够线性编码数学问题的难度，特定注意力头可感知难易差异，表明LLM具备内在难度感知能力，可用于自动难度标注。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型是否能在内部隐式感知问题难度，为自适应推理和资源分配提供依据，并减少对人工标注难度的依赖。

Method: 使用线性探测方法分析LLM最后token的表征，并定位Transformer最后一层中与难度感知相关的特定注意力头，结合消融实验验证其作用。

Result: 发现数学问题难度可在LLM内部被线性建模，特定注意力头对简单和困难问题表现出相反的激活模式，且token级别的熵与难度感知存在显著差异。

Conclusion: LLM不仅具备内在的难度感知能力，且该能力在结构上有序组织，可为基准构建和课程学习提供自动难度标注的新方法。

Abstract: Large language models (LLMs) are increasingly deployed on complex reasoning
tasks, yet little is known about their ability to internally evaluate problem
difficulty, which is an essential capability for adaptive reasoning and
efficient resource allocation. In this work, we investigate whether LLMs
implicitly encode problem difficulty in their internal representations. Using a
linear probe on the final-token representations of LLMs, we demonstrate that
the difficulty level of math problems can be linearly modeled. We further
locate the specific attention heads of the final Transformer layer: these
attention heads have opposite activation patterns for simple and difficult
problems, thus achieving perception of difficulty. Our ablation experiments
prove the accuracy of the location. Crucially, our experiments provide
practical support for using LLMs as automatic difficulty annotators,
potentially substantially reducing reliance on costly human labeling in
benchmark construction and curriculum learning. We also uncover that there is a
significant difference in entropy and difficulty perception at the token level.
Our study reveals that difficulty perception in LLMs is not only present but
also structurally organized, offering new theoretical insights and practical
directions for future research.

</details>


### [150] [LexiCon: a Benchmark for Planning under Temporal Constraints in Natural Language](https://arxiv.org/abs/2510.05972)
*Periklis Mantenoglou,Rishi Hazra,Pedro Zuidberg Dos Martires,Luc De Raedt*

Main category: cs.CL

TL;DR: 提出 LexiCon，一个基于自然语言的可扩展、未来可扩展的时序约束规划评测基准，用于评估大模型在带约束（特别是安全约束）规划任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有大模型在无约束规划任务中表现良好，但在现实世界中需满足安全等关键约束，因此需要系统评估其在约束规划中的能力。

Method: 基于现有规划环境构建时序状态约束，并自动将其转化为自然语言问题；支持扩展新环境并自动生成约束，形成 LexiCon 基准。

Result: 实验表明，随着任务约束程度增加，包括 GPT-5、o3 和 R1 等先进推理模型的性能显著下降。

Conclusion: 约束规划是当前 LLMs 的薄弱环节，LexiCon 提供了一个可扩展、可演进的基准，有助于推动安全可靠的规划能力发展。

Abstract: Owing to their reasoning capabilities, large language models (LLMs) have been
evaluated on planning tasks described in natural language. However, LLMs have
largely been tested on planning domains without constraints. In order to deploy
them in real-world settings where adherence to constraints, in particular
safety constraints, is critical, we need to evaluate their performance on
constrained planning tasks. We introduce LexiCon -- a natural language-based
(Lexi) constrained (Con) planning benchmark, consisting of a suite of
environments, that can be used to evaluate the planning capabilities of LLMs in
a principled fashion. The core idea behind LexiCon is to take existing planning
environments and impose temporal constraints on the states. These constrained
problems are then translated into natural language and given to an LLM to
solve. A key feature of LexiCon is its extensibility. That is, the set of
supported environments can be extended with new (unconstrained) environment
generators, for which temporal constraints are constructed automatically. This
renders LexiCon future-proof: the hardness of the generated planning problems
can be increased as the planning capabilities of LLMs improve. Our experiments
reveal that the performance of state-of-the-art LLMs, including reasoning
models like GPT-5, o3, and R1, deteriorates as the degree of constrainedness of
the planning tasks increases.

</details>


### [151] [Exploring Gaps in the APS: Direct Minimal Pair Analysis in LLM Syntactic Assessments](https://arxiv.org/abs/2510.06001)
*Timothy Pistotti,Jason Brown,Michael Witbrock*

Main category: cs.CL

TL;DR: 本研究通过改进的寄生间隙刺激范式和GPT-2模型，采用直接最小对比较方法（wh效应），发现LLM在复杂填空依赖环境中表现出稳健的句法知识，表明评估指标的选择对判断LLM句法能力至关重要。


<details>
  <summary>Details</summary>
Motivation: 近年来基于大语言模型（LLM）对“刺激贫乏论据”的研究采用不同评估指标得出了不一致的结论，尤其是关于模型是否掌握复杂句法结构（如寄生间隙）。本研究旨在澄清这些分歧，探讨何种评估方法更具诊断力。

Method: 构建包含8种排列组合的精细化寄生间隙刺激范式，对GPT-2模型进行系统性wh效应分析（直接最小对比较），并将其结果与基于差异中差异（DiD）的评估方法进行对比。

Result: GPT-2在全部四个测试条件下均表现出显著的wh效应，显示出对填空-间隙依存关系的稳健掌握；而DiD方法此前得出‘模型失败’的结论较为模糊。

Conclusion: 直接最小对比较方法比DiD更具诊断透明性，评估指标的选择显著影响对LLM句法能力的判断，当前结果支持LLM能掌握复杂句法结构的观点。

Abstract: Recent studies probing the Argument from the Poverty of the Stimulus (APS)
have applied Large Language Models (LLMs) to test the learnability of complex
syntax through surprisal-based metrics. However, divergent conclusions raise
questions concerning the insights these metrics offer. While Wilcox et al.
(2024) used direct minimal pair comparisons (the "wh-effect") to demonstrate
that models successfully generalise knowledge of filler-gap dependencies, Lan
et al. (2024) used a Difference-in-Differences (DiD) metric and found that
models largely fail on parasitic gaps (PGs). This paper argues that the direct
minimal pair approach offers greater diagnostic transparency. We demonstrate
this by generating a full 8-permutation paradigm of refined PG stimuli and
evaluating the GPT-2 model used in previous studies with a systematic
Wilcox-style wh-effect analysis. Our results show that GPT-2 succeeds across
all four tested conditions, indicating robust knowledge of filler-gap licensing
principles even in complex PG environments. This finding, which contrasts with
the more ambiguous results from DiD-style metrics, suggests that the choice of
evaluation metric is critical for assessing an LLM's syntactic competence.

</details>


### [152] [MASA: Rethinking the Representational Bottleneck in LoRA with Multi-A Shared Adaptation](https://arxiv.org/abs/2510.06005)
*Qin Dong,Yuntian Tang,Heming Jia,Yunhang Shen,Bohan Jia,Wenxuan Huang,Lianyue Zhang,Jiao Xie,Shaohui Lin*

Main category: cs.CL

TL;DR: 提出MASA架构，通过多A单B结构和跨层不对称共享专家机制，在保持参数效率的同时提升LoRA在下游任务中的适应能力，在MMLU等多任务上优于标准LoRA。


<details>
  <summary>Details</summary>
Motivation: LoRA仅使用单一的下投影矩阵A导致表示能力受限，难以捕获复杂任务所需的多样化信号，因此需增强特征适应能力以提升模型在下游任务中的表现。

Method: 提出MASA架构，采用多A单B结构，多个A矩阵作为专业化特征提取专家，并在不同层间不对称共享，每个层通过一个特定的B矩阵整合特征，从而增强表示多样性并保持参数效率。

Result: 在多领域泛化、单领域专门化和多任务推理等任务上验证了MASA的有效性，在MMLU基准上达到59.62%的平均准确率，比标准LoRA提升1.08个百分点（相对提升1.84%），且可学习参数量相近（0.52%）

Conclusion: MASA通过丰富特征适配机制有效缓解了LoRA的表示瓶颈问题，在不显著增加参数的情况下显著提升模型适应能力，展现出更强的泛化与多任务处理性能。

Abstract: Low-Rank Adaptation (LoRA) has emerged as a dominant method in
Parameter-Efficient Fine-Tuning (PEFT) for large language models, which
augments the transformer layer with one down-projection $A$ and one
up-projection $B$. However, LoRA's reliance on a single down-projection matrix
($A$) creates a representational bottleneck, as this solitary feature extractor
is inherently insufficient for capturing the diverse signals required by
complex tasks. This motivates our architectural shift to focus on enriching the
feature adaptation to improve the downstream task adaptation ability. We
propose MASA (Multi-$A$ Shared Adaptation), an architecture that implements a
multi-$A$, single-$B$ structure where the multi-$A$ expert ensemble is
asymmetrically shared across layers to ensure parameter efficiency. In MASA,
these specialized experts capture diverse features, which are then integrated
by a single, layer-specific $B$-matrix. The effectiveness and versatility of
our method are validated through a comprehensive suite of experiments spanning
multi-domain generalization, single-domain specialization, and multi-task
reasoning. For example, on the MMLU benchmark, MASA achieves an average
accuracy of 59.62%, outperforming the standard LoRA by 1.08 points (a relative
improvement of 1.84%) with comparable learnable parameters of 0.52%.

</details>


### [153] [Evaluating The Impact of Stimulus Quality in Investigations of LLM Language Performance](https://arxiv.org/abs/2510.06018)
*Timothy Pistotti,Jason Brown,Michael Witbrock*

Main category: cs.CL

TL;DR: 本研究探讨了刺激材料的特性（如词汇歧义和结构复杂性）对大语言模型（LLM）在句法预测任务中表现的影响，提出通过改进数据集来更准确地评估LLM的句法能力。研究以GPT-2为例，使用语言学指导下的模板生成更纯净的测试数据，并发现GPT-2在优化后的刺激材料上表现显著提升，表明刺激质量显著影响LLM句法能力评估结果。


<details>
  <summary>Details</summary>
Motivation: 近期使用大语言模型（LLM）检验“刺激贫乏论”（APS）的研究在不同句法现象上得出矛盾结果，可能源于实验所用刺激材料存在词汇歧义和结构复杂性等混淆因素。本文旨在检验这一假设，并改进评估方法。

Method: 1) 在以往研究使用的过滤与未过滤刺激材料上建立GPT-2的基线表现；2) 利用先进的生成式LLM（Gemini 2.5 Pro Preview）结合语言学指导的模板，构建一个消除混淆因素的新数据集，并在该数据集上评估GPT-2的句法预测能力。

Result: 初步结果显示，GPT-2在经过优化的新刺激材料（PG stimuli）上的表现显著优于基线条件，表明去除混淆因素后模型的句法预测能力更强。

Conclusion: 刺激材料的质量显著影响基于意外性（surprisal）的LLM句法能力评估结果。为准确评估LLM的句法能力，需控制刺激材料中的语言混淆因素，采用更精细的实验设计。

Abstract: Recent studies employing Large Language Models (LLMs) to test the Argument
from the Poverty of the Stimulus (APS) have yielded contrasting results across
syntactic phenomena. This paper investigates the hypothesis that
characteristics of the stimuli used in recent studies, including lexical
ambiguities and structural complexities, may confound model performance. A
methodology is proposed for re-evaluating LLM competence on syntactic
prediction, focusing on GPT-2. This involves: 1) establishing a baseline on
previously used (both filtered and unfiltered) stimuli, and 2) generating a
new, refined dataset using a state-of-the-art (SOTA) generative LLM (Gemini 2.5
Pro Preview) guided by linguistically-informed templates designed to mitigate
identified confounds. Our preliminary findings indicate that GPT-2 demonstrates
notably improved performance on these refined PG stimuli compared to baselines,
suggesting that stimulus quality significantly influences outcomes in
surprisal-based evaluations of LLM syntactic competency.

</details>


### [154] [CDTP: A Large-Scale Chinese Data-Text Pair Dataset for Comprehensive Evaluation of Chinese LLMs](https://arxiv.org/abs/2510.06039)
*Chengwei Wu,Jiapu Wang,Mingyang Gao,Xingrui Zhuo,Jipeng Guo,Runlin Lei,Haoran Luo,Tianyu Chen,Haoyi Zhou,Shirui Pan,Zechao Li*

Main category: cs.CL

TL;DR: 提出一个基于中文数据-文本对（CDTP）的综合基准CB-ECLLM，用于更全面评估中文大语言模型，填补现有英文主导评测的不足。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评测基准以英文为主，缺乏对中文语言特性和结构化知识表示的支持，难以有效评估中文大模型在知识密集型任务上的表现。

Method: 构建包含700万文本-三元组对的CDTP数据集，覆盖四大领域共1500万三元组，并基于此开发CB-ECLLM评测基准，支持知识图谱补全、三元组生成文本和问答等多任务评估。

Result: 通过大量实验和消融研究验证了CDTP在监督微调、模型有效性与鲁棒性评估方面的优势，显著提升中文LLM在知识驱动任务中的评测能力。

Conclusion: CDTP和CB-ECLLM为中文大模型提供了高质量的结构化数据支持与系统评测方案，推动中文LLM向更可靠、可复现和知识增强的方向发展。

Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide
range of natural language processing tasks. However, Chinese LLMs face unique
challenges, primarily due to the dominance of unstructured free text and the
lack of structured representations in Chinese corpora. While existing
benchmarks for LLMs partially assess Chinese LLMs, they are still predominantly
English-centric and fail to address the unique linguistic characteristics of
Chinese, lacking structured datasets essential for robust evaluation. To
address these challenges, we present a Comprehensive Benchmark for Evaluating
Chinese Large Language Models (CB-ECLLM) based on the newly constructed Chinese
Data-Text Pair (CDTP) dataset. Specifically, CDTP comprises over 7 million
aligned text pairs, each consisting of unstructured text coupled with one or
more corresponding triples, alongside a total of 15 million triples spanning
four critical domains. The core contributions of CDTP are threefold: (i)
enriching Chinese corpora with high-quality structured information; (ii)
enabling fine-grained evaluation tailored to knowledge-driven tasks; and (iii)
supporting multi-task fine-tuning to assess generalization and robustness
across scenarios, including Knowledge Graph Completion, Triple-to-Text
generation, and Question Answering. Furthermore, we conduct rigorous
evaluations through extensive experiments and ablation studies to assess the
effectiveness, Supervised Fine-Tuning (SFT), and robustness of the benchmark.
To support reproducible research, we offer an open-source codebase and outline
potential directions for future investigations based on our insights.

</details>


### [155] [ASPO: Asymmetric Importance Sampling Policy Optimization](https://arxiv.org/abs/2510.06062)
*Jiakang Wang,Runze Liu,Lei Lin,Wenping Hu,Xiu Li,Fuzheng Zhang,Guorui Zhou,Kun Gai*

Main category: cs.CL

TL;DR: 提出了一种新的强化学习策略ASPO，通过修正重要性采样比率中的不对称问题，改善大语言模型后训练中的 token-level 加权不平衡问题，提升了训练稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于结果监督的强化学习（OSRL）方法在 token-level 使用重要性采样时存在正负 token 更新权重不平衡的问题，导致低概率 token 更新受抑制、高概率 token 过度放大，影响训练效果。

Method: 提出ASPO方法，对具有正优势的 token 的重要性采样比率进行翻转，使其更新方向与负优势 token 一致，并引入软双重裁剪机制以稳定极端更新并保持梯度流动。

Result: 在编程和数学推理基准上的实验表明，ASPO显著缓解了早停收敛问题，提升了训练稳定性，并优于基于GRPO的强基线方法。

Conclusion: 正确修正重要性采样在大模型强化学习中至关重要，ASPO通过解决 token-level 的重要性采样失配问题，为OSRL范式提供了更优的优化路径。

Abstract: Recent Large Language Model (LLM) post-training methods rely on token-level
clipping mechanisms during Reinforcement Learning (RL). However, we identify a
fundamental flaw in this Outcome-Supervised RL (OSRL) paradigm: the Importance
Sampling (IS) ratios of positive-advantage tokens are mismatched, leading to
unbalanced token weighting for positive and negative tokens. This mismatch
suppresses the update of low-probability tokens while over-amplifying already
high-probability ones. To address this, we propose Asymmetric Importance
Sampling Policy Optimization (ASPO), which uses a simple yet effective strategy
that flips the IS ratios of positive-advantage tokens, aligning their update
direction with the learning dynamics of negative ones. AIS further incorporates
a soft dual-clipping mechanism to stabilize extreme updates while maintaining
gradient flow. Comprehensive experiments on coding and mathematical reasoning
benchmarks demonstrate that ASPO significantly mitigates premature convergence,
improves training stability, and enhances final performance over strong
GRPO-based baselines. Our analysis provides new insights into the role of
token-level weighting in OSRL and highlights the critical importance of
correcting IS in LLM RL. The code and models of ASPO are available at
https://github.com/wizard-III/Archer2.0.

</details>


### [156] [Spectrum Tuning: Post-Training for Distributional Coverage and In-Context Steerability](https://arxiv.org/abs/2510.06084)
*Taylor Sorensen,Benjamin Newman,Jared Moore,Chan Park,Jillian Fisher,Niloofar Mireshghallah,Liwei Jiang,Yejin Choi*

Main category: cs.CL

TL;DR: 本文研究了语言模型后训练在条件分布建模中的负面影响，提出了三个关键目标：上下文可引导性、有效输出空间覆盖和分布对齐，并引入Spectrum Suite基准和Spectrum Tuning方法来改善模型在这些方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型后训练虽提升指令遵循能力，但常损害模型在多解任务中对多样化分布的适应能力，需系统评估并改进模型的分布建模能力。

Method: 提出Spectrum Suite——一个包含超40个数据源、90多个任务的大规模评估资源，用于衡量上下文可引导性、输出空间覆盖和分布对齐；并提出Spectrum Tuning，一种利用该资源进行后训练的新方法。

Result: 实验表明，当前的后训练方法虽能激发模型已有能力，但削弱了其上下文可引导性；而Spectrum Tuning相比预训练和指令微调模型，在多个指标上表现更优，提升了可引导性、输出多样性及分布对齐能力。

Conclusion: 应重视语言模型在分布多样性任务中的表现，Spectrum Tuning结合Spectrum Suite为提升模型灵活适应不同分布的能力提供了有效途径。

Abstract: Language model post-training has enhanced instruction-following and
performance on many downstream tasks, but also comes with an often-overlooked
cost on tasks with many possible valid answers. We characterize three
desiderata for conditional distributional modeling: in-context steerability,
valid output space coverage, and distributional alignment, and document across
three model families how current post-training can reduce these properties. In
particular, we disambiguate between two kinds of in-context learning: ICL for
eliciting existing underlying knowledge or capabilities, and in-context
steerability, where a model must use in-context information to override its
priors and steer to a novel data generating distribution. To better evaluate
and improve these desiderata, we introduce Spectrum Suite, a large-scale
resource compiled from >40 data sources and spanning >90 tasks requiring models
to steer to and match diverse distributions ranging from varied human
preferences to numerical distributions and more. We find that while current
post-training techniques help elicit underlying capabilities and knowledge,
they hurt models' ability to flexibly steer in-context. To mitigate these
issues, we propose Spectrum Tuning, a post-training method using Spectrum Suite
to improve steerability and distributional coverage. We find that Spectrum
Tuning often improves over pretrained models and their instruction-tuned
counterparts, enhancing steerability, spanning more of the output space, and
improving distributional alignment on held-out datasets.

</details>


### [157] [The Valley of Code Reasoning: Scaling Knowledge Distillation of Large Language Models](https://arxiv.org/abs/2510.06101)
*Muyu He,Muhammad Ali Shafique,Anand Kumar,Tsach Mackey,Nazneen Rajani*

Main category: cs.CL

TL;DR: 本文研究了将具有推理能力的大语言模型的思维链蒸馏到小模型中的数据量与性能的关系，发现存在“代码推理谷”现象：随着蒸馏数据量增加，下游任务性能先下降后迅速上升。研究还发现小模型在低中等数据阶段更受益于简单编程题，而训练数据中输出的正确性对蒸馏效果无显著影响。


<details>
  <summary>Details</summary>
Motivation: 尽管知识蒸馏已被证明有效，但模型性能如何随蒸馏数据量变化尚不清楚，尤其是在竞争性编码任务中。本文旨在揭示小模型在代码推理能力蒸馏中的训练动态和 Scaling 规律。

Method: 作者在两个小型非推理LLM上研究不同数量蒸馏数据下的性能变化，通过分析不同阶段的微调表现来识别学习相位，并比较使用简单与困难编程题目以及正确与错误输出数据的影响。

Result: 发现了“代码推理谷”现象：性能随数据量先降后升；小模型在低至中等数据阶段更受益于简单问题；训练数据中输出是否正确对蒸馏结果无显著影响。

Conclusion: 该工作揭示了代码推理知识蒸馏中非直观的训练动态，为小模型在数据有限情况下的高效训练提供了新见解。

Abstract: Distilling the thinking traces of a Large Language Model (LLM) with reasoning
capabilities into a smaller model has been proven effective. Yet, there is a
scarcity of work done on how model performances scale with the quantity of
distillation data. In this work, we study the scaling trend of distilling
competitive coding skills on two small non-reasoning LLMs. We validate the
hypothesis that there is a $\textit{valley of code reasoning}$: downstream
performance on competitive coding first drops as data quantity increases, then
it steadily increases in a sharper-than-log-linear fashion. Having identified
the trend, we further fine-tune the models at two different distillation stages
on the same data to ground conclusions on their respective learning phases. We
learn that across stages in the low and medium-low data regimes, small models
benefit significantly from easier coding questions than from harder ones. We
also find that, surprisingly, the correctness of outputs in training data makes
no difference to distillation outcomes. Our work represents a step forward in
understanding the training dynamics of code reasoning distillation outside
intuition

</details>


### [158] [Distributional Semantics Tracing: A Framework for Explaining Hallucinations in Large Language Models](https://arxiv.org/abs/2510.06107)
*Gagan Bhatia,Somayajulu G Sripada,Kevin Allan,Jacobo Azcona*

Main category: cs.CL

TL;DR: 本论文提出了一种名为分布语义追踪（DST）的新框架，用以分析大语言模型幻觉的内在机制，发现幻觉在特定“承诺层”变得不可避免，并揭示了由快速联想路径与慢速上下文路径冲突导致的可预测失败模式。


<details>
  <summary>Details</summary>
Motivation: 大语言模型容易产生事实错误的幻觉，现有研究多关注外部纠错，缺乏对模型内部架构层面根本成因的理解。本文旨在从模型内部语义表示和推理路径出发，揭示幻觉产生的机制性根源。

Method: 提出Distributional Semantics Tracing（DST）框架，结合可解释性技术追踪模型内部语义演变；通过因果推理识别导致幻觉的“承诺层”；引入双过程理论视角，分析快速联想路径与慢速上下文路径之间的冲突机制，并量化上下文路径的一致性与幻觉率的相关性。

Result: 成功定位到模型中幻觉变得不可避免的特定“承诺层”；发现了联想路径劫持上下文路径的‘推理捷径劫持’现象；上下文路径一致性与幻觉率呈强负相关（ρ = -0.863），表明幻觉是内部语义薄弱的可预测结果。

Conclusion: 幻觉并非随机错误，而是Transformer架构中语义表示退化的系统性结果；DST框架为理解、预测和缓解幻觉提供了可解释的机制路径，建议未来模型设计应增强上下文路径并抑制不良联想干扰。

Abstract: Large Language Models (LLMs) are prone to hallucination, the generation of
plausible yet factually incorrect statements. This work investigates the
intrinsic, architectural origins of this failure mode through three primary
contributions.First, to enable the reliable tracing of internal semantic
failures, we propose \textbf{Distributional Semantics Tracing (DST)}, a unified
framework that integrates established interpretability techniques to produce a
causal map of a model's reasoning, treating meaning as a function of context
(distributional semantics). Second, we pinpoint the model's layer at which a
hallucination becomes inevitable, identifying a specific \textbf{commitment
layer} where a model's internal representations irreversibly diverge from
factuality. Third, we identify the underlying mechanism for these failures. We
observe a conflict between distinct computational pathways, which we interpret
using the lens of dual-process theory: a fast, heuristic \textbf{associative
pathway} (akin to System 1) and a slow, deliberate \textbf{contextual pathway}
(akin to System 2), leading to predictable failure modes such as
\textit{Reasoning Shortcut Hijacks}. Our framework's ability to quantify the
coherence of the contextual pathway reveals a strong negative correlation
($\rho = -0.863$) with hallucination rates, implying that these failures are
predictable consequences of internal semantic weakness. The result is a
mechanistic account of how, when, and why hallucinations occur within the
Transformer architecture.

</details>


### [159] [Parallel Tokenizers: Rethinking Vocabulary Design for Cross-Lingual Transfer](https://arxiv.org/abs/2510.06128)
*Muhammad Dehan Al Kautsar,Fajri Koto*

Main category: cs.CL

TL;DR: 提出并行分词器框架，通过双语词典对齐多语言词汇表，使语义相同的词在不同语言中具有统一的表示，提升低资源语言下的跨语言迁移效果。


<details>
  <summary>Details</summary>
Motivation: 现有分词方法常将语义相同的跨语言词汇映射为不同嵌入，阻碍了有效的跨语言迁移，尤其是在低资源语言中表现更差。

Method: 分别对各语言独立训练单语分词器，然后利用双语词典或词对词翻译，对不同语言的词汇表进行完全对齐，确保语义等价词共享相同的词汇索引。

Result: 在13种低资源语言上从头预训练Transformer编码器，并在情感分析、仇恨言论检测、情感分类和句子相似度任务中优于传统多语言基线模型。

Conclusion: 重新设计分词方式对提升多语言表示学习至关重要，并行分词器通过构建共享语义空间显著增强了跨语言泛化能力，尤其适用于低资源语言场景。

Abstract: Tokenization defines the foundation of multilingual language models by
determining how words are represented and shared across languages. However,
existing methods often fail to support effective cross-lingual transfer because
semantically equivalent words are assigned distinct embeddings. For example, "I
eat rice" in English and "Ina cin shinkafa" in Hausa are typically mapped to
different vocabulary indices, preventing shared representations and limiting
cross-lingual generalization. We introduce parallel tokenizers. This new
framework trains tokenizers monolingually and then aligns their vocabularies
exhaustively using bilingual dictionaries or word-to-word translation, ensuring
consistent indices for semantically equivalent words. This alignment enforces a
shared semantic space across languages while naturally improving fertility
balance. To assess their effectiveness, we pretrain a transformer encoder from
scratch on thirteen low-resource languages and evaluate it on sentiment
analysis, hate speech detection, emotion classification, and sentence embedding
similarity. Across all tasks, models trained with parallel tokenizers
outperform conventional multilingual baselines, confirming that rethinking
tokenization is essential for advancing multilingual representation
learning--especially in low-resource settings.

</details>


### [160] [CreditDecoding: Accelerating Parallel Decoding in Diffusion Large Language Models with Trace Credits](https://arxiv.org/abs/2510.06133)
*Kangyu Wang,Zhiyun Jiang,Haibo Feng,Weijia Zhao,Lin Liu,Jianguo Li,Zhenzhong Lan,Weiyao Lin*

Main category: cs.CL

TL;DR: 提出了一种名为CreditDecoding的无需训练的并行解码算法，通过引入Trace Credit概念加速扩散大语言模型的解码过程，显著减少冗余迭代，在多个基准上实现显著加速和性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有扩散语言模型（dLLMs）在生成文本时因重复重掩码低置信度词元导致冗余迭代，限制了解码效率，亟需一种减少冗余、提升收敛速度的方法。

Method: 通过分析dLLM解码轨迹，提出Trace Credit概念，累积词元的历史logits以衡量其收敛潜力；在此基础上设计CreditDecoding算法，将当前logits与Trace Credit融合，加速正确但低置信词元的置信度收敛，实现高效并行解码。

Result: 在八个基准测试中，CreditDecoding相比LLaDA-8B-Instruct实现5.48倍加速和0.48性能提升，相比LLaDA-MoE-Instruct实现4.11倍加速和0.15性能提升，且在长序列上具有良好可扩展性。

Conclusion: CreditDecoding是一种高效、无需训练的并行解码方法，能有效减少dLLM中的冗余迭代，提升解码速度与性能，且可与其他推理优化技术正交，易于集成。

Abstract: Diffusion large language models (dLLMs) generate text through iterative
denoising steps, achieving parallel decoding by denoising only high-confidence
positions at each step. However, existing approaches often repetitively remask
tokens due to initially low confidence scores, leading to redundant iterations
and limiting overall acceleration. Through the analysis of dLLM decoding
traces, we observe that the model often determines the final prediction for a
token several steps before the decoding step. To leverage this historical
information and avoid redundant steps, we introduce the concept of Trace
Credit, which quantifies each token's convergence potential by accumulating
historical logits. Furthermore, we propose CreditDecoding, a training-free
parallel decoding algorithm that accelerates the confidence convergence of
correct but underconfident tokens by fusing current logits with Trace Credit.
This process significantly reduces redundant iterations and enhances decoding
robustness. On eight benchmarks, CreditDecoding achieves a 5.48 times speedup
and a 0.48 performance improvement over LLaDA-8B-Instruct, and a 4.11 times
speedup with a 0.15 performance improvement over LLaDA-MoE-Instruct.
Importantly, CreditDecoding scales effectively to long sequences and is
orthogonal to mainstream inference optimizations, making it a readily
integrable and versatile solution.

</details>


### [161] [RoSE: Round-robin Synthetic Data Evaluation for Selecting LLM Generators without Human Test Sets](https://arxiv.org/abs/2510.06143)
*Jan Cegin,Branislav Pecher,Ivan Srba,Jakub Simko*

Main category: cs.CL

TL;DR: 提出RoSE方法，通过训练小模型并交叉评估不同LLM生成的合成数据，无需人工标注即可有效选择最优LLM生成器。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言中，人工标注数据稀缺，需依赖LLM生成合成数据；但如何选择最适合训练下游模型的LLM生成器仍具挑战。

Method: 提出RoSE：训练小模型使用某一候选LLM生成的数据，并在其他候选LLM生成的数据上进行评估；最终得分为交叉评估的平均性能。

Result: 在6个LLM、11种语言和3项任务上，RoSE比现有内部指标更频繁地选出最优生成器，性能接近最优基准仅差0.76个百分点，且是唯一与人工测试集表现正相关的指标。

Conclusion: RoSE是一种有效且无需人工标注的LLM生成器选择代理指标，尤其适用于低资源语言场景。

Abstract: LLMs are powerful generators of synthetic data, which are used for training
smaller, specific models. This is especially valuable for low-resource
languages, where human-labelled data is scarce but LLMs can still produce
high-quality text. However, LLMs differ in how useful their outputs are for
training. Selecting the best LLM as a generator is challenging because
extrinsic evaluation requires costly human annotations (which are often
unavailable for low-resource languages), while intrinsic metrics correlate
poorly with downstream performance. We introduce Round robin Synthetic data
Evaluation (RoSE), a proxy metric for selecting the best LLM generator without
human test sets. RoSE trains a small model on the outputs of a candidate
generator (LLM) and then evaluates it on generated synthetic examples from all
other candidate LLMs. The final RoSE score is the mean performance of this
small model. Across six LLMs, eleven languages, and three tasks (sentiment,
topic, intent), RoSE identifies the optimal generator more often than any other
intrinsic heuristics. RoSE outperforms intrinsic heuristics and comes within
0.76 percentage points of the optimal generator baseline. This result is
measured in terms of downstream performance, obtained by training a small model
on the chosen generator's outputs (optimal vs. proxy metric selected) and
evaluating it on human-labelled test data. Additionally, RoSE is the only
metric to achieve a positive correlation with performance on human test data.

</details>


### [162] [VecInfer: Efficient LLM Inference with Low-Bit KV Cache via Outlier-Suppressed Vector Quantization](https://arxiv.org/abs/2510.06175)
*Dingyu Yao,Chenxu Yang,Zhengyang Tong,Zheng Lin,Wei Liu,Jian Luan,Weiping Wang*

Main category: cs.CL

TL;DR: VecInfer是一种新的向量量化方法，通过平滑和Hadamard变换抑制键缓存中的异常值，实现高效KV缓存压缩，在2比特量化下仍保持与全精度相当的性能，显著降低内存开销并提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 大语言模型推理中的KV缓存带来显著内存开销，现有向量量化方法在极低位宽下因键缓存异常值导致性能严重下降，需提高代码本利用率以实现高压缩率下的高效推理。

Method: 提出VecInfer，采用平滑和Hadamard变换抑制键缓存异常值，提升向量量化中代码本的覆盖能力；设计融合计算与反量化操作的优化CUDA内核，减少内存访问开销。

Result: 在长上下文理解和数学推理任务中，VecInfer优于现有量化方法；在Llama-3.1-8B模型上实现最高达2.7倍的大批量自注意力计算加速，以及单批次端到端延迟最高8.3倍的降低，2比特量化下性能接近全精度。

Conclusion: VecInfer通过异常值抑制和系统优化，实现了高压缩比下的高效KV缓存量化，兼顾性能与推理效率，适合长序列场景下的大模型部署。

Abstract: The Key-Value (KV) cache introduces substantial memory overhead during large
language model (LLM) inference. Although existing vector quantization (VQ)
methods reduce KV cache usage and provide flexible representational capacity
across bit-widths, they suffer severe performance degradation at ultra-low
bit-widths due to key cache outliers that hinder effective codebook
utilization. To address this challenge, we propose VecInfer, a novel VQ method
for aggressive KV cache compression while enabling efficient inference. By
applying smooth and Hadamard transformations, VecInfer suppresses outliers in
the key cache, enabling the codebook to comprehensively cover the original data
distribution and thereby reducing quantization difficulty. To facilitate
efficient deployment, we design an optimized CUDA kernel that fuses computation
with dequantization to minimize memory access overhead. Extensive evaluations
demonstrate that VecInfer consistently outperforms existing quantization
baselines across both long-context understanding and mathematical reasoning
tasks. With only 2-bit quantization, VecInfer achieves performance comparable
to full precision, while delivering up to $\mathbf{2.7\times}$ speedup in
large-batch self-attention computation and $\mathbf{8.3\times}$ reduction in
single-batch end-to-end latency on Llama-3.1-8B with a 196k sequence length.

</details>


### [163] [Mixing Mechanisms: How Language Models Retrieve Bound Entities In-Context](https://arxiv.org/abs/2510.06182)
*Yoav Gur-Arieh,Mor Geva,Atticus Geiger*

Main category: cs.CL

TL;DR: 研究发现语言模型在实体绑定与检索中不仅依赖位置机制，还结合词汇机制和反射机制，提出了一个包含三种机制的因果模型，能以95%的准确率预测下一个词的分布，并在更长、更自然的文本中表现出鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了理解语言模型在复杂上下文中如何有效绑定和检索实体，特别是在位置机制表现不佳的情况下，探索模型使用的其他机制。

Method: 通过对九个模型和十个绑定任务进行大量实验，分析语言模型在不同上下文长度和复杂度下的行为，识别出位置、词汇和反射三种检索机制，并构建一个结合这三种机制的因果模型。

Result: 发现位置机制在上下文中实体增多时变得不可靠，模型会补充使用词汇机制和反射机制；提出的因果模型在预测下一个词分布时达到95%的准确率，并能推广到更长的开放性文本。

Conclusion: 语言模型在实体绑定与检索中采用多种机制协同工作，本研究提供了更完整的机制解释，并验证了其在自然文本中的通用性和鲁棒性。

Abstract: A key component of in-context reasoning is the ability of language models
(LMs) to bind entities for later retrieval. For example, an LM might represent
"Ann loves pie" by binding "Ann" to "pie", allowing it to later retrieve "Ann"
when asked "Who loves pie?" Prior research on short lists of bound entities
found strong evidence that LMs implement such retrieval via a positional
mechanism, where "Ann" is retrieved based on its position in context. In this
work, we find that this mechanism generalizes poorly to more complex settings;
as the number of bound entities in context increases, the positional mechanism
becomes noisy and unreliable in middle positions. To compensate for this, we
find that LMs supplement the positional mechanism with a lexical mechanism
(retrieving "Ann" using its bound counterpart "pie") and a reflexive mechanism
(retrieving "Ann" through a direct pointer). Through extensive experiments on
nine models and ten binding tasks, we uncover a consistent pattern in how LMs
mix these mechanisms to drive model behavior. We leverage these insights to
develop a causal model combining all three mechanisms that estimates next token
distributions with 95% agreement. Finally, we show that our model generalizes
to substantially longer inputs of open-ended text interleaved with entity
groups, further demonstrating the robustness of our findings in more natural
settings. Overall, our study establishes a more complete picture of how LMs
bind and retrieve entities in-context.

</details>


### [164] [RECODE-H: A Benchmark for Research Code Development with Interactive Human Feedback](https://arxiv.org/abs/2510.06186)
*Chunyu Miao,Henry Peng Zou,Yangning Li,Yankai Chen,Yibo Wang,Fangxin Wang,Yifan Li,Wooseong Yang,Bowei He,Xinni Zhang,Dianzhi Yu,Hanchen Yang,Hoang H Nguyen,Yue Zhou,Jie Yang,Jizhou Guo,Wenzhe Fan,Chin-Yuan Yeh,Panpan Meng,Liancheng Fang,Jinhu Qi,Wei-Chieh Huang,Zhengyao Gu,Yuwei Han,Langzhou He,Yuyao Yang,Xue Liu,Irwin King,Philip S. Yu*

Main category: cs.CL

TL;DR: RECODE-H 是一个包含102个任务的新基准，用于通过多轮交互和模拟人类反馈评估大语言模型（LLM）代理在科研代码生成中的表现，同时提出了ReCodeAgent框架以整合反馈进行迭代代码生成。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在生成正确且可执行的科研代码方面能力有限，且多采用单次生成方式，忽略了科研开发中迭代和反馈驱动的实际工作流。因此需要一个更贴近真实科研协作的评估基准和框架。

Method: 提出RECODE-H基准，包含来自论文和代码库的102个任务，配备结构化指令、单元测试和五级反馈层次；设计ReCodeAgent框架，支持基于LLM模拟反馈的多轮迭代代码生成；在多个先进LLM上进行实验评估。

Result: 实验表明，在更丰富的反馈条件下，LLM的表现显著提升；但生成复杂科研代码仍存在挑战。RECODE-H有效反映了真实科研协作场景，ReCodeAgent能有效整合反馈提升代码生成质量。

Conclusion: RECODE-H和ReCodeAgent为构建适应性强、反馈驱动的科研用LLM代理提供了基础，推动LLM在科学计算和研究实现中的应用向更实用、协作的方向发展。

Abstract: Large language models (LLMs) show the promise in supporting scientific
research implementation, yet their ability to generate correct and executable
code remains limited. Existing works largely adopt one-shot settings, ignoring
the iterative and feedback-driven nature of realistic workflows of scientific
research development. To address this gap, we present RECODE-H, a benchmark of
102 tasks from research papers and repositories that evaluates LLM agents
through multi-turn interactions with LLM-simulated human feedback. It includes
structured instructions,unit tests, and a five-level feedback hierarchy to
reflect realistic researcher-agent collaboration. We further present
ReCodeAgent, a framework that integrates feedback into iterative code
generation. Experiments with leading LLMs, including GPT-5, Claude-Sonnet-4,
DeepSeek-V3.1, and Gemini 2.5, show substantial performance gains with richer
feedback, while also highlighting ongoing challenges in the generation of
complex research code. RECODE-H establishes a foundation for developing
adaptive, feedback-driven LLM agents in scientific research implementation

</details>


### [165] [BanglaTalk: Towards Real-Time Speech Assistance for Bengali Regional Dialects](https://arxiv.org/abs/2510.06188)
*Jakir Hasan,Shubhashis Roy Dipta*

Main category: cs.CL

TL;DR: 本文提出了BanglaTalk，首个支持孟加拉语方言的实时语音助手系统，具备低延迟、低带宽特性，并通过方言感知的ASR模型BRDialect显著提升识别性能。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为资源较少且方言差异大的语言，在实时语音助手方面进展有限，现有系统不支持方言且不适合实时应用，亟需一种支持方言并具备高实时性的系统。

Method: 采用客户端-服务器架构，使用RTP协议降低延迟；提出方言感知的ASR模型BRDialect，基于IndicWav2Vec在10种孟加拉方言上微调；系统优化至24 kbps低带宽运行。

Result: 在RegSpeech12数据集上，BRDialect比基线ASR模型性能提升12.41-33.98%；系统平均端到端延迟为4.9秒，支持低带宽运行，适合实时交互。

Conclusion: BanglaTalk实现了对孟加拉多方言的支持，兼顾低延迟与低带宽，提升了语音技术的可及性与包容性，为低资源多方言语言提供了可行的实时语音解决方案。

Abstract: Real-time speech assistants are becoming increasingly popular for ensuring
improved accessibility to information. Bengali, being a low-resource language
with a high regional dialectal diversity, has seen limited progress in
developing such systems. Existing systems are not optimized for real-time use
and focus only on standard Bengali. In this work, we present BanglaTalk, the
first real-time speech assistance system for Bengali regional dialects.
BanglaTalk follows the client-server architecture and uses the Real-time
Transport Protocol (RTP) to ensure low-latency communication. To address
dialectal variation, we introduce a dialect-aware ASR system, BRDialect,
developed by fine-tuning the IndicWav2Vec model in ten Bengali regional
dialects. It outperforms the baseline ASR models by 12.41-33.98% on the
RegSpeech12 dataset. Furthermore, BanglaTalk can operate at a low bandwidth of
24 kbps while maintaining an average end-to-end delay of 4.9 seconds. Low
bandwidth usage and minimal end-to-end delay make the system both
cost-effective and interactive for real-time use cases, enabling inclusive and
accessible speech technology for the diverse community of Bengali speakers.

</details>


### [166] [Latent Speech-Text Transformer](https://arxiv.org/abs/2510.06195)
*Yen-Ju Lu,Yashesh Gaur,Wei Zhou,Benjamin Muller,Jesus Villalba,Najim Dehak,Luke Zettlemoyer,Gargi Ghosh,Mike Lewis,Srinivasan Iyer,Duc Le*

Main category: cs.CL

TL;DR: 提出Latent Speech-Text Transformer (LST)，通过将语音令牌动态聚合成潜在语音块，提升语音-文本模型的预训练效率和表示对齐，实现更优的数据与计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有自回归语音-文本模型因语音令牌序列过长导致计算不平衡，影响模态对齐与扩展性，需提高训练效率和对齐效果。

Method: 引入LST模型，动态聚合语音令牌为潜在语音块，作为高级语义单元与文本对齐，减少计算量并增强多模态对齐能力。

Result: LST在语音到语音和文本到文本任务上均优于基线模型，在计算和数据受限条件下显著提升性能，HellaSwag任务上语音准确率分别提高6.5%和5.3%。

Conclusion: LST通过高效的语音块聚合机制，改善了语音-文本模型的表示学习与扩展性，推动多模态模型的高效训练。

Abstract: Auto-regressive speech-text models are typically pre-trained on a large
number of interleaved sequences of text tokens and raw speech encoded as speech
tokens using vector quantization. These models have demonstrated
state-of-the-art performance in speech-to-speech understanding and generation
benchmarks, together with promising scaling laws, primarily enabled by the
representational alignment between text and speech. Nevertheless, they suffer
from shortcomings, partly owing to the disproportionately longer sequences of
speech tokens in contrast to textual tokens. This results in a large compute
imbalance between modalities during pre-training as well as during inference,
and a potential hindrance to effectively aligning speech and text, ultimately
translating to several orders of magnitude slower scaling laws. We introduce
the Latent Speech-Text Transformer (LST), which makes pre-training speech-text
models more data-efficient by dynamically and inexpensively aggregating speech
tokens into latent speech patches. These patches serve as higher-level units
that can either align with corresponding textual units to aid capability
transfer or even encapsulate common speech sequences like silences to be more
compute-efficient. We show that LST outperforms vanilla approaches on
speech-to-speech as well as text-to-text benchmarks in both data- and
compute-controlled settings, the former indicating more effective
representational alignment and the latter indicating steeper scaling laws for
speech-text models. On HellaSwag story completion, LST achieves 6.5% absolute
gain in speech accuracy under compute-controlled training and 5.3% under
data-controlled training, while also improving text performance. We will
release our models, code, and the evaluation data to facilitate further
research.

</details>


### [167] [Peeking inside the Black-Box: Reinforcement Learning for Explainable and Accurate Relation Extraction](https://arxiv.org/abs/2510.06198)
*Xinyu Guo,Zhengliang Shi,Minglai Yang,Mahdi Rahimi,Mihai Surdeanu*

Main category: cs.CL

TL;DR: 本文提出了CogRE框架，通过认知启发的推理机制和强化学习优化，在关系抽取中同时提升准确性和可解释性，尤其在少样本场景下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统关系抽取缺乏对语言解释的监督，导致模型解释性差、注意力不集中且少样本学习能力弱，本文旨在提升模型的解释质量和一阶性能。

Method: 提出CogRE框架：1）设计受认知科学启发的推理机制，将关系抽取建模为一系列文本处理步骤；2）使用强化学习与新型奖励函数联合优化准确性和解释质量；3）利用大语言模型自动生成高质量关键词词典以引导解释输出。

Result: 在One-shot NYT29数据集上，基于Qwen2.5-15B-Instruct的CogRE达到24.65% F1，超过先前基于推理的方法；引入RL优化后绝对提升+23.46%；人工评估显示解释质量相对提升54%。

Conclusion: CogRE通过结构化推理与强化学习有效提升了关系抽取的准确性与可解释性，尤其在少样本场景下表现出色，验证了认知启发设计与显式优化解释质量的有效性。

Abstract: This paper introduces a framework for relation extraction (RE) that enhances
both accuracy and explainability. The framework has two key components: (i) a
reasoning mechanism that formulates relation extraction as a series of
text-processing steps inspired by cognitive science, and (ii) an optimization
process driven by reinforcement learning (RL) with a novel reward function
designed to improve both task accuracy and explanation quality. We call our
approach CogRE. Our framework addresses the lack of supervision for
language-based explanations in traditional RE by promoting outputs that include
important relation keywords. These keywords are drawn from a high-quality
dictionary that is automatically constructed using an LLM. We evaluate our
approach for the task of one-shot RE using two LLMs and two RE datasets. Our
experiments show that CogRE improves explanation quality by addressing two
common failure patterns in one-shot RE: poor attention focus and limited
one-shot learning capability. For example, our cognitive-structured reasoning
with Qwen2.5-15B-Instruct on One-shot NYT29 achieves 24.65% F1, surpassing
prior reasoning-based designs. Optimizing this approach with RL using our
reward further improves performance by +23.46% (absolute). Finally, human
evaluation shows that our best model generates relational keywords closely
aligned with gold labels, increasing human explanation quality ratings by 54%
(relative).

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [168] [Provable Speech Attributes Conversion via Latent Independence](https://arxiv.org/abs/2510.05191)
*Jonathan Svirsky,Ofir Lindenbaum,Uri Shaham*

Main category: cs.SD

TL;DR: 提出了一种具有理论保证的通用语音属性转换框架，通过非概率自编码器和独立性约束实现可靠、可解释的语音风格转换。


<details>
  <summary>Details</summary>
Motivation: 现有语音风格转换方法多为经验性，缺乏理论基础，难以保证可靠和可解释的控制。本文旨在构建具有理论支持的通用框架。

Method: 基于非概率自编码器架构，引入预测潜在变量与目标可控变量间的独立性约束，实现以观察到的风格变量为条件的信号转换，同时保持内容不变并修改目标属性。

Result: 在说话人身份和情感等语音风格转换任务上验证了方法的有效性和通用性，定量评估结果优于或可比于现有方法。

Conclusion: 所提框架为语音属性转换提供了理论基础和有效实现，具备良好可解释性和跨风格适用性。

Abstract: While signal conversion and disentangled representation learning have shown
promise for manipulating data attributes across domains such as audio, image,
and multimodal generation, existing approaches, especially for speech style
conversion, are largely empirical and lack rigorous theoretical foundations to
guarantee reliable and interpretable control. In this work, we propose a
general framework for speech attribute conversion, accompanied by theoretical
analysis and guarantees under reasonable assumptions. Our framework builds on a
non-probabilistic autoencoder architecture with an independence constraint
between the predicted latent variable and the target controllable variable.
This design ensures a consistent signal transformation, conditioned on an
observed style variable, while preserving the original content and modifying
the desired attribute. We further demonstrate the versatility of our method by
evaluating it on speech styles, including speaker identity and emotion.
Quantitative evaluations confirm the effectiveness and generality of the
proposed approach.

</details>


### [169] [AUREXA-SE: Audio-Visual Unified Representation Exchange Architecture with Cross-Attention and Squeezeformer for Speech Enhancement](https://arxiv.org/abs/2510.05295)
*M. Sajid,Deepanshu Gupta,Yash Modi,Sanskriti Jain,Harshith Jai Surya Ganji,A. Rahaman,Harshvardhan Choudhary,Nasir Saleem,Amir Hussain,M. Tanveer*

Main category: cs.SD

TL;DR: 提出了一种名为AUREXA-SE的音频-视觉语音增强模型，结合双向交叉注意力与Squeezeformer，实现高质量的语音增强。


<details>
  <summary>Details</summary>
Motivation: 为了提升复杂环境下的语音增强效果，充分利用音频与视觉模态的互补信息，解决传统方法在模态融合和时序建模上的局限性。

Method: 采用U-Net结构的1D卷积编码器处理音频，Swin Transformer V2提取视觉特征，通过双向交叉注意力实现深度模态融合，并使用轻量级Squeezeformer堆叠块捕捉时序依赖，最后通过U-Net解码器重建语音波形。

Result: 在多个指标上显著优于噪声基线：STOI达到0.516，PESQ为1.323，SI-SDR为-4.322 dB。

Conclusion: AUREXA-SE通过有效的跨模态融合和时序建模，在音频-视觉语音增强任务中表现出色，具有较强的实用性和推广潜力。

Abstract: In this paper, we propose AUREXA-SE (Audio-Visual Unified Representation
Exchange Architecture with Cross-Attention and Squeezeformer for Speech
Enhancement), a progressive bimodal framework tailored for audio-visual speech
enhancement (AVSE). AUREXA-SE jointly leverages raw audio waveforms and visual
cues by employing a U-Net-based 1D convolutional encoder for audio and a Swin
Transformer V2 for efficient and expressive visual feature extraction. Central
to the architecture is a novel bidirectional cross-attention mechanism, which
facilitates deep contextual fusion between modalities, enabling rich and
complementary representation learning. To capture temporal dependencies within
the fused embeddings, a stack of lightweight Squeezeformer blocks combining
convolutional and attention modules is introduced. The enhanced embeddings are
then decoded via a U-Net-style decoder for direct waveform reconstruction,
ensuring perceptually consistent and intelligible speech output. Experimental
evaluations demonstrate the effectiveness of AUREXA-SE, achieving significant
performance improvements over noisy baselines, with STOI of 0.516, PESQ of
1.323, and SI-SDR of -4.322 dB. The source code of AUREXA-SE is available at
https://github.com/mtanveer1/AVSEC-4-Challenge-2025.

</details>


### [170] [Sci-Phi: A Large Language Model Spatial Audio Descriptor](https://arxiv.org/abs/2510.05542)
*Xilin Jiang,Hannes Gamper,Sebastian Braun*

Main category: cs.SD

TL;DR: 本文提出了Sci-Phi，首个能够进行完整声学场景描述的双向空间与频谱编码音频大模型，可同时估计多个声源及环境参数，在合成与真实数据上均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有音频语言模型在声音识别方面表现良好，但由于单通道输入限制了对空间信息的理解，无法全面描述声学场景。因此需要一种能同时理解声音内容与空间属性的模型。

Method: 提出Sci-Phi模型，采用双分支架构，分别处理空间与频谱信息；在超过4000小时的合成一阶Ambisonics数据上进行训练，包含丰富元数据；模型可一键输出最多四个方向性声源、背景声及房间特性参数。

Result: 在包含内容、位置、时间、响度和混响等15项指标下，采用置换不变协议评估表现出色；对不同声源数量、信噪比、混响程度及声学/空间/时间相似混合物均具鲁棒性；仅用合成数据训练即可泛化至真实房间脉冲响应，性能下降轻微。

Conclusion: Sci-Phi是首个实现完整空间声学场景描述的音频大语言模型，具备强实际部署潜力，为真实环境下的音频理解提供了新方向。

Abstract: Acoustic scene perception involves describing the type of sounds, their
timing, their direction and distance, as well as their loudness and
reverberation. While audio language models excel in sound recognition,
single-channel input fundamentally limits spatial understanding. This work
presents Sci-Phi, a spatial audio large language model with dual spatial and
spectral encoders that estimates a complete parameter set for all sound sources
and the surrounding environment. Learning from over 4,000 hours of synthetic
first-order Ambisonics recordings including metadata, Sci-Phi enumerates and
describes up to four directional sound sources in one pass, alongside
non-directional background sounds and room characteristics. We evaluate the
model with a permutation-invariant protocol and 15 metrics covering content,
location, timing, loudness, and reverberation, and analyze its robustness
across source counts, signal-to-noise ratios, reverberation levels, and
challenging mixtures of acoustically, spatially, or temporally similar sources.
Notably, Sci-Phi generalizes to real room impulse responses with only minor
performance degradation. Overall, this work establishes the first audio LLM
capable of full spatial-scene description, with strong potential for real-world
deployment. Demo: https://sci-phi-audio.github.io/demo

</details>


### [171] [Sparse deepfake detection promotes better disentanglement](https://arxiv.org/abs/2510.05696)
*Antoine Teissier,Marie Tahon,Nicolas Dugué,Aghilas Sini*

Main category: cs.SD

TL;DR: 本文提出一种基于稀疏表示的深度伪造语音检测方法，通过在AASIST模型的最后一层使用TopK激活实现高稀疏性，提升检测性能并增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度伪造语音检测需兼顾高效性、鲁棒性与可解释性，尤其需要对模型的潜在表示进行解释以增强可信度。

Method: 聚焦AASIST模型最后一层嵌入，采用受SAE启发的TopK激活方法生成稀疏表示，并用于决策过程。

Result: 在ASVSpoof5测试集上实现23.36%的EER，稀疏度达95%，且稀疏表示在完整性与模块性指标下表现出更优的解耦能力，部分攻击方式被直接编码在潜在空间中。

Conclusion: 稀疏表示不仅能提升深度伪造检测性能，还增强了潜在空间的可解释性与特征解耦能力。

Abstract: Due to the rapid progress of speech synthesis, deepfake detection has become
a major concern in the speech processing community. Because it is a critical
task, systems must not only be efficient and robust, but also provide
interpretable explanations. Among the different approaches for explainability,
we focus on the interpretation of latent representations. In such paper, we
focus on the last layer of embeddings of AASIST, a deepfake detection
architecture. We use a TopK activation inspired by SAEs on this layer to obtain
sparse representations which are used in the decision process. We demonstrate
that sparse deepfake detection can improve detection performance, with an EER
of 23.36% on ASVSpoof5 test set, with 95% of sparsity. We then show that these
representations provide better disentanglement, using completeness and
modularity metrics based on mutual information. Notably, some attacks are
directly encoded in the latent space.

</details>


### [172] [MSF-SER: Enriching Acoustic Modeling with Multi-Granularity Semantics for Speech Emotion Recognition](https://arxiv.org/abs/2510.05749)
*Haoxun Li,Yuqing Sun,Hanlei Shi,Yu Liu,Leyuan Qu,Taihao Li*

Main category: cs.SD

TL;DR: 提出了一种多粒度语义融合方法MSF-SER，通过增强声学特征与多层次文本语义的融合，提升了连续维度情感识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于全局文本的多模态情感识别方法未能捕捉句子中不同词语的强调差异，且缺乏高层语义解释线索，限制了情感识别的精度。

Method: 提出MSF-SER，结合局部强调语义（LES）、全局语义（GS）和扩展语义（ES）三种文本语义层次，通过模态内门控融合和跨模态FiLM调制的轻量级专家混合模型（FM-MOE）与声学特征融合。

Result: 在MSP-Podcast和IEMOCAP数据集上实验表明，MSF-SER在效价、唤醒和主导度预测上均优于现有方法。

Conclusion: 引入多层次语义融合能有效提升连续维度语音情感识别性能，验证了语义丰富性对情感建模的重要性。

Abstract: Continuous dimensional speech emotion recognition captures affective
variation along valence, arousal, and dominance, providing finer-grained
representations than categorical approaches. Yet most multimodal methods rely
solely on global transcripts, leading to two limitations: (1) all words are
treated equally, overlooking that emphasis on different parts of a sentence can
shift emotional meaning; (2) only surface lexical content is represented,
lacking higher-level interpretive cues. To overcome these issues, we propose
MSF-SER (Multi-granularity Semantic Fusion for Speech Emotion Recognition),
which augments acoustic features with three complementary levels of textual
semantics--Local Emphasized Semantics (LES), Global Semantics (GS), and
Extended Semantics (ES). These are integrated via an intra-modal gated fusion
and a cross-modal FiLM-modulated lightweight Mixture-of-Experts (FM-MOE).
Experiments on MSP-Podcast and IEMOCAP show that MSF-SER consistently improves
dimensional prediction, demonstrating the effectiveness of enriched semantic
fusion for SER.

</details>


### [173] [Transcribing Rhythmic Patterns of the Guitar Track in Polyphonic Music](https://arxiv.org/abs/2510.05756)
*Aleksandr Lukoianov,Anssi Klapuri*

Main category: cs.SD

TL;DR: 提出了一种三步框架，用于从流行歌曲中自动转录节奏吉他模式，结合专家标注数据与预训练模型，在多音音乐中实现了高精度、可读的节奏模式识别。


<details>
  <summary>Details</summary>
Motivation: 节奏模式的转录在音乐信息检索中研究较少，尤其对于节奏吉他这类以重复和变化节奏型为主的乐器，缺乏客观的标注标准和有效方法，本文旨在建立一个可靠的节奏转录框架与评估体系。

Method: 提出三步框架：首先通过近似音轨分离提取吉他部分；然后利用预训练基础模型（MERT）检测分离后的吉他音频中的单个扫弦；最后通过模式解码，将扫弦序列映射到专家策划的节奏词汇表中的节奏模式。

Result: 在包含410首流行歌曲的数据集上验证了方法的有效性，能够以较高准确率转录多音音乐中的吉他节奏模式，生成包含小节线和拍号标记的、人类可读的节奏表示，并提出了评估节奏序列准确性和可读性的指标。

Conclusion: 该研究证明了利用专家标注与现代音频模型相结合的方法，可以有效实现节奏吉他的自动节奏转录，为音乐转录领域提供了新的数据集、方法和评估标准。

Abstract: Whereas chord transcription has received considerable attention during the
past couple of decades, far less work has been devoted to transcribing and
encoding the rhythmic patterns that occur in a song. The topic is especially
relevant for instruments such as the rhythm guitar, which is typically played
by strumming rhythmic patterns that repeat and vary over time. However, in many
cases one cannot objectively define a single "right" rhythmic pattern for a
given song section. To create a dataset with well-defined ground-truth labels,
we asked expert musicians to transcribe the rhythmic patterns in 410 popular
songs and record cover versions where the guitar tracks followed those
transcriptions. To transcribe the strums and their corresponding rhythmic
patterns, we propose a three-step framework. Firstly, we perform approximate
stem separation to extract the guitar part from the polyphonic mixture.
Secondly, we detect individual strums within the separated guitar audio, using
a pre-trained foundation model (MERT) as a backbone. Finally, we carry out a
pattern-decoding process in which the transcribed sequence of guitar strums is
represented by patterns drawn from an expert-curated vocabulary. We show that
it is possible to transcribe the rhythmic patterns of the guitar track in
polyphonic music with quite high accuracy, producing a representation that is
human-readable and includes automatically detected bar lines and time signature
markers. We perform ablation studies and error analysis and propose a set of
evaluation metrics to assess the accuracy and readability of the predicted
rhythmic pattern sequence.

</details>


### [174] [EMORL-TTS: Reinforcement Learning for Fine-Grained Emotion Control in LLM-based TTS](https://arxiv.org/abs/2510.05758)
*Haoxun Li,Yu Liu,Yuqing Sun,Hanlei Shi,Leyuan Qu,Taihao Li*

Main category: cs.SD

TL;DR: 提出EMORL-TTS，结合监督微调与强化学习，实现基于LLM的TTS系统中细粒度的情感控制，提升情感准确性、强度区分和重音清晰度。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的TTS系统依赖离散语音标记，难以实现细粒度情感控制，且现有方法受限于分类标签或无法适配LLM架构。

Method: 在VAD空间中统一全局强度控制与局部重音调节，结合监督微调与针对情感类别、强度和重音的任务特定奖励的强化学习。

Result: 实验表明，EMORL-TTS在情感准确性、强度区分和重音清晰度方面均有提升，同时保持与强基线相当的合成质量。

Conclusion: EMORL-TTS有效实现了LLM-TTS中的细粒度情感控制，并揭示了重音位置对情感强度的调制作用。

Abstract: Recent LLM-based TTS systems achieve strong quality and zero-shot ability,
but lack fine-grained emotional control due to their reliance on discrete
speech tokens. Existing approaches either limit emotions to categorical labels
or cannot generalize to LLM-based architectures. We propose EMORL-TTS
(Fine-grained Emotion-controllable TTS with Reinforcement Learning), a
framework that unifies global intensity control in the VAD space with local
emphasis regulation. Our method combines supervised fine-tuning with
reinforcement learning guided by task-specific rewards for emotion category,
intensity, and emphasis. Moreover, we further investigate how emphasis
placement modulates fine-grained emotion intensity. Experiments show that
EMORL-TTS improves emotion accuracy, intensity differentiation, and emphasis
clarity, while preserving synthesis quality comparable to strong LLM-based
baselines.

</details>


### [175] [StereoSync: Spatially-Aware Stereo Audio Generation from Video](https://arxiv.org/abs/2510.05828)
*Christian Marinoni,Riccardo Fosco Gramaccioni,Kazuki Shimada,Takashi Shibuya,Yuki Mitsufuji,Danilo Comminiello*

Main category: cs.SD

TL;DR: StereoSync是一种新颖的视频对齐音频生成模型，能够在时间上同步视频并在空间上与视觉内容对齐，利用预训练模型实现高效高质量音频合成。


<details>
  <summary>Details</summary>
Motivation: 现有的音频生成方法主要关注时间同步，缺乏对空间信息的利用，限制了音频的沉浸感和真实感。StereoSync旨在通过引入空间感知来弥补这一不足。

Method: StereoSync从深度图和边界框中提取空间线索，并将其作为交叉注意力条件输入到基于扩散的音频生成模型中，结合预训练基础模型提升效率和生成质量。

Result: 在Walking The Maps数据集上的实验表明，StereoSync在时间和空间对齐方面均优于现有方法，显著提升了生成音频的沉浸感和 realism。

Conclusion: StereoSync推动了视频到音频生成的前沿，首次实现了兼具时间同步和空间对齐的立体声生成，为虚拟现实和游戏等应用提供了更真实的音频体验。

Abstract: Although audio generation has been widely studied over recent years,
video-aligned audio generation still remains a relatively unexplored frontier.
To address this gap, we introduce StereoSync, a novel and efficient model
designed to generate audio that is both temporally synchronized with a
reference video and spatially aligned with its visual context. Moreover,
StereoSync also achieves efficiency by leveraging pretrained foundation models,
reducing the need for extensive training while maintaining high-quality
synthesis. Unlike existing methods that primarily focus on temporal
synchronization, StereoSync introduces a significant advancement by
incorporating spatial awareness into video-aligned audio generation. Indeed,
given an input video, our approach extracts spatial cues from depth maps and
bounding boxes, using them as cross-attention conditioning in a diffusion-based
audio generation model. Such an approach allows StereoSync to go beyond simple
synchronization, producing stereo audio that dynamically adapts to the spatial
structure and movement of a video scene. We evaluate StereoSync on Walking The
Maps, a curated dataset comprising videos from video games that feature
animated characters walking through diverse environments. Experimental results
demonstrate the ability of StereoSync to achieve both temporal and spatial
alignment, advancing the state of the art in video-to-audio generation and
resulting in a significantly more immersive and realistic audio experience.

</details>


### [176] [FoleyGRAM: Video-to-Audio Generation with GRAM-Aligned Multimodal Encoders](https://arxiv.org/abs/2510.05829)
*Riccardo Fosco Gramaccioni,Christian Marinoni,Eleonora Grassucci,Giordano Cicchetti,Aurelio Uncini,Danilo Comminiello*

Main category: cs.SD

TL;DR: FoleyGRAM 是一种基于 Gramian 表示对齐度量（GRAM）的视频到音频生成新方法，通过多模态编码对齐实现语义控制，在 Greatest Hits 数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频到音频生成方法在语义对齐和时间一致性方面存在不足，需要更精确的多模态对齐机制以提升生成音频的语义相关性。

Method: 提出 FoleyGRAM，采用 GRAM 对齐视频、文本和音频模态的嵌入表示，并结合扩散模型与波形包络，实现语义丰富且时间对齐的音频生成。

Result: 在 Greatest Hits 数据集上的实验表明，FoleyGRAM 在语义对齐和生成质量方面优于现有方法，提升了视频到音频合成的性能。

Conclusion: 通过 GRAM 实现的多模态编码对齐能有效增强生成音频与视频内容的语义一致性，为视频到音频生成提供了有效的新范式。

Abstract: In this work, we present FoleyGRAM, a novel approach to video-to-audio
generation that emphasizes semantic conditioning through the use of aligned
multimodal encoders. Building on prior advancements in video-to-audio
generation, FoleyGRAM leverages the Gramian Representation Alignment Measure
(GRAM) to align embeddings across video, text, and audio modalities, enabling
precise semantic control over the audio generation process. The core of
FoleyGRAM is a diffusion-based audio synthesis model conditioned on
GRAM-aligned embeddings and waveform envelopes, ensuring both semantic richness
and temporal alignment with the corresponding input video. We evaluate
FoleyGRAM on the Greatest Hits dataset, a standard benchmark for video-to-audio
models. Our experiments demonstrate that aligning multimodal encoders using
GRAM enhances the system's ability to semantically align generated audio with
video content, advancing the state of the art in video-to-audio synthesis.

</details>


### [177] [LARA-Gen: Enabling Continuous Emotion Control for Music Generation Models via Latent Affective Representation Alignment](https://arxiv.org/abs/2510.05875)
*Jiahao Mei,Xuenan Xu,Zeyu Xie,Zihao Zheng,Ye Tao,Yue Ding,Mengyue Wu*

Main category: cs.SD

TL;DR: LARA-Gen是一种实现文本到音乐生成中连续情感控制的新框架，通过潜在情感表示对齐（LARA）和连续效价-唤醒空间的情感控制模块，实现了对音乐情感的精细调控。


<details>
  <summary>Details</summary>
Motivation: 当前文本到音乐生成模型在细粒度情感控制方面仍存在不足，缺乏有效的情感对齐机制和客观评估基准。

Method: 提出LARA-Gen框架，采用潜在情感表示对齐（LARA）技术将生成模型的隐状态与外部音乐理解模型对齐，并设计基于连续效价-唤醒空间的情感控制模块，分离情感属性与文本内容。同时构建包含测试集和情感预测器的基准用于客观评估。

Result: 实验表明，LARA-Gen在情感贴合度和音乐质量上显著优于基线模型，实现了连续、细粒度的情感控制。提供了生成样本网站以供验证。

Conclusion: LARA-Gen有效解决了文本到音乐生成中的细粒度情感控制问题，为情感可控的音乐生成提供了新的解决方案和评估基准。

Abstract: Recent advances in text-to-music models have enabled coherent music
generation from text prompts, yet fine-grained emotional control remains
unresolved. We introduce LARA-Gen, a framework for continuous emotion control
that aligns the internal hidden states with an external music understanding
model through Latent Affective Representation Alignment (LARA), enabling
effective training. In addition, we design an emotion control module based on a
continuous valence-arousal space, disentangling emotional attributes from
textual content and bypassing the bottlenecks of text-based prompting.
Furthermore, we establish a benchmark with a curated test set and a robust
Emotion Predictor, facilitating objective evaluation of emotional
controllability in music generation. Extensive experiments demonstrate that
LARA-Gen achieves continuous, fine-grained control of emotion and significantly
outperforms baselines in both emotion adherence and music quality. Generated
samples are available at https://nieeim.github.io/LARA-Gen/.

</details>


### [178] [Segment-Factorized Full-Song Generation on Symbolic Piano Music](https://arxiv.org/abs/2510.05881)
*Ping-Yi Chen,Chih-Pin Tan,Yi-Hsuan Yang*

Main category: cs.SD

TL;DR: 提出了一种用于符号化全曲生成的分段全曲模型（SFS），通过将歌曲分段并利用选择性注意力机制生成，提升了生成质量与效率，并开发了支持人机协作的网页应用。


<details>
  <summary>Details</summary>
Motivation: 现有全曲生成模型在长程结构连贯性和生成效率上存在不足，难以满足人机协同创作的需求。

Method: 将歌曲按用户定义的结构分段，引入可选的短种子段落作为主题锚点，通过选择性注意力机制在段落间建立关联并逐段生成。

Result: 模型在生成质量和效率上优于先前方法，并成功集成到支持自定义结构和灵活排序的网页钢琴卷帘界面中，实现人机协同作曲。

Conclusion: SFS模型有效提升了符号音乐生成的结构性与交互性，为AI辅助音乐创作提供了实用工具。

Abstract: We propose the Segmented Full-Song Model (SFS) for symbolic full-song
generation. The model accepts a user-provided song structure and an optional
short seed segment that anchors the main idea around which the song is
developed. By factorizing a song into segments and generating each one through
selective attention to related segments, the model achieves higher quality and
efficiency compared to prior work. To demonstrate its suitability for human-AI
interaction, we further wrap SFS into a web application that enables users to
iteratively co-create music on a piano roll with customizable structures and
flexible ordering.

</details>


### [179] [ECTSpeech: Enhancing Efficient Speech Synthesis via Easy Consistency Tuning](https://arxiv.org/abs/2510.05984)
*Tao Zhu,Yinfeng Yu,Liejun Wang,Fuchun Sun,Wendong Zheng*

Main category: cs.SD

TL;DR: ECTSpeech提出了一种简单有效的单步语音合成框架，首次将易一致性调优（ECT）策略引入语音合成，通过逐步加强一致性约束，在预训练扩散模型上实现高质量单步生成，同时显著降低训练复杂度。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在语音合成中表现出色，但通常需要多步采样，推理效率低。现有方法通过蒸馏到一致性模型实现高效单步生成，但带来额外训练成本且依赖教师模型性能。

Method: 提出ECTSpeech框架，采用易一致性调优（ECT）策略，逐步收紧预训练扩散模型的一致性约束，并设计多尺度门控模块（MSGate）增强去噪器的多尺度特征融合能力。

Result: 在LJSpeech数据集上的实验表明，ECTSpeech在单步采样下实现了与当前最先进方法相当的音频质量，同时显著降低了训练成本和模型复杂度。

Conclusion: ECTSpeech是一种高效、低复杂度的单步语音合成方法，无需额外训练成本或依赖强教师模型，为扩散模型的高效推理提供了新思路。

Abstract: Diffusion models have demonstrated remarkable performance in speech
synthesis, but typically require multi-step sampling, resulting in low
inference efficiency. Recent studies address this issue by distilling diffusion
models into consistency models, enabling efficient one-step generation.
However, these approaches introduce additional training costs and rely heavily
on the performance of pre-trained teacher models. In this paper, we propose
ECTSpeech, a simple and effective one-step speech synthesis framework that, for
the first time, incorporates the Easy Consistency Tuning (ECT) strategy into
speech synthesis. By progressively tightening consistency constraints on a
pre-trained diffusion model, ECTSpeech achieves high-quality one-step
generation while significantly reducing training complexity. In addition, we
design a multi-scale gate module (MSGate) to enhance the denoiser's ability to
fuse features at different scales. Experimental results on the LJSpeech dataset
demonstrate that ECTSpeech achieves audio quality comparable to
state-of-the-art methods under single-step sampling, while substantially
reducing the model's training cost and complexity.

</details>


### [180] [EmoHRNet: High-Resolution Neural Network Based Speech Emotion Recognition](https://arxiv.org/abs/2510.06072)
*Akshay Muppidi,Martin Radfar*

Main category: cs.SD

TL;DR: 本文提出了一种基于高分辨率网络（HRNet）的语音情感识别模型EmoHRNet，通过保持高分辨率表征，有效捕捉语音中的细粒度和全局情感特征，在多个数据集上取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 语音情感识别（SER）对提升人机交互体验至关重要，现有方法在保留语音信号细节方面存在不足，因此需要一种能够同时捕获局部与全局情感信息的高性能模型。

Method: 将语音信号转换为频谱图，采用HRNet架构构建EmoHRNet，该网络在整个前向传播过程中保持高分辨率特征表示，从而更好地提取语音中的多层次情感特征。

Result: EmoHRNet在RAVDESS、IEMOCAP和EMOVO三个主流情感识别数据集上分别达到了92.45%、80.06%和92.77%的准确率，超越了当前领先模型。

Conclusion: EmoHRNet通过保持高分辨率特征表示，在语音情感识别任务中表现出卓越性能，建立了新的基准，验证了其结构在SER任务中的有效性。

Abstract: Speech emotion recognition (SER) is pivotal for enhancing human-machine
interactions. This paper introduces "EmoHRNet", a novel adaptation of
High-Resolution Networks (HRNet) tailored for SER. The HRNet structure is
designed to maintain high-resolution representations from the initial to the
final layers. By transforming audio samples into spectrograms, EmoHRNet
leverages the HRNet architecture to extract high-level features. EmoHRNet's
unique architecture maintains high-resolution representations throughout,
capturing both granular and overarching emotional cues from speech signals. The
model outperforms leading models, achieving accuracies of 92.45% on RAVDESS,
80.06% on IEMOCAP, and 92.77% on EMOVO. Thus, we show that EmoHRNet sets a new
benchmark in the SER domain.

</details>


### [181] [Modulation Discovery with Differentiable Digital Signal Processing](https://arxiv.org/abs/2510.06204)
*Christopher Mitcheltree,Hao Hao Tan,Joshua D. Reiss*

Main category: cs.SD

TL;DR: 提出一种基于神经网络的声⾳匹配⽅法，结合调制提取、约束控制信号参数化和可微数字信号处理（DDSP），⽤于⾃动发现声⾳中的调制结构，具有良好的解释性和⾳频匹配能⼒。


<details>
  <summary>Details</summary>
Motivation: 现有⾳⾊匹配或参数估计系统通常为难以解释的⿊箱，或忽略调制曲线的形状、结构和路由，导致无法有效还原复杂的⾳频调制设计。

Method: 采⽤神经⽹络结合调制提取与约束控制信号参数化的⽅法，利⽤可微数字信号处理（DDSP）实现对声⾳中调制信号的可解释性建模与优化。

Result: 在⾼度调制的合成与真实⾳频样本上验证了⽅法的有效性，适⽤于多种DDSP合成器架构，并在解释性与⾳频匹配精度之间实现了良好权衡。

Conclusion: 该⽅法能有效识别并重建⾳频中的调制结构，提⾼了声⾳设计的可解释性，且代码、⾳频样本和训练好的VST插件均已开源。

Abstract: Modulations are a critical part of sound design and music production,
enabling the creation of complex and evolving audio. Modern synthesizers
provide envelopes, low frequency oscillators (LFOs), and more parameter
automation tools that allow users to modulate the output with ease. However,
determining the modulation signals used to create a sound is difficult, and
existing sound-matching / parameter estimation systems are often
uninterpretable black boxes or predict high-dimensional framewise parameter
values without considering the shape, structure, and routing of the underlying
modulation curves. We propose a neural sound-matching approach that leverages
modulation extraction, constrained control signal parameterizations, and
differentiable digital signal processing (DDSP) to discover the modulations
present in a sound. We demonstrate the effectiveness of our approach on highly
modulated synthetic and real audio samples, its applicability to different DDSP
synth architectures, and investigate the trade-off it incurs between
interpretability and sound-matching accuracy. We make our code and audio
samples available and provide the trained DDSP synths in a VST plugin.

</details>
